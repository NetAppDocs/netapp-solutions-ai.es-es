---
sidebar: sidebar 
permalink: infra/ai-lenovo-train-intro.html 
keywords: tr4810, 4810, introduction, cluster architecture, lenovo, ai 
summary: 'Esta solución se centra en la arquitectura de clúster de nivel de entrada y de rango medio utilizando almacenamiento NetApp y servidores Lenovo optimizados para cargas de trabajo de inteligencia artificial.  Está destinado a equipos pequeños y medianos para los cuales la mayoría de los trabajos de cómputo son de un solo nodo (una o varias GPU) o están distribuidos en unos pocos nodos de cómputo.  Esto no es una limitación importante, porque la mayoría de los trabajos diarios de entrenamiento de IA son de un solo nodo.' 
---
= TR-4810: NetApp AFF A400 con Lenovo ThinkSystem SR670 V2 para entrenamiento de modelos de IA y ML
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


Sathish Thyagarajan, David Arnette, NetApp Mircea Troaca, Lenovo

[role="lead"]
Esta solución presenta una arquitectura de clúster de rango medio que utiliza almacenamiento NetApp y servidores Lenovo optimizados para cargas de trabajo de inteligencia artificial (IA).  Está destinado a empresas de tamaño pequeño a mediano para las que la mayoría de los trabajos de computación son de un solo nodo (una o varias GPU) o están distribuidos en unos pocos nodos de computación.  Esta solución se alinea con la mayoría de los trabajos diarios de capacitación en IA para muchas empresas.

Este documento cubre las pruebas y la validación de una configuración de cómputo y almacenamiento que consta de servidores Lenovo SR670V2 de ocho GPU, un sistema de almacenamiento NetApp AFF A400 de rango medio y un conmutador de interconexión de 100 GbE.  Para medir el rendimiento, utilizamos ResNet50 con el conjunto de datos ImageNet, un tamaño de lote de 408, precisión media, CUDA y cuDNN.  Esta arquitectura proporciona una solución eficiente y rentable para organizaciones pequeñas y medianas que recién comienzan con iniciativas de IA que requieren las capacidades de nivel empresarial del almacenamiento de datos conectado a la nube NetApp ONTAP .



== Público objetivo

Este documento está dirigido a los siguientes públicos:

* Científicos de datos, ingenieros de datos, administradores de datos y desarrolladores de sistemas de IA
* Arquitectos empresariales que diseñan soluciones para el desarrollo de modelos de IA
* Científicos de datos e ingenieros de datos que buscan formas eficientes de lograr objetivos de desarrollo de aprendizaje profundo (DL) y aprendizaje automático (ML)
* Líderes empresariales y tomadores de decisiones de OT/IT que desean lograr el tiempo de comercialización más rápido posible para iniciativas de IA




== Arquitectura de la solución

Esta solución con servidores Lenovo ThinkSystem y NetApp ONTAP con almacenamiento AFF está diseñada para manejar el entrenamiento de IA en grandes conjuntos de datos utilizando la potencia de procesamiento de las GPU junto con las CPU tradicionales.  Esta validación demuestra un alto rendimiento y una gestión óptima de datos con una arquitectura de escalamiento horizontal que utiliza uno, dos o cuatro servidores Lenovo SR670 V2 junto con un único sistema de almacenamiento NetApp AFF A400 .  La siguiente figura proporciona una descripción general de la arquitectura.

image:a400-thinksystem-002.png["Esta imagen muestra un conmutador Ethernet rodeado por el servidor de administración, cuatro SR670 V2 con ocho GPU cada uno y un sistema de almacenamiento NetApp ONTAP ."]

Esta solución de NetApp y Lenovo ofrece los siguientes beneficios clave:

* Rendimiento altamente eficiente y rentable al ejecutar múltiples trabajos de capacitación en paralelo
* Rendimiento escalable basado en diferentes cantidades de servidores Lenovo y diferentes modelos de controladores de almacenamiento NetApp
* Protección de datos robusta para cumplir con objetivos de punto de recuperación (RPO) bajos y objetivos de tiempo de recuperación (RTO) sin pérdida de datos
* Gestión de datos optimizada con instantáneas y clones para agilizar los flujos de trabajo de desarrollo

