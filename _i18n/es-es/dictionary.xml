<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="2b185d63fe43e391e79f2722fa9c01f4" category="summary">Lea blogs de IA/ML que destacan las tendencias de la industria, las innovaciones y el impacto en el mundo real, así como recursos para desarrolladores, conocimientos de la comunidad y herramientas prácticas para trabajar con las soluciones de IA de NetApp .</block>
  <block id="7a206e7f1f7bd7df4f649256e750768b" category="doc">Lea blogs de soluciones de IA de los expertos de NetApp</block>
  <block id="683be49e9105a56d06431bcdc1630cb6" category="paragraph">Lea los blogs de IA/ML que destacan las tendencias de la industria, las innovaciones y el impacto en el mundo real, así como recursos para desarrolladores, conocimientos de la comunidad y herramientas prácticas para trabajar con las soluciones de IA de NetApp .</block>
  <block id="5bbe94ba0a14c52be3cc9534b43f4713" category="paragraph-title">Tendencias de IA y perspectivas de la industria</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">Inglés</block>
  <block id="69501f595c5bd3cdb17ea63c90291622" category="paragraph">Explore las tendencias de la industria, las innovaciones y el impacto de la IA en el mundo real en varios sectores. <block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block> &amp;f:@facet_soultion_mktg=[IA,Analítica,inteligencia artificial]++[Lea blogs de IA en NetApp.com^]</block>
  <block id="d5769d364696d52f17c7b56bd51573f8" category="paragraph-title">Recursos y comunidad para desarrolladores</block>
  <block id="bb765a119d53333b43f301b6a00a388a" category="inline-link-macro">Lea blogs de IA en el Pub</block>
  <block id="43c273574ee7233878bcc9fc0bd893c9" category="paragraph">Información técnica, herramientas prácticas y contenido impulsado por la comunidad para profesionales de IA/ML.<block ref="f89e2ffa35ae5933259a8ae6e49a69ad" category="inline-link-macro-rx"></block></block>
  <block id="e7ee239a021c71c67431ac1c23b9cf1e" category="summary">El artículo proporciona una guía para crear una canalización MLOps con servicios de AWS, centrándose en el reentrenamiento automatizado de modelos, la implementación y la optimización de costos.</block>
  <block id="b77650c231f63812b48a3802736172ae" category="doc">Parte 3: Creación de una canalización de MLOps simplificada (CI/CT/CD)</block>
  <block id="3fc6ea95b9f9aac82c7a39c3743664ba" category="paragraph">Este artículo proporciona una guía para crear una canalización de MLOps con servicios de AWS, centrándose en el reentrenamiento automatizado de modelos, la implementación y la optimización de costos.</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">Introducción</block>
  <block id="4c04d3884cafb85369c7a0a6b81d10b0" category="paragraph">En este tutorial, aprenderá cómo aprovechar varios servicios de AWS para construir una canalización MLOps simple que abarque integración continua (CI), capacitación continua (CT) e implementación continua (CD).  A diferencia de los pipelines DevOps tradicionales, MLOps requiere consideraciones adicionales para completar el ciclo operativo.  Al seguir este tutorial, obtendrá conocimientos sobre cómo incorporar CT en el ciclo MLOps, lo que permitirá el entrenamiento continuo de sus modelos y una implementación perfecta para la inferencia.  El tutorial lo guiará a través del proceso de utilización de los servicios de AWS para establecer esta canalización MLOps de extremo a extremo.</block>
  <block id="76c3e002d3c052bd6a909366a8dc3845" category="section-title">Manifiesto</block>
  <block id="e7e0038bb30579a3120d266861982881" category="cell">Funcionalidad</block>
  <block id="49ee3087348e8d44e1feda1917443987" category="cell">Nombre</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">Comentario</block>
  <block id="dc21b082b0947a93d387b8c7e8f89ee5" category="cell">Almacenamiento de datos</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="cell">AWS FSx ONTAP</block>
  <block id="ae8cde6d64ec0b4ed71f7e4d5a28d65f" category="inline-link-macro">Parte 1: Integración de Amazon FSx for NetApp ONTAP (FSx ONTAP) como un bucket S3 privado en AWS SageMaker</block>
  <block id="273b64842c06632a1f361f1a341b8c24" category="cell">Consulte <block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="4c5f43ed06df4b05c18ca410c7016249" category="cell">IDE de ciencia de datos</block>
  <block id="5a1439989b12745b5a4ed4b944539247" category="cell">AWS SageMaker</block>
  <block id="4c99a9cb175cf27f5edb2b2a9e21f32c" category="inline-link-macro">Parte 2: Aprovechamiento de Amazon FSx for NetApp ONTAP (FSx ONTAP) como fuente de datos para el entrenamiento de modelos en SageMaker</block>
  <block id="077914145dbaab3cc9a1f25998b4b703" category="cell">Este tutorial se basa en el cuaderno Jupyter presentado en<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="e1d9ae96a3cc2d87549ec614a5eea75b" category="cell">Función para activar la canalización MLOps</block>
  <block id="10740b99bf79c58d32e1a8e73062d05c" category="cell">Función AWS Lambda</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="0fc1223c31c6d7d5d233235c0a8f3ee0" category="cell">Desencadenador de trabajo cron</block>
  <block id="0abaf4e46241f987a0b4e6a434e596cd" category="cell">Puente de eventos de AWS</block>
  <block id="e015867873eac103879d29f569610c66" category="cell">Marco de aprendizaje profundo</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="cell">PyTorch</block>
  <block id="6af8c08e3948b664c72a8cc3c2709254" category="cell">SDK de Python de AWS</block>
  <block id="6686853da3491a56c98917cc5c4ddea2" category="cell">boto3</block>
  <block id="4f465e36f699fcf0570d854d9f692508" category="cell">Lenguaje de programación</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="cell">Pitón</block>
  <block id="cd9ec78e2cad962acfcab027dd62d904" category="cell">v3.10</block>
  <block id="925335f81021de4d22fde55ae7f0e86a" category="section-title">Requisito previo</block>
  <block id="368743a79699dd2e9a1db93cb728196a" category="list-text">Un sistema de archivos FSx ONTAP preconfigurado.  Este tutorial utiliza datos almacenados en FSx ONTAP para el proceso de entrenamiento.</block>
  <block id="73d970f5582fe283900cc4b125f71ab0" category="list-text">Una *instancia de SageMaker Notebook* que está configurada para compartir la misma VPC que el sistema de archivos FSx ONTAP mencionado anteriormente.</block>
  <block id="cd201faac7e3cf792faa46c93195c65b" category="list-text">Antes de activar la *función AWS Lambda*, asegúrese de que la *instancia de SageMaker Notebook* esté en estado *detenida*.</block>
  <block id="238f736fdf6bcdcd7f397969fe6eb36e" category="list-text">El tipo de instancia *ml.g4dn.xlarge* es necesario para aprovechar la aceleración de la GPU necesaria para los cálculos de redes neuronales profundas.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="section-title">Arquitectura</block>
  <block id="2c03bdafce7f1816c8faa5db2e5d1258" category="paragraph"><block ref="2c03bdafce7f1816c8faa5db2e5d1258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e320ad9e531a78d8b06272138f0f29b7" category="paragraph">Esta canalización MLOps es una implementación práctica que utiliza un trabajo cron para activar una función sin servidor, que a su vez ejecuta un servicio de AWS registrado con una función de devolución de llamada de ciclo de vida.  *AWS EventBridge* actúa como trabajo cron.  Periódicamente invoca una *función AWS Lambda* responsable de volver a entrenar y reimplementar el modelo.  Este proceso implica poner en marcha la instancia *AWS SageMaker Notebook* para realizar las tareas necesarias.</block>
  <block id="2f53ab942978849d906d82a87554a1e2" category="section-title">Configuración paso a paso</block>
  <block id="ecce3b4394f7f06232bad571a96a0391" category="section-title">Configuraciones del ciclo de vida</block>
  <block id="8482e23b03456ee8ac2760d540c11442" category="paragraph">Para configurar la función de devolución de llamada del ciclo de vida para la instancia de AWS SageMaker Notebook, deberá utilizar *Configuraciones de ciclo de vida*.  Este servicio le permite definir las acciones necesarias que se deben realizar durante el inicio de la instancia del notebook.  Específicamente, se puede implementar un script de shell dentro de las *Configuraciones del ciclo de vida* para apagar automáticamente la instancia del notebook una vez que se hayan completado los procesos de entrenamiento e implementación.  Esta es una configuración obligatoria ya que el costo es una de las principales consideraciones en MLOps.</block>
  <block id="79d14d6493dc1a7a7d33bf031166f9a9" category="paragraph">Es importante tener en cuenta que la configuración para las *Configuraciones del ciclo de vida* debe realizarse con anticipación.  Por lo tanto, se recomienda priorizar la configuración de este aspecto antes de continuar con la configuración del resto del pipeline de MLOps.</block>
  <block id="29beb103651093d4e75530e25a50f4bd" category="list-text">Para configurar un ciclo de vida, abra el panel *Sagemaker* y navegue a *Configuraciones de ciclo de vida* en la sección *Configuraciones de administración*.</block>
  <block id="e40d22b369f011035946ad31f47b655a" category="inline-image-macro">Panel de SageMaker</block>
  <block id="808aecfbb727487113195461863f7b8f" category="paragraph"><block ref="808aecfbb727487113195461863f7b8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706c89d427897aa8c9093c9ea4ddf1cb" category="list-text">Seleccione la pestaña *Instancia de Notebook* y haga clic en el botón *Crear configuración*</block>
  <block id="6d548bb5536b7ca36996b9a2bf7f3fc9" category="inline-image-macro">Página de bienvenida de configuración del ciclo de vida</block>
  <block id="533585f6e9e5ce51a2cd2322d75dfd10" category="paragraph"><block ref="533585f6e9e5ce51a2cd2322d75dfd10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bfce2cb9f46fa7b22c7f04d6aa38b9e" category="list-text">Pegue el siguiente código en el área de entrada.</block>
  <block id="a3c7be0a54a45c8a39d852df0ffe5795" category="list-text">Este script ejecuta Jupyter Notebook, que maneja el reentrenamiento y la redistribución del modelo para la inferencia.  Una vez completada la ejecución, la computadora portátil se apagará automáticamente en 5 minutos.  Para obtener más información sobre el enunciado del problema y la implementación del código, consulte<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="f8d2f79250f54a742eec560a47022213" category="inline-image-macro">Crear configuración de ciclo de vida</block>
  <block id="32868d8eaf16b0e5d6cc389594591fa8" category="paragraph"><block ref="32868d8eaf16b0e5d6cc389594591fa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a835fb020d342258f64fe6be9b11cc29" category="list-text">Después de la creación, navegue a Instancias de Notebook, seleccione la instancia de destino y haga clic en *Actualizar configuración* en el menú desplegable Acciones.</block>
  <block id="386c8dd530ade6b4cdc15f9f6ebad5c4" category="inline-image-macro">Menú desplegable de configuración de actualización</block>
  <block id="c2ba792fac24b100bacf8cb5998dfc1e" category="paragraph"><block ref="c2ba792fac24b100bacf8cb5998dfc1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f80499d713c8d9fe19313ec1dc9bd45" category="list-text">Seleccione la *Configuración de ciclo de vida* creada y haga clic en *Actualizar instancia de notebook*.</block>
  <block id="929b843b11b6f17c62198cd38020bfe6" category="inline-image-macro">Actualizar la configuración del ciclo de vida del notebook</block>
  <block id="e0dc07a964d60792b3ec801e8395ef77" category="paragraph"><block ref="e0dc07a964d60792b3ec801e8395ef77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a0f9cbbefa9b9603cf2241f33621e37" category="section-title">Función sin servidor de AWS Lambda</block>
  <block id="4a799fa8d490fae92d630fe6cc65b928" category="paragraph">Como se mencionó anteriormente, la *función AWS Lambda* es responsable de poner en marcha la *instancia de AWS SageMaker Notebook*.</block>
  <block id="be107f93440a41fcae408e1abec6403e" category="list-text">Para crear una *función AWS Lambda*, navegue al panel correspondiente, cambie a la pestaña *Funciones* y haga clic en *Crear función*.</block>
  <block id="d28550fe1b16be91a51602ddd8c1d60f" category="inline-image-macro">Página de bienvenida de la función lambda de AWS</block>
  <block id="627b95a2fda6260f5df8d487a291ceea" category="paragraph"><block ref="627b95a2fda6260f5df8d487a291ceea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a60f634c6f68222d8abaaa29bd057217" category="list-text">Complete todas las entradas requeridas en la página y recuerde cambiar el tiempo de ejecución a *Python 3.10*.</block>
  <block id="267b7733eb14e4bbd98146ea3f8501b1" category="inline-image-macro">Crear una función lambda de AWS</block>
  <block id="cce551decdf09efb16caf7432d6c7eba" category="paragraph"><block ref="cce551decdf09efb16caf7432d6c7eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bee22bc8ca787cbf1475d27ae7429d6" category="list-text">Verifique que el rol designado tenga el permiso requerido *AmazonSageMakerFullAccess* y haga clic en el botón *Crear función*.</block>
  <block id="3f6a1b36a855303ea55de235a44c52b0" category="inline-image-macro">Seleccionar rol de ejecución</block>
  <block id="fa8e9001a3295e1f7a1f8d3ef3e92572" category="paragraph"><block ref="fa8e9001a3295e1f7a1f8d3ef3e92572" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcc43af2494337ee641b41a13f71fc46" category="list-text">Seleccione la función Lambda creada.  En la pestaña de código, copie y pegue el siguiente código en el área de texto.  Este código inicia la instancia del cuaderno denominada *fsxn-ontap*.</block>
  <block id="c2edd2bdf75433b7f31062be9571f528" category="list-text">Haga clic en el botón *Implementar* para aplicar este cambio de código.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="inline-image-macro">Despliegue</block>
  <block id="64446fff99d978434b172f7c745ece52" category="paragraph"><block ref="64446fff99d978434b172f7c745ece52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9bb44167ffa5f5dc2d30616b32fe21b" category="list-text">Para especificar cómo activar esta función de AWS Lambda, haga clic en el botón Agregar activador.</block>
  <block id="c8d04adc09d32f5c953177228f96826b" category="inline-image-macro">Agregar disparador de función de AWS</block>
  <block id="6297ab474f745fe7abc72cd5f148311b" category="paragraph"><block ref="6297ab474f745fe7abc72cd5f148311b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba138d79283b1a8aad0ef0cc35ce105" category="list-text">Seleccione EventBridge en el menú desplegable, luego haga clic en el botón denominado Crear una nueva regla.  En el campo de expresión de programación, ingrese<block ref="5bb28b828095c4a920fb3d34b89c2b84" prefix=" " category="inline-code"></block> y haga clic en el botón Agregar para crear y aplicar esta nueva regla de trabajo cron a la función AWS Lambda.</block>
  <block id="4ab295fce5805d57b17ce3316bf007fa" category="inline-image-macro">Finalizar disparador</block>
  <block id="46f9833b45661170323abab7808e6219" category="paragraph"><block ref="46f9833b45661170323abab7808e6219" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3643e50ab12ef03d2731f0654366409d" category="paragraph">Después de completar la configuración de dos pasos, diariamente, la *función AWS Lambda* iniciará *SageMaker Notebook*, realizará un reentrenamiento del modelo utilizando los datos del repositorio *FSx ONTAP*, volverá a implementar el modelo actualizado en el entorno de producción y apagará automáticamente la *instancia de SageMaker Notebook* para optimizar los costos.  Esto garantiza que el modelo se mantenga actualizado.</block>
  <block id="0be5bfaeb8f14cd39a235e5050cecbc9" category="paragraph">Con esto concluye el tutorial para desarrollar un pipeline MLOps.</block>
  <block id="fbf39511561166f560c51e6bdf601a0e" category="summary">Esta es la página de introducción a la sección MLOps de FSx ONTAP .</block>
  <block id="28cd7fd0e401ee73677b7f7441149a51" category="doc">Amazon FSx for NetApp ONTAP (FSx ONTAP) para MLOps</block>
  <block id="fba7ee1ae1e1979f64e6e11317d235ff" category="paragraph">Esta sección profundiza en la aplicación práctica del desarrollo de infraestructura de IA y proporciona un tutorial de principio a fin sobre la construcción de una canalización MLOps utilizando FSx ONTAP.  Compuesto por tres ejemplos completos, lo guía para satisfacer sus necesidades de MLOps a través de esta poderosa plataforma de gestión de datos.</block>
  <block id="e2e58416305212ecee9fc44a8a57e389" category="paragraph">Estos artículos se centran en:</block>
  <block id="a4f6db8ee799d71c8436c5d66421c857" category="list-text"><block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block></block>
  <block id="3f7fd29e3ed2add54c00cc8c8501cde7" category="list-text"><block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block></block>
  <block id="71b4f7c054c855f2e85df08fc5e39095" category="list-text"><block ref="71b4f7c054c855f2e85df08fc5e39095" category="inline-link-macro-rx"></block></block>
  <block id="8b34d4c412144b306293274a1964c465" category="paragraph">Al final de esta sección, habrá adquirido una comprensión sólida de cómo utilizar FSx ONTAP para optimizar los procesos de MLOps.</block>
  <block id="f3be583adfbfc01a44597d4c6f7e4ef5" category="summary">Esta publicación proporciona una guía sobre cómo configurar FSx ONTAP como un depósito S3 privado mediante AWS SageMaker.</block>
  <block id="405642837c20faf5ee6d81b4d039206f" category="paragraph">Esta sección proporciona una guía sobre cómo configurar FSx ONTAP como un depósito S3 privado mediante AWS SageMaker.</block>
  <block id="8c52c9bdd7d9ef6a6f82004af97fae7b" category="paragraph">Usando SageMaker como ejemplo, esta página proporciona orientación sobre cómo configurar FSx ONTAP como un depósito S3 privado.</block>
  <block id="69620f6919f430e72c0f67207535605b" category="inline-link-macro">Enlace de vídeo</block>
  <block id="2b6442845e4dd1bf2e9140ac796e1a93" category="paragraph">Para obtener más información sobre FSx ONTAP, consulte esta presentación (<block ref="f781ab67717d91cabffd32c6ef2dd731" category="inline-link-macro-rx"></block> )</block>
  <block id="7a97419a6312bf2f5dcdb87d844f3d07" category="section-title">Guía del usuario</block>
  <block id="2f5513954af7462427835c65fbeeac6d" category="section-title">Creación de servidores</block>
  <block id="aa5fe14483191172e4fb6ae032e063db" category="section-title">Crear una instancia de SageMaker Notebook</block>
  <block id="22a9741b15ba6b8515c1bcf1eb1e2424" category="list-text">Abra la consola de AWS.  En el panel de búsqueda, busque SageMaker y haga clic en el servicio *Amazon SageMaker*.</block>
  <block id="f81ad91c4e9a7e4840e3c7a28ad316cb" category="inline-image-macro">Abrir la consola de AWS</block>
  <block id="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="paragraph"><block ref="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b8d9a34ee98c3b1e7231bdb38a022c7" category="list-text">Abra las *Instancias de Notebook* en la pestaña Notebook, haga clic en el botón naranja *Crear instancia de notebook*.</block>
  <block id="519925d609277093d7d2ace0457f720a" category="inline-image-macro">Consola de instancia de cuaderno de AWS SageMaker</block>
  <block id="d8d17e525889b2a89d32645cb06938f6" category="paragraph"><block ref="d8d17e525889b2a89d32645cb06938f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b070f651df156f54539ea886d6fdb252" category="list-text">En la página de creación, ingrese el *nombre de la instancia de Notebook*, expanda el panel *Red*, deje las demás entradas predeterminadas y seleccione una *VPC*, una *Subred* y *Grupos de seguridad*.  (Esta *VPC* y *Subred* se usarán para crear el sistema de archivos FSx ONTAP más adelante) Haga clic en el botón naranja *Crear instancia de notebook* en la parte inferior derecha.</block>
  <block id="02ca97619a6b22b9a2f189b3ebb82b57" category="inline-image-macro">Crear una instancia de notebook</block>
  <block id="39578328ea9c3b8e5a35ce1c48b45447" category="paragraph"><block ref="39578328ea9c3b8e5a35ce1c48b45447" category="inline-image-macro-rx" type="image"></block></block>
  <block id="08bf44c8870f044a9c29ec0decd4506f" category="section-title">Crear un sistema de archivos FSx ONTAP</block>
  <block id="a0de53cada8c076391cb766a21d191f7" category="list-text">Abra la consola de AWS.  En el panel de búsqueda, busque Fsx y haga clic en el servicio *FSx*.</block>
  <block id="f815343e909cc0c69784c51630a10b2d" category="inline-image-macro">Panel de FSx</block>
  <block id="eb780b87d03905721f4484288ab2cde0" category="paragraph"><block ref="eb780b87d03905721f4484288ab2cde0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55ecf05d044f8d3b179ea6daf134664f" category="list-text">Haga clic en *Crear sistema de archivos*.</block>
  <block id="77d148bb10790640cfe7639dbc11e075" category="inline-image-macro">Crear un sistema de archivos</block>
  <block id="af10909a9067ddaba9079a1b5b37ca6d" category="paragraph"><block ref="af10909a9067ddaba9079a1b5b37ca6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83c8e65862a92cd7eadb9812c8c5f780" category="list-text">Seleccione la primera tarjeta *FSx ONTAP* y haga clic en *Siguiente*.</block>
  <block id="6277f28f413aee819a82e3e0058bc5ee" category="inline-image-macro">Seleccionar el tipo de sistema de archivos</block>
  <block id="03ad22f430d1bae0e9c295ff4191eac1" category="paragraph"><block ref="03ad22f430d1bae0e9c295ff4191eac1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b05d3465523c46c6ece6e36ff05bba" category="list-text">En la página de configuración de detalles.</block>
  <block id="720e4d0907f5f98d25c99b23a410c93c" category="list-text">Seleccione la opción *Creación estándar*.</block>
  <block id="fb23d0162f70b1382f3c50cb5b513f4d" category="inline-image-macro">Crear panel de sistema de archivos</block>
  <block id="69ff48a0fa8eb8c1e7999c1ff581fe73" category="paragraph"><block ref="69ff48a0fa8eb8c1e7999c1ff581fe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bea7f738749e0c476b2d1c016021ec5b" category="list-text">Introduzca el *Nombre del sistema de archivos* y la *Capacidad de almacenamiento SSD*.</block>
  <block id="aad9529851b728c0fb560a0f7d9b8a5b" category="inline-image-macro">Especificar detalles del sistema de archivos</block>
  <block id="1c15f13ef7a0d9e6720f0178a39c5dde" category="paragraph"><block ref="1c15f13ef7a0d9e6720f0178a39c5dde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5db4aeb81b94a1ba5cdcc12c96b36cb1" category="list-text">Asegúrese de utilizar la *VPC* y la *subred* mismas que para la instancia de *SageMaker Notebook*.</block>
  <block id="84e88a3298035d04334f19541c31a16a" category="inline-image-macro">Configuración de red y seguridad</block>
  <block id="3788a93ec701a347dfa0def01330fa09" category="paragraph"><block ref="1832dc909b2a82e8c4b70afb493963cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb695bdcb362931108f41ff0ec65293" category="list-text">Ingrese el nombre de la *máquina virtual de almacenamiento* y *especifique una contraseña* para su SVM (máquina virtual de almacenamiento).</block>
  <block id="691a3c3a3ffee99887addcf66bcceeec" category="inline-image-macro">Configuración de máquina virtual de almacenamiento predeterminada</block>
  <block id="68cc70fed3a17a1a1caec811e0d01f03" category="paragraph"><block ref="68cc70fed3a17a1a1caec811e0d01f03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4c7ba1524cf2b18e8592e9ceb83df71" category="list-text">Deje las demás entradas predeterminadas y haga clic en el botón naranja *Siguiente* en la parte inferior derecha.</block>
  <block id="38f46900c7e5018a4d712fad6dde98ea" category="inline-image-macro">Confirmar configuración</block>
  <block id="c715f26fb866d18303643cfaf886a63c" category="paragraph"><block ref="c715f26fb866d18303643cfaf886a63c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5ce0306761971a734da357efdf9e6f" category="list-text">Haga clic en el botón naranja *Crear sistema de archivos* en la parte inferior derecha de la página de revisión.</block>
  <block id="c0e0aca15b43c5f4360b8e6c8f2451d9" category="inline-image-macro">Revisar la configuración y confirmar la creación</block>
  <block id="29fe6a20d375efc9f6e4ae1a07258da3" category="paragraph"><block ref="29fe6a20d375efc9f6e4ae1a07258da3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c12346192a59739b1315d8d07143db6e" category="list-text">Puede tomar alrededor de *20 a 40 minutos* activar el sistema de archivos FSx.</block>
  <block id="391b09977b768e724f35dad726f1f3ef" category="inline-image-macro">Inspeccionar la consola FSx</block>
  <block id="37f274b71add0d0952db64f7c20abd4f" category="paragraph"><block ref="37f274b71add0d0952db64f7c20abd4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01ecbbb2b353cf4d915bbe1c1cd5505c" category="section-title">Configuración del servidor</block>
  <block id="d36647d06b353fcd6fedc60898e43187" category="section-title">Configuración de ONTAP</block>
  <block id="07afa2af969623c48103624cdb58551c" category="list-text">Abra el sistema de archivos FSx creado.  Asegúrese de que el estado sea *Disponible*.</block>
  <block id="69d4f895c19503f5e9f518c3b74993bb" category="inline-image-macro">Espere la creación del backend</block>
  <block id="a29e057394c30462c97d0a046428ccc6" category="paragraph"><block ref="a29e057394c30462c97d0a046428ccc6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cbcfc771dc80f5ee77c4deba078b135" category="list-text">Seleccione la pestaña *Administración* y conserve la *Dirección IP del punto final de administración* y el *Nombre de usuario del administrador de ONTAP *.</block>
  <block id="a63e6273ab6f9d27c79b63c3e31a3f35" category="inline-image-macro">Consola de detalles del sistema de archivos</block>
  <block id="3a0eb32361b0c7bfba5fc5c8da00fec5" category="paragraph"><block ref="3a0eb32361b0c7bfba5fc5c8da00fec5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0164aebedfb5a99b6386ba01ffbc963" category="list-text">Abra la instancia *SageMaker Notebook* creada y haga clic en *Abrir JupyterLab*.</block>
  <block id="5f42fc26006705fa3b9ffe25fe3d881d" category="inline-image-macro">Consola de instancia de AWS SageMaker Notebook</block>
  <block id="85c4a421924bf2d8fbb4d65b5fcd0317" category="paragraph"><block ref="85c4a421924bf2d8fbb4d65b5fcd0317" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12dbc394c66b065a1aef771f11914dad" category="list-text">En la página de Jupyter Lab, abra una nueva *Terminal*.</block>
  <block id="f3970717b786c14ff186b01681be062f" category="inline-image-macro">Página de bienvenida de Jupyter Lab</block>
  <block id="6774664dc7058399d3db96209da79e83" category="paragraph"><block ref="6774664dc7058399d3db96209da79e83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ad2ec02537c0b93a2b5a7937ea89048" category="list-text">Ingrese el comando ssh ssh &lt;nombre de usuario administrador&gt;@&lt;IP del servidor ONTAP &gt; para iniciar sesión en el sistema de archivos FSx ONTAP .  (El nombre de usuario y la dirección IP se recuperan del paso 2) Utilice la contraseña utilizada al crear la *máquina virtual de almacenamiento*.</block>
  <block id="7d71a86e3b4885ad307f3e18ba62c9cb" category="inline-image-macro">Terminal de Jupyter Lab</block>
  <block id="3907af7edeccc904e748efdec97a698b" category="paragraph"><block ref="3907af7edeccc904e748efdec97a698b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7fe5b2fa5a8ec0c7d2b2e65bce4c302" category="list-text">Ejecute los comandos en el siguiente orden.  Usamos *fsxn-ontap* como nombre para el *nombre del depósito S3 privado de FSx ONTAP *.  Utilice el *nombre de la máquina virtual de almacenamiento* para el argumento *-vserver*.</block>
  <block id="9166665a24ce86a4cdc78ee5dc10b99e" category="inline-image-macro">Salida de terminal de Jupyter Lab</block>
  <block id="f953d25a23501b488d1729dde1bcbfec" category="paragraph"><block ref="f953d25a23501b488d1729dde1bcbfec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09b48d43c330baa7527d4d5b785ddc78" category="list-text">Ejecute los siguientes comandos para recuperar la IP del punto final y las credenciales para FSx ONTAP Private S3.</block>
  <block id="1025c82e986534d7a6a941036fce2afd" category="list-text">Conserve la IP y las credenciales del punto final para uso futuro.</block>
  <block id="8d5111b0ef521165f30cc6043e79b8b4" category="paragraph"><block ref="8d5111b0ef521165f30cc6043e79b8b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb11dcb3b0575af26386e753c028e37d" category="section-title">Configuración del cliente</block>
  <block id="d885926aec2cdf1253c078102968eb8d" category="list-text">En la instancia de SageMaker Notebook, cree un nuevo cuaderno Jupyter.</block>
  <block id="6aa1a9a77e640f5f5edc06a932b6ed8a" category="inline-image-macro">Abrir un nuevo cuaderno Jupyter</block>
  <block id="28f138d5d6604c9e1a6788b166239c3f" category="paragraph"><block ref="28f138d5d6604c9e1a6788b166239c3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e248de3aba6cefa5adacaaee03aaa6e8" category="inline-link-macro">fsxn_demo.ipynb</block>
  <block id="3161057d478204432fe5225e86346e57" category="list-text">Utilice el código siguiente como solución alternativa para cargar archivos al depósito S3 privado de FSx ONTAP .  Para obtener un ejemplo de código completo, consulte este cuaderno.<block ref="5926c62f2c3d59c789081e1f0aff3f08" category="inline-link-macro-rx"></block></block>
  <block id="9c715084d36062c3ee5a47d1e528cd94" category="paragraph">Con esto concluye la integración entre FSx ONTAP y la instancia de SageMaker.</block>
  <block id="6d8aee76fb8c09877162ad6d9e5fdac9" category="section-title">Lista de verificación de depuración útil</block>
  <block id="c00ea068fc81a9c0fcad0e38fbc7bb94" category="list-text">Asegúrese de que la instancia de SageMaker Notebook y el sistema de archivos FSx ONTAP estén en la misma VPC.</block>
  <block id="2ec57b268e910c39ad70e1b259d09e1a" category="list-text">Recuerde ejecutar el comando *set dev* en ONTAP para establecer el nivel de privilegio en *dev*.</block>
  <block id="5a7d7d5f81481db284cc081576a810b0" category="section-title">Preguntas frecuentes (al 27 de septiembre de 2023)</block>
  <block id="de9370dee0783c12eee2dcba49377c0c" category="paragraph">P: ¿Por qué recibo el error "*Se produjo un error (no implementado) al llamar a la operación CreateMultipartUpload: el comando s3 que solicitó no está implementado*" al cargar archivos en FSx ONTAP?</block>
  <block id="b17f3ba7d3e19cd555784a4d2fd9e51b" category="paragraph">R: Como depósito S3 privado, FSx ONTAP admite la carga de archivos de hasta 100 MB.  Al utilizar el protocolo S3, los archivos de más de 100 MB se dividen en fragmentos de 100 MB y se llama a la función "CreateMultipartUpload".  Sin embargo, la implementación actual de FSx ONTAP Private S3 no admite esta función.</block>
  <block id="89551e14b23206a9d9d14f16530fc28d" category="paragraph">P: ¿Por qué recibo el error "*Se produjo un error (Acceso denegado) al llamar a las operaciones PutObject: Acceso denegado*" al cargar archivos en FSx ONTAP?</block>
  <block id="21ba2b927703c559d6b74e6dbc961ebb" category="paragraph">R: Para acceder al bucket S3 privado de FSx ONTAP desde una instancia de SageMaker Notebook, cambie las credenciales de AWS a las credenciales de FSx ONTAP .  Sin embargo, otorgar permiso de escritura a la instancia requiere una solución alternativa que implica montar el depósito y ejecutar el comando de shell 'chmod' para cambiar los permisos.</block>
  <block id="a713cfa91c4b5642352b00e081eca0ce" category="paragraph">P: ¿Cómo puedo integrar el bucket S3 privado de FSx ONTAP con otros servicios de SageMaker ML?</block>
  <block id="eae99a039ae09d5e28c061d7218d0efb" category="paragraph">R: Lamentablemente, el SDK de servicios de SageMaker no proporciona una manera de especificar el punto final para el bucket S3 privado.  Como resultado, FSx ONTAP S3 no es compatible con servicios de SageMaker como Sagemaker Data Wrangler, Sagemaker Clarify, Sagemaker Glue, Sagemaker Athena, Sagemaker AutoML y otros.</block>
  <block id="7892d93cdad4bcd1c3e8157592ed858e" category="summary">El artículo es un tutorial sobre el uso de Amazon FSx for NetApp ONTAP (FSx ONTAP) para entrenar modelos de PyTorch en SageMaker, específicamente para un proyecto de clasificación de calidad de neumáticos.</block>
  <block id="ecccb638c3da2e33f2ce538fc895233a" category="doc">Parte 2: Aprovechamiento de AWS Amazon FSx for NetApp ONTAP (FSx ONTAP) como fuente de datos para el entrenamiento de modelos en SageMaker</block>
  <block id="ca3ef01192dfa69eac50d8be997f6b51" category="paragraph">Este artículo es un tutorial sobre el uso de Amazon FSx for NetApp ONTAP (FSx ONTAP) para entrenar modelos de PyTorch en SageMaker, específicamente para un proyecto de clasificación de calidad de neumáticos.</block>
  <block id="23851f05df4c2ebe4433cd559cf23e55" category="paragraph">Este tutorial ofrece un ejemplo práctico de un proyecto de clasificación de visión artificial y proporciona experiencia práctica en la creación de modelos de aprendizaje automático que utilizan FSx ONTAP como fuente de datos dentro del entorno de SageMaker.  El proyecto se centra en el uso de PyTorch, un marco de aprendizaje profundo, para clasificar la calidad de los neumáticos basándose en imágenes de neumáticos.  Se enfatiza en el desarrollo de modelos de aprendizaje automático utilizando FSx ONTAP como fuente de datos en Amazon SageMaker.</block>
  <block id="516bec227f44816f7ecc2d58aae01bb2" category="section-title">¿Qué es FSx ONTAP?</block>
  <block id="e586360cf616ba9b2800383d7e36b444" category="paragraph">Amazon FSx ONTAP es de hecho una solución de almacenamiento totalmente administrada ofrecida por AWS.  Aprovecha el sistema de archivos ONTAP de NetApp para proporcionar almacenamiento confiable y de alto rendimiento.  Con soporte para protocolos como NFS, SMB e iSCSI, permite un acceso sin inconvenientes desde diferentes instancias de cómputo y contenedores.  El servicio está diseñado para ofrecer un rendimiento excepcional, garantizando operaciones de datos rápidas y eficientes.  También ofrece alta disponibilidad y durabilidad, garantizando que sus datos permanezcan accesibles y protegidos.  Además, la capacidad de almacenamiento de Amazon FSx ONTAP es escalable, lo que le permite ajustarla fácilmente según sus necesidades.</block>
  <block id="05ec336213c5aa3c3a49c743c5fbad19" category="section-title">Entorno de red</block>
  <block id="9e7ee35cf251304984a47d590762e1d2" category="inline-image-macro">Entorno de red</block>
  <block id="8ebf7b35e6a40f5a75092ae4b590f9d1" category="paragraph"><block ref="8ebf7b35e6a40f5a75092ae4b590f9d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a431daf3a478d96ed5ffc10a4056228" category="paragraph">FSx ONTAP (Amazon FSx ONTAP) es un servicio de almacenamiento de AWS.  Incluye un sistema de archivos que se ejecuta en el sistema NetApp ONTAP y una máquina virtual del sistema (SVM) administrada por AWS que se conecta a él.  En el diagrama proporcionado, el servidor NetApp ONTAP administrado por AWS está ubicado fuera de la VPC.  La SVM actúa como intermediario entre SageMaker y el sistema NetApp ONTAP , recibiendo solicitudes de operación de SageMaker y reenviándolas al almacenamiento subyacente.  Para acceder a FSx ONTAP, SageMaker debe ubicarse dentro de la misma VPC que la implementación de FSx ONTAP .  Esta configuración garantiza la comunicación y el acceso a los datos entre SageMaker y FSx ONTAP.</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="section-title">Acceso a datos</block>
  <block id="70385d02db6379c01d4b7b17101f2004" category="paragraph">En escenarios del mundo real, los científicos de datos normalmente utilizan los datos existentes almacenados en FSx ONTAP para construir sus modelos de aprendizaje automático.  Sin embargo, para fines de demostración, dado que el sistema de archivos FSx ONTAP está inicialmente vacío después de su creación, es necesario cargar manualmente los datos de entrenamiento.  Esto se puede lograr montando FSx ONTAP como un volumen en SageMaker.  Una vez que el sistema de archivos esté montado correctamente, puede cargar su conjunto de datos en la ubicación montada, lo que lo hará accesible para entrenar sus modelos dentro del entorno de SageMaker.  Este enfoque le permite aprovechar la capacidad de almacenamiento y las capacidades de FSx ONTAP mientras trabaja con SageMaker para el desarrollo y entrenamiento de modelos.</block>
  <block id="23ea498668d1fa717fb7cfb600bf3238" category="inline-link-macro">Parte 1: Integración de Amazon FSx for NetApp ONTAP (FSx ONTAP) como un bucket S3 privado en AWS SageMaker</block>
  <block id="95d89db7f4a106e280e1c30cde658610" category="paragraph">El proceso de lectura de datos implica configurar FSx ONTAP como un depósito S3 privado.  Para conocer las instrucciones de configuración detalladas, consulte<block ref="8e7379c67a0724b1a49308a7ae6ac3d5" category="inline-link-macro-rx"></block></block>
  <block id="30eaeebc8f9611f55e018d1dd51789ba" category="section-title">Descripción general de la integración</block>
  <block id="7ffc912d31a398685c5667622bb5ed7f" category="inline-image-macro">Flujo de trabajo de formación</block>
  <block id="29e5f040e75c8e4e628e90efc594e3ef" category="paragraph"><block ref="29e5f040e75c8e4e628e90efc594e3ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da4169484addf29c5d1d35a28a5073fd" category="paragraph">El flujo de trabajo de uso de datos de entrenamiento en FSx ONTAP para crear un modelo de aprendizaje profundo en SageMaker se puede resumir en tres pasos principales: definición del cargador de datos, entrenamiento del modelo e implementación.  En un nivel alto, estos pasos forman la base de un flujo de trabajo MLOps.  Sin embargo, cada paso implica varios subpasos detallados para una implementación integral.  Estos subpasos abarcan varias tareas, como el preprocesamiento de datos, la división del conjunto de datos, la configuración del modelo, el ajuste de hiperparámetros, la evaluación del modelo y la implementación del modelo.  Estos pasos garantizan un proceso exhaustivo y eficaz para crear e implementar modelos de aprendizaje profundo utilizando datos de entrenamiento de FSx ONTAP dentro del entorno de SageMaker.</block>
  <block id="2870e83ec05413b09bc7de07f60f54fa" category="section-title">Integración paso a paso</block>
  <block id="e3364bc8e125077137411ae17c13b771" category="section-title">Loader de datos</block>
  <block id="220b880a3d218e80d8fde5901827649a" category="paragraph">Para entrenar una red de aprendizaje profundo de PyTorch con datos, se crea un cargador de datos para facilitar la alimentación de datos.  El cargador de datos no solo define el tamaño del lote, sino que también determina el procedimiento para leer y preprocesar cada registro dentro del lote.  Al configurar el cargador de datos, podemos gestionar el procesamiento de datos en lotes, lo que permite el entrenamiento de la red de aprendizaje profundo.</block>
  <block id="cc0322e5278f21d6001e3995e46e2810" category="paragraph">El cargador de datos consta de 3 partes.</block>
  <block id="0cee527e2a952dcfca00fb6de192e2a1" category="section-title">Función de preprocesamiento</block>
  <block id="50a46eb952358276ed306b6d88aadc7d" category="paragraph">El fragmento de código anterior demuestra la definición de transformaciones de preprocesamiento de imágenes utilizando el módulo *torchvision.transforms*.  En este tutorial, se crea el objeto de preproceso para aplicar una serie de transformaciones.  En primer lugar, la transformación *ToTensor()* convierte la imagen en una representación tensorial.  Posteriormente, la transformación *Resize((224,224))* redimensiona la imagen a un tamaño fijo de 224x224 píxeles.  Finalmente, la transformación *Normalize()* normaliza los valores del tensor restando la media y dividiéndolos por la desviación estándar a lo largo de cada canal.  Los valores de media y desviación estándar utilizados para la normalización se emplean comúnmente en modelos de redes neuronales preentrenados.  En general, este código prepara los datos de la imagen para su posterior procesamiento o ingreso a un modelo entrenado previamente convirtiéndolos en un tensor, redimensionándolos y normalizando los valores de los píxeles.</block>
  <block id="578a55cb1cfe6e1363a1c73fec7d9c6f" category="section-title">La clase de conjunto de datos de PyTorch</block>
  <block id="7895a195c178ff4c5e59638a3c762dd2" category="paragraph">Esta clase proporciona funcionalidad para obtener el número total de registros en el conjunto de datos y define el método para leer datos para cada registro.  Dentro de la función *__getitem__*, el código utiliza el objeto bucket S3 boto3 para recuperar los datos binarios de FSx ONTAP.  El estilo de código para acceder a datos de FSx ONTAP es similar al de leer datos de Amazon S3.  La explicación siguiente profundiza en el proceso de creación del objeto privado S3 *bucket*.</block>
  <block id="76d805ebfad939474c22611b1a64ec91" category="section-title">FSx ONTAP como repositorio privado de S3</block>
  <block id="3d67de2c700f42063d686e92a37a82aa" category="paragraph">Para leer datos de FSx ONTAP en SageMaker, se crea un controlador que apunta al almacenamiento de FSx ONTAP mediante el protocolo S3.  Esto permite que FSx ONTAP sea tratado como un depósito S3 privado.  La configuración del controlador incluye la especificación de la dirección IP del SVM de FSx ONTAP , el nombre del depósito y las credenciales necesarias.  Para obtener una explicación completa sobre cómo obtener estos elementos de configuración, consulte el documento en<block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="ac5d6406e8dadcbc23e9cf65fe528510" category="paragraph">En el ejemplo mencionado anteriormente, el objeto bucket se utiliza para crear una instancia del objeto de conjunto de datos de PyTorch.  El objeto del conjunto de datos se explicará con más detalle en la sección siguiente.</block>
  <block id="e03717a5c1692689919250506bf382a0" category="section-title">El Loader de datos de PyTorch</block>
  <block id="0c919f2bf87f2c6df41e7bbc52c68d04" category="paragraph">En el ejemplo proporcionado, se especifica un tamaño de lote de 64, lo que indica que cada lote contendrá 64 registros.  Al combinar la clase *Dataset* de PyTorch, la función de preprocesamiento y el tamaño del lote de entrenamiento, obtenemos el cargador de datos para el entrenamiento.  Este cargador de datos facilita el proceso de iteración a través del conjunto de datos en lotes durante la fase de entrenamiento.</block>
  <block id="74415cec8ae4d65c228c7fa8da8eae8a" category="section-title">Entrenamiento de modelos</block>
  <block id="74492eb8210f5168d9ee3eff7524ecde" category="paragraph">Este código implementa un proceso de entrenamiento estándar de PyTorch.  Define un modelo de red neuronal llamado *TyreQualityClassifier* que utiliza capas convolucionales y una capa lineal para clasificar la calidad de los neumáticos.  El bucle de entrenamiento itera sobre lotes de datos, calcula la pérdida y actualiza los parámetros del modelo mediante retropropagación y optimización.  Además, imprime la hora actual, la época, el lote y la pérdida para fines de monitoreo.</block>
  <block id="4d2e185dfba9f3df542300054ad07998" category="section-title">Implementación del modelo</block>
  <block id="6116a0f9a85671aec95cc56a205cf186" category="paragraph">El código guarda el modelo de PyTorch en *Amazon S3* porque SageMaker requiere que el modelo se almacene en S3 para su implementación.  Al cargar el modelo en *Amazon S3*, se vuelve accesible para SageMaker, lo que permite la implementación y la inferencia en el modelo implementado.</block>
  <block id="075e4fb3d67ee1fb4bc39dbc5d72b129" category="paragraph">Este código facilita la implementación de un modelo de PyTorch en SageMaker.  Define un serializador personalizado, *TyreQualitySerializer*, que preprocesa y serializa los datos de entrada como un tensor de PyTorch.  La clase *TyreQualityPredictor* es un predictor personalizado que utiliza el serializador definido y un *JSONDeserializer*.  El código también crea un objeto *PyTorchModel* para especificar la ubicación S3 del modelo, la función IAM, la versión del marco y el punto de entrada para la inferencia.  El código genera una marca de tiempo y construye un nombre de punto final basado en el modelo y la marca de tiempo.  Finalmente, el modelo se implementa utilizando el método de implementación, especificando la cantidad de instancias, el tipo de instancia y el nombre del punto final generado.  Esto permite que el modelo PyTorch se implemente y sea accesible para inferencia en SageMaker.</block>
  <block id="bfc7647fbfe6e589911d2da73377b475" category="section-title">Inferencia</block>
  <block id="99e1766840e675b2dbd8230be049188f" category="paragraph">Este es el ejemplo del uso del punto final implementado para realizar la inferencia.</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">Esta sección resume este documento sobre las soluciones de almacenamiento de NetApp para Apache Spark.</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">Conclusión</block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">En este documento, analizamos la arquitectura de Apache Spark, los casos de uso de los clientes y la cartera de almacenamiento de NetApp en relación con el big data, el análisis moderno y la inteligencia artificial, el aprendizaje automático y el aprendizaje automático.  En nuestras pruebas de validación de rendimiento basadas en herramientas de evaluación comparativa estándar de la industria y la demanda de los clientes, las soluciones NetApp Spark demostraron un rendimiento superior en relación con los sistemas Hadoop nativos.  Una combinación de los casos de uso de clientes y los resultados de rendimiento presentados en este informe pueden ayudarlo a elegir una solución Spark adecuada para su implementación.</block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">Este documento se centra en la arquitectura Apache Spark, los casos de uso de los clientes y la cartera de almacenamiento de NetApp relacionada con el análisis de big data y la inteligencia artificial.  También presenta varios resultados de pruebas utilizando herramientas de inteligencia artificial, aprendizaje automático y aprendizaje profundo estándar de la industria contra un sistema Hadoop típico para que pueda elegir la solución Spark adecuada.</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570: Soluciones de almacenamiento de NetApp para Apache Spark: Arquitectura, casos de uso y resultados de rendimiento</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang, Karthikeyan Nagalingam, NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">Este documento se centra en la arquitectura Apache Spark, los casos de uso de los clientes y la cartera de almacenamiento de NetApp relacionada con el análisis de big data y la inteligencia artificial (IA).  También presenta varios resultados de pruebas utilizando herramientas de inteligencia artificial, aprendizaje automático (ML) y aprendizaje profundo (DL) estándar de la industria contra un sistema Hadoop típico para que pueda elegir la solución Spark adecuada.  Para comenzar, necesita una arquitectura Spark, componentes apropiados y dos modos de implementación (clúster y cliente).</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">Este documento también proporciona casos de uso de clientes para abordar problemas de configuración y analiza una descripción general de la cartera de almacenamiento de NetApp relevante para análisis de big data e IA, ML y DL con Spark.  Luego finalizamos con los resultados de las pruebas derivadas de los casos de uso específicos de Spark y la cartera de soluciones NetApp Spark.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="section-title">Desafíos del cliente</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">Esta sección se centra en los desafíos de los clientes con el análisis de big data y la IA/ML/DL en industrias de crecimiento de datos, como el comercio minorista, el marketing digital, la banca, la fabricación discreta, la fabricación de procesos, el gobierno y los servicios profesionales.</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">Rendimiento impredecible</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">Las implementaciones tradicionales de Hadoop generalmente utilizan hardware básico.  Para mejorar el rendimiento, debe ajustar la red, el sistema operativo, el clúster Hadoop, los componentes del ecosistema como Spark y el hardware.  Incluso si ajusta cada capa, puede ser difícil lograr los niveles de rendimiento deseados porque Hadoop se ejecuta en hardware básico que no fue diseñado para un alto rendimiento en su entorno.</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">Fallos de medios y nodos</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">Incluso en condiciones normales, el hardware comercial es propenso a fallar.  Si falla un disco en un nodo de datos, el maestro Hadoop considera, por defecto, que ese nodo no está en buen estado.  Luego, copia datos específicos de ese nodo a través de la red desde réplicas a un nodo en buen estado.  Este proceso ralentiza los paquetes de red para cualquier trabajo de Hadoop.  Luego, el clúster debe volver a copiar los datos y eliminar los datos sobre replicados cuando el nodo en mal estado vuelva a un estado correcto.</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Dependencia del proveedor de Hadoop</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Los distribuidores de Hadoop tienen su propia distribución de Hadoop con su propia versión, lo que limita al cliente a esas distribuciones.  Sin embargo, muchos clientes requieren soporte para análisis en memoria que no vincule al cliente a distribuciones específicas de Hadoop.  Necesitan la libertad de cambiar distribuciones y aún así llevar consigo sus análisis.</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">Falta de soporte para más de un idioma</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">Los clientes a menudo necesitan soporte para varios idiomas además de los programas Java MapReduce para ejecutar sus trabajos.  Opciones como SQL y scripts brindan más flexibilidad para obtener respuestas, más opciones para organizar y recuperar datos y formas más rápidas de mover datos a un marco de análisis.</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">Dificultad de uso</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">Desde hace algún tiempo, la gente se ha quejado de que Hadoop es difícil de usar.  Aunque Hadoop se ha vuelto más simple y más poderoso con cada nueva versión, esta crítica ha persistido.  Hadoop requiere que usted comprenda los patrones de programación Java y MapReduce, un desafío para los administradores de bases de datos y personas con habilidades de programación tradicionales.</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">Marcos y herramientas complicados</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">Los equipos de IA empresariales enfrentan múltiples desafíos.  Incluso con un conocimiento experto en ciencia de datos, las herramientas y los marcos para diferentes ecosistemas de implementación y aplicaciones podrían no ser fácilmente trasladables de uno a otro.  Una plataforma de ciencia de datos debe integrarse perfectamente con las plataformas de big data correspondientes creadas en Spark con facilidad de movimiento de datos, modelos reutilizables, código listo para usar y herramientas que respalden las mejores prácticas para crear prototipos, validar, controlar versiones, compartir, reutilizar e implementar rápidamente modelos en producción.</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">¿Por qué elegir NetApp?</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp puede mejorar su experiencia con Spark de las siguientes maneras:</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">El acceso directo a NFS de NetApp (que se muestra en la figura a continuación) permite a los clientes ejecutar trabajos de análisis de big data en sus datos NFSv3 o NFSv4 existentes o nuevos sin mover ni copiar los datos.  Evita copias múltiples de datos y elimina la necesidad de sincronizar los datos con una fuente.</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">Almacenamiento más eficiente y menos replicación de servidores.  Por ejemplo, la solución NetApp E-Series Hadoop requiere dos en lugar de tres réplicas de los datos, y la solución FAS Hadoop requiere una fuente de datos pero no replicación ni copias de datos.  Las soluciones de almacenamiento de NetApp también producen menos tráfico de servidor a servidor.</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">Mejor comportamiento de los trabajos y clústeres de Hadoop durante fallas de unidades y nodos.</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">Mejor rendimiento en la ingesta de datos.</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">Configuraciones alternativas de Apache Spark.</block>
  <block id="0c0038bcea5bace3c716607bdf5ea55f" category="paragraph"><block ref="0c0038bcea5bace3c716607bdf5ea55f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">Por ejemplo, en el sector financiero y sanitario, el traslado de datos de un lugar a otro debe cumplir obligaciones legales, lo que no es una tarea fácil.  En este escenario, el acceso directo de NetApp NFS analiza los datos financieros y de atención médica desde su ubicación original.  Otro beneficio clave es que el uso del acceso directo NFS de NetApp simplifica la protección de los datos de Hadoop mediante el uso de comandos nativos de Hadoop y la habilitación de flujos de trabajo de protección de datos con la amplia cartera de gestión de datos de NetApp.</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">El acceso directo NFS de NetApp ofrece dos tipos de opciones de implementación para clústeres Hadoop/Spark:</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">De forma predeterminada, los clústeres Hadoop o Spark utilizan el sistema de archivos distribuido Hadoop (HDFS) para el almacenamiento de datos y el sistema de archivos predeterminado.  El acceso directo NFS de NetApp puede reemplazar el HDFS predeterminado con almacenamiento NFS como sistema de archivos predeterminado, lo que permite el análisis directo de datos NFS.</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">En otra opción de implementación, el acceso directo NFS de NetApp admite la configuración de NFS como almacenamiento adicional junto con HDFS en un solo clúster Hadoop o Spark.  En este caso, el cliente puede compartir datos a través de exportaciones NFS y acceder a ellos desde el mismo clúster junto con los datos HDFS.</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">Los beneficios clave de utilizar el acceso directo NFS de NetApp incluyen los siguientes:</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">Analizar los datos desde su ubicación actual, lo que evita la tarea, que consume mucho tiempo y rendimiento, de mover datos analíticos a una infraestructura Hadoop como HDFS.</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">Reducir el número de réplicas de tres a una.</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">Permitir a los usuarios disociar el procesamiento y el almacenamiento para escalarlos de forma independiente.</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">Proporcionar protección de datos empresariales aprovechando las ricas capacidades de gestión de datos de ONTAP.</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Certificación con la plataforma de datos Hortonworks.</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">Habilitación de implementaciones de análisis de datos híbridos.</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">Reducir el tiempo de backup aprovechando la capacidad multihilo dinámico.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="inline-link-macro">TR-4657: Soluciones de datos en la nube híbrida de NetApp : Spark y Hadoop, basadas en casos de uso de clientes</block>
  <block id="c5153856e4d13c48696624c702620995" category="paragraph">Ver<block ref="46ae0631eaa2b1a19769e051f280e3cf" category="inline-link-macro-rx"></block> para realizar copias de seguridad de datos de Hadoop, realizar copias de seguridad y recuperación ante desastres desde la nube a las instalaciones locales, habilitar DevTest en datos de Hadoop existentes, protección de datos y conectividad multicloud, y acelerar las cargas de trabajo de análisis.</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">Las siguientes secciones describen las capacidades de almacenamiento que son importantes para los clientes de Spark.</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">Nivelación de almacenamiento</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Con los niveles de almacenamiento de Hadoop, puede almacenar archivos con diferentes tipos de almacenamiento de acuerdo con una política de almacenamiento.  Los tipos de almacenamiento incluyen<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block> ,<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block> ,<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block> ,<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block> ,<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block> , y<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block> .</block>
  <block id="c2398745386edbb0221cc4ee496ff79f" category="paragraph">Realizamos la validación de la clasificación en niveles del almacenamiento de Hadoop en un controlador de almacenamiento NetApp AFF y un controlador de almacenamiento E-Series con unidades SSD y SAS con diferentes políticas de almacenamiento.  El clúster Spark con AFF-A800 tiene cuatro nodos de trabajo de cómputo, mientras que el clúster con E-Series tiene ocho.  Esto es principalmente para comparar el rendimiento de las unidades de estado sólido (SSD) frente a los discos duros (HDD).</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">La siguiente figura muestra el rendimiento de las soluciones NetApp para un SSD Hadoop.</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">Es hora de ordenar 1 TB de datos.</block>
  <block id="12b6622989087d668bc9d1da31e9fb70" category="paragraph"><block ref="12b6622989087d668bc9d1da31e9fb70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">Solución NetApp E-Series TR-3969 para Hadoop</block>
  <block id="bd9ad8221382748a4f008c3af02731bd" category="list-text">La configuración básica de NL-SAS utilizó ocho nodos de cómputo y 96 unidades NL-SAS.  Esta configuración generó 1 TB de datos en 4 minutos y 38 segundos.  Ver<block ref="264d8d379e3a34fdac32f9057509bf65" category="inline-link-rx"></block> para obtener detalles sobre la configuración del clúster y del almacenamiento.</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">Con TeraGen, la configuración SSD generó 1 TB de datos 15,66 veces más rápido que la configuración NL-SAS.  Además, la configuración SSD utilizó la mitad del número de nodos de cómputo y la mitad del número de unidades de disco (24 unidades SSD en total).  Según el tiempo de finalización del trabajo, fue casi el doble de rápido que la configuración NL-SAS.</block>
  <block id="459f180fc71a8f8bb773d3c879314e39" category="list-text">Con TeraSort, la configuración SSD ordenó 1 TB de datos 1138,36 veces más rápido que la configuración NL-SAS.  Además, la configuración SSD utilizó la mitad del número de nodos de cómputo y la mitad del número de unidades de disco (24 unidades SSD en total).  Por lo tanto, por unidad, fue aproximadamente tres veces más rápido que la configuración NL-SAS.</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">La conclusión es que la transición de los discos giratorios a la tecnología flash mejora el rendimiento.  El número de nodos de cómputo no fue el cuello de botella.  Con el almacenamiento all-flash de NetApp, el rendimiento en tiempo de ejecución escala bien.</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">Con NFS, los datos eran funcionalmente equivalentes a estar agrupados todos juntos, lo que puede reducir la cantidad de nodos de cómputo según su carga de trabajo.  Los usuarios del clúster Apache Spark no tienen que reequilibrar manualmente los datos al cambiar la cantidad de nodos de cómputo.</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">Escalado del rendimiento - Escalamiento horizontal</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">Cuando necesita más potencia de procesamiento de un clúster Hadoop en una solución AFF , puede agregar nodos de datos con una cantidad adecuada de controladores de almacenamiento.  NetApp recomienda comenzar con cuatro nodos de datos por matriz de controlador de almacenamiento y aumentar la cantidad a ocho nodos de datos por controlador de almacenamiento, según las características de la carga de trabajo.</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF y FAS son perfectos para análisis in situ.  Según los requisitos de cálculo, puede agregar administradores de nodos, y las operaciones no disruptivas le permiten agregar un controlador de almacenamiento a pedido sin tiempo de inactividad.  Ofrecemos funciones avanzadas con AFF y FAS, como compatibilidad con medios NVME, eficiencia garantizada, reducción de datos, calidad de servicio, análisis predictivo, niveles de nube, replicación, implementación de nube y seguridad.  Para ayudar a los clientes a satisfacer sus necesidades, NetApp ofrece funciones como análisis del sistema de archivos, cuotas y equilibrio de carga integrado sin costos de licencia adicionales.  NetApp tiene un mejor rendimiento en cantidad de trabajos simultáneos, menor latencia, operaciones más simples y mayor rendimiento de gigabytes por segundo que nuestros competidores.  Además, NetApp Cloud Volumes ONTAP se ejecuta en los tres principales proveedores de nube.</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">Escalado del rendimiento: escalar hacia arriba</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">Las funciones de ampliación le permiten agregar unidades de disco a los sistemas AFF, FAS y E-Series cuando necesita capacidad de almacenamiento adicional.  Con Cloud Volumes ONTAP, escalar el almacenamiento al nivel de PB es una combinación de dos factores: agrupar los datos poco utilizados en el almacenamiento de objetos desde el almacenamiento en bloque y apilar licencias de Cloud Volumes ONTAP sin procesamiento adicional.</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">Múltiples protocolos</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">Los sistemas NetApp admiten la mayoría de los protocolos para implementaciones de Hadoop, incluidos SAS, iSCSI, FCP, InfiniBand y NFS.</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">Soluciones operativas y soportadas</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">proceso de dar un título</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">pareja</block>
  <block id="24cd9f53ddcc21c3360cfbf1ab787373" category="paragraph">Las soluciones Hadoop descritas en este documento son compatibles con NetApp.  Estas soluciones también están certificadas con los principales distribuidores de Hadoop.  Para obtener más información, consulte la<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> sitio y Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> y<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> sitios.</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">Esta sección describe la naturaleza y los componentes de Apache Spark y cómo contribuyen a esta solución.</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="doc">Tecnología de soluciones</block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark es un marco de programación popular para escribir aplicaciones Hadoop que funciona directamente con el sistema de archivos distribuidos Hadoop (HDFS).  Spark está listo para producción, admite el procesamiento de datos de transmisión y es más rápido que MapReduce.  Spark tiene almacenamiento en caché de datos en memoria configurable para una iteración eficiente, y el shell de Spark es interactivo para aprender y explorar datos.  Con Spark, puedes crear aplicaciones en Python, Scala o Java.  Las aplicaciones Spark constan de uno o más trabajos que tienen una o más tareas.</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">Cada aplicación Spark tiene un controlador Spark.  En el modo YARN-Client, el controlador se ejecuta en el cliente localmente.  En el modo YARN-Cluster, el controlador se ejecuta en el clúster en el maestro de aplicaciones.  En el modo de clúster, la aplicación continúa ejecutándose incluso si el cliente se desconecta.</block>
  <block id="5e8f0f670e38fbdf628b0883f946934f" category="inline-image-macro">Figura que muestra el diálogo de entrada/salida o representa contenido escrito</block>
  <block id="bb21b729c47dce20f94160002efec039" category="paragraph"><block ref="bb21b729c47dce20f94160002efec039" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">Hay tres administradores de clúster:</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*Autónomo.*  Este administrador es parte de Spark, lo que facilita la configuración de un clúster.</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">*Mesos Apache.*  Este es un administrador de clúster general que también ejecuta MapReduce y otras aplicaciones.</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">*HILO DE HADOOP.*  Este es un administrador de recursos en Hadoop 3.</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">El conjunto de datos distribuidos resilientes (RDD) es el componente principal de Spark.  RDD recrea los datos perdidos y faltantes a partir de los datos almacenados en la memoria del clúster y almacena los datos iniciales que provienen de un archivo o se crean mediante programación.  Los RDD se crean a partir de archivos, datos en la memoria u otro RDD.  La programación Spark realiza dos operaciones: transformación y acciones.  La transformación crea un nuevo RDD basado en uno existente.  Las acciones devuelven un valor de un RDD.</block>
  <block id="1af693ed22a2df92eb5adff8c506d0ef" category="paragraph">Las transformaciones y acciones también se aplican a los conjuntos de datos y marcos de datos de Spark.  Un conjunto de datos es una colección distribuida de datos que proporciona los beneficios de los RDD (tipificación fuerte, uso de funciones lambda) con los beneficios del motor de ejecución optimizado de Spark SQL.  Se puede construir un conjunto de datos a partir de objetos JVM y luego manipularlo mediante transformaciones funcionales (mapa, flatMap, filtro, etc.).  Un DataFrame es un conjunto de datos organizado en columnas con nombre.  Es conceptualmente equivalente a una tabla en una base de datos relacional o un marco de datos en R/Python.  Los DataFrames se pueden construir a partir de una amplia variedad de fuentes, como archivos de datos estructurados, tablas en Hive/HBase, bases de datos externas locales o en la nube, o RDD existentes.</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Las aplicaciones Spark incluyen uno o más trabajos Spark.  Los trabajos ejecutan tareas en ejecutores, y los ejecutores se ejecutan en contenedores YARN.  Cada ejecutor se ejecuta en un solo contenedor y los ejecutores existen durante toda la vida de una aplicación.  Un ejecutor se fija después de que se inicia la aplicación y YARN no redimensiona el contenedor ya asignado.  Un ejecutor puede ejecutar tareas simultáneamente en datos en memoria.</block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">En esta sección se describe quién podría estar interesado en el contenido de esta solución.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="doc">Público objetivo</block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">El mundo del análisis y la ciencia de datos afecta a múltiples disciplinas en TI y negocios:</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">El científico de datos necesita la flexibilidad de utilizar las herramientas y bibliotecas que elija.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">El ingeniero de datos necesita saber cómo fluyen los datos y dónde residen.</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">Un ingeniero de DevOps necesita las herramientas para integrar nuevas aplicaciones de IA y ML en sus canales de CI y CD.</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">Los administradores y arquitectos de la nube deben poder configurar y gestionar recursos de nube híbrida.</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">Los usuarios comerciales quieren tener acceso a aplicaciones de análisis, inteligencia artificial, aprendizaje automático y aprendizaje automático.</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">En este informe técnico, describimos cómo NetApp AFF, E-Series, StorageGRID, acceso directo NFS, Apache Spark, Horovod y Keras ayudan a cada uno de estos roles a aportar valor al negocio.</block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">Utilizamos los scripts TeraSort y TeraValidate en la herramienta de evaluación comparativa TeraGen para medir la validación del rendimiento de Spark con configuraciones E5760, E5724 y AFF-A800.  Además, se probaron tres casos de uso principales: pipelines de Spark NLP y capacitación distribuida de TensorFlow, capacitación distribuida de Horovod y aprendizaje profundo de múltiples trabajadores usando Keras para predicción de CTR con DeepFM.</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">Resultados de las pruebas</block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">Utilizamos los scripts TeraSort y TeraValidate en la herramienta de evaluación comparativa TeraGen para medir la validación del rendimiento de Spark con configuraciones E5760, E5724 y AFF-A800.  Además, se probaron tres casos de uso principales: pipelines de Spark NLP y capacitación distribuida de TensorFlow, capacitación distribuida de Horovod y aprendizaje profundo de múltiples trabajadores usando Keras para predicción de CTR con DeepFM.</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">Para la validación de E-Series y StorageGRID , utilizamos el factor de replicación de Hadoop 2.  Para la validación de AFF , solo utilizamos una fuente de datos.</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">La siguiente tabla enumera la configuración de hardware para la validación del rendimiento de Spark.</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">Tipo</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Nodos de trabajo de Hadoop</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">Tipo de unidad</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">Unidades por nodo</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">Controlador de almacenamiento</block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="cell">SG6060</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">Par único de alta disponibilidad (HA)</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">Par de HA único</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">Unidad de estado sólido</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">La siguiente tabla enumera los requisitos de software.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">Software</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">Versión</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7,9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">Entorno de ejecución de OpenJDK</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">Máquina virtual de servidor OpenJDK de 64 bits</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25,302</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="cell">Git</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">Chispa</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">Flujo de tensor</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">Keras</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">Horovod</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">Análisis del sentimiento financiero</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="inline-link-macro">TR-4910: Análisis de sentimientos de las comunicaciones de los clientes con NetApp AI</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link">Kit de herramientas DataOps de NetApp</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">SDK de NVIDIA Riva</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">Marco del Tao</block>
  <block id="460926218a6b1ab3e124f410ee69f408" category="paragraph">Nosotros publicamos<block ref="d791c48f7898bbaecde983abed6ac7c1" category="inline-link-macro-rx"></block> , en el que se construyó una canalización de IA conversacional de extremo a extremo utilizando<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block> , almacenamiento AFF y sistema NVIDIA DGX.  El pipeline realiza procesamiento de señales de audio por lotes, reconocimiento automático de voz (ASR), aprendizaje por transferencia y análisis de sentimientos aprovechando el kit de herramientas DataOps.<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block> , y el<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block> .  Al ampliar el caso de uso del análisis de sentimientos a la industria de servicios financieros, creamos un flujo de trabajo SparkNLP, cargamos tres modelos BERT para varias tareas de PNL, como el reconocimiento de entidades nombradas, y obtuvimos sentimientos a nivel de oración para las llamadas de ganancias trimestrales de las 10 principales empresas del NASDAQ.</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">El siguiente script<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block> utiliza el modelo FinBERT para procesar transcripciones en HDFS y producir recuentos de sentimientos positivos, neutrales y negativos, como se muestra en la siguiente tabla:</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">La siguiente tabla enumera el análisis de sentimiento a nivel de oración, tras la presentación de resultados, de las 10 principales empresas del NASDAQ de 2016 a 2020.</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">Recuentos y porcentajes de sentimientos</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">Las 10 empresas</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">Amazon</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">Director Ejecutivo</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOOGL</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">Recuentos positivos</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">Conteos neutrales</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">Recuentos negativos</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">Recuentos sin categorizar</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(recuentos totales)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">En términos de porcentajes, la mayoría de las frases pronunciadas por los directores ejecutivos y directores financieros son factuales y, por lo tanto, transmiten un sentimiento neutral.  Durante una conferencia telefónica sobre ganancias, los analistas hacen preguntas que pueden transmitir un sentimiento positivo o negativo.  Vale la pena investigar más a fondo cuantitativamente cómo el sentimiento negativo o positivo afecta los precios de las acciones el mismo día o el siguiente de negociación.</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">La siguiente tabla enumera el análisis de sentimiento a nivel de oración para las 10 principales empresas del NASDAQ, expresado en porcentaje.</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">Porcentaje de sentimiento</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">Positivo</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="doc"></block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06%</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">Neutral</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">Negativo</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92%</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49%</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51%</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42%</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96%</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">Sin categorizar</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27%</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37%</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">En términos del tiempo de ejecución del flujo de trabajo, vimos una mejora significativa de 4,78x<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> modo a un entorno distribuido en HDFS y una mejora adicional del 0,14 % al aprovechar NFS.</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">Como muestra la siguiente figura, el paralelismo de datos y modelos mejoró el procesamiento de datos y la velocidad de inferencia del modelo distribuido de TensorFlow.  La ubicación de datos en NFS produjo un tiempo de ejecución ligeramente mejor porque el cuello de botella del flujo de trabajo es la descarga de modelos previamente entrenados.  Si aumentamos el tamaño del conjunto de datos de transcripciones, la ventaja de NFS es más obvia.</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Tiempo de ejecución del flujo de trabajo de extremo a extremo del análisis de sentimientos de Spark NLP.</block>
  <block id="44ec3b18d4516fc85f1a9789d47bd91c" category="paragraph"><block ref="44ec3b18d4516fc85f1a9789d47bd91c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Entrenamiento distribuido con rendimiento de Horovod</block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="inline-link-macro">Scripts de Python para cada caso de uso principal</block>
  <block id="1bdfd0f4247bc70668e65a97471adcb5" category="paragraph">El siguiente comando produjo información de tiempo de ejecución y un archivo de registro en nuestro clúster Spark usando un solo<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block> nodo con 160 ejecutores cada uno con un núcleo.  La memoria del ejecutor se limitó a 5 GB para evitar errores de falta de memoria.  Ver la sección<block ref="bda46a99ea3f7d5775466396b660e993" category="inline-link-macro-rx"></block> Para obtener más detalles sobre el procesamiento de datos, el entrenamiento del modelo y el cálculo de la precisión del modelo en<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">El tiempo de ejecución resultante con diez épocas de entrenamiento fue el siguiente:</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">Se necesitaron más de 43 minutos para procesar datos de entrada, entrenar un modelo DNN, calcular la precisión y producir puntos de control de TensorFlow y un archivo CSV para los resultados de la predicción.  Limitamos el número de épocas de entrenamiento a 10, que en la práctica suele establecerse en 100 para garantizar una precisión satisfactoria del modelo.  El tiempo de entrenamiento normalmente se escala linealmente con el número de épocas.</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">A continuación, utilizamos los cuatro nodos de trabajo disponibles en el clúster y ejecutamos el mismo script en<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> modo con datos en HDFS:</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">El tiempo de ejecución resultante se mejoró de la siguiente manera:</block>
  <block id="68b0154732e3239041317d0c7d4ac636" category="paragraph">Con el modelo de Horovod y el paralelismo de datos en Spark, vimos una aceleración del tiempo de ejecución de 5,29x<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> versus<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> Modo con diez épocas de entrenamiento.  Esto se muestra en la siguiente figura con las leyendas.<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block> y<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block> .  El entrenamiento del modelo DNN de TensorFlow subyacente se puede acelerar aún más con GPU si están disponibles.  Planeamos realizar estas pruebas y publicar los resultados en un futuro informe técnico.</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">Nuestra siguiente prueba comparó los tiempos de ejecución con datos de entrada que residen en NFS versus HDFS.  El volumen NFS en el AFF A800 se montó en<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block> en los cinco nodos (uno maestro y cuatro trabajadores) de nuestro clúster Spark.  Ejecutamos un comando similar al de las pruebas anteriores, con el<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block> parámetro que ahora apunta al montaje NFS:</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">El tiempo de ejecución resultante con NFS fue el siguiente:</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">Hubo una aceleración adicional de 1,43x, como se muestra en la siguiente figura.  Por lo tanto, con un almacenamiento all-flash de NetApp conectado a su clúster, los clientes disfrutan de los beneficios de la transferencia y distribución rápida de datos para los flujos de trabajo de Horovod Spark, logrando una aceleración de 7,55 veces en comparación con la ejecución en un solo nodo.</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Tiempo de ejecución del flujo de trabajo de Horovod Spark.</block>
  <block id="aab5160a7c41d499723acfc13e430eef" category="paragraph"><block ref="aab5160a7c41d499723acfc13e430eef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">Modelos de aprendizaje profundo para el rendimiento de la predicción de CTR</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">Para los sistemas de recomendación diseñados para maximizar el CTR, es necesario aprender interacciones de características sofisticadas detrás de los comportamientos de los usuarios que se puedan calcular matemáticamente desde el orden bajo hasta el orden alto.  Las interacciones de características de orden bajo y de orden alto deberían ser igualmente importantes para un buen modelo de aprendizaje profundo sin sesgarse hacia una u otra.  Deep Factorization Machine (DeepFM), una red neuronal basada en máquinas de factorización, combina máquinas de factorización para recomendación y aprendizaje profundo para el aprendizaje de características en una nueva arquitectura de red neuronal.</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">Modelos anchos y profundos</block>
  <block id="8a7e0c5a65151889fa193b20e6ea6484" category="paragraph">Aunque las máquinas de factorización convencionales modelan interacciones de características por pares como un producto interno de vectores latentes entre características y teóricamente pueden capturar información de alto orden, en la práctica los profesionales del aprendizaje automático usualmente solo usan interacciones de características de segundo orden debido a la alta complejidad de cálculo y almacenamiento.  Variantes de redes neuronales profundas como la de Google<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> Por otro lado, aprende interacciones de características sofisticadas en una estructura de red híbrida combinando un modelo lineal amplio y un modelo profundo.</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">Hay dos entradas para este modelo amplio y profundo: una para el modelo amplio subyacente y otra para el profundo; la última parte aún requiere ingeniería de características experta y, por lo tanto, hace que la técnica sea menos generalizable a otros dominios.  A diferencia del modelo ancho y profundo, DeepFM se puede entrenar de manera eficiente con características sin procesar sin ninguna ingeniería de características porque su parte ancha y su parte profunda comparten la misma entrada y el vector de incrustación.</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">Scripts de Python para cada caso de uso principal.</block>
  <block id="e78769fdc1aff8f5383517c0dc3ec750" category="paragraph">Primero procesamos el Criteo<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> (11 GB) en un archivo CSV llamado<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> almacenado en un montaje NFS<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block> usando<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> de la sección<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> Dentro de este script, la función<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block> Realiza varios métodos de cadena para eliminar tabulaciones e insertar<block ref="433beb9a090abf694184e96d76b3046d" prefix=" " category="inline-code"></block> como delimitador y<block ref="11b282e345a74511901532f5c84b59ee" prefix=" " category="inline-code"></block> como nueva línea.  Tenga en cuenta que solo necesita procesar el original.<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> una vez, para que el bloque de código se muestre como comentarios.</block>
  <block id="02aeed17192e292b1708094a50785b65" category="paragraph">Para las siguientes pruebas de diferentes modelos DL, utilizamos<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> como archivo de entrada.  En ejecuciones de prueba posteriores, el archivo CSV de entrada se leyó en un Spark DataFrame con un esquema que contenía un campo de<block ref="182ea3b4ea8b947ba1626831aa9debbe" prefix=" " category="inline-code"></block> , características densas de números enteros<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block> , y características dispersas<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block> .  La siguiente<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block> El comando toma un CSV de entrada, entrena los modelos DeepFM con una división del 20 % para la validación cruzada y elige el mejor modelo después de diez épocas de entrenamiento para calcular la precisión de la predicción en el conjunto de prueba:</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">Tenga en cuenta que dado que el archivo de datos<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> Si tiene más de 11 GB, debe establecer un espacio suficiente<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block> mayor que el tamaño del conjunto de datos para evitar errores.</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Flecha apache</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">En lo anterior<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block> configuración que también habilitamos<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block> , que convierte un Spark DataFrame en un Pandas DataFrame con el<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block> método.</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">Después de la división aleatoria, hay más de 36 millones de filas en el conjunto de datos de entrenamiento y 9 millones de muestras en el conjunto de prueba:</block>
  <block id="a390a463e93dd87edffb2c8b23242507" category="paragraph">Debido a que este informe técnico se centra en las pruebas de CPU sin utilizar ninguna GPU, es imperativo que cree TensorFlow con los indicadores de compilador adecuados.  Este paso evita invocar bibliotecas aceleradas por GPU y aprovecha al máximo las extensiones vectoriales avanzadas (AVX) y las instrucciones AVX2 de TensorFlow.  Estas características están diseñadas para cálculos algebraicos lineales como suma vectorizada, multiplicaciones de matrices dentro de un entrenamiento DNN de propagación hacia adelante o hacia atrás.  La instrucción FMA (Multiplicación y Suma Fusionada) disponible con AVX2 que utiliza registros de punto flotante (FP) de 256 bits es ideal para códigos enteros y tipos de datos, lo que da como resultado una aceleración de hasta 2x.  Para los tipos de datos y códigos FP, AVX2 logra una aceleración del 8 % con respecto a AVX.</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">Bazel</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">Para crear TensorFlow desde la fuente, NetApp recomienda usar<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block> .  Para nuestro entorno, ejecutamos los siguientes comandos en el indicador de shell para instalar<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block> ,<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block> y Bazel.</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">Debe habilitar GCC 5 o una versión más reciente para usar las características de C++17 durante el proceso de compilación, que proporciona RHEL con la Biblioteca de colecciones de software (SCL).  Los siguientes comandos instalan<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block> y GCC 11.2.1 en nuestro clúster RHEL 7.9:</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">artículo</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">Tenga en cuenta que los dos últimos comandos habilitan<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block> , que utiliza<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block> (CCG 11.2.1).  Además, asegúrese de que su<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> La versión es mayor que 1.8.3 (viene con RHEL 7.9).  Consulte esto<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> para actualizar<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> a 2.24.1.</block>
  <block id="ba89c701879ec1f07e28185e3446d252" category="inline-link-macro">Scripts de Python para cada caso de uso principal,</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="inline-link">CUDA</block>
  <block id="e63cc75a56452201d199b8b0694ad9c1" category="paragraph">Suponemos que ya ha clonado el último repositorio maestro de TensorFlow.  Luego crea un<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block> directorio con un<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block> archivo para compilar TensorFlow desde la fuente con AVX, AVX2 y FMA.  Ejecutar el<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block> archivo y especifique la ubicación binaria de Python correcta.<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> está deshabilitado para nuestras pruebas porque no usamos una GPU.  A<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> El archivo se genera según su configuración.  Además, editamos el archivo y lo configuramos.<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block> para habilitar la compatibilidad con HDFS.  Referirse a<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> en la sección<block ref="f76831928c99e33a4e51e1e38bb9ab3c" category="inline-link-macro-rx"></block> para obtener una lista completa de configuraciones y banderas.</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">Después de crear TensorFlow con los indicadores correctos, ejecute el siguiente script para procesar el conjunto de datos de anuncios de Criteo Display, entrenar un modelo DeepFM y calcular el área bajo la curva característica operativa del receptor (ROC AUC) a partir de los puntajes de predicción.</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">Después de diez épocas de entrenamiento, obtuvimos la puntuación AUC en el conjunto de datos de prueba:</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">De manera similar a los casos de uso anteriores, comparamos el tiempo de ejecución del flujo de trabajo de Spark con datos que residen en diferentes ubicaciones.  La siguiente figura muestra una comparación de la predicción de CTR de aprendizaje profundo para un tiempo de ejecución de flujos de trabajo de Spark.</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Comparación de la predicción de CTR de aprendizaje profundo para un tiempo de ejecución de flujos de trabajo de Spark.</block>
  <block id="f68ffbfae290c4d8a7f8381ad0cad4ff" category="paragraph"><block ref="f68ffbfae290c4d8a7f8381ad0cad4ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">En esta página se describen las diferentes áreas en las que se puede utilizar esta solución.</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">Resumen del caso de uso</block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">Transmisión de datos</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark puede procesar datos de streaming, que se utilizan para procesos de extracción, transformación y carga (ETL) de streaming, enriquecimiento de datos, detección de eventos de activación y análisis de sesiones complejas:</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*Transmisión ETL.*  Los datos se limpian y agregan continuamente antes de ingresarlos en los almacenes de datos.  Netflix utiliza Kafka y Spark Streaming para crear una solución de recomendación de películas en línea y monitoreo de datos en tiempo real que puede procesar miles de millones de eventos por día desde diferentes fuentes de datos.  Sin embargo, el ETL tradicional para el procesamiento por lotes se trata de manera diferente.  Estos datos se leen primero y luego se convierten a un formato de base de datos antes de escribirse en la base de datos.</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*Enriquecimiento de datos.*  Spark Streaming enriquece los datos en vivo con datos estáticos para permitir un análisis de datos más en tiempo real.  Por ejemplo, los anunciantes en línea pueden ofrecer anuncios personalizados y específicos basados en información sobre el comportamiento del cliente.</block>
  <block id="c8fc01958b8b24afef85387342bc2aef" category="list-text">*Detección de eventos desencadenantes.*  Spark Streaming le permite detectar y responder rápidamente a comportamientos inusuales que podrían indicar problemas potencialmente graves.  Por ejemplo, las instituciones financieras utilizan desencadenadores para detectar y detener transacciones fraudulentas, y los hospitales utilizan desencadenadores para detectar cambios peligrosos para la salud detectados en los signos vitales de un paciente.</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*Análisis de sesión complejo.*  Spark Streaming recopila eventos como la actividad del usuario después de iniciar sesión en un sitio web o aplicación, que luego se agrupan y analizan.  Por ejemplo, Netflix utiliza esta funcionalidad para ofrecer recomendaciones de películas en tiempo real.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link-macro">TR-4912: Pautas recomendadas para el almacenamiento en niveles de Confluent Kafka con NetApp</block>
  <block id="519be207be9b1131f1e8524db61cf335" category="paragraph">Para obtener más información sobre la configuración de datos de transmisión, la verificación de Confluent Kafka y las pruebas de rendimiento, consulte<block ref="474863345040f8931cecadcc38733702" category="inline-link-macro-rx"></block> .</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">aprendizaje automático</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">El marco integrado de Spark le ayuda a ejecutar consultas repetidas en conjuntos de datos utilizando la biblioteca de aprendizaje automático (MLlib).  MLlib se utiliza en áreas como agrupamiento, clasificación y reducción de dimensionalidad para algunas funciones comunes de big data, como inteligencia predictiva, segmentación de clientes para fines de marketing y análisis de sentimientos.  MLlib se utiliza en seguridad de red para realizar inspecciones en tiempo real de paquetes de datos en busca de indicios de actividad maliciosa.  Ayuda a los proveedores de seguridad a conocer nuevas amenazas y mantenerse a la vanguardia de los piratas informáticos mientras protegen a sus clientes en tiempo real.</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">aprendizaje profundo</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow es un marco de aprendizaje profundo popular utilizado en toda la industria.  TensorFlow admite el entrenamiento distribuido en un clúster de CPU o GPU.  Este entrenamiento distribuido permite a los usuarios ejecutarlo en una gran cantidad de datos con muchas capas profundas.</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">Hasta hace poco, si queríamos usar TensorFlow con Apache Spark, necesitábamos realizar todo el ETL necesario para TensorFlow en PySpark y luego escribir los datos en un almacenamiento intermedio.  Luego, esos datos se cargarían en el clúster TensorFlow para el proceso de entrenamiento real.  Este flujo de trabajo requería que el usuario mantuviera dos clústeres diferentes, uno para ETL y otro para el entrenamiento distribuido de TensorFlow.  Normalmente, ejecutar y mantener varios clústeres era una tarea tediosa y que consumía mucho tiempo.</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">Los DataFrames y RDD en versiones anteriores de Spark no eran adecuados para el aprendizaje profundo porque el acceso aleatorio era limitado.  En Spark 3.0 con el proyecto Hydrogen, se agrega soporte nativo para los marcos de aprendizaje profundo.  Este enfoque permite la programación no basada en MapReduce en el clúster Spark.</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">Análisis interactivo</block>
  <block id="9650da7c8eb40c14055202b3dd7f4443" category="paragraph">Apache Spark es lo suficientemente rápido para realizar consultas exploratorias sin muestrear con lenguajes de desarrollo distintos de Spark, incluidos SQL, R y Python.  Spark utiliza herramientas de visualización para procesar datos complejos y visualizarlos de forma interactiva.  Spark con transmisión estructurada realiza consultas interactivas sobre datos en vivo en análisis web que le permiten ejecutar consultas interactivas sobre la sesión actual de un visitante web.</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">Sistema de recomendación</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">A lo largo de los años, los sistemas de recomendación han traído enormes cambios a nuestras vidas, a medida que las empresas y los consumidores han respondido a cambios dramáticos en las compras en línea, el entretenimiento en línea y muchas otras industrias.  De hecho, estos sistemas se encuentran entre las historias de éxito más evidentes de la IA en la producción.  En muchos casos de uso práctico, los sistemas de recomendación se combinan con IA conversacional o chatbots interconectados con un backend de PNL para obtener información relevante y producir inferencias útiles.</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">Hoy en día, muchos minoristas están adoptando modelos de negocio más nuevos, como comprar en línea y recoger en la tienda, recoger en la acera, autopago, escanear y listo, y más.  Estos modelos han cobrado relevancia durante la pandemia de COVID-19 al hacer que las compras sean más seguras y cómodas para los consumidores.  La IA es crucial para estas tendencias digitales crecientes, que están influenciadas por el comportamiento del consumidor y viceversa.  Para satisfacer las crecientes demandas de los consumidores, aumentar la experiencia del cliente, mejorar la eficiencia operativa y aumentar los ingresos, NetApp ayuda a sus clientes empresariales y empresas a utilizar algoritmos de aprendizaje automático y aprendizaje profundo para diseñar sistemas de recomendación más rápidos y precisos.</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">Existen varias técnicas populares que se utilizan para proporcionar recomendaciones, incluido el filtrado colaborativo, los sistemas basados en contenido, el modelo de recomendación de aprendizaje profundo (DLRM) y las técnicas híbridas.  Los clientes utilizaron anteriormente PySpark para implementar el filtrado colaborativo para crear sistemas de recomendación.  Spark MLlib implementa mínimos cuadrados alternos (ALS) para el filtrado colaborativo, un algoritmo muy popular entre las empresas antes del surgimiento de DLRM.</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">Procesamiento del lenguaje natural</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">La IA conversacional, posible gracias al procesamiento del lenguaje natural (PLN), es la rama de la IA que ayuda a las computadoras a comunicarse con los humanos.  La PNL prevalece en todos los sectores industriales y en muchos casos de uso, desde asistentes inteligentes y chatbots hasta búsquedas de Google y texto predictivo.  Según un<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> Predicción: para 2022, el 70% de las personas interactuarán con plataformas de IA conversacional a diario.  Para una conversación de alta calidad entre un humano y una máquina, las respuestas deben ser rápidas, inteligentes y que suenen naturales.</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">Los clientes necesitan una gran cantidad de datos para procesar y entrenar sus modelos de PNL y reconocimiento automático de voz (ASR).  También necesitan mover datos a través del borde, el núcleo y la nube, y necesitan el poder de realizar inferencias en milisegundos para establecer una comunicación natural con los humanos.  NetApp AI y Apache Spark son una combinación ideal para computación, almacenamiento, procesamiento de datos, entrenamiento de modelos, ajuste e implementación.</block>
  <block id="6ecf226f4b849e3111584c1eebd25f3c" category="paragraph">El análisis de sentimientos es un campo de estudio dentro de la PNL en el que se extraen sentimientos positivos, negativos o neutrales del texto.  El análisis de sentimientos tiene una variedad de casos de uso, desde determinar el desempeño de los empleados del centro de soporte en conversaciones con las personas que llaman hasta brindar respuestas de chatbot automatizadas apropiadas.  También se ha utilizado para predecir el precio de las acciones de una empresa basándose en las interacciones entre los representantes de la empresa y la audiencia en las conferencias de ganancias trimestrales.  Además, el análisis de sentimientos se puede utilizar para determinar la opinión de un cliente sobre los productos, servicios o soporte proporcionado por la marca.</block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="inline-link">Spark PNL</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">Laboratorios John Snow</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">sentimiento de las noticias financieras</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBERT</block>
  <block id="c1856f13b6ce4dd1f710cf08138e0c51" category="paragraph">Usamos el<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> biblioteca de<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> para cargar tuberías entrenadas previamente y modelos de Representaciones de Codificador Bidireccional de Transformadores (BERT), incluidos<block ref="1a3a0057856cc0bfa7cb2c9343eb2415" category="inline-link-rx"></block> y<block ref="ac723dc3fc44f63057a74e935ae9db52" category="inline-link-rx"></block> , realizando tokenización, reconocimiento de entidades nombradas, entrenamiento de modelos, ajuste y análisis de sentimientos a escala.  Spark NLP es la única biblioteca de PNL de código abierto en producción que ofrece transformadores de última generación como BERT, ALBERT, ELECTRA, XLNet, DistilBERT, RoBERTa, DeBERTa, XLM- RoBERTa, Longformer, ELMO, Universal Sentence Encoder, Google T5, MarianMT y GPT2.  La biblioteca funciona no solo en Python y R, sino también en el ecosistema JVM (Java, Scala y Kotlin) a escala al extender Apache Spark de forma nativa.</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">Abstracto</block>
  <block id="c9da861bd07fd9446a0e4f9108517532" category="paragraph">Este documento describe cómo trasladar datos de sistemas de análisis de big data y computación de alto rendimiento (HPC) para que puedan utilizarse en flujos de trabajo de inteligencia artificial (IA).  La IA normalmente procesa datos NFS a través de exportaciones NFS.  Sin embargo, es posible que tenga sus datos de IA en una plataforma de análisis de big data y computación de alto rendimiento (HPC).  Este podría ser el sistema de archivos distribuidos Hadoop (HDFS), un objeto binario grande (Blob), almacenamiento S3 o el sistema de archivos paralelos general (GPFS) de IBM.  En este documento, describimos cómo mover datos desde una plataforma de análisis de big data y GPFS a NFS mediante comandos nativos de Hadoop, el módulo de análisis local de NetApp (NIPAM) y NetApp XCP.  Este documento también analiza los beneficios comerciales de trasladar datos de big data y HPC a IA.</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Dónde encontrar información adicional</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Para obtener más información sobre la información que se describe en este documento, revise los siguientes documentos y/o sitios web:</block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">Guía de implementación y mejores prácticas de NetApp FlexGroup Volume</block>
  <block id="7d72333a4556beea0bd57e4b8a007b47" category="paragraph"><block ref="7d72333a4556beea0bd57e4b8a007b47" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">Documentación de productos de NetApp</block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">Esta sección describe los beneficios comerciales de esta solución.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">Beneficios empresariales</block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">Trasladar datos del análisis de big data a la IA ofrece los siguientes beneficios:</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">La capacidad de extraer datos de diferentes sistemas de archivos Hadoop y GPFS en un sistema de almacenamiento NFS unificado</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Una forma automatizada e integrada con Hadoop de transferir datos</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Una reducción en el costo del desarrollo de bibliotecas para trasladar datos desde los sistemas de archivos Hadoop</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">Máximo rendimiento mediante el rendimiento agregado de múltiples interfaces de red desde una única fuente de datos mediante el uso de NIPAM</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">Métodos programados y bajo demanda para transferir datos</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">Eficiencia de almacenamiento y capacidad de gestión empresarial para datos NFS unificados mediante el uso del software de gestión de datos ONTAP</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">Costo cero para el movimiento de datos con el método Hadoop para transferencia de datos</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">Esta página analiza los desafíos que podría enfrentar un cliente al intentar acceder a datos de análisis de big data para operaciones de IA.</block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">Los clientes podrían enfrentar los siguientes desafíos al intentar acceder a datos de análisis de big data para operaciones de IA:</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">Los datos del cliente se encuentran en un repositorio de datos.  El lago de datos puede contener diferentes tipos de datos, como datos estructurados, no estructurados, semiestructurados, registros y datos de máquina a máquina.  Todos estos tipos de datos deben procesarse en sistemas de IA.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">La IA no es compatible con los sistemas de archivos Hadoop.  Una arquitectura de IA típica no puede acceder directamente a los datos HDFS y HCFS, que deben trasladarse a un sistema de archivos comprensible para IA (NFS).</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">Para trasladar los datos del lago de datos a la IA normalmente se necesitan procesos especializados.  La cantidad de datos en el lago de datos puede ser muy grande.  Un cliente debe tener una forma eficiente, de alto rendimiento y rentable de trasladar datos a los sistemas de IA.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">Sincronización de datos.  Si un cliente desea sincronizar datos entre la plataforma de big data y la IA, a veces los datos procesados a través de la IA se pueden usar con big data para el procesamiento analítico.</block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">En un clúster de big data, los datos se almacenan en HDFS o HCFS, como MapR-FS, Windows Azure Storage Blob, S3 o el sistema de archivos de Google.  Realizamos pruebas con HDFS, MapR-FS y S3 como fuente para copiar datos a la exportación NFS de NetApp ONTAP con la ayuda de NIPAM utilizando el comando hadoop distcp desde la fuente.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="doc">Solución de transferencia de datos</block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">En un clúster de big data, los datos se almacenan en HDFS o HCFS, como MapR-FS, Windows Azure Storage Blob, S3 o el sistema de archivos de Google.  Realizamos pruebas con HDFS, MapR-FS y S3 como fuente para copiar datos a la exportación NFS de NetApp ONTAP con la ayuda de NIPAM mediante el uso de<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> comando de la fuente.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">El siguiente diagrama ilustra el movimiento de datos típico de un clúster Spark que se ejecuta con almacenamiento HDFS a un volumen NFS de NetApp ONTAP para que NVIDIA pueda procesar operaciones de IA.</block>
  <block id="67ed14506d4065a668f7cb0136039d8b" category="paragraph"><block ref="67ed14506d4065a668f7cb0136039d8b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">El<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> El comando utiliza el programa MapReduce para copiar los datos.  NIPAM trabaja con MapReduce para actuar como controlador del clúster Hadoop al copiar datos.  NIPAM puede distribuir una carga a través de múltiples interfaces de red para una sola exportación.  Este proceso maximiza el rendimiento de la red al distribuir los datos a través de múltiples interfaces de red cuando copia los datos de HDFS o HCFS a NFS.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM no es compatible ni está certificado con MapR.</block>
  <block id="20220b4c576eeca673151438f5ee1da9" category="summary">La solución de transferencia de datos para IA se basa en las necesidades de los clientes de procesar datos de Hadoop a partir de operaciones de IA.  NetApp mueve datos de HDFS a NFS mediante NIPAM.  En un caso de uso, el cliente necesitaba mover datos a NFS en las instalaciones y otro cliente necesitaba mover datos desde Windows Azure Storage Blob a Google Cloud NetApp Volumes para procesar los datos de las instancias de nube de GPU en la nube.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">Solución de transferencia de datos para IA</block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">El siguiente diagrama ilustra los detalles de la solución de transferencia de datos.</block>
  <block id="44c3f61c0684bc5b43b5e243a139152c" category="paragraph"><block ref="44c3f61c0684bc5b43b5e243a139152c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Para crear la solución de transporte de datos se requieren los siguientes pasos:</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN proporciona HDFS y NAS proporciona el volumen NFS a través de NIPAM al clúster del lago de datos de producción.</block>
  <block id="625dd6cfdf4a097dff4340366eec8942" category="list-text">Los datos del cliente están en HDFS y NFS.  Los datos NFS pueden ser datos de producción de otras aplicaciones que se utilizan para análisis de big data y operaciones de IA.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">La tecnología NetApp FlexClone crea un clon del volumen NFS de producción y lo aprovisiona en el clúster de IA en las instalaciones.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">Los datos de un LUN SAN HDFS se copian en un volumen NFS con NIPAM y el<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> dominio.  NIPAM utiliza el ancho de banda de múltiples interfaces de red para transferir datos.  Este proceso reduce el tiempo de copia de datos para que se puedan transferir más datos.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">Ambos volúmenes NFS se aprovisionan en el clúster de IA para operaciones de IA.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">Para procesar datos NFS locales con GPU en la nube, los volúmenes NFS se reflejan en NetApp Private Storage (NPS) con tecnología NetApp SnapMirror y se montan en proveedores de servicios en la nube para GPU.</block>
  <block id="98105737f8ac55863a4e0763f588cab5" category="list-text">El cliente desea procesar datos en servicios EC2/EMR, HDInsight o DataProc en GPU de proveedores de servicios en la nube.  El transportador de datos de Hadoop mueve los datos de los servicios de Hadoop a Google Cloud NetApp Volumes con NIPAM y<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> dominio.</block>
  <block id="f490cd633c8e7648911d95daf043af8f" category="list-text">Los datos de Google Cloud NetApp Volumes se aprovisionan a IA a través del protocolo NFS. Los datos que se procesan a través de IA se pueden enviar a una ubicación local para análisis de big data, además del clúster NVIDIA a través de NIPAM, SnapMirror y NPS.</block>
  <block id="f13f02e9fbfc272070bb10c4ae60e707" category="paragraph">En este escenario, el cliente tiene una gran cantidad de datos de archivos en el sistema NAS en una ubicación remota que son necesarios para el procesamiento de IA en el controlador de almacenamiento de NetApp en las instalaciones.  En este escenario, es mejor utilizar la herramienta de migración XCP para migrar los datos a una velocidad más rápida.</block>
  <block id="74c03e6f525ff7a5f56d15dd77d9d7ee" category="paragraph">El cliente con caso de uso híbrido puede usar BlueXP Copy and Sync para migrar datos locales desde datos NFS, CIFS y S3 a la nube y viceversa para el procesamiento de IA mediante GPU como las de un clúster NVIDIA .  Tanto BlueXP Copy and Sync como la herramienta de migración XCP se utilizan para la migración de datos NFS a NetApp ONTAP NFS.</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">En esta validación, utilizamos cuatro servidores como servidores de disco compartido de red (NSD) para proporcionar discos físicos para GPFS.  GPFS se crea sobre los discos NSD para exportarlos como exportaciones NFS para que los clientes NFS puedan acceder a ellos, como se muestra en la siguiente figura.  Usamos XCP para copiar los datos de NFS exportado por GPFS a un volumen NFS de NetApp .</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS a NetApp ONTAP NFS</block>
  <block id="f0987b9b1ed71523f2b4be4961e35e12" category="paragraph"><block ref="f0987b9b1ed71523f2b4be4961e35e12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">Fundamentos de GPFS</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">Los siguientes tipos de nodos se utilizan en GPFS:</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*Nodo de administración.*  Especifica un campo opcional que contiene un nombre de nodo utilizado por los comandos de administración para comunicarse entre nodos.  Por ejemplo, el nodo de administración<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block> Podría pasar una comprobación de red a todos los demás nodos del clúster.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*Nodo de quórum.*  Determina si un nodo está incluido en el grupo de nodos del que se deriva el quórum.  Necesita al menos un nodo como nodo de quórum.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*Nodo administrador.*  Indica si un nodo es parte del grupo de nodos desde el cual se pueden seleccionar administradores de sistemas de archivos y administradores de tokens.  Es una buena idea definir más de un nodo como nodo administrador.  La cantidad de nodos que designe como administrador dependerá de la carga de trabajo y de la cantidad de licencias de servidor GPFS que tenga.  Si está ejecutando trabajos paralelos grandes, es posible que necesite más nodos de administrador que en un clúster de cuatro nodos que admita una aplicación web.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*Servidor NSD.*  El servidor que prepara cada disco físico para su uso con GPFS.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*Nodo de protocolo.*  El nodo que comparte datos GPFS directamente a través de cualquier protocolo Secure Shell (SSH) con el NFS.  Este nodo requiere una licencia de servidor GPFS.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">Lista de operaciones para GPFS, NFS y XCP</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">Esta sección proporciona la lista de operaciones que crean GPFS, exportan GPFS como una exportación NFS y transfieren los datos mediante XCP.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">Crear GPFS</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">Para crear GPFS, complete los siguientes pasos:</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Descargue e instale el acceso a datos a escala de espectro para la versión Linux en uno de los servidores.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">Instale el paquete de requisitos previos (chef por ejemplo) en todos los nodos y deshabilite Security-Enhanced Linux (SELinux) en todos los nodos.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">Configure el nodo de instalación y agregue el nodo de administración y el nodo GPFS al archivo de definición del clúster.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">Agregue el nodo administrador, el nodo de quórum, los servidores NSD y el nodo GPFS.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">Agregue los nodos GUI, de administración y GPFS, y agregue un servidor GUI adicional si es necesario.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">Agregue otro nodo GPFS y verifique la lista de todos los nodos.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">Especifique un nombre de clúster, un perfil, un binario de shell remoto, un binario de copia de archivo remoto y un rango de puertos que se configurarán en todos los nodos GPFS en el archivo de definición de clúster.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">Vea la configuración de GPFS y agregue un nodo de administración adicional.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">Deshabilite la recopilación de datos y cargue el paquete de datos en el Centro de soporte de IBM.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">Habilite NTP y verifique previamente las configuraciones antes de la instalación.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">Configurar, crear y comprobar los discos NSD.</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">Crear el GPFS.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">Monte el GPFS.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">Verificar y proporcionar los permisos necesarios al GPFS.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">Verifique la lectura y escritura de GPFS ejecutando el<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> dominio.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">Exportar GPFS a NFS</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">Para exportar el GPFS a NFS, complete los siguientes pasos:</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">Exportar GPFS como NFS a través de<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">Instale los paquetes de servidor NFS necesarios.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">Inicie el servicio NFS.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">Enumere los archivos en el GPFS para validar el cliente NFS.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">Configurar el cliente NFS</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">Para configurar el cliente NFS, complete los siguientes pasos:</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">Exportar el GPFS como NFS a través de<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">Inicie los servicios de cliente NFS.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">Monte el GPFS a través del protocolo NFS en el cliente NFS.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">Validar la lista de archivos GPFS en la carpeta montada NFS.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">Mueva los datos de NFS exportado GPFS a NFS de NetApp mediante XCP.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">Validar los archivos GPFS en el cliente NFS.</block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">Esta sección proporciona los pasos detallados necesarios para configurar GPFS y mover datos a NFS mediante NetApp XCP.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">Pasos detallados de GPFS a NFS</block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">Configurar GPFS</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">Descargue e instale Spectrum Scale Data Access para Linux en uno de los servidores.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">Instale el paquete de requisitos previos (incluido chef y los encabezados del kernel) en todos los nodos.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">Deshabilite SELinux en todos los nodos.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">Configurar el nodo de instalación.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">Agregue el nodo de administración y el nodo GPFS al archivo de definición del clúster.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">Agregue el nodo administrador y el nodo GPFS.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">Agregue el nodo de quórum y el nodo GPFS.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">Agregue los servidores NSD y el nodo GPFS.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">Agregue los nodos GUI, de administración y GPFS.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">Agregue otro servidor GUI.</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">Agregue otro nodo GPFS.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">Verificar y enumerar todos los nodos.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">Especifique un nombre de clúster en el archivo de definición de clúster.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">Especifique el perfil.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">Especifique el binario de shell remoto que utilizará GPFS; utilice<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block> .</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">Especifique el binario de copia de archivo remoto que utilizará GPFS; utilice<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block> .</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">Especifique el rango de puertos que se establecerá en todos los nodos GPFS; utilice<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block> .</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">Ver la configuración de GPFS.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">Añadir un nodo de administración.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">Habilitar NTP.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">Verifique las configuraciones antes de la instalación.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">Configurar los discos NSD.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">Crear los discos NSD.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">Verifique el estado del disco NSD.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">Verifique y proporcione los permisos necesarios al GPFS.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">Verifique la lectura y escritura de GPFS ejecutando el<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> dominio.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">Para exportar GPFS a NFS, complete los siguientes pasos:</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">Enumere los archivos en GPFS para validar el cliente NFS.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">Configurar el cliente NFS</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">Instalar paquetes en el cliente NFS.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">Validar la lista de archivos GPFS en la carpeta montada en NFS.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">Mueva los datos del NFS exportado mediante GPFS al NFS de NetApp mediante XCP.</block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">Para esta solución, NetApp validó la migración de datos desde el lago de datos (HDFS) y los datos del clúster MapR a ONTAP NFS.  Los datos residían en MapR-FS y HDFS.  NetApp XCP presentó una nueva función que migra directamente los datos de un sistema de archivos distribuido como HDFS y MapR-FS a ONTAP NFS.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS y MapR-FS a ONTAP NFS</block>
  <block id="676df8e27b06b6dd639822191d432dc2" category="paragraph">Para esta solución, NetApp validó la migración de datos desde el lago de datos (HDFS) y los datos del clúster MapR a ONTAP NFS.  Los datos residían en MapR-FS y HDFS.  NetApp XCP presentó una nueva función que migra directamente los datos de un sistema de archivos distribuido como HDFS y MapR-FS a ONTAP NFS.  XCP utiliza subprocesos asincrónicos y llamadas API C de HDFS para comunicarse y transferir datos desde MapR-FS así como también desde HDFS.</block>
  <block id="adc95e83c5f5ce743bb6468ffdef4fc3" category="paragraph">La siguiente figura muestra la migración de datos desde el lago de datos (HDFS) y MapR-FS a ONTAP NFS.  Con esta nueva función, no es necesario exportar la fuente como un recurso compartido NFS.</block>
  <block id="3789ec0eac19c6a55506d3fe4f2e880e" category="paragraph"><block ref="3789ec0eac19c6a55506d3fe4f2e880e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">¿Por qué los clientes están migrando de HDFS y MapR-FS a NFS?</block>
  <block id="8616e2393304ffc26da9b5e853b8db33" category="paragraph">La mayoría de las distribuciones de Hadoop, como Cloudera y Hortonworks, utilizan HDFS y las distribuciones MapR utilizan su propio sistema de archivos llamado Mapr-FS para almacenar datos.  Los datos HDFS y MapR-FS brindan a los científicos de datos información valiosa que puede aprovecharse en el aprendizaje automático (ML) y el aprendizaje profundo (DL).  Los datos en HDFS y MapR-FS no se comparten, lo que significa que no pueden ser utilizados por otras aplicaciones.  Los clientes buscan datos compartidos, especialmente en el sector bancario, donde múltiples aplicaciones utilizan datos confidenciales de los clientes.  La última versión de Hadoop (3.x o posterior) admite fuentes de datos NFS, a las que se puede acceder sin software adicional de terceros.  Con la nueva función XCP de NetApp , los datos se pueden mover directamente desde HDFS y MapR-FS a NetApp NFS para proporcionar acceso a múltiples aplicaciones.</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">Se realizaron pruebas en Amazon Web Services (AWS) para transferir los datos de MapR-FS a NFS para la prueba de rendimiento inicial con 12 nodos MAPR y 4 servidores NFS.</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">Cantidad</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">Size</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">CPU virtual</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">Memoria</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="cell">Almacenamiento</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">Red</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">Servidor NFS</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8 unidades SSD NVMe de 7500</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">Nodos MapR</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4 unidades SSD NVMe de 7500</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">Según las pruebas iniciales, obtuvimos un rendimiento de 20 GBps y pudimos transferir 2 PB de datos por día.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link-macro">TR-4863: Pautas de mejores prácticas para NetApp XCP: Transferencia de datos, migración de archivos y análisis</block>
  <block id="d7b251f310540db8b677090e4068b718" category="paragraph">Para obtener más información sobre la migración de datos HDFS sin exportar HDFS a NFS, consulte la sección "Pasos de implementación - NAS" en<block ref="8057f0a15e6751a5fa14293a5e88f017" category="inline-link-macro-rx"></block> .</block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">Este documento proporciona pautas para trasladar datos de análisis de big data y datos de HPC a IA mediante el uso de NetApp XCP y NIPAM.  También analizamos los beneficios comerciales de trasladar datos de big data y HPC a IA.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732: Análisis de big data para inteligencia artificial</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam, NetApp</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">Este documento describe cómo trasladar datos de análisis de big data y datos de HPC a IA.  La IA procesa datos NFS a través de exportaciones NFS, mientras que los clientes a menudo tienen sus datos de IA en una plataforma de análisis de big data, como HDFS, Blob o almacenamiento S3, así como plataformas HPC como GPFS.  Este documento proporciona pautas para trasladar datos de análisis de big data y datos de HPC a IA mediante el uso de NetApp XCP y NIPAM.  También analizamos los beneficios comerciales de trasladar datos de big data y HPC a IA.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">Conceptos y componentes</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">Almacenamiento de análisis de big data</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">Big Data Analytics es el principal proveedor de almacenamiento para HDFS.  Un cliente a menudo utiliza un sistema de archivos compatible con Hadoop (HCFS), como Windows Azure Blob Storage, MapR File System (MapR-FS) y almacenamiento de objetos S3.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">Sistema de archivos paralelo general</block>
  <block id="510b2e746f7cab5126465c64edad8541" category="paragraph">GPFS de IBM es un sistema de archivos empresarial que ofrece una alternativa a HDFS.  GPFS proporciona flexibilidad para que las aplicaciones decidan el tamaño del bloque y el diseño de la replicación, lo que proporciona buen rendimiento y eficiencia.</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">Módulo de análisis local de NetApp</block>
  <block id="f1b570aebec7f92867ad62cf2fe7c50c" category="paragraph">El módulo de análisis local de NetApp (NIPAM) funciona como controlador para que los clústeres de Hadoop accedan a datos NFS.  Tiene cuatro componentes: un grupo de conexiones, un NFS InputStream, un caché de controladores de archivos y un NFS OutputStream. Para obtener más información, consulte <block ref="ead8bf031afc74347ebd06de968e5895" category="inline-link-rx"></block> .</block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Copia distribuida de Hadoop</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy (DistCp) es una herramienta de copia distribuida que se utiliza para grandes tareas de copia entre clústeres y dentro de clústeres.  Esta herramienta utiliza MapReduce para la distribución de datos, el manejo de errores y la generación de informes.  Amplía la lista de archivos y directorios y los ingresa en tareas de mapeo para copiar los datos de la lista de origen.  La siguiente imagen muestra la operación DistCp en HDFS y no HDFS.</block>
  <block id="513bd70b6fe800dda2548dae1bc404df" category="paragraph"><block ref="513bd70b6fe800dda2548dae1bc404df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp mueve datos entre los dos sistemas HDFS sin utilizar un controlador adicional.  NetApp proporciona el controlador para sistemas que no son HDFS.  Para un destino NFS, NIPAM proporciona el controlador para copiar datos que Hadoop DistCp utiliza para comunicarse con destinos NFS al copiar datos.</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="section-title">Google Cloud NetApp Volumes</block>
  <block id="e6b6086807cb6588f15ae36a2a999e8f" category="paragraph">Google Cloud NetApp Volumes es un servicio de archivos nativo de la nube con un rendimiento extremo.  Este servicio ayuda a los clientes a acelerar su tiempo de comercialización activando y desactivando rápidamente los recursos y utilizando las características de NetApp para mejorar la productividad y reducir el tiempo de inactividad del personal.  Google Cloud NetApp Volumes es la alternativa adecuada para la recuperación ante desastres y la copia de seguridad en la nube porque reduce el espacio total del centro de datos y consume menos almacenamiento nativo en la nube pública.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">XCP de NetApp</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP es un software cliente que permite una migración rápida y confiable de datos de cualquier plataforma a NetApp y de NetApp a NetApp .  Esta herramienta está diseñada para copiar una gran cantidad de datos NAS no estructurados desde cualquier sistema NAS a un controlador de almacenamiento NetApp .  La herramienta de migración XCP utiliza un motor de transmisión de E/S multicanal y multinúcleo que puede procesar muchas solicitudes en paralelo, como migración de datos, listados de archivos o directorios e informes de espacio.  Esta es la herramienta de migración de datos de NetApp predeterminada.  Puede utilizar XCP para copiar datos de un clúster de Hadoop y HPC al almacenamiento NFS de NetApp .  El siguiente diagrama muestra la transferencia de datos desde un clúster de Hadoop y HPC a un volumen NFS de NetApp mediante XCP.</block>
  <block id="31e2e6a49223ff3b99782fced8ae2f33" category="paragraph"><block ref="31e2e6a49223ff3b99782fced8ae2f33" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf66760432e212bf920c4b630bf24a8" category="section-title">Copia y sincronización de NetApp BlueXP</block>
  <block id="182c915d2a513090f731fbf85d4576bd" category="paragraph">NetApp BlueXP Copy and Sync es un software como servicio de replicación de datos híbrido que transfiere y sincroniza datos NFS, S3 y CIFS de forma segura y sin problemas entre el almacenamiento local y el almacenamiento en la nube.  Este software se utiliza para migración de datos, archivado, colaboración, análisis y más.  Una vez transferidos los datos, BlueXP Copy and Sync sincroniza continuamente los datos entre el origen y el destino.  De ahí en adelante se transfiere el delta.  También protege los datos dentro de su propia red, en la nube o en sus instalaciones.  Este software se basa en un modelo de pago por uso, que proporciona una solución rentable y proporciona capacidades de monitoreo y generación de informes para su transferencia de datos.</block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">Esta sección proporciona los pasos detallados necesarios para mover datos de MapR-FS a ONTAP NFS mediante NetApp XCP.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS a ONTAP NFS</block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">Asignar tres LUN a cada nodo MapR y otorgarles la propiedad de todos los nodos MapR.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">Durante la instalación, elija los LUN recién agregados para los discos del clúster MapR que se utilizan para MapR-FS.</block>
  <block id="87ae055df3def21f83bbbb9e287167b6" category="list-text">Instale un clúster MapR de acuerdo con la documentación de MapR 6.1.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">Verifique las operaciones básicas de Hadoop utilizando comandos MapReduce como<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block> .</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">Mantenga los datos del cliente en MapR-FS.  Por ejemplo, generamos aproximadamente un terabyte de datos de muestra en MapR-FS utilizando Teragen.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">Configurar MapR-FS como exportación NFS.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">Deshabilite el servicio nlockmgr en todos los nodos MapR.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">Exportar carpetas específicas desde MapR-FS en todos los nodos MapR en el<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block> archivo.  No exporte la carpeta principal con diferentes permisos cuando exporte subcarpetas.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">Actualice el servicio NFS MapR-FS.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">Asignar un rango de IP virtual a un servidor específico o a un conjunto de servidores en el clúster MapR.  Luego, el clúster MapR asigna una IP a un servidor específico para el acceso a datos NFS.  Las IP permiten una alta disponibilidad, lo que significa que, si un servidor o red con una IP particular experimenta una falla, la siguiente IP del rango de IP se puede utilizar para el acceso NFS.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">Si desea proporcionar acceso NFS desde todos los nodos MapR, puede asignar un conjunto de IP virtuales a cada servidor y puede utilizar los recursos de cada nodo MapR para acceder a los datos NFS.</block>
  <block id="c508683f7afca451e58f95b67197d51f" category="paragraph"><block ref="c508683f7afca451e58f95b67197d51f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b9596f082ff106a71134b100eee486" category="paragraph"><block ref="54b9596f082ff106a71134b100eee486" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be91199bb393028826e953c78a526a54" category="paragraph"><block ref="be91199bb393028826e953c78a526a54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">Verifique las IP virtuales asignadas en cada nodo MapR y úselas para acceder a datos NFS.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">Monte el MapR-FS exportado por NFS utilizando la IP virtual asignada para verificar el funcionamiento de NFS.  Sin embargo, este paso no es necesario para la transferencia de datos mediante NetApp XCP.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">Configure NetApp XCP para transferir datos desde la puerta de enlace NFS de MapR-FS a ONTAP NFS.</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">Configurar la ubicación del catálogo para XCP.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">Copiar el archivo de licencia a<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block> .</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">Activar XCP usando el<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block> dominio.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">Verifique la fuente para la exportación NFS.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">Transfiera los datos usando XCP desde múltiples nodos MapR desde múltiples IP de origen y múltiples IP de destino (ONTAP LIF).</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">Verifique la distribución de carga en el controlador de almacenamiento.</block>
  <block id="af7ba099603ccd4070a5102166f2c998" category="summary">Con base en esta validación, los científicos e ingenieros de datos pueden acceder a datos NFS desde AWS SageMaker Jupyter Notebooks a través de buckets S3 desde NetApp Cloud Volumes ONTAP.  Este enfoque permite acceder fácilmente y compartir los mismos datos tanto de NFS como de S3 sin necesidad de software adicional.</block>
  <block id="8053f00cf5e08f449b7cafe189c73a39" category="list-text">Clasificación de texto con SageMaker BlazingText</block>
  <block id="d6667429b7c60bcbf5e5d593e91d6cae" category="list-text">Compatibilidad de la versión ONTAP con el almacenamiento de objetos S3</block>
  <block id="91ef54d96688b56bf968f57803df6675" category="inline-link"><block ref="91ef54d96688b56bf968f57803df6675" category="inline-link-rx"></block></block>
  <block id="53a581d907d105a589be9419e91b16fa" category="paragraph"><block ref="53a581d907d105a589be9419e91b16fa" category="inline-link-rx"></block></block>
  <block id="6e74710636e2da95cda4899adcdf891e" category="summary">Los datos están disponibles en NFS y se accede a ellos desde S3 desde AWS SageMaker.</block>
  <block id="8394db253ec71ed9d59b9429983b8eb4" category="doc">Dualidad de datos para científicos de datos y otras aplicaciones</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">Requisitos tecnológicos</block>
  <block id="f4900d1d4a0a26325c4c9514e57c2c75" category="paragraph">Necesita NetApp BlueXP, NetApp Cloud Volumes ONTAP y AWS SageMaker Notebooks para el caso de uso de dualidad de datos.</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">Requisitos de software</block>
  <block id="6e6b6052efed2574e2dc05cbdc5d66d5" category="paragraph">La siguiente tabla enumera los componentes de software necesarios para implementar el caso de uso.</block>
  <block id="9b9477e579c3b44dd623d5a6e1ea8d78" category="cell">BlueXP</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="cell">Volúmenes en la nube de NetApp Cloud Volumes ONTAP</block>
  <block id="dda9f6d67571441afa5cfb6b54b70873" category="cell">Cuaderno de AWS SageMaker</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="section-title">Procedimientos de implementación</block>
  <block id="cc5f7f3bee6dcb16913051d6fc267977" category="paragraph">La implementación de la solución de dualidad de datos implica las siguientes tareas:</block>
  <block id="6bb1f60bf0d00924a1bba54557e1feae" category="list-text">Conector BlueXP</block>
  <block id="cf25fa6cf104cc1a67119acb6d4d364d" category="list-text">Datos para el aprendizaje automático</block>
  <block id="59b20c2117a395af59d54a6533498e99" category="list-text">Aprendizaje automático validado desde Jupyter Notebooks</block>
  <block id="46e0bb4f28dbf5013a68a8a69a3cf9f5" category="section-title">Conector BlueXP</block>
  <block id="6ff27f6b5b95b177c735d22a2783e9ef" category="paragraph">En esta validación, utilizamos AWS.  También es aplicable a Azure y Google Cloud.  Para crear un conector BlueXP en AWS, complete los siguientes pasos:</block>
  <block id="4d7b48a5181bdd203b2ff52910c67d94" category="list-text">Utilizamos las credenciales basadas en mcarl-marketplace-subscription en BlueXP.</block>
  <block id="c0caffb5ab49caead75d39f6416ba841" category="list-text">Elija la región adecuada para su entorno (por ejemplo, us-east-1 [N. Virginia]) y seleccione el método de autenticación (por ejemplo, Asumir rol o claves de AWS).  En esta validación, utilizamos claves de AWS.</block>
  <block id="86b72593a2ce2f4e46e7669ced916111" category="list-text">Proporcione el nombre del conector y cree un rol.</block>
  <block id="71ffd00d3592df40d0db94a71ceab12d" category="list-text">Proporcione los detalles de la red, como la VPC, la subred o el par de claves, dependiendo de si necesita una IP pública o no.</block>
  <block id="b5b37cef840fa0a17af0ef55c09a0e1f" category="list-text">Proporcione los detalles del grupo de seguridad, como acceso HTTP, HTTPS o SSH desde el tipo de origen, como cualquier lugar e información de rango de IP.</block>
  <block id="45b20434e20aeebd5991cd84f2cf11c9" category="list-text">Revise y cree el conector BlueXP .</block>
  <block id="92043f8a1dc0b0180854c25bcf5ff79d" category="list-text">Verifique que el estado de la instancia EC2 de BlueXP se esté ejecutando en la consola de AWS y verifique la dirección IP en la pestaña *Redes*.</block>
  <block id="7044ee6a43ee2152ca6d008fcb8228c3" category="list-text">Inicie sesión en la interfaz de usuario del conector desde el portal BlueXP o puede utilizar la dirección IP para acceder desde el navegador.</block>
  <block id="064d933c0c02c4fe7ef1a07ad3a537d7" category="paragraph">Para crear una instancia de Cloud Volumes ONTAP en BlueXP, complete los siguientes pasos:</block>
  <block id="35d88740e5ca53f6cabb06b3fce807b7" category="list-text">Cree un nuevo entorno de trabajo, seleccione el proveedor de nube y seleccione el tipo de instancia de Cloud Volumes ONTAP (como CVO único, HA o Amazon FSx ONTAP para ONTAP).</block>
  <block id="dcb89e397dde3dedb1a32224f0c15b78" category="list-text">Proporcione detalles como el nombre y las credenciales del clúster de Cloud Volumes ONTAP .  En esta validación, creamos una instancia de Cloud Volumes ONTAP llamada<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> .</block>
  <block id="9cf479af21359b2928a1b672d60577f2" category="list-text">Seleccione los servicios necesarios para Cloud Volumes ONTAP.  En esta validación, elegimos solo monitorear, por lo que deshabilitamos *Data Sense &amp; Compliance* y *Backup to Cloud Services*.</block>
  <block id="cb95ef3838d59d553c71f50b1cadee27" category="list-text">En la sección *Ubicación y conectividad*, seleccione la región de AWS, la VPC, la subred, el grupo de seguridad, el método de autenticación SSH y una contraseña o un par de claves.</block>
  <block id="fdd5d37c21ee01084537317345b3d78b" category="list-text">Elija el método de carga.  Utilizamos *Profesional* para esta validación.</block>
  <block id="00efec60d606ea6ad0bafe93bc77df92" category="list-text">Puede elegir un paquete preconfigurado, como *POC y cargas de trabajo pequeñas*, *Cargas de trabajo de producción de datos de aplicaciones y bases de datos*, *DR rentable* o *Cargas de trabajo de producción de mayor rendimiento*.  En esta validación elegimos *Poc y cargas de trabajo pequeñas*.</block>
  <block id="f22934293c2f2a761ea26fa4ae1828e1" category="list-text">Cree un volumen con un tamaño específico, protocolos permitidos y opciones de exportación.  En esta validación, creamos un volumen llamado<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="f2706214c4a60177d14fb8495cbc6924" category="list-text">Elija un tipo de disco de perfil y una política de niveles.  En esta validación, deshabilitamos *Eficiencia de almacenamiento* y *SSD de propósito general – Rendimiento dinámico*.</block>
  <block id="40d3f73a73f67ce67b286aef7a5d3ecb" category="list-text">Por último, revise y cree la instancia de Cloud Volumes ONTAP .  Luego espere entre 15 y 20 minutos para que BlueXP cree el entorno de trabajo de Cloud Volumes ONTAP .</block>
  <block id="a8b538b74c3f662c2248af9c6d4742db" category="list-text">Configure los siguientes parámetros para habilitar el protocolo Duality.  El protocolo Duality (NFS/S3) es compatible con ONTAP 9.  12.1 y posteriores.</block>
  <block id="15b53c14b58ee146309847451d1eb90a" category="list-text">En esta validación, creamos un SVM llamado<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> y volumen<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="3514969b2381af83551c246e34b74403" category="list-text">Verifique que la SVM tenga soporte de protocolo para NFS y S3.  En caso contrario, modifique el SVM para admitirlos.</block>
  <block id="e41c06ffff0f8c9cadbc7f8bb37f8ae5" category="list-text">Cree e instale un certificado CA si es necesario.</block>
  <block id="0395f8062a8a7f4af05113bae8133737" category="list-text">Crear una política de datos de servicio.</block>
  <block id="6e16e110899749a795fe713253d850e7" category="list-text">Verifique los detalles agregados.</block>
  <block id="5d3f8e127103f0d5cf3de305db892b4d" category="list-text">Crear un usuario y un grupo.</block>
  <block id="efa22127bde2d3ab2e4f5b9a42d14814" category="list-text">Cree un depósito en el volumen NFS.</block>
  <block id="c3fd6f44bf88d3f0eae4742edb58eafc" category="paragraph">Para crear un cuaderno de AWS desde AWS SageMaker, complete los siguientes pasos:</block>
  <block id="31378aab1ee6190e0b7fe33c501a5625" category="list-text">Asegúrese de que el usuario que está creando la instancia de Notebook tenga una política de IAM de AmazonSageMakerFullAccess o sea parte de un grupo existente que tenga derechos de AmazonSageMakerFullAccess.  En esta validación, el usuario es parte de un grupo existente.</block>
  <block id="13c1455885d16af64f1bb96c4e48680a" category="list-text">Proporcione la siguiente información:</block>
  <block id="bb8101aed18120fa18dedaa994ffeea0" category="list-text">Nombre de la instancia del cuaderno.</block>
  <block id="6239d232142a089e53e7a13fa721237a" category="list-text">Tipo de instancia.</block>
  <block id="37056dac7373f7e1b74382036d25b69e" category="list-text">Identificador de plataforma.</block>
  <block id="38e2059c32c628cf89e90a6844a93800" category="list-text">Seleccione la función de IAM que tenga derechos AmazonSageMakerFullAccess.</block>
  <block id="55d7da5ede713135b1c2ebd7a615c3b4" category="list-text">Acceso root – habilitar.</block>
  <block id="8f0e92e4434abc32ff62a914ae9f2ba6" category="list-text">Clave de cifrado: no seleccione ningún cifrado personalizado.</block>
  <block id="8b77028d248afd826900d895636b4e98" category="list-text">Mantenga las opciones predeterminadas restantes.</block>
  <block id="78456ee20793f732edfa9105bbb4e490" category="list-text">En esta validación, los detalles de la instancia de SageMaker son los siguientes:</block>
  <block id="e90e797343ea3f751b0c32e808edaff8" category="inline-image-macro">Captura de pantalla que representa el paso.</block>
  <block id="e987fe9ec5699958a73a8f310b4d99e8" category="paragraph"><block ref="e987fe9ec5699958a73a8f310b4d99e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4414f1275568cfaaea91b68f1514516e" category="paragraph"><block ref="4414f1275568cfaaea91b68f1514516e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4789a9ab6472480889e111503d068623" category="list-text">Inicie el cuaderno de AWS.</block>
  <block id="ce1d8475b6a4d461318eb3139cc54a3b" category="paragraph"><block ref="ce1d8475b6a4d461318eb3139cc54a3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfbebd805ee7945ad38bc26f8fa9f1b" category="list-text">Abra el laboratorio de Jupyter.</block>
  <block id="d81c10b932515c107a06a3737d985eaf" category="paragraph"><block ref="d81c10b932515c107a06a3737d985eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab3269ab0de58f5611205f6ace06f3af" category="list-text">Inicie sesión en la terminal y monte el volumen Cloud Volumes ONTAP .</block>
  <block id="cc0649b0871fde24c4a46e09186a36e0" category="list-text">Verifique el depósito creado en el volumen Cloud Volumes ONTAP mediante los comandos de AWS CLI.</block>
  <block id="4f31ff9815d3a8a959e7c557213068d6" category="paragraph">En esta validación, utilizamos un conjunto de datos de DBpedia, un esfuerzo comunitario de colaboración colectiva, para extraer contenido estructurado de la información creada en varios proyectos de Wikimedia.</block>
  <block id="06d6ccf33b49ed20a34cdc26b6820253" category="list-text">Descargue los datos de la ubicación de GitHub de DBpedia y extráigalos.  Utilice la misma terminal utilizada en la sección anterior.</block>
  <block id="7f50b7f719282741fdf7ce5b8ca1f3dd" category="list-text">Copie los datos en la ubicación de Cloud Volumes ONTAP y verifíquelos desde el depósito S3 mediante la AWS CLI.</block>
  <block id="0ecfbac978ab3f5979ec31eb5574d93e" category="list-text">Realice una validación básica para asegurarse de que la funcionalidad de lectura y escritura funcione en el bucket S3.</block>
  <block id="877169a066e14f0512d5f119945ef14d" category="section-title">Validar el aprendizaje automático desde Jupyter Notebooks</block>
  <block id="6f73420916237ed836932ccf967d82ba" category="paragraph">La siguiente validación permite construir, entrenar e implementar modelos de aprendizaje automático a través de la clasificación de texto utilizando el siguiente ejemplo de SageMaker BlazingText:</block>
  <block id="3cf03767e04159d1ec88e7fb0827b487" category="list-text">Instale los paquetes boto3 y SageMaker.</block>
  <block id="b1282d58a4dcde0a2015d98ad33afd4c" category="paragraph">Producción:</block>
  <block id="39017441ac701ebaef8de7116e7f71a0" category="list-text">En el siguiente paso, los datos<block ref="0a726fdd06082d233cd4eade40f12612" prefix="(" category="inline-code"></block> ) se descarga del depósito s3<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> a una instancia de Jupyter Notebook utilizada en aprendizaje automático.</block>
  <block id="a270350e3527fea9a36815fa5fe04ba0" category="list-text">El siguiente código crea la asignación de índices enteros a etiquetas de clase que se utilizan para recuperar el nombre de clase real durante la inferencia.</block>
  <block id="d17fa3d0aed3f8aaa5e78b447054126d" category="paragraph">La salida enumera los archivos y carpetas en el<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> depósitos que se utilizan como datos para la validación de aprendizaje automático de AWS SageMaker.</block>
  <block id="0cfbf64679378e3e5367734fd2bd69aa" category="list-text">Inicie la fase de preprocesamiento de datos para preprocesar los datos de entrenamiento en un formato de texto tokenizado y separado por espacios que pueda ser utilizado por el algoritmo BlazingText y la biblioteca nltk para tokenizar las oraciones de entrada del conjunto de datos DBPedia.  Descargue el tokenizador nltk y otras bibliotecas.  El<block ref="6d49a792c1080aa5b33d27ec694621b6" prefix=" " category="inline-code"></block> aplicado a cada instancia de datos en paralelo utiliza el módulo de multiprocesamiento de Python.</block>
  <block id="d68566815a7248bae03e105c2db8853a" category="list-text">Cargue el conjunto de datos formateados y de entrenamiento en S3 para que SageMaker pueda usarlo para ejecutar trabajos de entrenamiento.  Luego, cargue dos archivos en el depósito y prefije la ubicación usando el SDK de Python.</block>
  <block id="e886ad36e527d85b26c492618651edad" category="list-text">Configure una ubicación de salida en S3 donde se carga el artefacto del modelo para que los artefactos puedan ser la salida del trabajo de entrenamiento del algoritmo.  Crear una<block ref="6e3281884db83f9ee468a6e798b6bdfb" prefix=" " category="inline-code"></block> objeto para lanzar el trabajo de entrenamiento.</block>
  <block id="41215e143c2b3810b37c4e4f47819077" category="list-text">Definir SageMaker<block ref="a0b1f5f7b93af313b6e2452f52c8f3f6" prefix=" " category="inline-code"></block> con configuraciones de recursos e hiperparámetros para entrenar la clasificación de texto en el conjunto de datos DBPedia utilizando el modo supervisado en una instancia c4.4xlarge.</block>
  <block id="6c773c4d6e4a7dda7e00352894786bdb" category="list-text">Preparar un protocolo de enlace entre los canales de datos y el algoritmo.  Para ello, cree el<block ref="0e021845d2c0e4ad94a91ce444c13681" prefix=" " category="inline-code"></block> objetos de los canales de datos y los guarda en un diccionario para que el algoritmo los consuma.</block>
  <block id="3b29bef19a742b8ab66cddf620871d31" category="list-text">Una vez finalizado el trabajo, aparece un mensaje de Trabajo completado.  El modelo entrenado se puede encontrar en el bucket S3 que se configuró como<block ref="212ad7a4c11069727ffd02f333d7d8b1" prefix=" " category="inline-code"></block> en el estimador.</block>
  <block id="6cb5683d87e53b375bd915572f960759" category="list-text">Una vez finalizado el entrenamiento, implemente el modelo entrenado como un punto final alojado en tiempo real de Amazon SageMaker para realizar predicciones.</block>
  <block id="4254a612097ca58653de7c0c39da8df2" category="list-text">De forma predeterminada, el modelo devuelve una predicción con la mayor probabilidad.  Para recuperar la parte superior<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> predicciones, establecer<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> en el archivo de configuración.</block>
  <block id="67be4f1bb90039baec0d8f73ff82a47e" category="list-text">Elimine el punto final antes de cerrar el cuaderno.</block>
  <block id="16147684eb6910d9d73a43bb83091da4" category="summary">Los científicos e ingenieros de datos a menudo necesitan acceder a datos almacenados en formato NFS, pero acceder a estos datos directamente desde el protocolo S3 en AWS SageMaker puede ser un desafío porque AWS solo admite el acceso a buckets S3.  Sin embargo, NetApp ONTAP proporciona una solución al permitir el acceso de protocolo dual para NFS y S3.  Con esta solución, los científicos e ingenieros de datos pueden acceder a datos NFS desde notebooks de AWS SageMaker a través de buckets S3 desde NetApp Cloud Volumes ONTAP.  Este enfoque permite acceder fácilmente y compartir los mismos datos tanto de NFS como de S3 sin necesidad de software adicional.</block>
  <block id="e8ce8afdd7d335aed5b93d4a41ae0115" category="doc">TR-4967: Gestión de datos en la nube con la dualidad archivo-objeto de NetApp y AWS SageMaker</block>
  <block id="7caace9abf76a798c629a9134d1bb259" category="summary">Un caso de uso potencial para el acceso mediante protocolo dual de NFS y S3 se encuentra en los campos del aprendizaje automático y la ciencia de datos.  Por ejemplo, un equipo de científicos de datos podría estar trabajando en un proyecto de aprendizaje automático utilizando AWS SageMaker, que requiere acceso a datos almacenados en formato NFS.  Sin embargo, es posible que también sea necesario acceder a los datos y compartirlos a través de buckets S3 para colaborar con otros miembros del equipo o para integrarlos con otras aplicaciones que usan S3.</block>
  <block id="ee8cf3bf54dea46135e299d79fa1c179" category="paragraph">Esta solución utiliza las siguientes tecnologías:</block>
  <block id="a03ea23912d3b35c875ff398aa4888af" category="list-text">*Cuaderno de AWS SageMaker.*  Ofrece capacidades de aprendizaje automático a desarrolladores y científicos de datos para crear, entrenar e implementar modelos de aprendizaje automático de alta calidad de manera eficiente.</block>
  <block id="bbe2552dc6295d353c02fd85c243f334" category="list-text">* NetApp BlueXP.*  Permite el descubrimiento, la implementación y la operación del almacenamiento en las instalaciones, así como en AWS, Azure y Google Cloud.  Proporciona protección de datos contra pérdida de datos, amenazas cibernéticas e interrupciones no planificadas y optimiza el almacenamiento y la infraestructura de datos.</block>
  <block id="aa6fa71ab9848c5875470d36bbc2138a" category="list-text">* Cloud Volumes ONTAP de NetApp ONTAP.*  Proporciona volúmenes de almacenamiento de nivel empresarial con protocolos NFS, SMB/CIFS, iSCSI y S3 en AWS, Azure y Google Cloud, lo que brinda a los usuarios mayor flexibilidad para acceder y administrar sus datos en la nube.</block>
  <block id="eea496572a01ca3e5ced1dfe99a5809c" category="paragraph">NetApp Cloud Volumes ONTAP creado a partir de BlueXP para almacenar datos de ML.</block>
  <block id="923baf107dc23ca10f968a4fdecd4f4f" category="paragraph">La siguiente figura muestra los componentes técnicos de la solución.</block>
  <block id="8afbfe3aeb9c594404d5c244cf8f6024" category="inline-image-macro">Esta figura muestra los componentes técnicos de la solución.</block>
  <block id="d3d9ae40ce6d205245ae4b8c9649b6e2" category="paragraph"><block ref="d3d9ae40ce6d205245ae4b8c9649b6e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55c5281d80934f950192f768715495f0" category="paragraph">Al utilizar NetApp Cloud Volumes ONTAP, el equipo puede almacenar sus datos en una única ubicación y tenerlos accesibles con los protocolos NFS y S3.  Los científicos de datos pueden acceder a los datos en formato NFS directamente desde AWS SageMaker, mientras que otros miembros del equipo o aplicaciones pueden acceder a los mismos datos a través de buckets S3.</block>
  <block id="f8ba1b513231e9ca54a5c3b94733c28d" category="paragraph">Este enfoque permite acceder a los datos y compartirlos de forma fácil y eficiente sin necesidad de software adicional ni migración de datos entre diferentes soluciones de almacenamiento.  También permite un flujo de trabajo más optimizado y la colaboración entre los miembros del equipo, lo que resulta en un desarrollo más rápido y efectivo de modelos de aprendizaje automático.</block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">Este documento proporciona pautas recomendadas para usar Kafka con el almacenamiento de NetApp , incluidas pruebas de certificación Confluent Kafka, resultados de rendimiento, ajustes, conectores de Kafka y la función de reequilibrio automático.</block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">Este documento proporciona pautas recomendadas para usar Confluent Tiered Storage con almacenamiento NetApp , incluidas pruebas de verificación, resultados de rendimiento del almacenamiento en niveles, ajustes, conectores Confluent S3 y la función de autoequilibrio.  Teniendo en cuenta las políticas de ILM, el rendimiento de Confluent con múltiples pruebas de rendimiento para verificación y las API S3 estándares de la industria, el almacenamiento de objetos NetApp StorageGRID es una opción óptima para el almacenamiento en niveles de Confluent.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">¿Qué es Apache Kafka?</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">Detalles de los parámetros del sumidero S3</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">Apache Kafka</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Almacenamiento infinito en la plataforma Confluent</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Almacenamiento en niveles de Confluent: mejores prácticas y dimensionamiento</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Conector de receptor de Amazon S3 para la plataforma Confluent</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">El tamaño de Kafka</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">Dimensionamiento de StorageGRID</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Casos de uso de Kafka</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Clústeres de Kafka autoequilibrados en la plataforma Confluent 6.0</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">Este documento describe las pautas recomendadas para usar Kafka en un controlador de almacenamiento de NetApp .</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam, Joseph Kandatilparambil, NetApp Rankesh Kumar, Confluent</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka es una plataforma de transmisión de eventos distribuida por la comunidad capaz de gestionar billones de eventos al día.  Inicialmente concebido como una cola de mensajes, Kafka se basa en una abstracción de un registro de confirmación distribuido.  Desde que LinkedIn lo creó y lo puso en código abierto en 2011, Kafka ha evolucionado desde una cola de mensajes a una plataforma completa de transmisión de eventos.  Confluent ofrece la distribución de Apache Kafka con la plataforma Confluent.  La plataforma Confluent complementa Kafka con funciones comerciales y comunitarias adicionales diseñadas para mejorar la experiencia de transmisión tanto de operadores como de desarrolladores en producción a gran escala.</block>
  <block id="4a967c3b711955b2fd888bf0abedb515" category="paragraph">Este documento describe las pautas recomendadas para usar Confluent Tiered Storage en una oferta de almacenamiento de objetos de NetApp proporcionando el siguiente contenido:</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">Verificación confluente con almacenamiento de objetos de NetApp – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">Pruebas de rendimiento de almacenamiento por niveles</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">Pautas de mejores prácticas para Confluent en sistemas de almacenamiento NetApp</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">¿Por qué el almacenamiento en niveles de Confluent?</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">Este artículo de Confluent</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent se ha convertido en la plataforma de transmisión en tiempo real predeterminada para muchas aplicaciones, especialmente para big data, análisis y cargas de trabajo de transmisión.  El almacenamiento en niveles permite a los usuarios separar el procesamiento del almacenamiento en la plataforma Confluent.  Hace que el almacenamiento de datos sea más rentable, le permite almacenar cantidades prácticamente infinitas de datos y escalar cargas de trabajo hacia arriba (o hacia abajo) según demanda, y facilita las tareas administrativas como el reequilibrio de datos e inquilinos.  Los sistemas de almacenamiento compatibles con S3 pueden aprovechar todas estas capacidades para democratizar los datos con todos los eventos en un solo lugar, eliminando la necesidad de una ingeniería de datos compleja.  Para obtener más información sobre por qué debería utilizar almacenamiento por niveles para Kafka, consulte<block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block> .</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">¿Por qué NetApp StorageGRID para el almacenamiento en niveles?</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID es una plataforma de almacenamiento de objetos líder en la industria de NetApp.  StorageGRID es una solución de almacenamiento basada en objetos y definida por software que admite API de objetos estándar de la industria, incluida la API de Amazon Simple Storage Service (S3).  StorageGRID almacena y administra datos no estructurados a escala para proporcionar un almacenamiento de objetos seguro y duradero.  El contenido se coloca en el lugar correcto, en el momento correcto y en el nivel de almacenamiento correcto, lo que optimiza los flujos de trabajo y reduce los costos de los medios enriquecidos distribuidos globalmente.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">El mayor diferenciador de StorageGRID es su motor de políticas de gestión del ciclo de vida de la información (ILM) que permite la gestión del ciclo de vida de los datos basada en políticas.  El motor de políticas puede usar metadatos para administrar cómo se almacenan los datos a lo largo de su vida útil para optimizar inicialmente el rendimiento y optimizar automáticamente el costo y la durabilidad a medida que los datos envejecen.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">Habilitación del almacenamiento en niveles confluent</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">La idea básica del almacenamiento por niveles es separar las tareas de almacenamiento de datos del procesamiento de datos.  Con esta separación, resulta mucho más fácil que el nivel de almacenamiento de datos y el nivel de procesamiento de datos escalen de forma independiente.</block>
  <block id="ec4d623bd1019ab2fabc3a02ae9dc70d" category="paragraph">Una solución de almacenamiento por niveles para Confluent debe tener en cuenta dos factores.  En primer lugar, debe solucionar o evitar las propiedades comunes de consistencia y disponibilidad del almacén de objetos, como las inconsistencias en las operaciones LIST y la falta de disponibilidad ocasional de objetos.  En segundo lugar, debe gestionar correctamente la interacción entre el almacenamiento en niveles y el modelo de replicación y tolerancia a fallas de Kafka, incluida la posibilidad de que los líderes zombis sigan compensando rangos en niveles.  El almacenamiento de objetos de NetApp brinda disponibilidad de objetos constante y el modelo HA hace que el almacenamiento agotado esté disponible para rangos de compensación de niveles.  El almacenamiento de objetos de NetApp brinda disponibilidad de objetos constante y un modelo de alta disponibilidad (HA) para que el almacenamiento agotado esté disponible para rangos de compensación de niveles.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">Con el almacenamiento en niveles, puede usar plataformas de alto rendimiento para lecturas y escrituras de baja latencia cerca del final de sus datos de transmisión, y también puede usar almacenes de objetos más económicos y escalables como NetApp StorageGRID para lecturas históricas de alto rendimiento.  También tenemos una solución técnica para Spark con controlador de almacenamiento NetApp y los detalles están aquí.  La siguiente figura muestra cómo Kafka encaja en un flujo de trabajo de análisis en tiempo real.</block>
  <block id="eea5b5aaa7bc893f83efe26850f04584" category="paragraph"><block ref="eea5b5aaa7bc893f83efe26850f04584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0977e5b84fa31f5087efbbc1dc355236" category="paragraph">La siguiente figura muestra cómo NetApp StorageGRID encaja como nivel de almacenamiento de objetos de Confluent Kafka.</block>
  <block id="baa92f35a9209359bb52e9fa325d0e29" category="paragraph"><block ref="baa92f35a9209359bb52e9fa325d0e29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">Esta sección cubre el hardware y el software utilizados para la certificación Confluent.  Esta información es aplicable a la implementación de Kafka con almacenamiento NetApp .</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">Apresto</block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">El dimensionamiento de Kafka se puede realizar con cuatro modos de configuración: simple, granular, inverso y particiones.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">Simple</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">El modo simple es apropiado para quienes utilizan Apache Kafka por primera vez o para casos de uso en etapas iniciales.  Para este modo, debe proporcionar requisitos como el rendimiento en MBps, la distribución de lectura, la retención y el porcentaje de utilización de recursos (el 60 % es el valor predeterminado).  También ingresa al entorno, como local (bare-metal, VMware, Kubernetes u OpenStack) o en la nube.  En función de esta información, el dimensionamiento de un clúster de Kafka proporciona la cantidad de servidores necesarios para el broker, el zookeeper, los trabajadores de conexión de Apache Kafka, el registro de esquema, un proxy REST, ksqlDB y el centro de control de Confluent.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">Para el almacenamiento en niveles, considere el modo de configuración granular para dimensionar un clúster de Kafka.  El modo granular es apropiado para usuarios experimentados de Apache Kafka o casos de uso bien definidos.  Esta sección describe el dimensionamiento para productores, procesadores de flujo y consumidores.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">Productores</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Para describir los productores de Apache Kafka (por ejemplo, un cliente nativo, un proxy REST o un conector de Kafka), proporcione la siguiente información:</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*Nombre.*  Chispa.</block>
  <block id="b39a7ae16ea364375daa4f600ebed072" category="list-text">*Tipo de productor.*  Aplicación o servicio, proxy (REST, MQTT, otros) y base de datos existente (RDBMS, NOSQL, otros).  También puedes seleccionar "No sé".</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*Rendimiento promedio.*  En eventos por segundo (1.000.000 por ejemplo).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*Rendimiento máximo.*  En eventos por segundo (4.000.000 por ejemplo).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*Tamaño promedio del mensaje.*  En bytes, sin comprimir (máximo 1 MB; 1000 por ejemplo).</block>
  <block id="f56fd2104d8bf51910ee81196e8b4751" category="list-text">*Formato del mensaje.*  Las opciones incluyen Avro, JSON, buffers de protocolo, binario, texto, "No sé" y otros.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*Factor de replicación.*  Las opciones son 1, 2, 3 (recomendación Confluent), 4, 5 o 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*Tiempo de retención.*  Un día (por ejemplo).  ¿Cuánto tiempo desea que sus datos se almacenen en Apache Kafka?  Introduzca -1 con cualquier unidad por tiempo infinito.  La calculadora asume un tiempo de retención de 10 años para una retención infinita.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">Seleccione la casilla de verificación "¿Habilitar almacenamiento en niveles para disminuir la cantidad de agentes y permitir almacenamiento infinito?"</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">Cuando el almacenamiento en niveles está habilitado, los campos de retención controlan el conjunto activo de datos que se almacenan localmente en el agente.  Los campos de retención de archivo controlan durante cuánto tiempo se almacenan los datos en el almacenamiento de objetos de archivo.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*Retención de almacenamiento de archivo.*  Un año (por ejemplo).  ¿Durante cuánto tiempo desea que sus datos se mantengan almacenados en el almacenamiento de archivo?  Introduce -1 con cualquier unidad durante una duración infinita.  La calculadora asume una retención de 10 años para una retención infinita.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*Multiplicador de crecimiento.*  1 (por ejemplo).  Si el valor de este parámetro se basa en el rendimiento actual, configúrelo en 1.  Para ajustar el tamaño en función del crecimiento adicional, configure este parámetro en un multiplicador de crecimiento.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">*Número de instancias de productor.*  10 (por ejemplo).  ¿Cuántas instancias de productor se ejecutarán?  Esta entrada es necesaria para incorporar la carga de la CPU en el cálculo de tamaño.  Un valor en blanco indica que la carga de la CPU no está incorporada en el cálculo.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">Con base en este ejemplo de entrada, el dimensionamiento tiene el siguiente efecto sobre los productores:</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">Rendimiento promedio en bytes sin comprimir: 1 GBps.  Rendimiento máximo en bytes sin comprimir: 4 GBps.  Rendimiento promedio en bytes comprimidos: 400 MBps.  Rendimiento máximo en bytes comprimidos: 1,6 GBps.  Esto se basa en una tasa de compresión predeterminada del 60 % (puede cambiar este valor).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">Almacenamiento total en el broker requerido: 31 104 TB, incluida la replicación, comprimido.  Almacenamiento de archivo total fuera del bróker requerido: 378 432 TB, comprimido.  Usar<block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> para dimensionar StorageGRID .</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">Los procesadores de flujo deben describir sus aplicaciones o servicios que consumen datos de Apache Kafka y los producen nuevamente en Apache Kafka.  En la mayoría de los casos, estos se construyen en ksqlDB o Kafka Streams.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*Nombre.*  Serpentina de chispas.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*Tiempo de procesamiento.*  ¿Cuánto tiempo tarda este procesador en procesar un solo mensaje?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ms (transformación simple, sin estado) [ejemplo], 10 ms (operación en memoria con estado).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100 ms (operación de disco o red con estado), 1000 ms (llamada REST de terceros).</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">He evaluado este parámetro y sé exactamente cuánto tiempo lleva.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*Retención de salida.*  1 día (ejemplo).  Un procesador de flujo produce su salida en Apache Kafka.  ¿Cuánto tiempo desea que se almacenen estos datos de salida en Apache Kafka?  Introduce -1 con cualquier unidad durante una duración infinita.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">Seleccione la casilla de verificación "¿Habilitar almacenamiento en niveles para disminuir el número de agentes y permitir almacenamiento infinito?"</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*Retención de almacenamiento de archivo.*  1 año (por ejemplo).  ¿Durante cuánto tiempo desea que sus datos se mantengan almacenados en el almacenamiento de archivo?  Introduce -1 con cualquier unidad durante una duración infinita.  La calculadora asume una retención de 10 años para una retención infinita.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*Porcentaje de paso de salida.*  100 (por ejemplo).  Un procesador de flujo produce su salida en Apache Kafka.  ¿Qué porcentaje del rendimiento entrante se devolverá a Apache Kafka?  Por ejemplo, si el rendimiento de entrada es de 20 MBps y este valor es 10, el rendimiento de salida será de 2 MBps.</block>
  <block id="aa35062fd231efb888b1d664e6480c1d" category="list-text">¿Desde qué aplicaciones se lee esto?  Seleccione “Spark”, el nombre utilizado en el dimensionamiento basado en el tipo de productor.  Con base en la información anterior, puede esperar los siguientes efectos del tamaño en las instancias del procesador de flujo y las estimaciones de partición de temas:</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">Esta aplicación de procesador de flujo requiere la siguiente cantidad de instancias.  Es probable que los temas entrantes también requieran esta cantidad de particiones.  Póngase en contacto con Confluent para confirmar este parámetro.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1.000 para un rendimiento promedio sin multiplicador de crecimiento</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4.000 para un rendimiento máximo sin multiplicador de crecimiento</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1.000 para un rendimiento promedio con un multiplicador de crecimiento</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4.000 para un rendimiento máximo con un multiplicador de crecimiento</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">Consumidores</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Describa sus aplicaciones o servicios que consumen datos de Apache Kafka y no los producen nuevamente en Apache Kafka; por ejemplo, un cliente nativo o un conector de Kafka.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*Nombre.*  Consumidor de Spark.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*Tiempo de procesamiento.*  ¿Cuánto tiempo tarda este consumidor en procesar un solo mensaje?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ms (por ejemplo, una tarea simple y sin estado como el registro)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ms (escrituras rápidas en un almacén de datos)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ms (escrituras lentas en un almacén de datos)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000 ms (llamada REST de terceros)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">Algún otro proceso referencial de duración conocida.</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*Tipo de consumidor.*  Aplicación, proxy o receptor de un almacén de datos existente (RDBMS, NoSQL, otros).</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">¿Desde qué aplicaciones se lee esto?  Conecte este parámetro con el productor y el tamaño del flujo determinados previamente.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">Con base en la información anterior, debe determinar el tamaño de las instancias de consumidor y las estimaciones de partición de temas.  Una aplicación de consumidor requiere la siguiente cantidad de instancias.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">2.000 para un rendimiento promedio, sin multiplicador de crecimiento</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">8.000 para un rendimiento máximo, sin multiplicador de crecimiento</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">2.000 para un rendimiento promedio, incluido el multiplicador de crecimiento</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8.000 para un rendimiento máximo, incluido el multiplicador de crecimiento</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">Es probable que los temas entrantes también necesiten esta cantidad de particiones.  Comuníquese con Confluent para confirmar.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">Además de los requisitos para productores, procesadores de flujo y consumidores, debe proporcionar los siguientes requisitos adicionales:</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*Tiempo de reconstrucción.*  Por ejemplo, 4 horas.  Si un host de agente Apache Kafka falla, se pierden sus datos y se aprovisiona un nuevo host para reemplazar al host fallado, ¿con qué rapidez debe reconstruirse este nuevo host?  Deje este parámetro en blanco si se desconoce el valor.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*Objetivo de utilización de recursos (porcentaje).*  Por ejemplo, 60.  ¿Qué tan utilizados desea que estén sus hosts durante el rendimiento promedio?  Confluent recomienda una utilización del 60 % a menos que utilice clústeres de autoequilibrio de Confluent, en cuyo caso la utilización puede ser mayor.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">Describe tu entorno</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">¿En qué entorno se ejecutará su clúster?  ¿Amazon Web Services, Microsoft Azure, plataforma en la nube de Google, hardware local, VMware local, OpenStack local o Kubernates local?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*Detalles del anfitrión.*  Número de núcleos: 48 (por ejemplo), tipo de tarjeta de red (10GbE, 40GbE, 16GbE, 1GbE u otro tipo).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*Volúmenes de almacenamiento.*  Anfitrión: 12 (por ejemplo).  ¿Cuántos discos duros o SSD se admiten por host?  Confluent recomienda 12 discos duros por host.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*Capacidad/volumen de almacenamiento (en GB).*  1000 (por ejemplo).  ¿Cuánto almacenamiento puede almacenar un solo volumen en gigabytes?  Confluent recomienda discos de 1TB.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">*Configuración de almacenamiento.*  ¿Cómo se configuran los volúmenes de almacenamiento?  Confluent recomienda RAID10 para aprovechar todas las funciones de Confluent.  También se admiten JBOD, SAN, RAID 1, RAID 0, RAID 5 y otros tipos.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*Rendimiento de volumen único (MBps).*  125 (por ejemplo).  ¿Qué tan rápido puede leer o escribir un solo volumen de almacenamiento en megabytes por segundo?  Confluent recomienda discos duros estándar, que normalmente tienen un rendimiento de 125 MBps.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*Capacidad de memoria (GB).*  64 (por ejemplo).</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">Después de haber determinado sus variables ambientales, seleccione Dimensionar mi clúster.  Basándonos en los parámetros de ejemplo indicados anteriormente, determinamos el siguiente tamaño para Confluent Kafka:</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">*Apache Kafka.*  Número de corredores: 22.  Su clúster está limitado al almacenamiento.  Considere habilitar el almacenamiento por niveles para disminuir la cantidad de hosts y permitir un almacenamiento infinito.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">*Apache Guardián del Zoológico.*  Recuento: 5; Trabajadores de Apache Kafka Connect: Recuento: 2; Registro de esquema: Recuento: 2; Proxy REST: Recuento: 2; ksqlDB: Recuento: 2; Centro de control de Confluent: Recuento: 1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">Utilice el modo inverso para equipos de plataforma que no tengan un caso de uso en mente.  Utilice el modo de particiones para calcular cuántas particiones requiere un solo tema.  Ver<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> para dimensionar en función de los modos inverso y de particiones.</block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">Detalles de la arquitectura de la solución</block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">Esta sección cubre el hardware y el software utilizados para la verificación de Confluent.  Esta información se aplica a la implementación de la plataforma Confluent con almacenamiento NetApp .  La siguiente tabla cubre la arquitectura de la solución probada y los componentes base.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">Componentes de la solución</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">Detalles</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka versión 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">Tres cuidadores del zoológico</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">Cinco servidores de corredores</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">Cinco servidores de herramientas</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">Una Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">Un centro de control</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux (ubuntu 18.04)</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">Todos los servidores</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">NetApp StorageGRID para almacenamiento en niveles</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">Software StorageGRID</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000 (balanceador de carga)</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 x SGF6024</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 x 24 x 800 SSD</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">Protocolo S3</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100 GbE (conectividad de red entre el agente y las instancias de StorageGRID )</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 servidores Fujitsu PRIMERGY RX2540</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">Cada uno equipado con: * 2 CPU, 16 núcleos físicos en total * Intel Xeon * 256 GB de memoria física * Puerto dual de 100 GbE</block>
  <block id="06a768157cb89879ca041da1b730da6e" category="summary">Este documento proporciona pautas recomendadas para usar Dremio con almacenamiento NetApp , incluidas pruebas de certificación TPCDS, ajustes y detalles de casos de uso del cliente.</block>
  <block id="5539c6da3e2032488a631305f1265434" category="paragraph">En conclusión, este informe técnico ha proporcionado detalles de implementación completos de q Hybrid Iceberg Lakehouse con Dremio junto con varias fuentes de datos de controladores de almacenamiento de NetApp , incluidos ONTAP S3, NAS y StorageGRID.  El proceso de implementación se ejecutó con éxito y se utilizó la herramienta de evaluación comparativa TPC-DS para realizar 99 consultas SQL en las diferentes fuentes de datos.  El informe también ha explorado casos de uso de clientes dentro de NetApp, demostrando la versatilidad y eficacia de Dremio para satisfacer diversos requisitos comerciales.  Además, se examinó un caso de uso específico que involucraba a un cliente de ventas de autopartes, destacando la aplicación práctica y los beneficios de aprovechar Dremio para el análisis y la obtención de información de datos.</block>
  <block id="682cc1e627af4457882db17515ccaf5b" category="paragraph">En general, este documento sirve como un recurso valioso para comprender la implementación y el uso de Dremio con controladores de almacenamiento NetApp , mostrando sus capacidades y potencial para impulsar la toma de decisiones basada en datos y la optimización en diversas industrias.</block>
  <block id="c63354da3a3a21f3ae0083d0a275540c" category="list-text">Instalación de Zookeeper</block>
  <block id="661fab58be11f3fe0e5fd03c183c9a3b" category="paragraph"><block ref="661fab58be11f3fe0e5fd03c183c9a3b" category="inline-link-rx"></block></block>
  <block id="288e0e9ab8b8ac8737afefecf16f61fd" category="list-text">Dremio</block>
  <block id="d9f3b0f9c66b1c99f5e01fefb31f3280" category="paragraph"><block ref="d9f3b0f9c66b1c99f5e01fefb31f3280" category="inline-link-rx"></block></block>
  <block id="7d56340ec96dd44dedf67654c4b228a9" category="list-text">Configuración de Dremio con storageGRID</block>
  <block id="d6a7c21494adf18f10c2f9b2b6da5584" category="paragraph"><block ref="d6a7c21494adf18f10c2f9b2b6da5584" category="inline-link-rx"></block></block>
  <block id="719a5826913817829f2d138a33720835" category="list-text">Caso de uso de NetApp</block>
  <block id="abd766d13b2562c1684015edb41ddc75" category="paragraph"><block ref="abd766d13b2562c1684015edb41ddc75" category="inline-link-rx"></block></block>
  <block id="108f231402daaaf5b7a58841053615dd" category="summary">Hemos realizado la certificación con la Plataforma Dremio con validación lakehouse en NetApp Object storage.</block>
  <block id="3cd3290a9231e38be51fc2cb3ce01572" category="doc">Procedimiento de implementación</block>
  <block id="d44c5f08c906e8f8bc746c8e4083522e" category="inline-image-macro">Figura que muestra la arquitectura dremio con el controlador de almacenamiento NetApp</block>
  <block id="5e5f3a2661fa2ba525c6c6d493b1058d" category="paragraph">En esta validación de arquitectura de referencia, utilizamos una configuración de Dremio compuesta por un coordinador y cuatro ejecutores<block ref="b76f8c360d80a001aee0571894d68ba2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="07efd46e12f0d695c6aa9e2abf057781" category="section-title">Configuración de NetApp</block>
  <block id="82c8a5cee83d98576ecd7fb9135c1b41" category="list-text">Inicialización del sistema de almacenamiento</block>
  <block id="8028442c79907b3f88933ff5c16fac5e" category="list-text">Creación de una máquina virtual de almacenamiento (SVM)</block>
  <block id="ff602335ea946bbb0494a8ca5aa58bf5" category="list-text">Asignación de interfaces de red lógicas</block>
  <block id="c1d1275f7bc999e53ce84a9b2a48cc7f" category="list-text">Configuración y licencias de NFS, S3</block>
  <block id="bbc1adf735eb5e7f9c1e5bae1fb2aed8" category="paragraph">Siga los pasos a continuación para NFS (sistema de archivos de red): 1.  Cree un volumen de grupo flexible para NFSv4 o NFSv3.  En nuestra configuración para esta validación, hemos utilizado 48 SSD, 1 SSD dedicado al volumen raíz del controlador y 47 SSD distribuidos para NFSv4.  Verifique que la política de exportación NFS para el volumen Flex Group tenga permisos de lectura y escritura para la red de servidores Dremio.</block>
  <block id="77cf539931cef9f508e194dbd28a0bc0" category="list-text">En todos los servidores Dremio, cree una carpeta y monte el volumen Flex Group en esta carpeta a través de una interfaz lógica (LIF) en cada servidor Dremio.</block>
  <block id="575afa472f95d77f2af74b7f99bc9d28" category="paragraph">Siga los pasos a continuación para S3 (Servicio de almacenamiento simple):</block>
  <block id="28863b320894e844cb1d2df9a479aa31" category="list-text">Configure un servidor de almacén de objetos con HTTP habilitado y el estado de administrador establecido en "activo" mediante el comando "vserver object-store-server create".  Tiene la opción de habilitar HTTPS y configurar un puerto de escucha personalizado.</block>
  <block id="993520e0cce3e5f87179d01caa10a746" category="list-text">Cree un usuario de servidor de almacén de objetos mediante el comando "vserver object-store-server user create -user &lt;nombre de usuario&gt;".</block>
  <block id="4c7b617c418e3a5f7073d2d64ba8cb1c" category="list-text">Para obtener la clave de acceso y la clave secreta, puede ejecutar el siguiente comando: "set diag; vserver object-store-server user show -user &lt;username&gt;".  Sin embargo, en el futuro, estas claves se proporcionarán durante el proceso de creación del usuario o se podrán recuperar mediante llamadas a la API REST.</block>
  <block id="c3d4f7a6161c482cb921db78c64d1543" category="list-text">Establezca un grupo de servidores de almacén de objetos utilizando el usuario creado en el paso 2 y otorgue acceso.  En este ejemplo, proporcionamos "Acceso completo".</block>
  <block id="f346ebaf71f9d3850361e0b732a352f5" category="list-text">Cree dos depósitos S3 configurando su tipo en "S3".  Uno para la configuración de Dremio y otro para los datos del cliente.</block>
  <block id="3c29c74ed24f85f4cf464243c6d69bc7" category="section-title">Configuración de Zookeeper</block>
  <block id="a284e9d9802d2b863fce5aa237106342" category="paragraph">Puede utilizar la configuración del zoológico proporcionada por Dremio.  En esta validación, utilizamos un zookeeper independiente. Seguimos los pasos mencionados en este enlace web.<block ref="757110f854f50ea29baeb536bc067417" category="inline-link-rx"></block></block>
  <block id="fb6e0f74d4f2cd819e198308d0e560c8" category="section-title">Configuración de Dremio</block>
  <block id="3e793dc4b6b41d43692a24d29150ed55" category="paragraph">Seguimos este enlace web para instalar Dremio mediante paquete tar.</block>
  <block id="694299a05f621f9d6c47fbc0cdd75cdb" category="list-text">Crea un grupo Dremio.</block>
  <block id="28b115fb542519f28216941113c7fc69" category="list-text">Crear un usuario dremio.</block>
  <block id="6190c0f96190f68e7387989b98fecd3c" category="list-text">Crear directorios de Dremio.</block>
  <block id="b8d53340c1af1590a07a31d4782e75c8" category="list-text">Descargue el archivo tar desde<block ref="993599c5d8336ec040e5e84c23246c65" category="inline-link-rx"></block></block>
  <block id="38152bcebb8f6d46160b6d2462ce40a0" category="list-text">Desempaquete Dremio en el directorio /opt/dremio.</block>
  <block id="9af78d03c81be6e6dd350c73be883f9b" category="list-text">Crea un enlace simbólico para la carpeta de configuración.</block>
  <block id="a16cec17e87f61728dcdd563b7d8ecc7" category="list-text">Configure la configuración de su servicio (configuración de SystemD).</block>
  <block id="44aba27523001647040cfa3dab851cbb" category="list-text">Copie el archivo de unidad del demonio dremio desde /opt/dremio/share/dremio.service a /etc/systemd/system/dremio.service.</block>
  <block id="617a522470fb25e0b60757c2347779fd" category="list-text">Reiniciar el sistema</block>
  <block id="b0a645a7658dbbe597c81a61d8095535" category="list-text">Habilitar dremio para que se inicie durante el arranque.</block>
  <block id="715ae8a49286aaa14659522218602fba" category="list-text">Configurar Dremio en el coordinador.  Consulte Configuración de Dremio para obtener más información</block>
  <block id="940845b76f9832cb794ce21b8053c3d9" category="list-text">Dremio.conf</block>
  <block id="e49741f6cfbc4fdc21eaf59a034e694c" category="list-text">Sitio principal.xml</block>
  <block id="157bf0c98c644ad5d09f3dda0843bb8d" category="list-text">La configuración de Dremio se almacena en el almacenamiento de objetos de NetApp .  En nuestra validación, el bucket "dremioconf" reside en un bucket S3 de ontap.  La siguiente imagen muestra algunos detalles de las carpetas "scratch" y "uploads" del bucket S3 "dremioconf".</block>
  <block id="dec65ddc4408a5fd22bf6eef9c5dc2c4" category="inline-image-macro">Figura que muestra dremio con almacenamiento de objetos NetApp</block>
  <block id="3f6534c1dba4ce90c550aec7ec304146" category="paragraph"><block ref="3f6534c1dba4ce90c550aec7ec304146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="536241c2f7d1f3fbe227bc001b56b949" category="list-text">Configurar Dremio en ejecutores.  En nuestra configuración, tenemos 3 ejecutores.</block>
  <block id="98acd539813ecdb677a633c1e8d72ba9" category="list-text">dremio.conf</block>
  <block id="19aac463221a9324b146be45c5f27561" category="list-text">Core-site.xml: igual que la configuración del coordinador.</block>
  <block id="9ebe81db6df147f3eea7002c858d2821" category="admonition">NetApp recomienda StorageGRID como su principal solución de almacenamiento de objetos para entornos Datalake y Lakehouse.  Además, NetApp ONTAP se utiliza para la dualidad archivo/objeto.  En el contexto de este documento, hemos realizado pruebas en ONTAP S3 en respuesta a una solicitud del cliente y funciona exitosamente como fuente de datos.</block>
  <block id="5b8d6104bd7d25e99e47f619fdfd8f81" category="section-title">Configuración de múltiples fuentes</block>
  <block id="4ee12bc75bcc4f7fb3bbf527ef1d2720" category="list-text">Configurar ONTAP S3 y storageGRID como una fuente s3 en Dremio.</block>
  <block id="dbd1ae231acf755d63de74b16a8cbeb7" category="list-text">Panel de Dremio -&gt; conjuntos de datos -&gt; fuentes -&gt; agregar fuente.</block>
  <block id="c102e8893995a295f2cc62063b2e0cd5" category="list-text">En la sección general, actualice el acceso y la clave secreta de AWS.</block>
  <block id="71a7d593565f192b138481a0e8d335c4" category="list-text">En la opción avanzada, habilite el modo de compatibilidad, actualice las propiedades de conexión con los siguientes detalles.  La IP/nombre del punto final del controlador de almacenamiento de NetApp , ya sea de ontap S3 o storageGRID.</block>
  <block id="4f594a255a564afe3df4ac263caedbb5" category="list-text">Habilitar el almacenamiento en caché local cuando sea posible. Porcentaje máximo del caché total disponible para usar cuando sea posible = 100</block>
  <block id="c71df1ddac771fdc9b484b0ed6f6d9f7" category="inline-image-macro">Figura que muestra la lista de archivos del almacenamiento de objetos de NetApp</block>
  <block id="a4d1986a0b1a4f12d2237b0963d2e43d" category="list-text">Luego vea la lista de depósitos del almacenamiento de objetos de NetApp .<block ref="3774299f093c28855158f425c629b55d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c80afe9a6ef853e0d394059a332a406d" category="list-text">Vista de muestra de los detalles del depósito de storageGRID<block ref="e0f51eae5ca0e68849adc9661a7def73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18ebb902e9ccb331331d9d1b8b5e0f76" category="list-text">Configurar NAS (específicamente NFS) como fuente en Dremio.</block>
  <block id="08a5aec8691cede64f84acb42700e07d" category="list-text">En la sección general, ingrese el nombre y la ruta de montaje NFS.  Asegúrese de que la ruta de montaje de NFS esté montada en la misma carpeta en todos los nodos del clúster Dremio.</block>
  <block id="eaa2d3817be8fb7b330c01f9605f0808" category="paragraph"><block ref="eaa2d3817be8fb7b330c01f9605f0808" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26b17225b626fb9238849fd60eabdf60" category="paragraph">+</block>
  <block id="b134468afaa618eaef2e7bfaf5f30da7" category="summary">Este documento describe las pautas recomendadas para usar Dremio en un controlador de almacenamiento NetApp .</block>
  <block id="53bd7dac219a2662a137c6de870224d2" category="doc">La solución Iceberg Lakehouse híbrida de próxima generación de NetApp y Dremio</block>
  <block id="0c74f27a6d1c41b83e5cc59468f24a0d" category="paragraph">En este documento, analizamos los detalles de implementación de Dremio con diferentes fuentes de datos de los controladores de almacenamiento de NetApp , incluidos ONTAP S3, NAS y StorageGRID.  Durante la implementación, utilizamos la herramienta de evaluación comparativa TPC-DS para ejecutar 99 consultas SQL en varias fuentes.  El documento también explora casos de uso de clientes dentro de NetApp, así como un caso de uso que involucra a un cliente de ventas de repuestos de automóviles.</block>
  <block id="d4b28ab5babb078bc6498faee7c53a81" category="summary">Esta sección cubre el hardware y el software utilizados para la certificación dremio.  Esta información es aplicable a la implementación de dremio con almacenamiento NetApp .</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">Descripción general de la solución</block>
  <block id="9953e901936889810e67ec0949c6b2fc" category="paragraph">La solución Hybrid Iceberg Lakehouse ofrece beneficios únicos para abordar los desafíos que enfrentan los clientes del lago de datos.  Al aprovechar la plataforma Dremio Unified Lakehouse y las soluciones NetApp ONTAP, StorageGRID y NetApp Cloud, las empresas pueden agregar valor significativo a sus operaciones comerciales.  La solución no solo brinda acceso a múltiples fuentes de datos, incluidas las fuentes de NetApp , sino que también mejora el rendimiento analítico general y ayuda a las empresas a generar conocimientos comerciales que conducen al crecimiento empresarial.</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">Descripción general de NetApp</block>
  <block id="b630104207f28e8a0523849fe77c1e9f" category="list-text">Las ofertas de NetApp, como ONTAP y StorageGRID, permiten la separación del almacenamiento y la computación, lo que posibilita una utilización óptima de los recursos según los requisitos específicos.  Esta flexibilidad permite a los clientes escalar de forma independiente su almacenamiento utilizando soluciones de almacenamiento de NetApp.</block>
  <block id="bc213af00312a8c2d752b8b42715eed6" category="list-text">Al aprovechar los controladores de almacenamiento de NetApp, los clientes pueden servir datos de manera eficiente a su base de datos vectorial utilizando los protocolos NFS y S3.  Estos protocolos facilitan el almacenamiento de datos de clientes y administran el índice de la base de datos vectorial, eliminando la necesidad de múltiples copias de datos a los que se accede a través de métodos de archivos y objetos.</block>
  <block id="1557c431be0fea4f212f4006eafc9a8c" category="list-text">NetApp ONTAP proporciona soporte nativo para NAS y almacenamiento de objetos en los principales proveedores de servicios de nube como AWS, Azure y Google Cloud.  Esta amplia compatibilidad garantiza una integración perfecta, lo que permite la movilidad de los datos del cliente, la accesibilidad global, la recuperación ante desastres, la escalabilidad dinámica y el alto rendimiento.</block>
  <block id="392d70ca39f31f10bd637936769788df" category="section-title">StorageGRID</block>
  <block id="9409f64cd9405163cc619bf89c44eaf4" category="paragraph">Nuestro almacenamiento de objetos líder en la industria, storageGRID, ofrece un potente motor de políticas para la ubicación automatizada de datos, opciones de implementación flexibles y una durabilidad inigualable con codificación de borrado en capas.  Tiene una arquitectura escalable que admite miles de millones de objetos y petabytes de datos en un solo espacio de nombres.  La solución permite la integración de la nube híbrida, lo que permite la organización de datos en niveles en las principales plataformas de nube.  Ha sido reconocido como líder en la Evaluación mundial de proveedores basados en objetos de IDC Marketscape 2019.</block>
  <block id="546a8027b219510c369554288fd7eff4" category="paragraph">Además, storageGRID se destaca en la gestión de datos no estructurados a escala con almacenamiento de objetos definido por software, redundancia geográfica y capacidades de múltiples sitios.  Incorpora gestión del ciclo de vida de la información basada en políticas y ofrece funciones de integración en la nube como duplicación y búsqueda.  Cuenta con diversas certificaciones, entre ellas Common Criteria, NF203 Digital Safe Component, ISO/IEC 25051, KPMG y Cohasset Compliance Assessment.</block>
  <block id="030de30483fabd3aca42be7503592961" category="paragraph">En resumen, NetApp storageGRID ofrece potentes funciones, escalabilidad, integración de nube híbrida y certificaciones de cumplimiento para una gestión eficiente de datos no estructurados a escala.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">ONTAP de NetApp</block>
  <block id="185a43d593912638c2bb37ef99444fc9" category="paragraph">NetApp ONTAP es una solución de almacenamiento sólida que ofrece una amplia gama de funciones empresariales.  Incluye Snapshot, que proporciona copias de seguridad instantáneas, consistentes con la aplicación y a prueba de manipulaciones.  SnapRestore permite la restauración casi instantánea de copias de seguridad a pedido, mientras que SnapMirror ofrece capacidades integradas de copia de seguridad remota y recuperación ante desastres.  La solución también incorpora Autonomous Ransomware Protection (ARP), que garantiza la seguridad de los datos con funciones como verificación de múltiples administradores, cifrado de datos en reposo con certificación FIPS, cifrado de datos en tránsito, autenticación multifactor (MFA) y control de acceso basado en roles (RBAC).  El registro integral, la auditoría, la gestión de claves integradas y externas, la purga segura y la gestión segura de múltiples inquilinos mejoran aún más la seguridad y el cumplimiento de los datos.</block>
  <block id="48af054a9eb5d217f15aab37f5fe9b91" category="paragraph">NetApp ONTAP también cuenta con SnapLock, que proporciona retención de datos que cumple con las normativas con altos niveles de integridad, rendimiento y retención a un bajo costo total de propiedad.  Está completamente integrado con NetApp ONTAP 9 y ofrece protección contra actos maliciosos, administradores deshonestos y ransomware.</block>
  <block id="afd4da5566327275499951d8db99e683" category="paragraph">La solución incluye cifrado NSE/NVE para cifrado en tránsito y de datos en reposo, acceso de administrador multifactor y verificación de múltiples administradores.  Active IQ proporciona análisis predictivos y acciones correctivas basados en IA, mientras que QoS garantiza el control de la carga de trabajo de la calidad del servicio.  La integración de la gestión y la automatización es intuitiva a través de SysMgr/GUI/CLI/API.  FabricPool permite la clasificación automática de datos y la solución ofrece eficiencia a través de la compresión, deduplicación y compactación de datos en línea.  NetApp garantiza el cumplimiento de los objetivos de eficiencia de la carga de trabajo sin coste para el cliente.</block>
  <block id="327b294a4782dbbd617ca02b0227198e" category="paragraph">NetApp ONTAP admite varios protocolos, incluidos NVMe/FC, FC, NVMe/TCP, iSCSI, NFS, SMB y S3, lo que lo convierte en una solución de almacenamiento unificada.  En general, NetApp ONTAP ofrece amplias funciones empresariales, seguridad sólida, cumplimiento, eficiencia y versatilidad para satisfacer diversas necesidades de almacenamiento.</block>
  <block id="5504df296ab63119754ecfd92e6a07d7" category="section-title">Descripción general de Dremio</block>
  <block id="46664b9047c24c224cf4898236ac4159" category="paragraph">Dremio es la plataforma unificada de Lakehouse para análisis de autoservicio e IA.  La plataforma de análisis unificado Dremio acerca a los usuarios a los datos con la flexibilidad, escalabilidad y rendimiento de un lago a una fracción del costo de las soluciones de almacenamiento de datos tradicionales.  Dremio permite el análisis "shift-left" para eliminar la integración de datos y ETL complejos y costosos, brindando un análisis a escala empresarial sin inconvenientes y sin movimiento de datos.  Dremio también incluye:</block>
  <block id="2f0acfc3dbf17a0571810cc0dedaf64f" category="list-text">Análisis de autoservicio fácil de usar habilitado a través de una capa semántica universal y un motor de consulta SQL altamente integrado y de alto rendimiento, lo que facilita la conexión, la gestión y el análisis de todos los datos, tanto en la nube como en las instalaciones.</block>
  <block id="88be140c20067da1baf354c05223a2c6" category="list-text">Las capacidades de administración de lakehouse nativas de Apache Iceberg de Dremio simplifican el descubrimiento de datos y automatizan la optimización de datos, brindando análisis de alto rendimiento con versiones de datos inspiradas en Git.</block>
  <block id="fe08740b7cac34b055da6ec6bfe79c3f" category="list-text">Dremio, basado en código abierto y estándares abiertos, permite a las empresas evitar el estancamiento y permanecer posicionadas para la innovación.  Las empresas confían en Dremio como la plataforma lakehouse más fácil de usar y con la mejor relación precio-rendimiento en todas las cargas de trabajo.</block>
  <block id="e95806f0d7b4743b250387c094acef2b" category="section-title">¿Qué valor ofrece la solución híbrida Iceberg Lakehouse de Dremio y NetApp a los clientes?</block>
  <block id="81c79525dc5cb78051ffe86a4b85377f" category="list-text">*Gestión y accesibilidad de datos mejoradas*: Dremio es conocido por su plataforma de lago de datos que permite a las organizaciones consultar datos directamente desde sus lagos de datos a alta velocidad.  NetApp, por otro lado, es un proveedor líder de servicios de datos en la nube y soluciones de almacenamiento de datos.  La oferta conjunta proporciona a los clientes una solución integral para almacenar, gestionar, acceder y analizar los datos de su empresa de forma eficiente y eficaz.</block>
  <block id="4bb8954089d2a9fb6c99825861c39f62" category="list-text">*Optimización del rendimiento*: Con la experiencia de NetApp en almacenamiento de datos y las capacidades de Dremio en procesamiento y optimización de datos, la asociación ofrece una solución que mejora el rendimiento de las operaciones de datos, reduce la latencia y aumenta la velocidad para obtener información empresarial.  Dremio incluso ha proporcionado beneficios de rendimiento a la propia infraestructura analítica de TI interna de NetApp.</block>
  <block id="737f740962d700c8fb65a99e34900bc9" category="list-text">*Escalabilidad*: Tanto Dremio como NetApp ofrecen una solución diseñada para escalar.  La solución conjunta proporciona a los clientes entornos de almacenamiento, gestión y análisis de datos altamente escalables.  En un entorno híbrido Iceberg Lakehouse, el motor de consulta SQL de Dremio combinado con NetApp StorageGRID ofrece escalabilidad, simultaneidad y rendimiento de consultas incomparables, capaz de gestionar las necesidades analíticas de cualquier empresa.</block>
  <block id="38eb37e9ecd9ccb05b8fda4a7890c571" category="list-text">*Seguridad y gobernanza de datos*: Ambas empresas tienen un fuerte enfoque en la seguridad y gobernanza de datos.  Juntos, ofrecen funciones robustas de seguridad y gobernanza de datos, lo que garantiza que los datos estén protegidos y que se cumplan los requisitos de gobernanza de datos.  Características como controles de acceso basados en roles y de grano fino, auditoría integral, linaje de datos de extremo a extremo, gestión de identidad unificada y SSO con un amplio marco de cumplimiento y seguridad garantizan que los entornos de datos analíticos de las empresas sean seguros y estén gobernados.</block>
  <block id="b10c860483a8763cd915a0459af4c444" category="list-text">*Relación costo-eficiencia*: Al integrar el motor de lago de datos de Dremio con las soluciones de almacenamiento de NetApp, los clientes pueden reducir los costos asociados con la gestión y el movimiento de datos.  Las organizaciones también pueden migrar de entornos de data lake tradicionales a una solución de lakehouse más moderna compuesta por NetApp y Dremio.  Esta solución híbrida Iceberg Lakehouse ofrece un rendimiento de consultas de alta velocidad y una concurrencia de consultas líder en el mercado que reduce el TCO y el tiempo para obtener información comercial.</block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">Esta sección describe la tecnología utilizada en esta solución.</block>
  <block id="910af13beca7193218f534b5af1d8881" category="doc">Requisitos tecnológicos</block>
  <block id="915f99cb757b24fafb485b82cc5fe20e" category="paragraph">Las configuraciones de hardware y software que se describen a continuación se utilizaron para las validaciones realizadas en este documento.  Estas configuraciones sirven como guía para ayudarle a configurar su entorno. Sin embargo, tenga en cuenta que los componentes específicos pueden variar según los requisitos individuales del cliente.</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">Requisitos de hardware</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">Hardware</block>
  <block id="74cc4ae913d72260c083ab2b346121ec" category="cell">Par HA de matriz de almacenamiento AFF de NetApp</block>
  <block id="e4044b704224bc11ad4a58e92f2131d7" category="list-text">A800</block>
  <block id="8020ad245e7cbc2ac49c84b7f4ace684" category="list-text">ONTAP 9.14.1</block>
  <block id="4c365c4afab33ac328254bd7c2ae19a9" category="list-text">48 unidades SSD-NVM de 3,49 TB</block>
  <block id="fe001f20ed0495ea55b4938631878b7a" category="list-text">Dos depósitos S3: metadatos de Dremio y datos de clientes.</block>
  <block id="637071f2d4a8f15942d2e18657010fa9" category="cell">4 x FUJITSU PRIMERGY RX2540 M4</block>
  <block id="e0c5e2628a6e691fa3fafe35f3bf20c3" category="list-text">64 CPU</block>
  <block id="319d86787ef65ef260e666cc63f6e1a3" category="list-text">Procesador Intel Xeon Gold 6142 a 2,60 GHz</block>
  <block id="d6b9b9dc5caf5833c325bc02278f4817" category="list-text">Memoria física de 256 GM</block>
  <block id="81555075e106886f4be11de9599425a6" category="list-text">1 puerto de red de 100 GbE</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">Redes</block>
  <block id="edcd3f3adc6d51b309e9115847fa497f" category="list-text">100 GbE</block>
  <block id="9de4526063d2d5dc8600f1abb273fb87" category="cell">* 1 x SG100, 3 x SGF6024 * 3 x 24 x 7,68 TB * Dos buckets S3: metadatos de Dremio y datos de clientes.</block>
  <block id="500084ff15a1d3831b2b0a0cc8efb3b4" category="list-text">versión - 25.0.3-202405170357270647-d2042e1b</block>
  <block id="b5251cb924b1e27d2fa914e7b3dbd75c" category="list-text">Edición empresarial</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="cell">En las instalaciones</block>
  <block id="fd50fb0f59921345e87394051ed99e40" category="list-text">Clúster Dremio de 5 nodos</block>
  <block id="743d1e7bf62dfc8a183c666693662dc6" category="list-text">1 coordinador maestro y 4 ejecutores</block>
  <block id="cce86ec0e697036ce6aa6105904b06de" category="summary">Esta sección cubre los detalles del caso de uso del cliente de Dremio con almacenamiento de objetos Netapp.</block>
  <block id="fe0bd5fc290c9a203c8e8f18a2b6e647" category="doc">Casos de uso de clientes</block>
  <block id="46233f9bd0306ff790c810922b25e957" category="section-title">Caso de uso de NetApp ActiveIQ</block>
  <block id="994534c401b3a0f86cd899f3b7b6ec57" category="inline-image-macro">Arquitectura antigua de ActiveIQ</block>
  <block id="3002c8327e7407633cb1d61c6e798c05" category="paragraph"><block ref="3002c8327e7407633cb1d61c6e798c05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e9e9a9c8ceef33ee9b9839f01cdf06a" category="paragraph">*Desafío*: La solución interna Active IQ de NetApp, diseñada inicialmente para soportar numerosos casos de uso, había evolucionado hasta convertirse en una oferta integral tanto para usuarios internos como para clientes.  Sin embargo, la infraestructura subyacente de backend basada en Hadoop/MapR planteó desafíos en términos de costos y rendimiento, debido al rápido crecimiento de los datos y la necesidad de un acceso eficiente a los mismos.  Ampliar el almacenamiento implicaba añadir recursos informáticos innecesarios, lo que generaba mayores costos.</block>
  <block id="66c90395e80a7e0f428abf5cf77fa1f4" category="paragraph">Además, gestionar el clúster Hadoop consumía mucho tiempo y requería conocimientos especializados.  Los problemas de rendimiento y gestión de datos complicaron aún más la situación: las consultas tardaban un promedio de 45 minutos y los recursos se agotaban debido a configuraciones incorrectas.  Para abordar estos desafíos, NetApp buscó una alternativa al entorno Hadoop existente y determinó que una nueva solución moderna basada en Dremio reduciría costos, desacoplaría el almacenamiento y el cómputo, mejoraría el rendimiento, simplificaría la gestión de datos, ofrecería controles detallados y proporcionaría capacidades de recuperación ante desastres.</block>
  <block id="f4327571cd8b76a68a25a1d8487a0db0" category="inline-image-macro">Nueva arquitectura de ActiveIQ con dremio</block>
  <block id="954cc37909c75a2221a99b0c02a26f82" category="paragraph">*Solución*:<block ref="4a878fba67d10f0324250d8d1dafdcc5" category="inline-image-macro-rx" type="image"></block> Dremio permitió a NetApp modernizar su infraestructura de datos basada en Hadoop en un enfoque gradual, proporcionando una hoja de ruta para análisis unificados.  A diferencia de otros proveedores que requirieron cambios significativos en el procesamiento de datos, Dremio se integró perfectamente con las tuberías existentes, ahorrando tiempo y gastos durante la migración.  Al realizar la transición a un entorno completamente en contenedores, NetApp redujo la sobrecarga de administración, mejoró la seguridad y mejoró la resiliencia.  La adopción por parte de Dremio de ecosistemas abiertos como Apache Iceberg y Arrow garantizó la protección futura, la transparencia y la extensibilidad.</block>
  <block id="6f323477260e85221bf9876e157b69d0" category="paragraph">Como reemplazo de la infraestructura Hadoop/Hive, Dremio ofreció funcionalidad para casos de uso secundarios a través de la capa semántica.  Si bien los mecanismos de ingesta de datos y ETL basados en Spark existentes se mantuvieron, Dremio proporcionó una capa de acceso unificada para facilitar el descubrimiento y la exploración de datos sin duplicación.  Este enfoque redujo significativamente los factores de replicación de datos y desacopló el almacenamiento de la computación.</block>
  <block id="ef3e4aef01dbcfe8475e127bc34ac240" category="paragraph">*Beneficios*: Con Dremio, NetApp logró importantes reducciones de costos al minimizar el consumo de cómputo y los requisitos de espacio en disco en sus entornos de datos.  El nuevo Active IQ Data Lake está compuesto por 8.900 tablas que contienen 3 petabytes de datos, en comparación con la infraestructura anterior con más de 7 petabytes.  La migración a Dremio también implicó la transición de 33 miniclústeres y 4000 núcleos a 16 nodos ejecutores en clústeres de Kubernetes.  Incluso con disminuciones significativas en los recursos informáticos, NetApp experimentó mejoras notables en el rendimiento.  Al acceder directamente a los datos a través de Dremio, el tiempo de ejecución de las consultas se redujo de 45 minutos a 2 minutos, lo que resultó en un tiempo 95 % más rápido para obtener información para el mantenimiento predictivo y la optimización.  La migración también produjo una reducción de más del 60% en los costos de procesamiento, consultas más de 20 veces más rápidas y un ahorro de más del 30% en el costo total de propiedad (TCO).</block>
  <block id="a0c64f41c7126c9e86274e0e58d4bc01" category="section-title">Caso de uso de un cliente de venta de autopartes.</block>
  <block id="866dec6bda5d640e2bb5d1c8de8d6f67" category="paragraph">*Desafíos*: Dentro de esta empresa global de ventas de autopartes, los grupos de planificación y análisis financiero ejecutivo y corporativo no pudieron obtener una visión consolidada de los informes de ventas y se vieron obligados a leer los informes de métricas de ventas de cada línea de negocios e intentar consolidarlos.  Esto dio lugar a que los clientes tomaran decisiones con datos que tenían al menos un día de antigüedad.  Los plazos para obtener nuevos conocimientos analíticos normalmente demoran más de cuatro semanas.  La solución de problemas en las canalizaciones de datos requeriría incluso más tiempo, sumando tres días o más al ya extenso cronograma.  El lento proceso de desarrollo de informes, así como su rendimiento, obligaron a la comunidad de analistas a esperar continuamente a que los datos se procesaran o cargaran, en lugar de permitirles descubrir nuevos conocimientos comerciales e impulsar nuevos comportamientos comerciales.  Estos entornos problemáticos estaban compuestos por numerosas bases de datos diferentes para distintas líneas de negocio, lo que daba lugar a numerosos silos de datos.  El entorno lento y fragmentado complicó la gobernanza de los datos, ya que había demasiadas formas para que los analistas elaboraran su propia versión de la verdad frente a una única fuente de verdad.  El enfoque costó más de 1,9 millones de dólares en costos de plataforma de datos y personal.  El mantenimiento de la plataforma heredada y el cumplimiento de las solicitudes de datos requerían siete ingenieros técnicos de campo (ETC) por año.  Con el aumento de las solicitudes de datos, el equipo de inteligencia de datos no pudo escalar el entorno heredado para satisfacer las necesidades futuras.</block>
  <block id="9de1ea6ce232738b38a6f50397411de0" category="paragraph">*Solución*: Almacenar y administrar de forma rentable tablas Iceberg grandes en NetApp Object Store.  Cree dominios de datos utilizando la capa semántica de Dremio, lo que permite a los usuarios comerciales crear, buscar y compartir productos de datos fácilmente.</block>
  <block id="859dc66fff375d140e35011f5d94d363" category="paragraph">*Beneficios para el cliente*: • Arquitectura de datos existente mejorada y optimizada y tiempo reducido para obtener información de cuatro semanas a solo horas • Tiempo de resolución de problemas reducido de tres días a solo horas • Costos de plataforma y administración de datos reducidos en más de $380,000 • (2) FTE de esfuerzo de inteligencia de datos ahorrados por año</block>
  <block id="4bf80525d5b2bad7362ea2ddc1239135" category="summary">Realizamos la prueba tpc-ds con cinco nodos para cargas de trabajo SQL con el almacenamiento de objetos NetApp , como en ONTAP y StorageGrid.</block>
  <block id="07c6b8ec7b7d3f9f4e97f8cab49e9952" category="doc">Descripción general de la verificación de la solución</block>
  <block id="d234b1c706880318f115c69f47d6dfa1" category="paragraph">En esta sección, hemos ejecutado consultas de prueba SQL desde múltiples fuentes para verificar la funcionalidad, probar y verificar el derrame al almacenamiento de NetApp .</block>
  <block id="399acee44d644dcec9afa1fb807677db" category="section-title">Consulta SQL sobre almacenamiento de objetos</block>
  <block id="fdbf3a00f4ffd80f1b71f818ac8c17b1" category="list-text">Establezca la memoria en 250 GB por servidor en dremio.env</block>
  <block id="f01e72d5763f7ff9b6212ae55fe5a618" category="list-text">Verifique la ubicación del derrame (${DREMIO_HOME}"/dremiocache) en el archivo dremio.conf y los detalles de almacenamiento.</block>
  <block id="c1fd3f5160a9be68b59f1459ab2d43ab" category="list-text">Apunte la ubicación de derrame de Dremio al almacenamiento NFS de NetApp</block>
  <block id="876f04ac63af2ea2d5f8fa3785b310ca" category="list-text">Seleccione el contexto.  En nuestra prueba, ejecutamos la prueba contra archivos parquet generados por TPCDS que residen en ONTAP S3.  Panel de control de Dremio -&gt; Ejecutor SQL -&gt; contexto -&gt; NetAppONTAPS3-&gt;Parquet1TB</block>
  <block id="005d28008e05dae0767805243a8fb4e4" category="inline-image-macro">Establezca el contexto en la carpeta parquet ontaps3</block>
  <block id="1737725edbb24ea279e1a45444de8083" category="paragraph"><block ref="1737725edbb24ea279e1a45444de8083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d627092b3c15550dd7a319a2762deb9" category="list-text">Ejecute la consulta TPC-DS67 desde el panel de Dremio</block>
  <block id="d73e35125ec82123636d65f59cd30912" category="inline-image-macro">Ejecute la consulta 67, que es una de las 99 consultas en TPC-DS</block>
  <block id="af576e90e15d8a6ff15105e65b4de6ca" category="paragraph"><block ref="af576e90e15d8a6ff15105e65b4de6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2f6a29c6a6cbd53a7eb78e09592b591" category="list-text">Verifique que el trabajo se esté ejecutando en todos los ejecutores.  Panel de Dremio -&gt; trabajos -&gt; &lt;jobid&gt; -&gt; perfil sin procesar -&gt; seleccionar EXTERNAL_SORT -&gt; Nombre de host</block>
  <block id="cc8a9d0051ce4ea66245ee1201332dba" category="inline-image-macro">lista de nodos en la consulta Q67</block>
  <block id="de7e26680d69dfee92356b33d4b9e852" category="paragraph"><block ref="de7e26680d69dfee92356b33d4b9e852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8ae43960f655adfac548cc72fd74e60" category="list-text">Cuando se ejecuta la consulta SQL, puede verificar la carpeta dividida para el almacenamiento en caché de datos en el controlador de almacenamiento de NetApp .</block>
  <block id="a6b711eedf77bebde70bdfc6f869c41f" category="inline-image-macro">detalles de derrame cuando se completa la consulta 67</block>
  <block id="9e9d6f8f3555c800bdfb98b69c82c2df" category="list-text">La consulta SQL se completó con derrame<block ref="d1b3ed2b7bf78249ccd584f190063118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="29f8ef4d2e7065fbaf7af29841718352" category="inline-image-macro">Resumen del trabajo de la consulta completada 67</block>
  <block id="af756b25baef2ba53e554daaf6f7d4b3" category="list-text">Resumen de finalización del trabajo.<block ref="91ffddffe841fcfba2fc7aad3683dff3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de80fdbcc7438b84f536fcf74c03921" category="inline-image-macro">Detalles de Splleddata del resultado de la consulta</block>
  <block id="eacfb80ed9b3da589a06f11817a18a8e" category="list-text">Verifique el tamaño de los datos derramados<block ref="c25c4cfe2a16a40eeaf1652c7ba5d9f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f8d7f6ab5b07156f7006507270c9869" category="paragraph">El mismo procedimiento se aplica para el almacenamiento de objetos NAS y StorageGRID .</block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">Esta sección proporciona un resumen de los casos de uso y las soluciones proporcionadas por NetApp para cumplir con varios requisitos de protección de datos de Hadoop.</block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">Esta sección proporciona un resumen de los casos de uso y las soluciones proporcionadas por NetApp para cumplir con varios requisitos de protección de datos de Hadoop.  Al utilizar la estructura de datos impulsada por NetApp, los clientes pueden:</block>
  <block id="095ece35729c37846889cf00d16bb141" category="list-text">Tenga la flexibilidad de elegir las soluciones de protección de datos adecuadas aprovechando las ricas capacidades de gestión de datos de NetApp y la integración con los flujos de trabajo nativos de Hadoop.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Reduce el tiempo de copia de seguridad de su clúster Hadoop en casi un 70%.</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Elimina cualquier efecto en el rendimiento resultante de las copias de seguridad del clúster Hadoop.</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">Proporciona protección de datos multicloud y acceso a datos de diferentes proveedores de nube simultáneamente a una única fuente de datos analíticos.</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">Cree copias de clústeres Hadoop rápidas y que ahorran espacio utilizando la tecnología FlexClone .</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">Para obtener más información sobre la información descrita en este documento, consulte los siguientes documentos y/o sitios web:</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">Soluciones de análisis de big data de NetApp</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">Carga de trabajo de Apache Spark con almacenamiento de NetApp</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">Soluciones de almacenamiento de NetApp para Apache Spark</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">Apache Hadoop en la red de datos habilitada por NetApp</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">Expresiones de gratitud</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland, Representante de ventas, Ventas del distrito de Victoria de ANZ, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, Gerente de Desarrollo Comercial, NetApp</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, Director de MPSG, NetApp</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, ingeniero de sistemas, ANZ Victoria District SE, NetApp</block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">Historial de versiones</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">Fecha</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">Historial de versiones del documento</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">Versión 1.0</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">enero de 2018</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">Lanzamiento inicial</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">Versión 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">octubre de 2021</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">Actualizado con el caso de uso n.° 5: Acelerar la carga de trabajo analítica</block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">Versión 3.0</block>
  <block id="fb784db76f57bc935639ba5340089d77" category="cell">noviembre de 2023</block>
  <block id="11ec45d75a4ad726423d44fadee3074a" category="cell">Se eliminaron los detalles de NIPAM</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">La estructura de datos impulsada por NetApp simplifica e integra la gestión de datos en entornos locales y de nube para acelerar la transformación digital.  La estructura de datos impulsada por NetApp ofrece servicios y aplicaciones de gestión de datos consistentes e integrados (bloques fundamentales) para la visibilidad y el conocimiento de los datos, el acceso y control de los mismos, y la protección y seguridad de los datos.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">Tejido de datos impulsado por NetApp para arquitectura de big data</block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">La estructura de datos impulsada por NetApp simplifica e integra la gestión de datos en entornos locales y de nube para acelerar la transformación digital.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">La estructura de datos impulsada por NetApp ofrece servicios y aplicaciones de gestión de datos consistentes e integrados (bloques fundamentales) para la visibilidad y el conocimiento de los datos, el acceso y el control de los mismos, y la protección y seguridad de los datos, tal como se muestra en la siguiente figura.</block>
  <block id="42e5faac50fa6c299b9293560a7e7052" category="paragraph"><block ref="42e5faac50fa6c299b9293560a7e7052" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">Casos de uso de clientes de Data Fabric probados</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">La estructura de datos impulsada por NetApp ofrece los siguientes nueve casos de uso comprobados para los clientes:</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">Acelerar las cargas de trabajo analíticas</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">Acelerar la transformación de DevOps</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">Construir infraestructura de alojamiento en la nube</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">Integrar servicios de datos en la nube</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">Proteger y asegurar los datos</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">Optimizar datos no estructurados</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">Gane eficiencia en el centro de datos</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">Proporcionar información y control sobre los datos</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">Simplificar y automatizar</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">Este documento cubre dos de los nueve casos de uso (junto con sus soluciones):</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">Acceso directo a NFS de NetApp</block>
  <block id="c2915c2b980396a00c86766bff7195e3" category="paragraph">NetApp NFS permite a los clientes ejecutar trabajos de análisis de big data en sus datos NFSv3 o NFSv4 existentes o nuevos sin mover ni copiar los datos.  Evita copias múltiples de datos y elimina la necesidad de sincronizar los datos con una fuente.  Por ejemplo, en el sector financiero, el movimiento de datos de un lugar a otro debe cumplir obligaciones legales, lo que no es una tarea fácil.  En este escenario, el acceso directo de NetApp NFS analiza los datos financieros desde su ubicación original.  Otro beneficio clave es que el uso del acceso directo NFS de NetApp simplifica la protección de los datos de Hadoop mediante el uso de comandos nativos de Hadoop y permite flujos de trabajo de protección de datos que aprovechan la amplia cartera de gestión de datos de NetApp.</block>
  <block id="1e72dcaa767fcc4be580ce5e9e1b52ea" category="paragraph"><block ref="1e72dcaa767fcc4be580ce5e9e1b52ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">El acceso directo a NFS de NetApp ofrece dos tipos de opciones de implementación para clústeres Hadoop/Spark:</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">De forma predeterminada, los clústeres Hadoop/Spark utilizan el sistema de archivos distribuido Hadoop (HDFS) para el almacenamiento de datos y el sistema de archivos predeterminado.  El acceso directo NFS de NetApp puede reemplazar el HDFS predeterminado con almacenamiento NFS como sistema de archivos predeterminado, lo que permite operaciones de análisis directo en datos NFS.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">En otra opción de implementación, el acceso directo NFS de NetApp admite la configuración de NFS como almacenamiento adicional junto con HDFS en un solo clúster Hadoop/Spark.  En este caso, el cliente puede compartir datos a través de exportaciones NFS y acceder a ellos desde el mismo clúster junto con los datos HDFS.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">Los beneficios clave de utilizar el acceso directo NFS de NetApp incluyen:</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">Analiza los datos desde su ubicación actual, lo que evita la tarea, que consume mucho tiempo y rendimiento, de mover datos analíticos a una infraestructura Hadoop como HDFS.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">Reduce el número de réplicas de tres a una.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">Permite a los usuarios disociar el cómputo y el almacenamiento para escalarlos de forma independiente.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">Proporciona protección de datos empresariales aprovechando las ricas capacidades de gestión de datos de ONTAP.</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Está certificado con la plataforma de datos Hortonworks.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">Permite implementaciones de análisis de datos híbridos.</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">Reduce el tiempo de respaldo al aprovechar la capacidad multiproceso dinámico.</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">Bloques de construcción para big data</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">La estructura de datos impulsada por NetApp integra servicios y aplicaciones de gestión de datos (bloques de construcción) para el acceso, control, protección y seguridad de los datos, como se muestra en la siguiente figura.</block>
  <block id="daa25861e76d8b4617b478f8cd89c0b2" category="paragraph"><block ref="daa25861e76d8b4617b478f8cd89c0b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">Los componentes básicos de la figura anterior incluyen:</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">*Acceso directo a NFS de NetApp .*  Proporciona los últimos clústeres Hadoop y Spark con acceso directo a volúmenes NFS de NetApp sin requisitos de software o controladores adicionales.</block>
  <block id="f79865a14977797753199d8c238eade6" category="list-text">* Cloud Volumes ONTAP NetApp Cloud ONTAP y Google Cloud NetApp Volumes.*  Almacenamiento conectado definido por software basado en ONTAP que se ejecuta en Amazon Web Services (AWS) o Azure NetApp Files (ANF) en los servicios de nube de Microsoft Azure.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">*Tecnología NetApp SnapMirror *.  Proporciona capacidades de protección de datos entre las instancias locales y las de ONTAP Cloud o NPS.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*Proveedores de servicios en la nube.*  Estos proveedores incluyen AWS, Microsoft Azure, Google Cloud e IBM Cloud.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*PaaS.*  Servicios de análisis basados en la nube como Amazon Elastic MapReduce (EMR) y Databricks en AWS, así como Microsoft Azure HDInsight y Azure Databricks.</block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp es una herramienta nativa que se utiliza para realizar copias a gran escala entre clústeres y dentro de ellos.  El proceso básico de Hadoop DistCp es un flujo de trabajo de respaldo típico que utiliza herramientas nativas de Hadoop, como MapReduce, para copiar datos de Hadoop desde una fuente HDFS a un destino correspondiente.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Protección de datos de Hadoop y NetApp</block>
  <block id="1d766990d66db8e06b462398928288cd" category="paragraph">Hadoop DistCp es una herramienta nativa que se utiliza para realizar copias a gran escala entre clústeres y dentro de ellos.  El proceso básico de Hadoop DistCp que se muestra en la figura a continuación es un flujo de trabajo de respaldo típico que utiliza herramientas nativas de Hadoop, como MapReduce, para copiar datos de Hadoop desde una fuente HDFS a un destino correspondiente.</block>
  <block id="7cded69de10ed23fb288e8f481913718" category="paragraph">El acceso directo NFS de NetApp permite a los clientes establecer NFS como destino para la herramienta Hadoop DistCp para copiar los datos de la fuente HDFS a un recurso compartido NFS a través de MapReduce.  El acceso directo NFS de NetApp actúa como un controlador NFS para la herramienta DistCp.</block>
  <block id="3225c81e14f83a90295391be9d81302a" category="paragraph"><block ref="3225c81e14f83a90295391be9d81302a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">Este documento describe soluciones de datos en nube híbrida utilizando sistemas de almacenamiento NetApp AFF y FAS , NetApp Cloud Volumes ONTAP, almacenamiento conectado de NetApp y tecnología NetApp FlexClone para Spark y Hadoop.  Estas arquitecturas de soluciones permiten a los clientes elegir una solución de protección de datos adecuada para su entorno.  NetApp diseñó estas soluciones basándose en la interacción con los clientes y sus casos de uso comerciales.</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam y Sathish Thyagarajan, NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">Este documento describe soluciones de datos en nube híbrida utilizando sistemas de almacenamiento NetApp AFF y FAS , NetApp Cloud Volumes ONTAP, almacenamiento conectado de NetApp y tecnología NetApp FlexClone para Spark y Hadoop.  Estas arquitecturas de soluciones permiten a los clientes elegir una solución de protección de datos adecuada para su entorno.  NetApp diseñó estas soluciones basándose en la interacción con los clientes y sus casos de uso comerciales.  Este documento proporciona la siguiente información detallada:</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Por qué necesitamos protección de datos para los entornos Spark y Hadoop y los desafíos de los clientes.</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">La estructura de datos impulsada por la visión de NetApp y sus componentes básicos y servicios.</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">Cómo se pueden utilizar estos bloques de construcción para diseñar flujos de trabajo de protección de datos flexibles.</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">Los pros y contras de varias arquitecturas basadas en casos de uso de clientes del mundo real.  Cada caso de uso proporciona los siguientes componentes:</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">Escenarios de clientes</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="list-text">Requisitos y desafíos</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">Soluciones</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">Resumen de las soluciones</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">¿Por qué proteger datos en Hadoop?</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">En un entorno de Hadoop y Spark, se deben abordar las siguientes preocupaciones:</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*Fallo de software o humano.*  El error humano en las actualizaciones de software mientras se realizan operaciones de datos de Hadoop puede generar un comportamiento defectuoso que puede generar resultados inesperados en el trabajo.  En tal caso, necesitamos proteger los datos para evitar fallas o resultados irrazonables.  Por ejemplo, como resultado de una actualización de software mal ejecutada en una aplicación de análisis de señales de tráfico, una nueva función que no analiza adecuadamente los datos de las señales de tráfico en forma de texto simple.  El software aún analiza JSON y otros formatos de archivos que no son de texto, lo que da como resultado que el sistema de análisis de control de tráfico en tiempo real produzca resultados de predicción en los que faltan puntos de datos.  Esta situación puede provocar salidas defectuosas que podrían provocar accidentes en los semáforos.  La protección de datos puede resolver este problema proporcionando la capacidad de volver rápidamente a la versión anterior de la aplicación en funcionamiento.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*Tamaño y escala.*  El tamaño de los datos analíticos crece día a día debido al número cada vez mayor de fuentes y volúmenes de datos.  Las redes sociales, las aplicaciones móviles, el análisis de datos y las plataformas de computación en la nube son las principales fuentes de datos en el actual mercado de big data, que está aumentando muy rápidamente y, por lo tanto, los datos deben protegerse para garantizar operaciones de datos precisas.</block>
  <block id="612be5fe1026c2566014b79f77403701" category="list-text">*Protección de datos nativa de Hadoop.*  Hadoop tiene un comando nativo para proteger los datos, pero este comando no proporciona consistencia de los datos durante la copia de seguridad.  Sólo admite copias de seguridad a nivel de directorio.  Las instantáneas creadas por Hadoop son de solo lectura y no se pueden utilizar para reutilizar los datos de respaldo directamente.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Desafíos de protección de datos para los clientes de Hadoop y Spark</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Un desafío común para los clientes de Hadoop y Spark es reducir el tiempo de respaldo y aumentar la confiabilidad del respaldo sin afectar negativamente el rendimiento en el clúster de producción durante la protección de datos.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">Los clientes también necesitan minimizar el tiempo de inactividad del objetivo de punto de recuperación (RPO) y del objetivo de tiempo de recuperación (RTO) y controlar sus sitios de recuperación ante desastres locales y basados en la nube para lograr una continuidad comercial óptima.  Este control generalmente proviene de tener herramientas de gestión a nivel empresarial.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Los entornos Hadoop y Spark son complicados porque no sólo el volumen de datos es enorme y está creciendo, sino que también aumenta la velocidad a la que llegan estos datos.  Este escenario dificulta la creación rápida de entornos DevTest y QA eficientes y actualizados a partir de los datos de origen.  NetApp reconoce estos desafíos y ofrece las soluciones presentadas en este documento.</block>
  <block id="7d617748001976c06ae87f824ca77b2d" category="summary">En este escenario, se modernizó la plataforma de análisis de un gran banco de inversión y servicios financieros utilizando la solución de almacenamiento NFS de NetApp para lograr una mejora significativa en el análisis de riesgos de inversión y derivados para su unidad de negocios de gestión de activos y cuantitativa.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">Caso de uso 5: Acelerar las cargas de trabajo analíticas</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">Guión</block>
  <block id="f3274c43bc916b05ebe766167f47a1ad" category="paragraph">En el entorno existente del cliente, la infraestructura Hadoop utilizada para la plataforma de análisis aprovechaba el almacenamiento interno de los servidores Hadoop.  Debido a la naturaleza propietaria del entorno JBOD, muchos clientes internos de la organización no pudieron aprovechar su modelo cuantitativo de Monte Carlo, una simulación que se basa en muestras recurrentes de datos en tiempo real.  La capacidad subóptima para comprender los efectos de la incertidumbre en los movimientos del mercado estaba perjudicando a la unidad de negocios de gestión de activos cuantitativos.</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">La unidad de negocios cuantitativa del banco quería un método de previsión eficiente para obtener predicciones precisas y oportunas.  Para lograrlo, el equipo reconoció la necesidad de modernizar la infraestructura, reducir el tiempo de espera de E/S existente y mejorar el rendimiento de las aplicaciones analíticas como Hadoop y Spark para simular eficientemente modelos de inversión, medir ganancias potenciales y analizar riesgos.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">Solución</block>
  <block id="43b3ece7a28edcf11ee066112179b834" category="paragraph">El cliente tenía JBOD para su solución Spark existente.  Luego se aprovecharon NetApp ONTAP, NetApp StorageGRID y MinIO Gateway to NFS para reducir el tiempo de espera de E/S para el grupo de finanzas cuantitativas del banco, que ejecuta simulaciones y análisis de modelos de inversión que evalúan posibles ganancias y riesgos.  Esta imagen muestra la solución Spark con almacenamiento NetApp .</block>
  <block id="d9e962022f714fc5ed8bccce82c920ac" category="paragraph"><block ref="d9e962022f714fc5ed8bccce82c920ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">Como se muestra en la figura anterior, se implementaron los sistemas AFF A800, A700 y StorageGRID para acceder a archivos parquet a través de protocolos NFS y S3 en un clúster Hadoop de seis nodos con Spark y servicios de metadatos YARN y Hive para operaciones de análisis de datos.</block>
  <block id="473d88a5512cc81d2571425bbea591d2" category="paragraph">Una solución de almacenamiento conectado directamente (DAS) en el antiguo entorno del cliente tenía la desventaja de escalar el cómputo y el almacenamiento de forma independiente.  Con la solución NetApp ONTAP para Spark, la unidad de negocios de análisis financiero del banco pudo disociar el almacenamiento del cómputo y brindar recursos de infraestructura de manera más efectiva y sin inconvenientes según fuera necesario.</block>
  <block id="fceb3129a02a41b3231baa9b6f633217" category="paragraph">Al usar ONTAP con NFS, las CPU del servidor de cómputo se utilizaron casi en su totalidad para los trabajos de Spark SQL y el tiempo de espera de E/S se redujo en casi un 70 %, lo que proporcionó una mejor potencia de cómputo y un aumento del rendimiento a las cargas de trabajo de Spark.  Posteriormente, aumentar la utilización de la CPU también permitió al cliente aprovechar las GPU, como GPUDirect, para una mayor modernización de la plataforma.  Además, StorageGRID proporciona una opción de almacenamiento de bajo costo para cargas de trabajo Spark y MinIO Gateway proporciona acceso seguro a datos NFS a través del protocolo S3.  Para los datos en la nube, NetApp recomienda Cloud Volumes ONTAP, Azure NetApp Files y Google Cloud NetApp Volumes.</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">Este caso de uso se basa en un cliente de radiodifusión que necesita realizar una copia de seguridad de los datos analíticos basados en la nube en su centro de datos local.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">Caso de uso 2: Copia de seguridad y recuperación ante desastres desde la nube a las instalaciones locales</block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">Este caso de uso se basa en un cliente de transmisión que necesita realizar una copia de seguridad de los datos analíticos basados en la nube en su centro de datos local, como se ilustra en la siguiente figura.</block>
  <block id="56f5fb8db5f5326b20e3fe17ce11efa4" category="paragraph"><block ref="56f5fb8db5f5326b20e3fe17ce11efa4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">En este escenario, los datos del sensor IoT se incorporan a la nube y se analizan mediante un clúster Apache Spark de código abierto dentro de AWS.  El requisito es realizar una copia de seguridad de los datos procesados desde la nube a las instalaciones locales.</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">Los principales requisitos y desafíos para este caso de uso incluyen:</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">Habilitar la protección de datos no debería causar ningún efecto en el rendimiento del clúster Spark/Hadoop de producción en la nube.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">Los datos de los sensores en la nube deben trasladarse y protegerse en las instalaciones locales de forma eficiente y segura.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">Flexibilidad para transferir datos desde la nube a las instalaciones locales en diferentes condiciones, como a pedido, instantáneamente y durante tiempos de baja carga del clúster.</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">El cliente utiliza AWS Elastic Block Store (EBS) para el almacenamiento HDFS de su clúster Spark para recibir e ingerir datos de sensores remotos a través de Kafka.  En consecuencia, el almacenamiento HDFS actúa como fuente de los datos de respaldo.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">Para cumplir con estos requisitos, NetApp ONTAP Cloud se implementa en AWS y se crea un recurso compartido NFS para que actúe como destino de respaldo para el clúster Spark/Hadoop.</block>
  <block id="3c0f76e2d6fa82b2004270ec86f39aa7" category="paragraph">Una vez creado el recurso compartido NFS, copie los datos del almacenamiento HDFS EBS al recurso compartido NFS de ONTAP .  Una vez que los datos residen en NFS en ONTAP Cloud, se puede utilizar la tecnología SnapMirror para reflejar los datos desde la nube al almacenamiento local según sea necesario de manera segura y eficiente.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">Esta imagen muestra la copia de seguridad y la recuperación ante desastres de la solución en la nube a las instalaciones locales.</block>
  <block id="6d742f93cf04e332b07c93ce2bc96163" category="paragraph"><block ref="6d742f93cf04e332b07c93ce2bc96163" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">En este escenario, el cliente tiene un gran repositorio de Hadoop local y desea realizar una copia de seguridad del mismo para fines de recuperación ante desastres.  Sin embargo, la solución de backup actual del cliente es costosa y tiene una ventana de backup prolongada de más de 24 horas.</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">Caso de uso 1: Copia de seguridad de datos de Hadoop</block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">Compatibilidad con versiones anteriores del software:</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">La solución de respaldo alternativa propuesta debe ser compatible con las versiones de software actuales que se utilizan en el clúster Hadoop de producción.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">Para cumplir con los SLA comprometidos, la solución alternativa propuesta debe lograr RPO y RTO muy bajos.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">La copia de seguridad creada por la solución de copia de seguridad de NetApp se puede utilizar en el clúster Hadoop creado localmente en el centro de datos, así como en el clúster Hadoop que se ejecuta en la ubicación de recuperación ante desastres en el sitio remoto.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">La solución propuesta debe ser rentable.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">La solución propuesta debe reducir el efecto sobre el rendimiento de los trabajos de análisis en producción que se están ejecutando actualmente durante los tiempos de respaldo.</block>
  <block id="265e759e2a3b4c55776e0de53887b3b4" category="section-title">Solución de respaldo existente del cliente</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">La siguiente figura muestra la solución de copia de seguridad nativa original de Hadoop.</block>
  <block id="f9efb12aa8582a65d79ac1fcd7574665" category="paragraph"><block ref="f9efb12aa8582a65d79ac1fcd7574665" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">Los datos de producción están protegidos en cinta a través del clúster de respaldo intermedio:</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">Los datos HDFS1 se copian a HDFS2 ejecutando el<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block> dominio.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">El clúster de respaldo actúa como una puerta de enlace NFS y los datos se copian manualmente en cinta a través de Linux.<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block> Comando a través de la biblioteca de cintas.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">Los beneficios de la solución de respaldo nativa original de Hadoop incluyen:</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">La solución se basa en comandos nativos de Hadoop, lo que evita que el usuario tenga que aprender nuevos procedimientos.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">La solución aprovecha la arquitectura y el hardware estándar de la industria.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">Las desventajas de la solución de copia de seguridad nativa original de Hadoop incluyen:</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">El tiempo de la ventana de respaldo supera las 24 horas, lo que hace que los datos de producción sean vulnerables.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">Degradación significativa del rendimiento del clúster durante los tiempos de copia de seguridad.</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">Copiar a cinta es un proceso manual.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">La solución de backup es costosa en términos del hardware requerido y las horas humanas requeridas para los procesos manuales.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">Soluciones de respaldo</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">En función de estos desafíos y requisitos, y teniendo en cuenta el sistema de respaldo existente, se sugirieron tres posibles soluciones de respaldo.  Las siguientes subsecciones describen cada una de estas tres soluciones de respaldo diferentes, denominadas solución A a solución C.</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">Solución A</block>
  <block id="bc98837ed486c01d428d23d0c3a83d6a" category="paragraph">En la Solución A, el clúster de respaldo Hadoop envía los respaldos secundarios a los sistemas de almacenamiento NFS de NetApp , lo que elimina el requisito de cinta, como se muestra en la siguiente figura.</block>
  <block id="c7446a7fd101a1f229e62b8dfc3f2627" category="paragraph"><block ref="c7446a7fd101a1f229e62b8dfc3f2627" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">Las tareas detalladas para la solución A incluyen:</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">El clúster de producción Hadoop tiene los datos analíticos del cliente en el HDFS que requiere protección.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">El clúster de respaldo Hadoop con HDFS actúa como una ubicación intermedia para los datos.  Solo un conjunto de discos (JBOD) proporciona el almacenamiento para HDFS en los clústeres Hadoop de producción y de respaldo.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Proteja los datos de producción de Hadoop desde el clúster de producción HDFS hasta el clúster de respaldo HDFS ejecutando el comando<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block> dominio.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">La instantánea de Hadoop se utiliza para proteger los datos desde la producción hasta el clúster de Hadoop de respaldo.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">El controlador de almacenamiento NetApp ONTAP proporciona un volumen exportado NFS, que se aprovisiona en el clúster Hadoop de respaldo.</block>
  <block id="1b449b0ea4a324dc81f41259db2c13e9" category="list-text">Al ejecutar el<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block> Al aprovechar MapReduce y varios mapeadores, los datos analíticos están protegidos desde el clúster Hadoop de respaldo a NFS.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">Una vez que los datos se almacenan en NFS en el sistema de almacenamiento NetApp , se utilizan las tecnologías NetApp Snapshot, SnapRestore y FlexClone para realizar copias de seguridad, restaurar y duplicar los datos de Hadoop según sea necesario.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">Los datos de Hadoop se pueden proteger en la nube y en ubicaciones de recuperación ante desastres mediante el uso de la tecnología SnapMirror .</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">Los beneficios de la solución A incluyen:</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Los datos de producción de Hadoop están protegidos desde el clúster de respaldo.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">Los datos HDFS están protegidos a través de NFS, lo que permite la protección en la nube y en ubicaciones de recuperación ante desastres.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">Mejora el rendimiento al descargar las operaciones de respaldo al clúster de respaldo.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">Elimina las operaciones manuales de cinta</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">Permite funciones de gestión empresarial a través de herramientas NetApp .</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">Requiere cambios mínimos en el entorno existente.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">Es una solución rentable.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">La desventaja de esta solución es que requiere un clúster de respaldo y mapeadores adicionales para mejorar el rendimiento.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">El cliente implementó recientemente la solución A debido a su simplicidad, costo y rendimiento general.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">En esta solución, se pueden utilizar discos SAN de ONTAP en lugar de JBOD.  Esta opción descarga la carga de almacenamiento del clúster de respaldo a ONTAP; sin embargo, la desventaja es que se requieren conmutadores de estructura SAN.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">Solución B</block>
  <block id="099eafc2208317136c2902383d7b0755" category="paragraph">La solución B agrega un volumen NFS al clúster Hadoop de producción, lo que elimina la necesidad del clúster Hadoop de respaldo, como se muestra en la siguiente figura.</block>
  <block id="5b70fb212e3f22443316e06668fb7eaf" category="paragraph"><block ref="5b70fb212e3f22443316e06668fb7eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">Las tareas detalladas para la solución B incluyen:</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">El controlador de almacenamiento NetApp ONTAP aprovisiona la exportación NFS al clúster Hadoop de producción.</block>
  <block id="b8c0e409f361575b0a2787968f3e6737" category="paragraph">El nativo de Hadoop<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> El comando protege los datos de Hadoop del clúster de producción HDFS a NFS.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">Una vez que los datos se almacenan en NFS en el sistema de almacenamiento NetApp , se utilizan las tecnologías Snapshot, SnapRestore y FlexClone para realizar copias de seguridad, restaurar y duplicar los datos de Hadoop según sea necesario.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">Los beneficios de la solución B incluyen:</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">El clúster de producción está ligeramente modificado para la solución de respaldo, lo que simplifica la implementación y reduce los costos adicionales de infraestructura.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">No se requiere un clúster de respaldo para la operación de respaldo.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">Los datos de producción HDFS están protegidos en la conversión a datos NFS.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">La solución permite funciones de gestión empresarial a través de herramientas NetApp .</block>
  <block id="f4ffcfc00594c5a445a43499130eb8d3" category="paragraph">La desventaja de esta solución es que se implementa en el clúster de producción, lo que puede agregar tareas de administrador adicionales en el clúster de producción.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">Solución C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">En la solución C, los volúmenes SAN de NetApp se aprovisionan directamente al clúster de producción de Hadoop para el almacenamiento HDFS, como se muestra en la siguiente figura.</block>
  <block id="016077aafc394500fb21c4f233724258" category="paragraph"><block ref="016077aafc394500fb21c4f233724258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">Los pasos detallados para la solución C incluyen:</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">El almacenamiento SAN ONTAP de NetApp se aprovisiona en el clúster Hadoop de producción para el almacenamiento de datos HDFS.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">Las tecnologías NetApp Snapshot y SnapMirror se utilizan para realizar copias de seguridad de los datos HDFS del clúster Hadoop de producción.</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">No hay ningún efecto en el rendimiento de la producción del clúster Hadoop/Spark durante el proceso de copia de seguridad instantánea porque la copia de seguridad se realiza en la capa de almacenamiento.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">La tecnología Snapshot proporciona copias de seguridad que se completan en segundos, independientemente del tamaño de los datos.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">Los beneficios de la solución C incluyen:</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">Se pueden crear copias de seguridad que ahorren espacio utilizando la tecnología Snapshot.</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">En este caso de uso, el requisito del cliente es construir de manera rápida y eficiente nuevos clústeres Hadoop/Spark basados en un clúster Hadoop existente que contiene una gran cantidad de datos analíticos para DevTest y propósitos de informes en el mismo centro de datos, así como en ubicaciones remotas.</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">Caso de uso 3: Habilitación de DevTest en datos Hadoop existentes</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">En este escenario, se crean múltiples clústeres Spark/Hadoop a partir de una gran implementación de lago de datos Hadoop en las instalaciones y en ubicaciones de recuperación ante desastres.</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">Cree varios clústeres de Hadoop para DevTest, QA o cualquier otro propósito que requiera acceso a los mismos datos de producción.  El desafío aquí es clonar un clúster Hadoop muy grande varias veces de manera instantánea y de manera muy eficiente en términos de espacio.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">Sincronice los datos de Hadoop con los equipos de DevTest e informes para lograr eficiencia operativa.</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">Distribuya los datos de Hadoop utilizando las mismas credenciales en los clústeres de producción y nuevos.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">Utilice políticas programadas para crear de manera eficiente clústeres de control de calidad sin afectar el clúster de producción.</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">Para responder a los requisitos que acabamos de describir se utiliza la tecnología FlexClone .  La tecnología FlexClone es la copia de lectura/escritura de una copia Snapshot.  Lee los datos de la copia de instantánea principal y solo consume espacio adicional para bloques nuevos o modificados.  Es rápido y ahorra espacio.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">En primer lugar, se creó una copia instantánea del clúster existente utilizando un grupo de consistencia de NetApp .</block>
  <block id="ff0e15997f709c232408a5055738df05" category="paragraph">Copias instantáneas dentro de NetApp System Manager o el indicador de administración de almacenamiento.  Las copias de instantáneas del grupo de consistencia son copias de instantáneas del grupo consistentes con la aplicación, y el volumen FlexClone se crea en función de las copias de instantáneas del grupo de consistencia.  Vale la pena mencionar que un volumen FlexClone hereda la política de exportación NFS del volumen principal.  Después de crear la copia instantánea, se debe instalar un nuevo clúster Hadoop para fines de DevTest y de informes, como se muestra en la siguiente figura.  El volumen NFS clonado del nuevo clúster Hadoop accede a los datos NFS.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">Esta imagen muestra el clúster Hadoop para DevTest.</block>
  <block id="abc9a1c20fcf276389f79d3093665e5c" category="paragraph"><block ref="abc9a1c20fcf276389f79d3093665e5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">Este caso de uso es relevante para un socio de servicios en la nube encargado de brindar conectividad multicloud para los datos de análisis de big data de los clientes.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">Caso de uso 4: Protección de datos y conectividad multicloud</block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">En este escenario, los datos de IoT recibidos en AWS desde diferentes fuentes se almacenan en una ubicación central en NPS.  El almacenamiento NPS está conectado a clústeres Spark/Hadoop ubicados en AWS y Azure, lo que permite que las aplicaciones de análisis de big data que se ejecutan en múltiples nubes accedan a los mismos datos.</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">Los clientes quieren ejecutar trabajos de análisis en los mismos datos utilizando múltiples nubes.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">Los datos deben recibirse de diferentes fuentes, como las instalaciones locales y la nube, a través de diferentes sensores y concentradores.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">La solución debe ser eficiente y rentable.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">El principal desafío es construir una solución rentable y eficiente que brinde servicios de análisis híbridos entre las instalaciones locales y en diferentes nubes.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">Esta imagen ilustra la solución de protección de datos y conectividad multicloud.</block>
  <block id="5308dad4844e43fdad02844ec50752c0" category="paragraph"><block ref="5308dad4844e43fdad02844ec50752c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ea48e5206de42785842cb864377766c" category="paragraph">Como se muestra en la figura anterior, los datos de los sensores se transmiten y se incorporan al clúster de AWS Spark a través de Kafka.  Los datos se almacenan en un recurso compartido NFS que reside en NPS, que se encuentra fuera del proveedor de la nube dentro de un centro de datos de Equinix.  Dado que NetApp NPS está conectado a Amazon AWS y Microsoft Azure a través de conexiones Direct Connect y Express Route, respectivamente, los clientes pueden acceder a los datos NFS desde los clústeres de análisis de Amazon y AWS.  Este enfoque resuelve el problema de tener análisis en la nube en múltiples hiperescaladores.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">En consecuencia, debido a que tanto el almacenamiento local como el NPS ejecutan el software ONTAP , SnapMirror puede reflejar los datos de NPS en el clúster local, lo que proporciona análisis de nube híbrida en las instalaciones locales y en múltiples nubes.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">Para obtener el mejor rendimiento, NetApp generalmente recomienda utilizar múltiples interfaces de red y conexiones directas/exprés para acceder a los datos desde las instancias de la nube.</block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">Esta sección proporciona una descripción de alto nivel de los casos de uso de protección de datos, que constituyen el foco de este documento.  Las secciones restantes proporcionan más detalles para cada caso de uso, como el problema del cliente (escenario), los requisitos y desafíos, y las soluciones.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Descripción general de los casos de uso de protección de datos de Hadoop</block>
  <block id="6f2c5dcd0294b9c34430b1de4713c06d" category="paragraph">Para este caso de uso, el volumen NFS de NetApp ayudó a una gran institución financiera a reducir el largo tiempo de la ventana de respaldo de más de 24 horas a poco menos de unas pocas horas.</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">Al usar la estructura de datos impulsada por NetApp como bloques de construcción, una gran empresa de radiodifusión pudo cumplir con su requisito de realizar copias de seguridad de los datos de la nube en su centro de datos local dependiendo de los diferentes modos de transferencia de datos, como a pedido, instantáneo o según la carga del clúster Hadoop/Spark.</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">Las soluciones de NetApp ayudaron a un distribuidor de música en línea a construir rápidamente múltiples clústeres Hadoop que ahorran espacio en diferentes sucursales para crear informes y ejecutar tareas diarias de DevTest mediante políticas programadas.</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">Un gran proveedor de servicios utilizó la estructura de datos impulsada por NetApp para brindar análisis multicloud a sus clientes desde diferentes instancias de nube.</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">Uno de los bancos de inversión y servicios financieros más grandes utilizó la solución de almacenamiento conectado a red de NetApp para reducir el tiempo de espera de E/S y acelerar su plataforma de análisis financiero cuantitativo.</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">En esta sección se presentan las lecciones aprendidas de esta certificación.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">Pautas de mejores prácticas</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">Según nuestra validación, el almacenamiento de objetos S3 es la mejor opción para que Confluent conserve datos.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">Podemos usar SAN de alto rendimiento (específicamente FC) para mantener los datos activos del broker o el disco local, porque, en la configuración de almacenamiento en niveles de Confluent, el tamaño de los datos almacenados en el directorio de datos del broker se basa en el tamaño del segmento y el tiempo de retención cuando los datos se mueven al almacenamiento de objetos.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">Los almacenes de objetos proporcionan un mejor rendimiento cuando segment.bytes es mayor; probamos 512 MB.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">En Kafka, la longitud de la clave o el valor (en bytes) para cada registro producido para el tema está controlada por el<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> parámetro.  Para StorageGRID, el rendimiento de ingesta y recuperación de objetos S3 aumentó a valores más altos.  Por ejemplo, 512 bytes proporcionaron una recuperación de 5,8 GBps, 1024 bytes proporcionaron una recuperación s3 de 7,5 GBps y 2048 bytes proporcionaron cerca de 10 GBps.</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">La siguiente figura presenta la ingesta y recuperación de objetos S3 en función de<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> .</block>
  <block id="88108446d5ab5e54118010ab8c716e93" category="paragraph"><block ref="88108446d5ab5e54118010ab8c716e93" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">*Afinación de Kafka.*  Para mejorar el rendimiento del almacenamiento en niveles, puede aumentar TierFetcherNumThreads y TierArchiverNumThreads.  Como regla general, se recomienda aumentar TierFetcherNumThreads para que coincida con la cantidad de núcleos de CPU físicos y aumentar TierArchiverNumThreads a la mitad de la cantidad de núcleos de CPU.  Por ejemplo, en las propiedades del servidor, si tiene una máquina con ocho núcleos físicos, configure confluent.tier.fetcher.num.threads = 8 y confluent.tier.archiver.num.threads = 4.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*Intervalo de tiempo para eliminar temas.*  Cuando se elimina un tema, la eliminación de los archivos de segmentos de registro en el almacenamiento de objetos no comienza de inmediato.  Más bien, hay un intervalo de tiempo con un valor predeterminado de 3 horas antes de que se eliminen esos archivos.  Puede modificar la configuración, confluent.tier.topic.delete.check.interval.ms, para cambiar el valor de este intervalo.  Si elimina un tema o un clúster, también puede eliminar manualmente los objetos en el depósito correspondiente.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*ACL sobre temas internos de almacenamiento en niveles.*  Una práctica recomendada para las implementaciones locales es habilitar un autorizador de ACL en los temas internos utilizados para el almacenamiento en niveles.  Establezca reglas de ACL para limitar el acceso a estos datos únicamente al usuario del corredor.  Esto protege los temas internos y evita el acceso no autorizado a los metadatos y datos de almacenamiento en niveles.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">Reemplazar al usuario<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block> con el principal del broker real en su implementación.</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">Por ejemplo, el comando<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block> Establece ACL en el tema interno para el almacenamiento en niveles.  Actualmente, solo hay un único tema interno relacionado con el almacenamiento en niveles.  El ejemplo crea una ACL que proporciona el permiso principal de Kafka para todas las operaciones en el tema interno.</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">Hemos realizado la certificación con Confluent Platform con Kafka para almacenamiento por niveles en NetApp StorageGRID.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Verificación confluente</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">Realizamos la verificación con Confluent Platform 6.2 Tiered Storage en NetApp StorageGRID.  Los equipos de NetApp y Confluent trabajaron juntos en esta verificación y ejecutaron los casos de prueba necesarios para la verificación.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Configuración de la plataforma Confluent</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">Utilizamos la siguiente configuración para la verificación.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">Para la verificación, utilizamos tres guardianes del zoológico, cinco corredores, cinco servidores de ejecución de scripts de prueba, servidores de herramientas con nombre con 256 GB de RAM y 16 CPU.  Para el almacenamiento de NetApp , utilizamos StorageGRID con un balanceador de carga SG1000 con cuatro SGF6024.  El almacenamiento y los intermediarios se conectaron a través de conexiones de 100 GbE.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">La siguiente figura muestra la topología de red de la configuración utilizada para la verificación de Confluent.</block>
  <block id="275745d9c13bf80b7275e6f8633d15e4" category="paragraph"><block ref="275745d9c13bf80b7275e6f8633d15e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">Los servidores de herramientas actúan como clientes de aplicaciones que envían solicitudes a los nodos Confluent.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Configuración de almacenamiento en niveles de Confluent</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">La configuración de almacenamiento por niveles requiere los siguientes parámetros en Kafka:</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">Para la verificación, utilizamos StorageGRID con el protocolo HTTP, pero HTTPS también funciona.  La clave de acceso y la clave secreta se almacenan en el nombre de archivo proporcionado en el<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> parámetro.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">Almacenamiento de objetos de NetApp - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">Configuramos la configuración de sitio único en StorageGRID para la verificación.</block>
  <block id="dddbd2d03db81f9c6cb7d2dc1329df76" category="paragraph"><block ref="dddbd2d03db81f9c6cb7d2dc1329df76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">Pruebas de verificación</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">Completamos los siguientes cinco casos de prueba para la verificación.  Estas pruebas se ejecutan en el marco Trogdor.  Las dos primeras fueron pruebas de funcionalidad y las tres restantes fueron pruebas de rendimiento.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">Prueba de corrección del almacén de objetos</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">Esta prueba determina si todas las operaciones básicas (por ejemplo, obtener/colocar/eliminar) en la API del almacén de objetos funcionan bien de acuerdo con las necesidades del almacenamiento en niveles.  Es una prueba básica que todo servicio de almacenamiento de objetos debe esperar pasar antes de las siguientes pruebas.  Es una prueba asertiva que o se aprueba o se suspende.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">Prueba de corrección de la funcionalidad de niveles</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">Esta prueba determina si la funcionalidad de almacenamiento en niveles de extremo a extremo funciona bien con una prueba asertiva que pasa o falla.  La prueba crea un tema de prueba que, de manera predeterminada, está configurado con niveles habilitados y un tamaño de conjunto activo muy reducido.  Produce un flujo de eventos para el tema de prueba recién creado, espera a que los intermediarios archiven los segmentos en el almacén de objetos y luego consume el flujo de eventos y valida que el flujo consumido coincida con el flujo producido.  La cantidad de mensajes producidos en el flujo de eventos es configurable, lo que permite al usuario generar una carga de trabajo suficientemente grande según las necesidades de las pruebas.  El tamaño reducido del conjunto activo garantiza que las búsquedas del consumidor fuera del segmento activo se atiendan solo desde el almacén de objetos; esto ayuda a probar la exactitud del almacén de objetos para las lecturas.  Hemos realizado esta prueba con y sin inyección de falla en el almacén de objetos.  Simulamos una falla de nodo deteniendo el servicio del administrador de servicios en uno de los nodos en StorageGRID y validando que la funcionalidad de extremo a extremo funciona con el almacenamiento de objetos.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">Punto de referencia de búsqueda de niveles</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">Esta prueba validó el rendimiento de lectura del almacenamiento de objetos en niveles y verificó las solicitudes de lectura de obtención de rango bajo una carga pesada de los segmentos generados por el punto de referencia.  En este punto de referencia, Confluent desarrolló clientes personalizados para atender las solicitudes de búsqueda de niveles.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">Referencia de carga de trabajo de producción y consumo</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">Esta prueba generó indirectamente una carga de trabajo de escritura en el almacén de objetos a través del archivado de segmentos.  La carga de trabajo de lectura (segmentos leídos) se generó desde el almacenamiento de objetos cuando los grupos de consumidores obtuvieron los segmentos.  Esta carga de trabajo fue generada por el script de prueba.  Esta prueba verificó el rendimiento de lectura y escritura en el almacenamiento de objetos en subprocesos paralelos.  Realizamos pruebas con y sin inyección de fallas en el almacén de objetos tal como lo hicimos para la prueba de corrección de la funcionalidad de niveles.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">Punto de referencia de la carga de trabajo de retención</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">Esta prueba verificó el rendimiento de eliminación de un almacén de objetos bajo una carga de trabajo pesada de retención de temas.  La carga de trabajo de retención se generó utilizando un script de prueba que produce muchos mensajes en paralelo a un tema de prueba.  El tema de prueba fue configurar una configuración de retención agresiva basada en el tamaño y el tiempo que provocó que el flujo de eventos se purgara continuamente del almacén de objetos.  Los segmentos fueron luego archivados.  Esto provocó una gran cantidad de eliminaciones en el almacenamiento de objetos por parte del agente y la recopilación del rendimiento de las operaciones de eliminación del almacén de objetos.</block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">¿Qué es Apache Kafka?</block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">¿Qué es un cambio de nombre tonto?</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">ONATP se lee para aplicaciones de streaming.</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">Documentación de productos de NetApp</block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">¿Qué es NFS?</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">¿Qué es la reasignación de particiones de Kafka?</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">¿Qué es el OpenMessaging Benchmark?</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">¿Cómo migrar un broker de Kafka?</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">¿Cómo monitorear el broker Kafka con Prometheus?</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="c8219112931de58f84e7a14a0d24d1ce" category="list-text">Plataforma administrada para Apache Kafka</block>
  <block id="a96e98488edf9123c2fb5281e71c6ec2" category="paragraph"><block ref="a96e98488edf9123c2fb5281e71c6ec2" category="inline-link-rx"></block></block>
  <block id="0cb1f340d12ba20e283d00e1e0823526" category="list-text">Compatibilidad con Apache Kafka</block>
  <block id="14bb5ca8b6287991417f8f43b4d9eb0c" category="paragraph"><block ref="14bb5ca8b6287991417f8f43b4d9eb0c" category="inline-link-rx"></block></block>
  <block id="9d5591555b2fbddd314212720dc97729" category="list-text">Servicios de consultoría para Apache Kafka</block>
  <block id="583ea5ea8c7ad81fed86a1925483124c" category="paragraph"><block ref="583ea5ea8c7ad81fed86a1925483124c" category="inline-link-rx"></block></block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">La solución de NetApp para el tonto problema del cambio de nombre proporciona una forma de almacenamiento simple, económica y administrada de manera centralizada para cargas de trabajo que antes eran incompatibles con NFS.</block>
  <block id="5fe141c77d102adcaccfa6da33564741" category="paragraph">Este nuevo paradigma permite a los clientes crear clústeres de Kafka más manejables que son más fáciles de migrar y reflejar para fines de recuperación ante desastres y protección de datos.  También hemos visto que NFS proporciona beneficios adicionales, como una menor utilización de la CPU y un tiempo de recuperación más rápido, una eficiencia de almacenamiento drásticamente mejorada y un mejor rendimiento a través de NetApp ONTAP.</block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">Este documento describe los siguientes temas: el problema del cambio de nombre tonto y la validación de la solución, la reducción del uso de la CPU para reducir el tiempo de espera de E/S, un tiempo de recuperación más rápido del agente de Kafka y el rendimiento en la nube y en las instalaciones.</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947: Carga de trabajo de Apache Kafka con almacenamiento NFS de NetApp : validación funcional y rendimiento</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">Shantanu Chakole, Karthikeyan Nagalingam y Joe Scott, NetApp</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">Kafka es un sistema de mensajería distribuida de publicación y suscripción con una cola robusta que puede aceptar grandes cantidades de datos de mensajes.  Con Kafka, las aplicaciones pueden escribir y leer datos en temas de forma muy rápida.  Debido a su tolerancia a fallas y escalabilidad, Kafka se utiliza a menudo en el espacio de big data como una forma confiable de ingerir y mover muchos flujos de datos muy rápidamente.  Los casos de uso incluyen procesamiento de transmisiones, seguimiento de la actividad del sitio web, recopilación y monitoreo de métricas, agregación de registros, análisis en tiempo real, etc.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">aquí</block>
  <block id="e1304dc2c6d37619b73112fae0bd8411" category="paragraph">Si bien las operaciones normales de Kafka en NFS funcionan bien, el problema del cambio de nombre tonto hace que la aplicación se bloquee durante el cambio de tamaño o la repartición de un clúster de Kafka que se ejecuta en NFS.  Este es un problema importante porque es necesario redimensionar o reparticionar un clúster de Kafka para equilibrar la carga o realizar mantenimiento.  Puede encontrar detalles adicionales<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block> .</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">Este documento describe los siguientes temas:</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">El problema del cambio de nombre tonto y la validación de la solución</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">Reducir la utilización de la CPU para reducir el tiempo de espera de E/S</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">Tiempo de recuperación del agente de Kafka más rápido</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">Rendimiento en la nube y en las instalaciones</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">¿Por qué utilizar almacenamiento NFS para cargas de trabajo de Kafka?</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">Las cargas de trabajo de Kafka en aplicaciones de producción pueden transmitir enormes cantidades de datos entre aplicaciones.  Estos datos se guardan y almacenan en los nodos del agente de Kafka en el clúster de Kafka.  Kafka también es conocido por su disponibilidad y paralelismo, que logra dividiendo los temas en particiones y luego replicando esas particiones en todo el clúster.  Al final, esto significa que la enorme cantidad de datos que fluye a través de un clúster de Kafka generalmente se multiplica en tamaño.  NFS permite reequilibrar los datos a medida que cambia el número de corredores de forma muy rápida y sencilla.  En el caso de entornos grandes, reequilibrar los datos en DAS cuando cambia la cantidad de intermediarios consume mucho tiempo y, en la mayoría de los entornos de Kafka, la cantidad de intermediarios cambia con frecuencia.</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">Otros beneficios incluyen los siguientes:</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*Madurez.*  NFS es un protocolo maduro, lo que significa que la mayoría de los aspectos de su implementación, protección y uso se comprenden bien.</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*Abierto.*  NFS es un protocolo abierto y su desarrollo continuo está documentado en las especificaciones de Internet como un protocolo de red libre y abierto.</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">*Rentable.*  NFS es una solución de bajo costo para compartir archivos en red que es fácil de configurar porque utiliza la infraestructura de red existente.</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*Gestión centralizada.*  La gestión centralizada de NFS reduce la necesidad de software y espacio en disco adicionales en los sistemas de usuarios individuales.</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*Repartido.*  NFS se puede utilizar como un sistema de archivos distribuido, lo que reduce la necesidad de dispositivos de almacenamiento de medios extraíbles.</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">¿Por qué NetApp para las cargas de trabajo de Kafka?</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">La implementación de NFS de NetApp se considera un estándar de oro para el protocolo y se utiliza en innumerables entornos NAS empresariales. Además de la credibilidad de NetApp, también ofrece los siguientes beneficios:</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">Fiabilidad y eficiencia</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">Escalabilidad y rendimiento</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">Alta disponibilidad (socio de alta disponibilidad en un clúster NetApp ONTAP )</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="list-text">Protección de datos</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">*Recuperación ante desastres (NetApp SnapMirror).*  Su sitio se cae o desea comenzar en un sitio diferente y continuar desde donde lo dejó.</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">Gestionabilidad de su sistema de almacenamiento (administración y gestión mediante NetApp OnCommand).</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*Equilibrio de carga.*  El clúster le permite acceder a diferentes volúmenes de LIF de datos alojados en diferentes nodos.</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*Operaciones sin interrupciones.*  Los LIF o movimientos de volumen son transparentes para los clientes NFS.</block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">En las instalaciones, utilizamos el controlador de almacenamiento NetApp AFF A900 con ONTAP 9.12.1RC1 para validar el rendimiento y la escalabilidad de un clúster de Kafka.  Utilizamos el mismo banco de pruebas que en nuestras prácticas recomendadas de almacenamiento en niveles anteriores con ONTAP y AFF.</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">Descripción general del rendimiento y validación con AFF A900 en las instalaciones</block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">En las instalaciones, utilizamos el controlador de almacenamiento NetApp AFF A900 con ONTAP 9.12.1RC1 para validar el rendimiento y la escalabilidad de un clúster de Kafka.  Utilizamos el mismo banco de pruebas que en nuestras prácticas recomendadas de almacenamiento en niveles anteriores con ONTAP y AFF.</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">Utilizamos Confluent Kafka 6.2.0 para evaluar el AFF A900.  El clúster cuenta con ocho nodos intermediarios y tres nodos guardianes del zoológico.  Para probar el rendimiento, utilizamos cinco nodos de trabajo OMB.</block>
  <block id="7d23a6a699d760fc27aa7ce39406c010" category="paragraph"><block ref="7d23a6a699d760fc27aa7ce39406c010" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">Configuración de almacenamiento</block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">Utilizamos instancias de NetApp FlexGroups para proporcionar un único espacio de nombres para los directorios de registro, lo que simplifica la recuperación y la configuración.  Utilizamos NFSv4.1 y pNFS para proporcionar acceso directo a los datos del segmento de registro.</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">Ajuste del cliente</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">Cada cliente montó la instancia de FlexGroup con el siguiente comando.</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">Además, aumentamos la<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block> del valor predeterminado<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block> a<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block> .  Esto coincide con el límite de espacio de sesión predeterminado en ONTAP.</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">Ajuste del bróker de Kafka</block>
  <block id="4ed38f0369b8bb562a96594ca860ab81" category="paragraph">Para maximizar el rendimiento en el sistema bajo prueba, aumentamos significativamente los parámetros predeterminados para ciertos grupos de subprocesos clave.  Recomendamos seguir las mejores prácticas de Confluent Kafka para la mayoría de las configuraciones.  Este ajuste se utilizó para maximizar la concurrencia de E/S pendientes al almacenamiento.  Estos parámetros se pueden ajustar para que coincidan con los recursos computacionales y los atributos de almacenamiento de su corredor.</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">Metodología de prueba del generador de carga de trabajo</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">Utilizamos las mismas configuraciones OMB que para las pruebas en la nube para el controlador de rendimiento y la configuración del tema.</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">Se aprovisionó una instancia de FlexGroup mediante Ansible en un clúster AFF .</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">Se habilitó pNFS en ONTAP SVM.</block>
  <block id="62313ead30e5ae09df5e2329bfe44784" category="list-text">La carga de trabajo se activó con el controlador de rendimiento utilizando la misma configuración de carga de trabajo que para Cloud Volumes ONTAP.  Ver la sección "<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block> " abajo.  La carga de trabajo utilizó un factor de replicación de 3, lo que significa que se mantuvieron tres copias de segmentos de registro en NFS.</block>
  <block id="823002616491cde5a10847131e46b9a6" category="list-text">Por último, completamos mediciones utilizando un backlog para medir la capacidad de los consumidores para ponerse al día con los últimos mensajes.  La OMB crea un backlog pausando a los consumidores durante el comienzo de una medición.  Esto produce tres fases distintas: creación de cartera de pedidos (tráfico exclusivo del productor), vaciado de cartera de pedidos (una fase de gran actividad del consumidor en la que los consumidores se ponen al día con los eventos perdidos en un tema) y el estado estable. Ver la sección "<block ref="67d9096f7dc6dfc3943f178b4a30cff8" category="inline-xref-macro-rx"></block> " para obtener más información.</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">Rendimiento en estado estacionario</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">Evaluamos el AFF A900 utilizando OpenMessaging Benchmark para proporcionar una comparación similar a la de Cloud Volumes ONTAP en AWS y DAS en AWS.  Todos los valores de rendimiento representan el rendimiento del clúster de Kafka a nivel de productor y consumidor.</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">El rendimiento en estado estable con Confluent Kafka y AFF A900 logró un rendimiento promedio de más de 3,4 GBps tanto para el productor como para los consumidores.  Esto supone más de 3,4 millones de mensajes en todo el clúster de Kafka.  Al visualizar el rendimiento sostenido en bytes por segundo para BrokerTopicMetrics, vemos el excelente rendimiento en estado estable y el tráfico admitido por el AFF A900.</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">Este gráfico muestra el rendimiento de la red del broker.</block>
  <block id="7965f443cb0aaaa8c5c51bc5dec6bed3" category="paragraph"><block ref="7965f443cb0aaaa8c5c51bc5dec6bed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">Esto se alinea bien con la vista de los mensajes entregados por tema.  El siguiente gráfico proporciona un desglose por tema.  En la configuración probada, vimos casi 900 000 mensajes por tema en cuatro temas.</block>
  <block id="a6f05b2032cdce5554a9058f33e2d728" category="paragraph"><block ref="a6f05b2032cdce5554a9058f33e2d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">Rendimiento extremo y exploración de los límites del almacenamiento</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">Para AFF, también realizamos pruebas con OMB utilizando la función de backlog.  La función de acumulación de eventos pausa las suscripciones de los consumidores mientras se crea una acumulación de eventos en el clúster de Kafka.  Durante esta fase, solo se produce tráfico de productor, lo que genera eventos que se confirman en los registros.  Esto emula de manera más cercana el procesamiento por lotes o los flujos de trabajo de análisis fuera de línea; en estos flujos de trabajo, se inician las suscripciones de los consumidores y deben leer datos históricos que ya se han eliminado de la memoria caché del agente.</block>
  <block id="2aeeb1b752e68f3fabc8026c34af1e23" category="paragraph">Para comprender las limitaciones de almacenamiento en el rendimiento del consumidor en esta configuración, medimos solo la fase de productor para comprender cuánto tráfico de escritura podía absorber el A900.  Vea la siguiente sección "<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block> "para entender cómo aprovechar estos datos.</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">Durante la parte de esta medición solo para productores, vimos un alto pico de rendimiento que empujó los límites del rendimiento del A900 (cuando otros recursos del broker no estaban saturados y atendían el tráfico de productores y consumidores).</block>
  <block id="bab88ff8b10be68a7d1ab6839852ce6b" category="paragraph"><block ref="bab88ff8b10be68a7d1ab6839852ce6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">Aumentamos el tamaño del mensaje a 16k para esta medición para limitar los costos generales por mensaje y maximizar el rendimiento del almacenamiento en los puntos de montaje NFS.</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">El clúster Confluent Kafka alcanzó un rendimiento máximo de producción de 4,03 GBps.</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">Después de que OMB terminó de completar el registro de eventos, se reinició el tráfico del consumidor.  Durante las mediciones con drenaje de cartera, observamos un rendimiento máximo del consumidor de más de 20 GBps en todos los temas.  El rendimiento combinado del volumen NFS que almacena los datos del registro OMB se acercó a ~30 GBps.</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">Guía de tallas</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">guía de tallas</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">Amazon Web Services ofrece una<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block> para dimensionar y escalar clústeres de Kafka.</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">Este dimensionamiento proporciona una fórmula útil para determinar los requisitos de rendimiento de almacenamiento para su clúster de Kafka:</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">Para un rendimiento agregado producido en el clúster tcluster con un factor de replicación de r, el rendimiento recibido por el almacenamiento del intermediario es el siguiente:</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">Esto se puede simplificar aún más:</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">El uso de esta fórmula le permite seleccionar la plataforma ONTAP adecuada para sus necesidades de nivel activo de Kafka.</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">La siguiente tabla explica el rendimiento del productor previsto para el A900 con diferentes factores de replicación:</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">Factor de replicación</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">Rendimiento del productor (GPps)</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3 (medido)</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3,4</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5,1</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10,2</block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">Se evaluó el rendimiento de un clúster de Kafka con la capa de almacenamiento montada en NetApp NFS en la nube de AWS.  Los ejemplos de evaluación comparativa se describen en las siguientes secciones.</block>
  <block id="bf57de8e029ea3108f102be3202cff5f" category="doc">Descripción general del rendimiento y validación en AWS FSx ONTAP</block>
  <block id="71db594c48140b244b2b54ff2bdedb71" category="paragraph">Se evaluó el rendimiento de un clúster de Kafka con la capa de almacenamiento montada en NetApp NFS en AWS FSx ONTAP.  Los ejemplos de evaluación comparativa se describen en las siguientes secciones.</block>
  <block id="1c036e91476215fff31a2c45fdf276f9" category="section-title">Apache Kafka en AWS FSx ONTAP</block>
  <block id="29144a8d530212e5210d98eceae62106" category="paragraph">El sistema de archivos de red (NFS) es un sistema de archivos de red ampliamente utilizado para almacenar grandes cantidades de datos.  En la mayoría de las organizaciones, los datos se generan cada vez más mediante aplicaciones de transmisión como Apache Kafka.  Estas cargas de trabajo requieren escalabilidad, baja latencia y una arquitectura de ingesta de datos sólida con capacidades de almacenamiento modernas.  Para permitir análisis en tiempo real y proporcionar información útil, se requiere una infraestructura bien diseñada y de alto rendimiento.</block>
  <block id="3c10ee4415fe854b95a1b3d124b0f0ea" category="paragraph">Kafka, por diseño, funciona con un sistema de archivos compatible con POSIX y se basa en el sistema de archivos para manejar las operaciones de archivos, pero al almacenar datos en un sistema de archivos NFSv3, el cliente NFS del agente de Kafka puede interpretar las operaciones de archivos de manera diferente a un sistema de archivos local como XFS o Ext4.  Un ejemplo común es el cambio de nombre tonto de NFS que provocó que los agentes de Kafka fallaran al expandir clústeres y reasignar particiones.  Para enfrentar este desafío, NetApp ha actualizado el cliente NFS de Linux de código abierto con cambios que ahora están generalmente disponibles en RHEL8.7, RHEL9.1 y son compatibles con la versión actual de FSx ONTAP , ONTAP 9.12.1.</block>
  <block id="2c69958ee453c213417e415ee57b1690" category="paragraph">Amazon FSx ONTAP proporciona un sistema de archivos NFS totalmente administrado, escalable y de alto rendimiento en la nube.  Los datos de Kafka en FSx ONTAP pueden escalar para manejar grandes cantidades de datos y garantizar la tolerancia a fallas.  NFS proporciona gestión de almacenamiento centralizada y protección de datos para conjuntos de datos críticos y confidenciales.</block>
  <block id="542c651fdfac42519bffb9b7ebf01539" category="paragraph">Estas mejoras permiten que los clientes de AWS aprovechen FSx ONTAP al ejecutar cargas de trabajo de Kafka en los servicios informáticos de AWS.  Estos beneficios son: * Reducir la utilización de la CPU para reducir el tiempo de espera de E/S * Tiempo de recuperación del agente de Kafka más rápido.  * Confiabilidad y eficiencia.  * Escalabilidad y rendimiento.  * Disponibilidad de zonas multidisponibilidad.  * Protección de datos.</block>
  <block id="cafd94f15e4ecd146a2af6ea620cc490" category="section-title">Kafka en AWS FSx ONTAP</block>
  <block id="7e3b8d1a53f4bf4f127be8ea0fda504d" category="paragraph">Se evaluó el rendimiento de un clúster de Kafka con AWS FSx ONTAP en la nube de AWS.  Esta evaluación comparativa se describe en las siguientes secciones.</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">Configuración arquitectónica</block>
  <block id="6d14883a196c6b234f62d60a400fe708" category="paragraph">La siguiente tabla muestra la configuración ambiental para un clúster de Kafka que utiliza AWS FSx ONTAP.</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">Componente de plataforma</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">Configuración del entorno</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">Kafka 3.2.3</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">3 x cuidadores del zoológico – t2.small</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">3 servidores intermediarios – i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1 x Grafana – c5n.2xgrande</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4 x productor/consumidor -- c5n.2xlarge *</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">Sistema operativo en todos los nodos</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="9e813193a6755822d3c1628326e814e6" category="cell">Multi-AZ con un rendimiento de 4 GB/seg y 160 000 IOPS</block>
  <block id="8eb6827eb8f798501ab14f58155a9982" category="section-title">Configuración de NetApp FSx ONTAP</block>
  <block id="eb1e12842ba64aa1b662a4e95a406d45" category="list-text">Para nuestras pruebas iniciales, hemos creado un sistema de archivos FSx ONTAP con 2 TB de capacidad y 40 000 IOP para un rendimiento de 2 GB/seg.</block>
  <block id="7ce8d5b94f98d9eb7023e64b4f92f5fd" category="paragraph">En nuestro ejemplo, estamos implementando FSx ONTAP a través de AWS CLI.  Necesitará personalizar aún más el comando en su entorno según sea necesario.  FSx ONTAP también se puede implementar y administrar a través de la consola de AWS para una experiencia de implementación más sencilla y optimizada con menos entrada de línea de comandos.</block>
  <block id="81656db36243146de24c60a68b7b395c" category="paragraph">Documentación En FSx ONTAP, las IOPS máximas alcanzables para un sistema de archivos con un rendimiento de 2 GB/seg en nuestra región de prueba (US-East-1) son 80 000 IOPS.  El total máximo de iops para un sistema de archivos FSx ONTAP es 160 000 iops, lo que requiere una implementación con un rendimiento de 4 GB/seg para lograrlo, lo cual demostraremos más adelante en este documento.</block>
  <block id="3c50ca3005ca0da0071db25317a45f47" category="paragraph">Para obtener más información sobre las especificaciones de rendimiento de FSx ONTAP , no dude en visitar la documentación de AWS FSx ONTAP aquí:<block ref="f270bb91d9718c264ef59ceaf9562990" category="inline-link-rx"></block> .</block>
  <block id="ac3f15100beedf3665df00f75c6a126e" category="paragraph">La sintaxis detallada de la línea de comandos para "create-file-system" de FSx se puede encontrar aquí:<block ref="6dfaa72a4db79e3cd69acb6bd09e3928" category="inline-link-rx"></block></block>
  <block id="4510c1fa7d54bc22137fc99fdee7ec14" category="paragraph">Por ejemplo, puede especificar una clave KMS específica en lugar de la clave maestra de AWS FSx predeterminada que se utiliza cuando no se especifica ninguna clave KMS.</block>
  <block id="b2d4bc4b14215051ed2eea3eff254d84" category="list-text">Al crear el sistema de archivos FSx ONTAP , espere hasta que el estado de "Ciclo de vida" cambie a "DISPONIBLE" en su devolución JSON después de describir su sistema de archivos de la siguiente manera:</block>
  <block id="fcd00639267fd24b3c25a30b3abcd5b0" category="list-text">Valide las credenciales iniciando sesión en FSx ONTAP SSH con el usuario fsxadmin: Fsxadmin es la cuenta de administrador predeterminada para los sistemas de archivos FSx ONTAP en el momento de la creación.  La contraseña para fsxadmin es la contraseña que se configuró cuando se creó por primera vez el sistema de archivos, ya sea en la consola de AWS o con la CLI de AWS, como completamos en el Paso 1.</block>
  <block id="89fd702da938a0842ce8bbbd1978c407" category="list-text">Una vez validadas sus credenciales, cree la máquina virtual de almacenamiento en el sistema de archivos FSx ONTAP</block>
  <block id="52140a6ade484065f20232f9d150ea61" category="paragraph">Una máquina virtual de almacenamiento (SVM) es un servidor de archivos aislado con sus propias credenciales administrativas y puntos finales para administrar y acceder a datos en volúmenes FSx ONTAP y proporciona multitenencia FSx ONTAP .</block>
  <block id="e05c7d2454cf3006c8871c25085ec858" category="list-text">Una vez que haya configurado su máquina virtual de almacenamiento principal, acceda por SSH al sistema de archivos FSx ONTAP recién creado y cree volúmenes en la máquina virtual de almacenamiento utilizando el siguiente comando de muestra y, de manera similar, creamos 6 volúmenes para esta validación.  Según nuestra validación, mantenga el constituyente predeterminado (8) o menos constituyentes, lo que proporcionará un mejor rendimiento a Kafka.</block>
  <block id="f82c8c9ef7e5f94bfc60abe80b30a2c1" category="list-text">Necesitaremos capacidad adicional en nuestros volúmenes para nuestras pruebas.  Amplíe el tamaño del volumen a 2 TB y móntelo en la ruta de unión.</block>
  <block id="401223c85704727381abb64f33f1e700" category="paragraph">En FSx ONTAP, los volúmenes pueden aprovisionarse de manera fina.  En nuestro ejemplo, la capacidad total del volumen extendido excede la capacidad total del sistema de archivos, por lo que necesitaremos ampliar la capacidad total del sistema de archivos para desbloquear capacidad de volumen aprovisionada adicional, lo que demostraremos en el próximo paso.</block>
  <block id="980bf78b74033a80493ead9ead18533e" category="list-text">A continuación, para obtener mayor rendimiento y capacidad, ampliamos la capacidad de rendimiento de FSx ONTAP de 2 GB/seg a 4 GB/seg y las IOPS a 160 000, y la capacidad a 5 TB.</block>
  <block id="cfd6d8adc21dc264014c117cc1a95fda" category="paragraph">La sintaxis detallada de la línea de comandos para "update-file-system" de FSx se puede encontrar aquí:<block ref="f3196344ef0cf3de8d956a0736aba68b" category="inline-link-rx"></block></block>
  <block id="d067a587144a5c3f420cd628e1e5e9ae" category="list-text">Los volúmenes de FSx ONTAP se montan con nconnect y opciones predeterminadas en los brokers de Kafka</block>
  <block id="fe25ee0c1614b7db9e4a6cec9f2cd488" category="paragraph">La siguiente imagen muestra nuestra arquitectura final de nuestro clúster Kafka basado en FSx ONTAP :</block>
  <block id="a09d4eb20485c4e2d2f9ed81274d727a" category="inline-image-macro">Esta imagen muestra la arquitectura de un clúster de Kafka basado en FSx ONTAP.</block>
  <block id="f230dbbbd1d967f5675641bd1e9ff03e" category="paragraph"><block ref="f230dbbbd1d967f5675641bd1e9ff03e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a205c51d74e59d28030cda2886e41130" category="list-text">Calcular.  Utilizamos un clúster Kafka de tres nodos con un conjunto Zookeeper de tres nodos ejecutándose en servidores dedicados.  Cada agente tenía seis puntos de montaje NFS en seis volúmenes en la instancia FSx ONTAP .</block>
  <block id="447931d0542671d1817df0b8bdc35ff4" category="list-text">Escucha.  Utilizamos dos nodos para una combinación Prometheus-Grafana.  Para generar cargas de trabajo, utilizamos un clúster separado de tres nodos que podía producir y consumir en este clúster de Kafka.</block>
  <block id="35f0ed4ee5bc59733f7cd41a36cf4721" category="list-text">Almacenamiento.  Utilizamos un FSx ONTAP con seis volúmenes de 2 TB montados.  Luego, el volumen se exportó al agente de Kafka con un montaje NFS. Los volúmenes de FSx ONTAP se montan con 16 sesiones nconnect y opciones predeterminadas en los agentes de Kafka.</block>
  <block id="c06018aab55e4fa9ef871b34b2cf7897" category="section-title">Configuraciones de evaluación comparativa de OpenMessage.</block>
  <block id="9300a7a969a31b3c5371c03474456ec3" category="paragraph">Usamos la misma configuración utilizada para los volúmenes NetApp Cloud ONTAP y sus detalles están aquí: enlace:kafka-nfs-performance-overview-and-validation-in-aws.html#architectural-setup</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">Metodología de pruebas</block>
  <block id="79f0e8e2c892a7ffb6c02f9be47fd6f5" category="list-text">Se aprovisionó un clúster de Kafka según la especificación descrita anteriormente utilizando Terraform y Ansible.  Terraform se utiliza para construir la infraestructura utilizando instancias de AWS para el clúster de Kafka y Ansible construye el clúster de Kafka en ellas.</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">Se activó una carga de trabajo OMB con la configuración de carga de trabajo descrita anteriormente y el controlador de sincronización.</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">Se activó otra carga de trabajo con el controlador de rendimiento con la misma configuración de carga de trabajo.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Observación</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">Se utilizaron dos tipos diferentes de controladores para generar cargas de trabajo para evaluar el rendimiento de una instancia de Kafka que se ejecuta en NFS.  La diferencia entre los controladores es la propiedad de vaciado del registro.</block>
  <block id="6e3e5905f95f1d3670a864fd2b1e1855" category="paragraph">Para un factor de replicación de Kafka 1 y FSx ONTAP:</block>
  <block id="477397883986e4a6ef0944db3f171a9a" category="list-text">Rendimiento total generado consistentemente por el controlador de sincronización: ~ 3218 MBps y rendimiento máximo en ~ 3652 MBps.</block>
  <block id="526cf61e40ed54cf3e36bc48e608fe6a" category="list-text">Rendimiento total generado consistentemente por el controlador de rendimiento: ~ 3679 MBps y rendimiento máximo en ~ 3908 MBps.</block>
  <block id="5c677e3834aab5345e650615a307b653" category="paragraph">Para Kafka con factor de replicación 3 y FSx ONTAP :</block>
  <block id="1d0957e5fc4340aeed631639b2076501" category="list-text">Rendimiento total generado consistentemente por el controlador de sincronización: ~ 1252 MBps y rendimiento máximo en ~ 1382 MBps.</block>
  <block id="e18b6be6753e1c55e4474648e1073e75" category="list-text">Rendimiento total generado consistentemente por el controlador de rendimiento: ~ 1218 MBps y rendimiento máximo en ~ 1328 MBps.</block>
  <block id="9e99c55380b9b536ec73cd9bdfbad865" category="paragraph">En el factor de replicación 3 de Kafka, la operación de lectura y escritura ocurrió tres veces en FSx ONTAP. En el factor de replicación 1 de Kafka, la operación de lectura y escritura ocurrió una vez en FSx ONTAP, por lo que en ambas validaciones pudimos alcanzar el rendimiento máximo de 4 GB/seg.</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">El controlador de sincronización puede generar un rendimiento constante a medida que los registros se vacían en el disco instantáneamente, mientras que el controlador de rendimiento genera ráfagas de rendimiento a medida que los registros se envían al disco en forma masiva.</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">Estos números de rendimiento se generan para la configuración de AWS dada.  Para requisitos de mayor rendimiento, los tipos de instancias se pueden escalar y ajustar aún más para obtener mejores números de rendimiento.  El rendimiento total o tasa total es la combinación de la tasa del productor y del consumidor.</block>
  <block id="5d4902b750979a6daa75a334daf3b4dd" category="inline-image-macro">Esta imagen muestra el rendimiento de Kafka con RF1 y RF3</block>
  <block id="67731dd79a61f656bfde458fade09eb2" category="paragraph"><block ref="67731dd79a61f656bfde458fade09eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3293059261e00d42aa4678d1677be1b1" category="paragraph">La siguiente gráfica muestra el rendimiento de FSx ONTAP a 2 GB/seg y de 4 GB/seg para el factor de replicación 3 de Kafka.  El factor de replicación 3 realiza la operación de lectura y escritura tres veces en el almacenamiento FSx ONTAP .  La tasa total del controlador de rendimiento es de 881 MB/seg, que realiza operaciones de lectura y escritura de Kafka a aproximadamente 2,64 GB/seg en el sistema de archivos FSx ONTAP de 2 GB/seg, y la tasa total del controlador de rendimiento es de 1328 MB/seg, que realiza operaciones de lectura y escritura de Kafka a aproximadamente 3,98 GB/seg.  El rendimiento de Kafka es lineal y escalable según el rendimiento de FSx ONTAP .</block>
  <block id="a7ddac9765853f96e59270871b8a3925" category="inline-image-macro">Esta imagen muestra el rendimiento de escalamiento de 2 GB/seg y 4 GB/seg.</block>
  <block id="94043e4666620e8e09ceedcb705c7951" category="paragraph"><block ref="94043e4666620e8e09ceedcb705c7951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61f2d83a3758c796ac8892836cada117" category="paragraph">El siguiente gráfico muestra el rendimiento entre la instancia EC2 y FSx ONTAP (factor de replicación de Kafka: 3)</block>
  <block id="b891a78e120a481bc23346cb210b2fa2" category="inline-image-macro">Esta imagen muestra la comparación de rendimiento de EC2 vs FSx ONTAP en RF3.</block>
  <block id="59b617ab46ce09f11c02ed94c18645e4" category="paragraph"><block ref="59b617ab46ce09f11c02ed94c18645e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">Descripción general del rendimiento y validación en AWS</block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">Kafka en la nube de AWS con NetApp Cloud Volumes ONTAP (par de alta disponibilidad y nodo único)</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">Se evaluó el rendimiento de un clúster de Kafka con NetApp Cloud Volumes ONTAP (par HA) en la nube de AWS.  Esta evaluación comparativa se describe en las siguientes secciones.</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">La siguiente tabla muestra la configuración ambiental para un clúster de Kafka que utiliza NAS.</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">Instancia NetApp Cloud Volumes ONTAP</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">Instancia de par HA: m5dn.12xLarge x 2 nodos Instancia de nodo único: m5dn.12xLarge x 1 nodo</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">Configuración de ONTAP del volumen del clúster de NetApp</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">Para el par Cloud Volumes ONTAP HA, creamos dos agregados con tres volúmenes en cada agregado en cada controlador de almacenamiento.  Para cada nodo de Cloud Volumes ONTAP , creamos seis volúmenes en total.</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">Esta imagen representa las propiedades de aggr3 y aggr22.</block>
  <block id="cc5972f21a1c1b3f25fd1c54ca580885" category="paragraph"><block ref="cc5972f21a1c1b3f25fd1c54ca580885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">Esta imagen representa las propiedades de aggr2.</block>
  <block id="7bf987d778dee1c98d1b0b2d5fb00a9c" category="paragraph"><block ref="7bf987d778dee1c98d1b0b2d5fb00a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">Para lograr un mejor rendimiento de la red, habilitamos redes de alta velocidad tanto para el par HA como para el nodo único.</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">Estas imágenes muestran cómo habilitar redes de alta velocidad.</block>
  <block id="49c32669e9d6be5a2b08ff5d8eb59127" category="paragraph"><block ref="49c32669e9d6be5a2b08ff5d8eb59127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">Notamos que la NVRAM de ONTAP tenía más IOPS, por lo que cambiamos las IOPS a 2350 para el volumen raíz de Cloud Volumes ONTAP .  El disco de volumen raíz en Cloud Volumes ONTAP tenía un tamaño de 47 GB.  El siguiente comando ONTAP es para el par HA y el mismo paso se aplica para el nodo único.</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">Esta imagen muestra cómo modificar las propiedades del volumen.</block>
  <block id="044b1cecac787ba4da45dc749881f5a1" category="paragraph"><block ref="044b1cecac787ba4da45dc749881f5a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">La siguiente figura muestra la arquitectura de un clúster de Kafka basado en NAS.</block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*Calcular.*  Utilizamos un clúster Kafka de tres nodos con un conjunto Zookeeper de tres nodos ejecutándose en servidores dedicados.  Cada agente tenía dos puntos de montaje NFS en un solo volumen en la instancia de Cloud Volumes ONTAP a través de un LIF dedicado.</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*Escucha.*  Utilizamos dos nodos para una combinación Prometheus-Grafana.  Para generar cargas de trabajo, utilizamos un clúster separado de tres nodos que podía producir y consumir en este clúster de Kafka.</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*Almacenamiento.*  Utilizamos una instancia de Cloud Volumes ONTAP de par HA con un volumen AWS-EBS GP3 de 6 TB montado en la instancia.  Luego, el volumen se exportó al broker de Kafka con un montaje NFS.</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">Esta figura representa la arquitectura de un clúster de Kafka basado en NAS.</block>
  <block id="474d97e74219f2fc9511f3691ed0ae94" category="paragraph"><block ref="474d97e74219f2fc9511f3691ed0ae94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">Configuraciones de evaluación comparativa de OpenMessage</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">Para un mejor rendimiento de NFS, necesitamos más conexiones de red entre el servidor NFS y el cliente NFS, que se pueden crear utilizando nconnect.  Monte los volúmenes NFS en los nodos del agente con la opción nconnect ejecutando el siguiente comando:</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">Verifique las conexiones de red en Cloud Volumes ONTAP.  El siguiente comando ONTAP se utiliza desde el único nodo Cloud Volumes ONTAP .  El mismo paso se aplica al par Cloud Volumes ONTAP HA.</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">Usamos el siguiente Kafka<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> en todos los brokers de Kafka para el par Cloud Volumes ONTAP HA.  El<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> La propiedad es diferente para cada corredor y las propiedades restantes son comunes para los corredores.  Para el broker1, el<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> El valor es el siguiente:</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">Para el broker2, el<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> El valor de la propiedad es el siguiente:</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">Para el broker3, el<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> El valor de la propiedad es el siguiente:</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">Para el nodo único de Cloud Volumes ONTAP , Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block> es lo mismo que para el par Cloud Volumes ONTAP HA excepto por el<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> propiedad.</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">Para el broker1, el<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> El valor es el siguiente:</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">Para el broker2, el<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> El valor es el siguiente:</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">La carga de trabajo en la OMB está configurada con las siguientes propiedades:<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block> .</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">El<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block> Puede variar para cada caso de uso.  En nuestra prueba de rendimiento, utilizamos 3K.</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">Utilizamos dos controladores diferentes, Sync o Throughput, de OMB para generar la carga de trabajo en el clúster de Kafka.</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">El archivo yaml utilizado para las propiedades del controlador de sincronización es el siguiente<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block> :</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">El archivo yaml utilizado para las propiedades del controlador de rendimiento es el siguiente<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block> :</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">Se aprovisionó un clúster de Kafka según la especificación descrita anteriormente utilizando Terraform y Ansible.  Terraform se utiliza para construir la infraestructura utilizando instancias de AWS para el clúster de Kafka y Ansible construye el clúster de Kafka en ellas.</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">Para un par de Cloud Volumes ONTAP HA:</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">Rendimiento total generado consistentemente por el controlador de sincronización: ~1236 MBps.</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">Rendimiento total generado para el controlador de rendimiento: pico ~1412 MBps.</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">Para un solo nodo de Cloud Volumes ONTAP :</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">Rendimiento total generado consistentemente por el controlador de sincronización: ~ 1962 MBps.</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">Rendimiento total generado por el controlador de rendimiento: pico ~1660 MBps</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">Aquí se presentan cuatro gráficos diferentes.  Controlador de rendimiento del par CVO-HA.  Controlador de sincronización del par CVO-HA.  Controlador de rendimiento de nodo único CVO.  Controlador de sincronización de nodo único CVO.</block>
  <block id="d2fc51602d60125ca82c279f8a8e03af" category="paragraph"><block ref="d2fc51602d60125ca82c279f8a8e03af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">Asegúrese de verificar el rendimiento del almacenamiento al realizar evaluaciones comparativas del controlador de sincronización o del rendimiento.</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">Este gráfico muestra el rendimiento en latencia, IOPS y rendimiento.</block>
  <block id="e34c5c483b0b104d0cc1453f3be5f6b4" category="paragraph"><block ref="e34c5c483b0b104d0cc1453f3be5f6b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">Esta sección describe el problema del cambio de nombre tonto y los cambios necesarios para que el servidor NFS y el cliente NFS solucionen el problema.</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">Solución de NetApp para el problema del cambio de nombre en cargas de trabajo de NFS a Kafka</block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">Kafka está construido bajo el supuesto de que el sistema de archivos subyacente es compatible con POSIX: por ejemplo, XFS o Ext4.  El reequilibrio de recursos de Kafka elimina archivos mientras la aplicación aún los está utilizando.  Un sistema de archivos compatible con POSIX permite que la desvinculación continúe.  Sin embargo, solo elimina el archivo después de que desaparezcan todas las referencias al mismo.  Si el sistema de archivos subyacente está conectado a la red, entonces el cliente NFS intercepta las llamadas de desvinculación y administra el flujo de trabajo.  Debido a que hay aperturas pendientes en el archivo que se va a desvincular, el cliente NFS envía una solicitud de cambio de nombre al servidor NFS y, en el último cierre del archivo desvinculado, emite una operación de eliminación en el archivo renombrado.  Este comportamiento se conoce comúnmente como cambio de nombre tonto de NFS y está orquestado por el cliente NFS.</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">Cualquier agente de Kafka que utilice almacenamiento de un servidor NFSv3 tendrá problemas debido a este comportamiento.  Sin embargo, el protocolo NFSv4.x tiene características para abordar este problema al permitir que el servidor se haga responsable de los archivos abiertos y no vinculados.  Los servidores NFS que admiten esta función opcional comunican la capacidad de propiedad al cliente NFS en el momento de la apertura del archivo.  El cliente NFS luego detiene la gestión de desvinculación cuando hay aperturas pendientes y permite que el servidor administre el flujo.  Aunque la especificación NFSv4 proporciona pautas para la implementación, hasta ahora no se conocía ninguna implementación de servidor NFS que admitiera esta característica opcional.</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">Se requieren los siguientes cambios para el servidor NFS y el cliente NFS para solucionar el problema del cambio de nombre tonto:</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*Cambios en el cliente NFS (Linux).*  En el momento de abrir un archivo, el servidor NFS responde con una bandera, indicando la capacidad de manejar la desvinculación de los archivos abiertos.  Los cambios del lado del cliente NFS permiten que el servidor NFS maneje la desvinculación en presencia del indicador.  NetApp ha actualizado el cliente NFS Linux de código abierto con estos cambios.  El cliente NFS actualizado ahora está disponible de forma general en RHEL8.7 y RHEL9.1.</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*Cambios en el servidor NFS.*  El servidor NFS realiza un seguimiento de las aperturas.  La desvinculación de un archivo abierto existente ahora es administrada por el servidor para que coincida con la semántica POSIX.  Cuando se cierra el último archivo abierto, el servidor NFS inicia la eliminación real del archivo y evita así el tonto proceso de cambio de nombre.  El servidor NFS de ONTAP ha implementado esta capacidad en su última versión, ONTAP 9.12.1.</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">Con los cambios mencionados anteriormente en el cliente y el servidor NFS, Kafka puede aprovechar de forma segura todos los beneficios del almacenamiento NFS conectado a la red.</block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">Para la validación funcional, demostramos que un clúster de Kafka con un montaje NFSv3 para almacenamiento no puede realizar operaciones de Kafka como la redistribución de particiones, mientras que otro clúster montado en NFSv4 con la solución puede realizar las mismas operaciones sin interrupciones.</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">Validación funcional: Solución para un cambio de nombre tonto</block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">Configuración de validación</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">La configuración se ejecuta en AWS.  La siguiente tabla muestra los diferentes componentes de la plataforma y la configuración ambiental utilizados para la validación.</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Plataforma Confluent versión 7.2.1</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">3 x cuidadores del zoológico – t3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4 servidores intermediarios – r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1 x Grafana – t3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">1 x centro de control – t3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3 x Productor/consumidor</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL8.7 o posterior</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">Instancia de un solo nodo – M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">La siguiente figura muestra la configuración arquitectónica para esta solución.</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">Esta imagen muestra la topología de AWS que contiene una VPC que contiene tres subredes privadas con un enjambre de productores, el clúster de Kafka y la instancia CVO respectivamente.</block>
  <block id="2046377162498de9fec810aafa41c2b3" category="paragraph"><block ref="2046377162498de9fec810aafa41c2b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">Flujo arquitectónico</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*Calcular.*  Utilizamos un clúster Kafka de cuatro nodos con un conjunto Zookeeper de tres nodos ejecutándose en servidores dedicados.</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*Escucha.*  Utilizamos dos nodos para una combinación Prometheus-Grafana.</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*Carga de trabajo.*  Para generar cargas de trabajo, utilizamos un clúster separado de tres nodos que puede producir y consumir desde este clúster de Kafka.</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*Almacenamiento.*  Utilizamos una instancia de NetApp Cloud Volumes ONTAP de un solo nodo con dos volúmenes AWS-EBS GP2 de 500 GB conectados a la instancia.  Luego, estos volúmenes se expusieron al clúster de Kafka como un único volumen NFSv4.1 a través de un LIF.</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">Se eligieron las propiedades predeterminadas de Kafka para todos los servidores.  Lo mismo se hizo con el enjambre de cuidadores del zoológico.</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">Actualizar<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block> Al volumen de Kafka, como sigue:</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">Se crearon dos clústeres de Kafka similares con la siguiente diferencia:</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*Grupo 1.*  El servidor backend NFS v4.1 que ejecutaba ONTAP versión 9.12.1 lista para producción estaba alojado en una instancia CVO de NetApp .  Se instalaron RHEL 8.7/RHEL 9.1 en los brokers.</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*Grupo 2.*  El servidor NFS backend era un servidor NFSv3 Linux genérico creado manualmente.</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">Se creó un tema de demostración en ambos clústeres de Kafka.</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">Grupo 1:</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">Esta captura de pantalla muestra el tema de demostración creado en el Clúster 1.</block>
  <block id="23e2fb3a3a7caf11826a6ddc3650812b" category="paragraph"><block ref="23e2fb3a3a7caf11826a6ddc3650812b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">Grupo 2:</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">Esta captura de pantalla muestra el tema de demostración creado en el Clúster 2.</block>
  <block id="2d82e26036412c43987356c7c8ca8fb3" category="paragraph"><block ref="2d82e26036412c43987356c7c8ca8fb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">Se cargaron datos en estos temas recién creados para ambos clústeres.  Esto se hizo utilizando el kit de herramientas de prueba de rendimiento del productor que viene en el paquete predeterminado de Kafka:</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">Se realizó una comprobación del estado del broker-1 para cada uno de los clústeres mediante telnet:</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">Telnet<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">Telnet<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">En la siguiente captura de pantalla se muestra una verificación de estado exitosa de los corredores en ambos clústeres:</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">Esta captura de pantalla muestra la lectura de una verificación de estado exitosa en ambos corredores.</block>
  <block id="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="paragraph"><block ref="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">Para activar la condición de error que provoca que los clústeres de Kafka que usan volúmenes de almacenamiento NFSv3 se bloqueen, iniciamos el proceso de reasignación de particiones en ambos clústeres.  La reasignación de particiones se realizó utilizando<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block> .  El proceso detallado es el siguiente:</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">Para reasignar las particiones de un tema en un clúster de Kafka, generamos el JSON de configuración de reasignación propuesto (esto se realizó para ambos clústeres).</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">Luego, el JSON de reasignación generado se guardó en<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block> .</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">El proceso de reasignación de partición real se activó mediante el siguiente comando:</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">Después de unos minutos, cuando se completó la reasignación, otra verificación del estado de los intermediarios mostró que el clúster que usaba volúmenes de almacenamiento NFSv3 se había topado con un problema de cambio de nombre tonto y se había bloqueado, mientras que el clúster 1 que usaba volúmenes de almacenamiento NetApp ONTAP NFSv4.1 con la solución continuó con sus operaciones sin interrupciones.</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">Esta captura de pantalla muestra la salida de un bróker bloqueado.</block>
  <block id="3a51f6a0340d9026c9fc6619a6584b83" category="paragraph"><block ref="3a51f6a0340d9026c9fc6619a6584b83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">Cluster1-Broker-1 está activo.</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">Cluster2-broker-1 está muerto.</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">Al verificar los directorios de registro de Kafka, quedó claro que el Clúster 1 que usaba volúmenes de almacenamiento NetApp ONTAP NFSv4.1 con la corrección tenía una asignación de partición limpia, mientras que el Clúster 2 que usaba almacenamiento NFSv3 genérico no la tenía debido a problemas de cambio de nombre tontos, que provocaron el bloqueo.  La siguiente imagen muestra el reequilibrio de la partición del Clúster 2, lo que provocó un problema de cambio de nombre tonto en el almacenamiento NFSv3.</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">Esta captura de pantalla muestra la salida del registro del bloqueo del Cluster 2.</block>
  <block id="587e107619187efb07b3bd05f8bcf7f9" category="paragraph"><block ref="587e107619187efb07b3bd05f8bcf7f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">La siguiente imagen muestra un reequilibrio de partición limpio del Clúster 1 utilizando almacenamiento NetApp NFSv4.1.</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">Esta captura de pantalla muestra la salida del registro para una asignación exitosa de partición limpia para el Clúster 1, mientras que</block>
  <block id="f3d0f09c5b4a3c2f532881572a744b6c" category="paragraph"><block ref="f3d0f09c5b4a3c2f532881572a744b6c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">Ahora que existe una solución para el problema del cambio de nombre tonto en el almacenamiento NFS con Kafka, puede crear implementaciones sólidas que aprovechen el almacenamiento NetApp ONTAP para su carga de trabajo de Kafka.  Esto no solo reduce significativamente los gastos generales operativos, sino que también aporta los siguientes beneficios a sus clústeres de Kafka.</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">¿Por qué NetApp NFS para cargas de trabajo de Kafka?</block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">Ahora que existe una solución para el problema del cambio de nombre tonto en el almacenamiento NFS con Kafka, puede crear implementaciones sólidas que aprovechen el almacenamiento NetApp ONTAP para su carga de trabajo de Kafka.  Esto no solo reduce significativamente los gastos operativos, sino que también aporta los siguientes beneficios a sus clústeres de Kafka:</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">*Utilización reducida de CPU en los brókers de Kafka.*  El uso de almacenamiento desagregado de NetApp ONTAP separa las operaciones de E/S de disco del agente y, de este modo, reduce su huella de CPU.</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*Tiempo de recuperación del corredor más rápido.*  Dado que el almacenamiento desagregado de NetApp ONTAP se comparte entre los nodos del agente de Kafka, una nueva instancia de cómputo puede reemplazar a un agente defectuoso en cualquier momento en una fracción del tiempo en comparación con las implementaciones convencionales de Kafka sin reconstruir los datos.</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">*Eficiencia de almacenamiento.* Como la capa de almacenamiento de la aplicación ahora se aprovisiona a través de NetApp ONTAP, los clientes pueden aprovechar todos los beneficios de eficiencia de almacenamiento que viene con ONTAP, como compresión de datos en línea, deduplicación y compactación.</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">Estos beneficios fueron probados y validados en casos de prueba que discutimos en detalle en esta sección.</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">Uso reducido de la CPU en el bróker de Kafka</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">Descubrimos que la utilización general de la CPU es menor que la de su contraparte DAS cuando ejecutamos cargas de trabajo similares en dos clústeres de Kafka separados que eran idénticos en sus especificaciones técnicas pero diferían en sus tecnologías de almacenamiento.  No solo la utilización general de la CPU es menor cuando el clúster de Kafka usa almacenamiento ONTAP , sino que el aumento en la utilización de la CPU demostró un gradiente más suave que en un clúster de Kafka basado en DAS.</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">La siguiente tabla muestra la configuración ambiental utilizada para demostrar una utilización reducida de la CPU.</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Herramienta de evaluación comparativa de Kafka 3.2.3: OpenMessaging</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4 x Productor/Consumidor -- c5n.2xlarge</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7 o posterior</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">Instancia de nodo único – M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">Herramienta de evaluación comparativa</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">Mensajería abierta</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">La herramienta de evaluación comparativa utilizada en este caso de prueba es la<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block> estructura.  OpenMessaging es neutral respecto de proveedores e independiente del lenguaje; proporciona pautas industriales para finanzas, comercio electrónico, IoT y big data; y ayuda a desarrollar aplicaciones de mensajería y transmisión en sistemas y plataformas heterogéneos.  La siguiente figura muestra la interacción de los clientes de OpenMessaging con un clúster de Kafka.</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">Esta imagen muestra la interacción de los clientes de OpenMessaging con un clúster de Kafka.</block>
  <block id="9cb3e560e852dc92918678c092a4105e" category="paragraph"><block ref="9cb3e560e852dc92918678c092a4105e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*Calcular.*  Utilizamos un clúster Kafka de tres nodos con un conjunto Zookeeper de tres nodos ejecutándose en servidores dedicados.  Cada agente tenía dos puntos de montaje NFSv4.1 en un solo volumen en la instancia CVO de NetApp a través de un LIF dedicado.</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*Escucha.*  Utilizamos dos nodos para una combinación Prometheus-Grafana.  Para generar cargas de trabajo, tenemos un clúster separado de tres nodos que puede producir y consumir desde este clúster de Kafka.</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*Almacenamiento.*  Utilizamos una instancia de NetApp Cloud Volumes ONTAP de un solo nodo con seis volúmenes AWS-EBS GP2 de 250 GB montados en la instancia.  Luego, estos volúmenes se expusieron al clúster de Kafka como seis volúmenes NFSv4.1 a través de LIF dedicados.</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*Configuración.*  Los dos elementos configurables en este caso de prueba fueron los agentes de Kafka y las cargas de trabajo de OpenMessaging.</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*Configuración del corredor.*  Se seleccionaron las siguientes especificaciones para los corredores de Kafka.  Utilizamos un factor de replicación de 3 para todas las mediciones, como se destaca a continuación.</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">Esta imagen muestra las especificaciones seleccionadas para los brokers de Kafka.</block>
  <block id="41b835894ba02ffb1ba3f3fdae71877c" category="paragraph"><block ref="41b835894ba02ffb1ba3f3fdae71877c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">*Configuración de carga de trabajo de referencia de OpenMessaging (OMB).*  Se proporcionaron las siguientes especificaciones:  Especificamos una tasa de productor objetivo, resaltada a continuación.</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">Esta imagen muestra las especificaciones seleccionadas para la configuración de la carga de trabajo de referencia de OpenMessaging.</block>
  <block id="41106ec7ad546fdd6a08b370c8093ab9" category="paragraph"><block ref="41106ec7ad546fdd6a08b370c8093ab9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">Se crearon dos clústeres similares, cada uno con su propio conjunto de enjambres de clústeres de evaluación comparativa.</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">*Grupo 1.*  Clúster Kafka basado en NFS.</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">*Grupo 2.*  Clúster Kafka basado en DAS.</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">Usando un comando OpenMessaging, se activaron cargas de trabajo similares en cada clúster.</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">La configuración de la tasa de producción se incrementó en cuatro iteraciones y la utilización de la CPU se registró con Grafana.  La tasa de producción se fijó en los siguientes niveles:</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10.000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40.000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80.000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100.000</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">Hay dos beneficios principales de usar almacenamiento NFS de NetApp con Kafka:</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*Puede reducir el uso de la CPU en casi un tercio.*  El uso general de la CPU bajo cargas de trabajo similares fue menor para NFS en comparación con los SSD DAS; los ahorros varían del 5 % para tasas de producción más bajas al 32 % para tasas de producción más altas.</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">*Una reducción de tres veces en la deriva de utilización de la CPU a tasas de producción más altas.*  Como era de esperar, hubo una tendencia ascendente en el aumento de la utilización de la CPU a medida que aumentaron las tasas de producción.  Sin embargo, la utilización de la CPU en los brókers de Kafka que usan DAS aumentó del 31 % para la tasa de producción más baja al 70 % para la tasa de producción más alta, un aumento del 39 %.  Sin embargo, con un backend de almacenamiento NFS, la utilización de la CPU aumentó del 26% al 38%, un aumento del 12%.</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">Este gráfico representa el comportamiento de un clúster basado en DAS.</block>
  <block id="9630ee6aa29406a977bc5179849d2639" category="paragraph"><block ref="9630ee6aa29406a977bc5179849d2639" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">Este gráfico representa el comportamiento de un clúster basado en NFS.</block>
  <block id="74336896d4b61e55ed364028f046f35b" category="paragraph"><block ref="74336896d4b61e55ed364028f046f35b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">Además, con 100.000 mensajes, DAS muestra una mayor utilización de la CPU que un clúster NFS.</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">Este gráfico representa el comportamiento de un clúster basado en DAS con 100.000 mensajes.</block>
  <block id="73c360518d32a693e133ab63604b2ab4" category="paragraph"><block ref="73c360518d32a693e133ab63604b2ab4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">Este gráfico representa el comportamiento de un clúster basado en NFS con 100.000 mensajes.</block>
  <block id="be31c668debc31c9573036c63b1b4f49" category="paragraph"><block ref="be31c668debc31c9573036c63b1b4f49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">Recuperación más rápida del corredor</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">Descubrimos que los agentes de Kafka se recuperan más rápido cuando utilizan almacenamiento NFS compartido de NetApp .  Cuando un broker falla en un clúster de Kafka, este broker puede ser reemplazado por un broker en buen estado con el mismo ID de broker.  Al realizar este caso de prueba, descubrimos que, en el caso de un clúster de Kafka basado en DAS, el clúster reconstruye los datos en un agente en buen estado recién agregado, lo que consume mucho tiempo.  En el caso de un clúster Kafka basado en NFS de NetApp , el agente de reemplazo continúa leyendo datos del directorio de registro anterior y se recupera mucho más rápido.</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4 x productor/consumidor -- c5n.2xlarge</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1 nodo de respaldo de Kafka – i3en.2xlarge</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7 o posterior</block>
  <block id="477284b661c88fdd810eb7273729b5ed" category="paragraph"><block ref="477284b661c88fdd810eb7273729b5ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*Calcular.*  Un clúster de Kafka de tres nodos con un conjunto Zookeeper de tres nodos que se ejecuta en servidores dedicados.  Cada agente tiene dos puntos de montaje NFS en un solo volumen en la instancia CVO de NetApp a través de un LIF dedicado.</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*Escucha.*  Dos nodos para una combinación Prometheus-Grafana.  Para generar cargas de trabajo, utilizamos un clúster separado de tres nodos que puede producir y consumir en este clúster de Kafka.</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*Almacenamiento.*  Una instancia de volúmenes NetApp Cloud ONTAP de un solo nodo con seis volúmenes AWS-EBS GP2 de 250 GB montados en la instancia.  Luego, estos volúmenes se exponen al clúster de Kafka como seis volúmenes NFS a través de LIF dedicados.</block>
  <block id="7a4e5e874bf6fcf8217de7f8f0af5acb" category="list-text">*Configuración del broker.*  El único elemento configurable en este caso de prueba son los brokers de Kafka.  Se seleccionaron las siguientes especificaciones para los corredores de Kafka.  El<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block> se establece en un valor alto porque esto determina qué tan rápido se saca un nodo particular de la lista ISR.  Cuando cambia entre nodos defectuosos y saludables, no desea que ese ID de agente se excluya de la lista de ISR.</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">Esta imagen muestra las especificaciones elegidas para los brokers de Kafka.</block>
  <block id="ce565ed35fddb2c8191f4b8496e98245" category="paragraph"><block ref="ce565ed35fddb2c8191f4b8496e98245" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">Se crearon dos clústeres similares:</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">Un clúster confluente basado en EC2.</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">Un clúster confluente basado en NFS de NetApp .</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">Se creó un nodo de Kafka en espera con una configuración idéntica a los nodos del clúster de Kafka original.</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">En cada uno de los clústeres, se creó un tema de muestra y se completaron aproximadamente 110 GB de datos en cada uno de los corredores.</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">*Clúster basado en EC2.*  Un directorio de datos del corredor de Kafka está asignado a<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block> (En la siguiente figura, Broker-1 del cluster1 [terminal izquierda]).</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">* Clúster basado en NFS de NetApp .*  Un directorio de datos del agente de Kafka está montado en el punto NFS<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block> (En la siguiente figura, Broker-1 del cluster2 [terminal derecha]).</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">Esta imagen muestra dos pantallas de terminal.</block>
  <block id="3a534dc7ed1f2e8444c4b278dd70aa7e" category="paragraph"><block ref="3a534dc7ed1f2e8444c4b278dd70aa7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">En cada uno de los clústeres, se finalizó Broker-1 para desencadenar un proceso de recuperación de broker fallido.</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">Una vez finalizado el broker, su dirección IP se asignó como IP secundaria al broker en espera.  Esto fue necesario porque un bróker en un clúster de Kafka se identifica por lo siguiente:</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">*Dirección IP.*  Se asigna reasignando la IP del agente fallido al agente en espera.</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*Identificación del corredor.*  Esto se configuró en el agente en espera<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> .</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">Tras la asignación de IP, se inició el servicio Kafka en el bróker en espera.</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">Después de un tiempo, se extrajeron los registros del servidor para verificar el tiempo que tomó generar datos en el nodo de reemplazo en el clúster.</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">La recuperación del corredor de Kafka fue casi nueve veces más rápida.  Se descubrió que el tiempo necesario para recuperar un nodo de agente fallido era significativamente más rápido cuando se usaba almacenamiento compartido NFS de NetApp en comparación con el uso de SSD DAS en un clúster de Kafka.  Para 1 TB de datos de temas, el tiempo de recuperación de un clúster basado en DAS fue de 48 minutos, en comparación con menos de 5 minutos para un clúster Kafka basado en NetApp-NFS.</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">Observamos que el clúster basado en EC2 tardó 10 minutos en reconstruir los 110 GB de datos en el nuevo nodo del agente, mientras que el clúster basado en NFS completó la recuperación en 3 minutos.  También observamos en los registros que las compensaciones del consumidor para las particiones de EC2 eran 0, mientras que, en el clúster NFS, las compensaciones del consumidor se tomaron del agente anterior.</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">Clúster basado en DAS</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">El nodo de respaldo se inició a las 08:55:53,730.</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">Esta imagen muestra la salida del registro para un clúster basado en DAS.</block>
  <block id="91569a3f4fee956cd801e625cc8eb34f" category="paragraph"><block ref="91569a3f4fee956cd801e625cc8eb34f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">El proceso de reconstrucción de datos finalizó a las 09:05:24.860.  El procesamiento de 110 GB de datos requirió aproximadamente 10 minutos.</block>
  <block id="d598dda290e226574121bf65a66222c1" category="paragraph"><block ref="d598dda290e226574121bf65a66222c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">Clúster basado en NFS</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">El nodo de respaldo se inició a las 09:39:17,213.  La entrada del registro de inicio se resalta a continuación.</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">Esta imagen muestra la salida del registro para un clúster basado en NFS.</block>
  <block id="bbb8038819966fa92b04b31dfe935e66" category="paragraph"><block ref="bbb8038819966fa92b04b31dfe935e66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">El proceso de reconstrucción de datos finalizó a las 09:42:29,115.  El procesamiento de 110 GB de datos requirió aproximadamente 3 minutos.</block>
  <block id="bb69fdfb2a75f135682b3880999f8c2e" category="paragraph"><block ref="bb69fdfb2a75f135682b3880999f8c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">La prueba se repitió para los corredores que contenían alrededor de 1 TB de datos, lo que tomó aproximadamente 48 minutos para DAS y 3 minutos para NFS.  Los resultados se muestran en el siguiente gráfico.</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">Este gráfico muestra el tiempo que tarda el agente en recuperarse según la cantidad de datos cargados en el agente para un clúster basado en DAS o un clúster basado en NFS.</block>
  <block id="fcc7c3e745c4c2ba0f4fe48c8d589122" category="paragraph"><block ref="fcc7c3e745c4c2ba0f4fe48c8d589122" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd18465573ec21a6218982055981f6b1" category="section-title">Eficiencia de almacenamiento</block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">Debido a que la capa de almacenamiento del clúster Kafka se aprovisionó a través de NetApp ONTAP, obtuvimos todas las capacidades de eficiencia de almacenamiento de ONTAP.  Esto se probó generando una cantidad significativa de datos en un clúster de Kafka con almacenamiento NFS aprovisionado en Cloud Volumes ONTAP.  Pudimos ver que hubo una reducción de espacio significativa debido a las capacidades de ONTAP .</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">Instancia de nodo único – M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*Calcular.*  Utilizamos un clúster Kafka de tres nodos con un conjunto Zookeeper de tres nodos ejecutándose en servidores dedicados.  Cada agente tenía dos puntos de montaje NFS en un solo volumen en la instancia CVO de NetApp a través de un LIF dedicado.</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*Almacenamiento.*  Utilizamos una instancia de NetApp Cloud Volumes ONTAP de un solo nodo con seis volúmenes AWS-EBS GP2 de 250 GB montados en la instancia.  Luego, estos volúmenes se expusieron al clúster de Kafka como seis volúmenes NFS a través de LIF dedicados.</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*Configuración.*  Los elementos configurables en este caso de prueba fueron los brokers de Kafka.</block>
  <block id="8e44bdd37fc66a06e9780582642d0c37" category="paragraph">La compresión se desactivó en el extremo del productor, lo que permitió a los productores generar un alto rendimiento.  La eficiencia del almacenamiento, en cambio, quedó a cargo de la capa de cómputo.</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">Se aprovisionó un clúster de Kafka con las especificaciones mencionadas anteriormente.</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">En el clúster, se produjeron alrededor de 350 GB de datos utilizando la herramienta OpenMessaging Benchmarking.</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">Una vez completada la carga de trabajo, se recopilaron las estadísticas de eficiencia de almacenamiento utilizando ONTAP System Manager y la CLI.</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">En el caso de los datos generados con la herramienta OMB, observamos un ahorro de espacio de aproximadamente un 33 % con una relación de eficiencia de almacenamiento de 1,70:1.  Como se ve en las siguientes figuras, el espacio lógico utilizado por los datos producidos fue de 420,3 GB y el espacio físico utilizado para almacenar los datos fue de 281,7 GB.</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">Esta imagen muestra el ahorro de espacio en VMDISK.</block>
  <block id="565d9cbc0c15374b9bdebe62dd5efe32" category="paragraph"><block ref="565d9cbc0c15374b9bdebe62dd5efe32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">Captura de pantalla</block>
  <block id="50abdfc5295b4aedbb53a46e0bd7512b" category="paragraph"><block ref="50abdfc5295b4aedbb53a46e0bd7512b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6c6f7c15f1d0324567be0828cb855f7" category="paragraph"><block ref="c6c6f7c15f1d0324567be0828cb855f7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">Este documento describe los puntos de referencia de rendimiento para la plataforma Confluent en NetApp ONTAP utilizando un kit de evaluación comparativa de almacenamiento por niveles.</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941: Compatible con controladores de almacenamiento NetApp ONTAP</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam, Joe Scott, NetApp Rankesh Kumar, Confluent</block>
  <block id="30f774bc5050b82b9a42fe5d8f4bc99f" category="paragraph">Para que la plataforma Confluent sea más escalable y elástica, debe poder escalar y equilibrar cargas de trabajo muy rápidamente.  El almacenamiento por niveles permite almacenar grandes volúmenes de datos en Confluent de forma manejable, reduciendo esta carga operativa.</block>
  <block id="981ac9f1443bdd13b0920d6ca1ee4eb3" category="paragraph">La idea fundamental es separar el almacenamiento de datos del procesamiento de datos, lo que hace que sea mucho más fácil escalar cada uno de ellos independientemente.</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">Cargado con innovaciones líderes en la industria, el software de gestión de datos NetApp ONTAP proporciona a Confluent muchas ventajas en cualquier lugar donde se encuentren los datos.</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">Realizamos pruebas de almacenamiento en niveles con tres o cuatro nodos para cargas de trabajo de producción y consumo con la configuración NetApp StorageGRID .</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">Pruebas de rendimiento con escalabilidad</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">Realizamos pruebas de almacenamiento en niveles con tres o cuatro nodos para cargas de trabajo de productores y consumidores con la configuración NetApp StorageGRID .  Según nuestras pruebas, el tiempo de finalización y los resultados de rendimiento fueron directamente proporcionales a la cantidad de nodos StorageGRID .  La configuración de StorageGRID requirió un mínimo de tres nodos.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">El tiempo para completar la operación de producción y consumo disminuyó linealmente cuando aumentó el número de nodos de almacenamiento.</block>
  <block id="5393f806598ea16510805a4ab3b20623" category="paragraph"><block ref="5393f806598ea16510805a4ab3b20623" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">El rendimiento de la operación de recuperación s3 aumentó linealmente según la cantidad de nodos StorageGRID .  StorageGRID admite hasta 200 nodos StorgeGRID.</block>
  <block id="d73d827635c7a6fcfa52120cc6f3b96d" category="paragraph"><block ref="d73d827635c7a6fcfa52120cc6f3b96d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">Esta prueba se basa en la función de clústeres de autoequilibrio, que automatiza el reequilibrio en función de los cambios en la topología del clúster o de la carga desigual.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Clústeres autoequilibrados confluentes</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">Si ha administrado un clúster de Kafka anteriormente, probablemente esté familiarizado con los desafíos que implica reasignar manualmente particiones a diferentes agentes para asegurarse de que la carga de trabajo esté equilibrada en todo el clúster.  Para las organizaciones con grandes implementaciones de Kafka, reorganizar grandes cantidades de datos puede ser una tarea abrumadora, tediosa y riesgosa, especialmente si las aplicaciones de misión crítica se crean sobre el clúster.  Sin embargo, incluso para los casos de uso más pequeños de Kafka, el proceso consume mucho tiempo y es propenso a errores humanos.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">En nuestro laboratorio, probamos la función de clústeres de autoequilibrio de Confluent, que automatiza el reequilibrio en función de los cambios en la topología del clúster o de la carga desigual.  La prueba de reequilibrio de Confluent ayuda a medir el tiempo necesario para agregar un nuevo agente cuando falla un nodo o el nodo de escalamiento requiere reequilibrar los datos entre los agentes.  En las configuraciones clásicas de Kafka, la cantidad de datos a reequilibrar crece a medida que crece el clúster, pero, en el almacenamiento en niveles, el reequilibrio está restringido a una pequeña cantidad de datos.  Según nuestra validación, el reequilibrio en el almacenamiento en niveles toma segundos o minutos en una arquitectura clásica de Kafka y crece linealmente a medida que crece el clúster.</block>
  <block id="829c663686b68c76ea97bd7a23d534b6" category="paragraph">En los clústeres con autoequilibrio, los reequilibrios de particiones están completamente automatizados para optimizar el rendimiento de Kafka, acelerar el escalamiento del agente y reducir la carga operativa de ejecutar un clúster grande.  En estado estable, los clústeres autoequilibrados monitorean la desviación de los datos entre los intermediarios y reasignan particiones continuamente para optimizar el rendimiento del clúster.  Al escalar la plataforma hacia arriba o hacia abajo, los clústeres de autoequilibrio reconocen automáticamente la presencia de nuevos intermediarios o la eliminación de intermediarios antiguos y activan una reasignación de partición posterior.  Esto le permite agregar y desmantelar corredores fácilmente, lo que hace que sus clústeres de Kafka sean fundamentalmente más elásticos.  Estos beneficios se obtienen sin necesidad de intervención manual, cálculos matemáticos complejos o el riesgo de error humano que normalmente conllevan las reasignaciones de particiones.  Como resultado, los reequilibrios de datos se completan en mucho menos tiempo y usted puede concentrarse en proyectos de transmisión de eventos de mayor valor en lugar de tener que supervisar constantemente sus clústeres.</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">En esta configuración, le mostramos cómo leer y escribir temas en el almacenamiento de objetos desde Kafka directamente usando el conector de receptor Kafka s3.  Para esta prueba, utilizamos un clúster Confluent independiente, pero esta configuración es aplicable a un clúster distribuido.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Conector s3 confluente</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">El conector Amazon S3 Sink exporta datos de temas de Apache Kafka a objetos S3 en formatos Avro, JSON o Bytes.  El conector de sumidero de Amazon S3 sondea periódicamente datos de Kafka y, a su vez, los carga en S3.  Se utiliza un particionador para dividir los datos de cada partición de Kafka en fragmentos.  Cada fragmento de datos se representa como un objeto S3.  El nombre de la clave codifica el tema, la partición de Kafka y el desplazamiento de inicio de este fragmento de datos.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Descargue Confluent Kafka desde el sitio web de Confluent.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">Descomprima el paquete en una carpeta en su servidor.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">Exportar dos variables.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">Para una configuración independiente de Confluent Kafka, el clúster crea una carpeta raíz temporal en<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> También crea carpetas de Zookeeper, Kafka, un registro de esquema, connect, un ksql-server y un centro de control y copia sus respectivos archivos de configuración desde<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block> .  Vea el siguiente ejemplo:</block>
  <block id="ed529b17b192b6bcfa1fb220aa0f37e4" category="list-text">Configurar Zookeeper.  No es necesario cambiar nada si utiliza los parámetros predeterminados.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">En la configuración anterior, actualizamos el<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block> propiedad.  De forma predeterminada, se necesitan tres guardianes del zoológico para la selección del líder de Kafka.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">Creamos un archivo myid en<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block> con un ID único:</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">Utilizamos el último número de direcciones IP para el archivo myid.  Utilizamos valores predeterminados para las configuraciones de Kafka, connect, control-center, Kafka, Kafka-rest, ksql-server y schema-registry.</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Inicie los servicios de Kafka.</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">Hay una carpeta de registro para cada configuración, que ayuda a solucionar problemas.  En algunos casos los servicios tardan más tiempo en iniciarse.  Asegúrese de que todos los servicios estén en funcionamiento.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">Instalar Kafka connect usando<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block> .</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">También puedes instalar una versión específica usando<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block> .</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">Por defecto,<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> está instalado en<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block> .</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">Actualice la ruta del complemento con el nuevo<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> .</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Detenga los servicios de Confluent y reinícielos.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">Configurar el ID de acceso y la clave secreta en el<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">Verifique que el depósito sea accesible.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">Configure el archivo de propiedades s3-sink para la configuración de s3 y del bucket.</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">Importar algunos registros al bucket s3.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">Cargue el conector s3-sink.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">Verifique el estado del receptor s3.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">Verifique el registro para asegurarse de que s3-sink esté listo para aceptar temas.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Consulte los temas en Kafka.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">Verifique los objetos en el bucket s3.</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">Para verificar el contenido, copie cada archivo de S3 a su sistema de archivos local ejecutando el siguiente comando:</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Archivos Apache</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">Para imprimir los registros, utilice avro-tools-1.11.0.1.jar (disponible en el<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block> ).</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">Esta página describe las mejores prácticas para mejorar el rendimiento de esta solución.</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">Pautas de mejores prácticas de rendimiento</block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">Para ONTAP, cuando sea posible, utilice un tamaño GET &gt;=1 MB.</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">Creciente<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> y<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> en<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> en los nodos del intermediario le permite impulsar una mayor actividad de niveles al nivel S3.  Estos resultados son con<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> y<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> establecido en 32.</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">Los grupos S3 deben tener como objetivo ocho constituyentes por agregado de miembros.</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">Los enlaces Ethernet que conducen tráfico S3 deben utilizar una MTU de 9k cuando sea posible tanto en el almacenamiento como en el cliente.</block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">Esta prueba de verificación alcanzó 31,74 GBps de rendimiento de niveles en Confluent con un controlador de almacenamiento NetApp ONTAP .</block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">Esta prueba de verificación alcanzó 31,74 GBps de rendimiento de niveles en Confluent con el controlador de almacenamiento NetApp ONTAP .</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">¿Qué es Confluent?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">Mejores prácticas de S3 en ONTAP</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">Gestión de almacenamiento de objetos S3</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">Esta página describe la validación del rendimiento de Confluent dentro de los parámetros de esta solución.</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Validación del rendimiento de Confluent</block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">Hemos realizado la verificación con Confluent Platform para almacenamiento en niveles en NetApp ONTAP.  Los equipos de NetApp y Confluent trabajaron juntos en esta verificación y ejecutaron los casos de prueba necesarios para ello.</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Configuración confluente</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">Para la configuración, utilizamos tres zookeepers, cinco brokers y cinco servidores de prueba con 256 GB de RAM y 16 CPU.  Para el almacenamiento de NetApp , utilizamos ONTAP con un par AFF A900 HA.  El almacenamiento y los intermediarios estaban conectados a través de conexiones de 100 GbE.</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">La siguiente figura muestra la topología de red de la configuración utilizada para la verificación del almacenamiento en niveles.</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">Este gráfico muestra la topología de red de la configuración utilizada para la verificación del almacenamiento en niveles.</block>
  <block id="b460294b1898fd26dfbb545338caacee" category="paragraph"><block ref="b460294b1898fd26dfbb545338caacee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">Los servidores de herramientas actúan como clientes de aplicaciones que envían o reciben eventos hacia o desde los nodos Confluent.</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">Utilizamos los siguientes parámetros de prueba:</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">Para la verificación, utilizamos ONTAP con el protocolo HTTP, pero HTTPS también funcionó.  La clave de acceso y la clave secreta se almacenan en el nombre de archivo proporcionado en el<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> parámetro.</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">Controlador de almacenamiento NetApp – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">Configuramos una única configuración de par HA en ONTAP para verificación.</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">Este gráfico muestra cómo se configuró el entorno como un solo par HA para verificación.</block>
  <block id="267b459a69088e0dc82f7fe972205f92" category="paragraph"><block ref="267b459a69088e0dc82f7fe972205f92" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">Resultados de la verificación</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">Completamos los siguientes cinco casos de prueba para la verificación.  Las dos primeras fueron pruebas de funcionalidad y las tres restantes fueron pruebas de rendimiento.</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">Esta prueba realiza operaciones básicas como obtener, colocar y eliminar en el almacén de objetos utilizado para el almacenamiento en niveles mediante llamadas API.</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">Esta prueba verifica la funcionalidad de extremo a extremo del almacenamiento de objetos.  Crea un tema, produce un flujo de eventos para el tema recién creado, espera a que los intermediarios archiven los segmentos en el almacenamiento de objetos, consume el flujo de eventos y valida que el flujo consumido coincida con el flujo producido.  Hemos realizado esta prueba con y sin inyección de falla en el almacén de objetos.  Simulamos una falla de nodo deteniendo el servicio del administrador de servicios en uno de los nodos en ONTAP y validando que la funcionalidad de extremo a extremo funciona con el almacenamiento de objetos.</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">Generador de carga de trabajo de producción y consumo</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">Esta prueba genera indirectamente una carga de trabajo de escritura en el almacén de objetos a través del archivado de segmentos.  La carga de trabajo de lectura (segmentos leídos) se generó desde el almacenamiento de objetos cuando los grupos de consumidores obtuvieron los segmentos.  Esta carga de trabajo fue generada por un script TOCC.  Esta prueba verificó el rendimiento de lectura y escritura en el almacenamiento de objetos en subprocesos paralelos.  Realizamos pruebas con y sin inyección de fallas en el almacén de objetos como lo hicimos para la prueba de corrección de la funcionalidad de niveles.</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">Generador de carga de trabajo de retención</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">Esta prueba verificó el rendimiento de eliminación de un almacenamiento de objetos bajo una carga de trabajo pesada de retención de temas.  La carga de trabajo de retención se generó utilizando un script TOCC que produce muchos mensajes en paralelo a un tema de prueba.  El tema de prueba fue configurar una configuración de retención agresiva basada en el tamaño y el tiempo que provocó que el flujo de eventos se purgara continuamente del almacén de objetos.  Los segmentos fueron luego archivados.  Esto provocó muchas eliminaciones en el almacenamiento de objetos por parte del agente y la recopilación del rendimiento de las operaciones de eliminación del almacén de objetos.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="inline-link">Confluente</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">Para obtener detalles de verificación, consulte la<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> sitio web.</block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">Realizamos pruebas de almacenamiento en niveles con cinco u ocho nodos intermediarios durante una carga de trabajo de producción-consumo con un controlador de almacenamiento NetApp de par AFF A900 HA.  Según nuestras pruebas, el tiempo de finalización y los resultados de rendimiento aumentaron con el número de nodos del intermediario hasta que la utilización de recursos del AFF A900 alcanzó el cien por ciento.  La configuración del controlador de almacenamiento ONTAP requiere un mínimo de un par HA.</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">Pruebas de rendimiento con generador de carga de trabajo de producción y consumo</block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">El rendimiento de la operación de recuperación de S3 aumentó linealmente en función del número de nodos del agente Confluent.  El controlador de almacenamiento ONTAP admite hasta 12 pares HA en una sola implementación.</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">El siguiente gráfico muestra el tráfico combinado de niveles S3 con cinco u ocho nodos de intermediario.  Maximizamos el rendimiento del par HA único AFF A900 .</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">Este gráfico de datos muestra el tráfico combinado en niveles S3 con cinco u ocho nodos de intermediario.</block>
  <block id="d1912fadda4ef80cc1a01c7f3f919602" category="paragraph"><block ref="d1912fadda4ef80cc1a01c7f3f919602" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">El siguiente gráfico muestra el rendimiento de Kafka en aproximadamente 31,74 GBps.</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">Este gráfico de datos muestra el rendimiento de Kafka en aproximadamente 31,74 GBps.</block>
  <block id="a9504735d0b0cbb3b424919bb1328a7d" category="paragraph"><block ref="a9504735d0b0cbb3b424919bb1328a7d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">También observamos un rendimiento similar en el controlador de almacenamiento ONTAP<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block> informe.</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">Esta sección cubre el hardware y el software utilizados para la verificación del rendimiento en la implementación de Confluent Platform con NetApp ONTAP para almacenamiento en niveles.  La siguiente tabla cubre la arquitectura de la solución y los componentes base.</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">El controlador de almacenamiento Confluent y NetApp AFF A900 impulsado por ONTAP son sistemas distribuidos diseñados para flujos de datos.  Ambos son escalables horizontalmente, tolerantes a fallas y proporcionan un excelente rendimiento bajo carga.  Se complementan entre sí en la transmisión distribuida de datos y el procesamiento de flujos con menores costos de almacenamiento con tecnologías de reducción de datos que minimizan la huella de datos.  El controlador de almacenamiento AFF A900 proporciona un gran rendimiento, al tiempo que permite disociar los recursos de procesamiento y almacenamiento de datos.  Esto simplifica la administración del sistema y permite escalar los recursos de forma independiente.</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">Imagen que representa la descripción general de la solución.</block>
  <block id="c7c06ecce0e6f1e46fab6853d4d45058" category="paragraph"><block ref="c7c06ecce0e6f1e46fab6853d4d45058" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Plataforma Confluent versión 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3 x cuidadores del zoológico</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8 servidores de intermediarios</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5 servidores de herramientas</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 x Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 x centro de control</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">NetApp ONTAP para buckets calientes</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 par de alta disponibilidad (HA) AFF A900</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2 CPU; 16 núcleos físicos en total</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">Intel Xeon</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256 GB de memoria física</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">Puerto dual de 100 GbE</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">Esta página describe la tecnología utilizada en esta solución.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">Descripción general de la tecnología</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">Controlador de almacenamiento NetApp ONTAP</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP es un sistema operativo de almacenamiento de nivel empresarial y alto rendimiento.</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8 presenta compatibilidad con las API de Amazon Simple Storage Service (S3).  ONTAP admite un subconjunto de acciones de API S3 de Amazon Web Services (AWS) y permite que los datos se representen como objetos en sistemas basados en ONTAP en proveedores de nube (AWS, Azure y GCP) y en las instalaciones locales.</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">El software NetApp StorageGRID es la solución insignia de NetApp para el almacenamiento de objetos.  ONTAP complementa StorageGRID al proporcionar un punto de ingesta y preprocesamiento en el borde, expandiendo la estructura de datos impulsada por NetApp para datos de objetos y aumentando el valor de la cartera de productos de NetApp .</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">El acceso a un bucket S3 se proporciona a través de aplicaciones cliente y de usuarios autorizados.  El siguiente diagrama muestra la aplicación accediendo a un bucket S3.</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">Este gráfico muestra la aplicación accediendo a un bucket S3.</block>
  <block id="185bab9f8946071e86896c051a520617" category="paragraph"><block ref="185bab9f8946071e86896c051a520617" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">Casos de uso principales</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">El propósito principal de soportar las API de S3 es proporcionar acceso a los objetos en ONTAP.  La arquitectura de almacenamiento unificada ONTAP ahora admite archivos (NFS y SMB), bloques (FC e iSCSI) y objetos (S3).</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">Aplicaciones nativas de S3</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">Un número cada vez mayor de aplicaciones pueden aprovechar el soporte de ONTAP para el acceso a objetos mediante S3.  Si bien es adecuado para cargas de trabajo de archivo de alta capacidad, la necesidad de alto rendimiento en aplicaciones S3 nativas está creciendo rápidamente e incluye:</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">Analítica</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">Inteligencia artificial</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">Ingesta de borde a núcleo</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">Los clientes ahora pueden usar herramientas de administración familiares como ONTAP System Manager para aprovisionar rápidamente almacenamiento de objetos de alto rendimiento para el desarrollo y las operaciones en ONTAP, aprovechando las eficiencias y la seguridad del almacenamiento de ONTAP al hacerlo.</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">Puntos finales de FabricPool</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">A partir de ONTAP 9.8, FabricPool admite la organización en niveles de buckets en ONTAP, lo que permite la organización en niveles de ONTAP a ONTAP .  Esta es una excelente opción para los clientes que desean reutilizar la infraestructura FAS existente como un punto final de almacenamiento de objetos.</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool admite la creación de niveles en ONTAP de dos maneras:</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*Niveles de clúster local.*  Los datos inactivos se agrupan en niveles en un depósito ubicado en el clúster local mediante LIF de clúster.</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*Niveles de clúster remotos.*  Los datos inactivos se agrupan en niveles en un depósito ubicado en un clúster remoto de manera similar a un nivel de nube FabricPool tradicional utilizando LIF de IC en el cliente FabricPool y LIF de datos en el almacén de objetos de ONTAP .</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">ONTAP S3 es adecuado si desea capacidades de S3 en clústeres existentes sin hardware ni administración adicionales.  Para implementaciones de más de 300 TB, el software NetApp StorageGRID sigue siendo la solución insignia de NetApp para el almacenamiento de objetos.  No se requiere una licencia de FabricPool cuando se utiliza ONTAP o StorageGRID como nivel de nube.</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">NetApp ONTAP para almacenamiento en niveles Confluent</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">Todo centro de datos necesita mantener las aplicaciones críticas para el negocio en funcionamiento y los datos importantes disponibles y seguros.  El nuevo sistema NetApp AFF A900 está equipado con el software ONTAP Enterprise Edition y un diseño de alta resiliencia.  Nuestro nuevo sistema de almacenamiento NVMe ultrarrápido elimina las interrupciones en las operaciones de misión crítica, minimiza el ajuste del rendimiento y protege sus datos de los ataques de ransomware.</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">Desde la implementación inicial hasta la ampliación de su clúster Confluent, su entorno exige una adaptación rápida a cambios que no interrumpan sus aplicaciones críticas para el negocio.  La gestión de datos empresariales, la calidad de servicio (QoS) y el rendimiento de ONTAP le permiten planificar y adaptarse a su entorno.</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">El uso conjunto de NetApp ONTAP y Confluent Tiered Storage simplifica la administración de clústeres Apache Kafka al aprovechar ONTAP como un destino de almacenamiento de escalamiento horizontal y permite el escalamiento independiente de los recursos de cómputo y almacenamiento para Confluent.</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">Un servidor ONTAP S3 está construido sobre las maduras capacidades de almacenamiento de escalamiento horizontal de ONTAP.  Es posible escalar su clúster ONTAP sin inconvenientes ampliando sus buckets S3 para usar nodos recientemente agregados al clúster ONTAP .</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">Gestión sencilla con ONTAP System Manager</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP System Manager es una interfaz gráfica basada en navegador que le permite configurar, administrar y monitorear su controlador de almacenamiento ONTAP en ubicaciones distribuidas globalmente en un solo panel.</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">Este gráfico muestra el espacio de trabajo del Administrador del sistema ONTAP .</block>
  <block id="db8cf11125f7909f889c4894d1b8c042" category="paragraph"><block ref="db8cf11125f7909f889c4894d1b8c042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">Puede configurar y administrar ONTAP S3 con el Administrador del sistema y la CLI de ONTAP .  Cuando habilita S3 y crea depósitos mediante el Administrador del sistema, ONTAP proporciona valores predeterminados recomendados para una configuración simplificada.  Si configura el servidor S3 y los depósitos desde la CLI, aún puede administrarlos con el Administrador del sistema si lo desea o viceversa.</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">Cuando crea un bucket S3 mediante el Administrador del sistema, ONTAP configura un nivel de servicio de rendimiento predeterminado que es el más alto disponible en su sistema.  Por ejemplo, en un sistema AFF , la configuración predeterminada sería Extrema.  Los niveles de servicio de rendimiento son grupos de políticas de QoS adaptativas predefinidos.  En lugar de uno de los niveles de servicio predeterminados, puede especificar un grupo de políticas de QoS personalizado o ningún grupo de políticas.</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">Los grupos de políticas de QoS adaptativas predefinidos incluyen lo siguiente:</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*Extremo.*  Se utiliza para aplicaciones que requieren la menor latencia y el mayor rendimiento.</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*Actuación.*  Se utiliza para aplicaciones con necesidades de rendimiento y latencia modestas.</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*Valor.*  Se utiliza para aplicaciones donde el rendimiento y la capacidad son más importantes que la latencia.</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*Costumbre.*  Especifique una política de QoS personalizada o ninguna política de QoS.</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">Si selecciona *Usar para niveles*, no se seleccionarán niveles de servicio de rendimiento y el sistema intentará seleccionar medios de bajo costo con un rendimiento óptimo para los datos escalonados.</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP intenta aprovisionar este depósito en niveles locales que tengan los discos más apropiados, satisfaciendo el nivel de servicio elegido.  Sin embargo, si necesita especificar qué discos incluir en el depósito, considere configurar el almacenamiento de objetos S3 desde la CLI especificando los niveles locales (agregados).  Si configura el servidor S3 desde la CLI, aún puede administrarlo con el Administrador del sistema si lo desea.</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">Si desea tener la capacidad de especificar qué agregados se utilizan para los depósitos, solo puede hacerlo mediante la CLI.</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent Platform es una plataforma de transmisión de datos a gran escala que le permite acceder, almacenar y administrar datos fácilmente como transmisiones continuas en tiempo real.  Desarrollado por los creadores originales de Apache Kafka, Confluent amplía los beneficios de Kafka con funciones de nivel empresarial y al mismo tiempo elimina la carga de la administración o el monitoreo de Kafka.  Hoy en día, más del 80% de las empresas Fortune 100 funcionan con tecnología de transmisión de datos y la mayoría utiliza Confluent.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">¿Por qué Confluent?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">Al integrar datos históricos y en tiempo real en una única fuente central de verdad, Confluent facilita la creación de una categoría totalmente nueva de aplicaciones modernas basadas en eventos, obtiene una canalización de datos universal y desbloquea nuevos casos de uso poderosos con total escalabilidad, rendimiento y confiabilidad.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">¿Para qué se utiliza Confluent?</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Confluent Platform le permite centrarse en cómo obtener valor comercial de sus datos en lugar de preocuparse por la mecánica subyacente, como la forma en que se transportan o integran los datos entre sistemas dispares.  En concreto, Confluent Platform simplifica la conexión de fuentes de datos a Kafka, la creación de aplicaciones de transmisión, así como la protección, la supervisión y la gestión de su infraestructura de Kafka.  Hoy en día, Confluent Platform se utiliza para una amplia gama de casos de uso en numerosas industrias, desde servicios financieros, venta minorista omnicanal y automóviles autónomos hasta detección de fraudes, microservicios e IoT.</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">La siguiente figura muestra los componentes de Confluent Platform.</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">Este gráfico muestra los componentes de la plataforma Confluent.</block>
  <block id="e21a51ac4ed645780def5d56f85ac9a8" category="paragraph"><block ref="e21a51ac4ed645780def5d56f85ac9a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Descripción general de la tecnología de transmisión de eventos de Confluent</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">Kafka</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">En el núcleo de la Plataforma Confluent se encuentra<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block> , la plataforma de transmisión distribuida de código abierto más popular.  Las capacidades clave de Kafka incluyen las siguientes:</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">Publicar y suscribirse a flujos de registros.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">Almacene flujos de registros de manera tolerante a fallos.</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">Procesar flujos de registros.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">De fábrica, Confluent Platform también incluye Schema Registry, REST Proxy, un total de más de 100 conectores Kafka prediseñados y ksqlDB.</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Descripción general de las funciones empresariales de la plataforma Confluent</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*Centro de Control de Confluentes.*  Un sistema basado en UI para administrar y monitorear Kafka.  Le permite administrar fácilmente Kafka Connect y crear, editar y administrar conexiones a otros sistemas.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*Confluent para Kubernetes.*  Confluent for Kubernetes es un operador de Kubernetes.  Los operadores de Kubernetes amplían las capacidades de orquestación de Kubernetes al proporcionar características y requisitos únicos para una aplicación de plataforma específica.  Para Confluent Platform, esto incluye simplificar enormemente el proceso de implementación de Kafka en Kubernetes y automatizar las tareas típicas del ciclo de vida de la infraestructura.</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">*Conectores de Kafka Connect.*  Los conectores utilizan la API de Kafka Connect para conectar Kafka a otros sistemas, como bases de datos, almacenes de clave-valor, índices de búsqueda y sistemas de archivos.  Confluent Hub tiene conectores descargables para las fuentes y receptores de datos más populares, incluidas versiones totalmente probadas y compatibles de estos conectores con Confluent Platform.  Se pueden encontrar más detalles<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*Clústeres autoequilibrados.*  Proporciona equilibrio de carga automatizado, detección de fallas y autorreparación.  También proporciona soporte para agregar o desmantelar corredores según sea necesario, sin necesidad de realizar ajustes manuales.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*Enlace de clústeres confluentes.*  Conecta directamente los clústeres entre sí y refleja temas de un clúster a otro a través de un puente de enlace.  La vinculación de clústeres simplifica la configuración de implementaciones de múltiples centros de datos, múltiples clústeres y nubes híbridas.</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*Balanceador automático de datos Confluent.*  Supervisa su clúster para conocer la cantidad de intermediarios, el tamaño de las particiones, la cantidad de particiones y la cantidad de líderes dentro del clúster.  Le permite cambiar datos para crear una carga de trabajo uniforme en todo el clúster, al mismo tiempo que limita el tráfico de reequilibrio para minimizar el efecto en las cargas de trabajo de producción durante el reequilibrio.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*Replicador confluente.*  Hace que sea más fácil que nunca mantener múltiples clústeres de Kafka en múltiples centros de datos.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*Almacenamiento por niveles.*  Proporciona opciones para almacenar grandes volúmenes de datos de Kafka utilizando su proveedor de nube favorito, reduciendo así la carga operativa y los costos.  Con el almacenamiento por niveles, puede mantener los datos en un almacenamiento de objetos rentable y escalar intermediarios solo cuando necesite más recursos computacionales.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">*Cliente JMS Confluent.*  Confluent Platform incluye un cliente compatible con JMS para Kafka.  Este cliente de Kafka implementa la API estándar JMS 1.1, utilizando intermediarios de Kafka como backend.  Esto es útil si tiene aplicaciones heredadas que usan JMS y desea reemplazar el agente de mensajes JMS existente con Kafka.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Proxy MQTT confluente.*  Proporciona una manera de publicar datos directamente en Kafka desde dispositivos y puertas de enlace MQTT sin la necesidad de un agente MQTT en el medio.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">*Complementos de seguridad de Confluent.*  Los complementos de seguridad de Confluent se utilizan para agregar capacidades de seguridad a varias herramientas y productos de la plataforma Confluent.  Actualmente, hay un complemento disponible para el proxy REST de Confluent que ayuda a autenticar las solicitudes entrantes y propagar el principal autenticado a las solicitudes a Kafka.  Esto permite que los clientes proxy REST de Confluent utilicen las funciones de seguridad multiinquilino del bróker Kafka.</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">StorageGRID en NetApp</block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID es una plataforma de almacenamiento de objetos rentable y de alto rendimiento.  Al utilizar almacenamiento en niveles, la mayoría de los datos en Confluent Kafka, que se almacenan en el almacenamiento local o en el almacenamiento SAN del broker, se descargan al almacén de objetos remoto.  Esta configuración genera mejoras operativas significativas al reducir el tiempo y el costo de reequilibrar, expandir o reducir clústeres o reemplazar un agente fallido.  El almacenamiento de objetos juega un papel importante en la administración de datos que residen en el nivel de almacenamiento de objetos, por eso es importante elegir el almacenamiento de objetos correcto.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID ofrece una gestión de datos global inteligente basada en políticas mediante una arquitectura de cuadrícula distribuida basada en nodos.  Simplifica la gestión de petabytes de datos no estructurados y miles de millones de objetos a través de su omnipresente espacio de nombres de objetos globales combinado con sofisticadas funciones de gestión de datos.  El acceso a objetos mediante una sola llamada se extiende a través de los sitios y simplifica las arquitecturas de alta disponibilidad al tiempo que garantiza el acceso continuo a los objetos, independientemente de las interrupciones del sitio o la infraestructura.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">La multitenencia permite que múltiples aplicaciones de datos empresariales y en la nube no estructurados se atiendan de forma segura dentro de la misma red, lo que aumenta el retorno de la inversión y los casos de uso de NetApp StorageGRID.  Puede crear múltiples niveles de servicio con políticas de ciclo de vida de objetos basadas en metadatos, optimizando la durabilidad, la protección, el rendimiento y la localidad en múltiples geografías.  Los usuarios pueden ajustar las políticas de gestión de datos y monitorear y aplicar límites de tráfico para realinearlos al panorama de datos de manera no disruptiva a medida que sus requisitos cambian en entornos de TI en constante cambio.</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Gestión sencilla con Grid Manager</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID Grid Manager es una interfaz gráfica basada en navegador que le permite configurar, administrar y monitorear su sistema StorageGRID en ubicaciones distribuidas globalmente en un solo panel.</block>
  <block id="772a64d9b71789d3f7910c440c370541" category="paragraph"><block ref="772a64d9b71789d3f7910c440c370541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">Puede realizar las siguientes tareas con la interfaz de StorageGRID Grid Manager:</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">Administre repositorios de objetos, como imágenes, vídeos y registros, distribuidos globalmente y a escala de petabytes.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">Supervisar los nodos y servicios de la red para garantizar la disponibilidad de los objetos.</block>
  <block id="e21286be18c417a3042cb53e1dd1e8da" category="list-text">Gestione la ubicación de los datos de objetos a lo largo del tiempo utilizando reglas de gestión del ciclo de vida de la información (ILM).  Estas reglas rigen lo que sucede con los datos de un objeto después de su ingesta, cómo se protegen contra pérdidas, dónde se almacenan los datos del objeto y durante cuánto tiempo.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">Supervisar transacciones, rendimiento y operaciones dentro del sistema.</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">Políticas de gestión del ciclo de vida de la información</block>
  <block id="0550f1f7df7311673165b9915b4d10b2" category="paragraph">StorageGRID tiene políticas de administración de datos flexibles que incluyen mantener copias de réplica de sus objetos y usar esquemas EC (codificación de borrado) como 2+1 y 4+2 (entre otros) para almacenar sus objetos, dependiendo de los requisitos específicos de rendimiento y protección de datos.  A medida que las cargas de trabajo y los requisitos cambian con el tiempo, es común que las políticas de ILM también deban cambiar con el tiempo.  La modificación de las políticas de ILM es una característica fundamental que permite a los clientes de StorageGRID adaptarse a su entorno en constante cambio de forma rápida y sencilla.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Actuación</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 o SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID escala el rendimiento agregando más nodos de almacenamiento, que pueden ser máquinas virtuales, hardware o dispositivos diseñados específicamente como el<block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block> .  En nuestras pruebas, superamos los requisitos clave de rendimiento de Apache Kafka con una cuadrícula de tres nodos de tamaño mínimo utilizando el dispositivo SGF6024.  A medida que los clientes escalan su clúster de Kafka con agentes adicionales, pueden agregar más nodos de almacenamiento para aumentar el rendimiento y la capacidad.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">Configuración del balanceador de carga y del punto final</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">Los nodos de administración en StorageGRID proporcionan la interfaz de usuario (IU) de Grid Manager y el punto final de API REST para ver, configurar y administrar su sistema StorageGRID , así como registros de auditoría para rastrear la actividad del sistema.  Para proporcionar un punto final S3 de alta disponibilidad para el almacenamiento en niveles de Confluent Kafka, implementamos el balanceador de carga StorageGRID , que se ejecuta como un servicio en los nodos de administración y los nodos de puerta de enlace.  Además, el balanceador de carga también administra el tráfico local y se comunica con GSLB (Global Server Load Balancing) para ayudar con la recuperación ante desastres.</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">Para mejorar aún más la configuración de los puntos finales, StorageGRID proporciona políticas de clasificación de tráfico integradas en el nodo de administración, le permite monitorear el tráfico de su carga de trabajo y aplica varios límites de calidad de servicio (QoS) a sus cargas de trabajo.  Las políticas de clasificación de tráfico se aplican a los puntos finales del servicio StorageGRID Load Balancer para los nodos de puerta de enlace y los nodos de administración.  Estas políticas pueden ayudar a configurar y monitorear el tráfico.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">Clasificación del tráfico en StorageGRID</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID tiene funcionalidad QoS incorporada.  Las políticas de clasificación de tráfico pueden ayudar a monitorear diferentes tipos de tráfico S3 provenientes de una aplicación cliente.  Luego, puede crear y aplicar políticas para poner límites a este tráfico en función del ancho de banda de entrada y salida, la cantidad de solicitudes de lectura y escritura simultáneas o la tasa de solicitudes de lectura y escritura.</block>
  <block id="75dab812558989436263375877a82fb6" category="paragraph">Apache Kafka es una implementación de marco de un bus de software que utiliza procesamiento de flujo escrito en Java y Scala.  Su objetivo es proporcionar una plataforma unificada, de alto rendimiento y baja latencia para gestionar transmisiones de datos en tiempo real.  Kafka puede conectarse a un sistema externo para exportar e importar datos a través de Kafka Connect y proporciona Kafka Streams, una biblioteca de procesamiento de flujos de Java.  Kafka utiliza un protocolo binario basado en TCP que está optimizado para la eficiencia y se apoya en una abstracción de "conjunto de mensajes" que agrupa naturalmente los mensajes para reducir la sobrecarga del viaje de ida y vuelta de la red.  Esto permite operaciones de disco secuenciales más grandes, paquetes de red más grandes y bloques de memoria contiguos, lo que permite a Kafka convertir un flujo ráfaga de escrituras de mensajes aleatorios en escrituras lineales.  La siguiente figura representa el flujo de datos básico de Apache Kafka.</block>
  <block id="3c061e9fbf92872063da256279195fbb" category="paragraph"><block ref="3c061e9fbf92872063da256279195fbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka almacena mensajes clave-valor que provienen de una cantidad arbitraria de procesos llamados productores.  Los datos se pueden dividir en diferentes particiones dentro de diferentes temas.  Dentro de una partición, los mensajes se ordenan estrictamente por sus desplazamientos (la posición de un mensaje dentro de una partición) y se indexan y almacenan junto con una marca de tiempo.  Otros procesos llamados consumidores pueden leer mensajes de las particiones.  Para el procesamiento de flujos, Kafka ofrece la API Streams que permite escribir aplicaciones Java que consumen datos de Kafka y escriben los resultados en Kafka.  Apache Kafka también funciona con sistemas de procesamiento de flujo externos como Apache Apex, Apache Flink, Apache Spark, Apache Storm y Apache NiFi.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka se ejecuta en un clúster de uno o más servidores (llamados intermediarios) y las particiones de todos los temas se distribuyen entre los nodos del clúster.  Además, las particiones se replican en múltiples intermediarios.  Esta arquitectura permite a Kafka entregar flujos masivos de mensajes de manera tolerante a fallos y le ha permitido reemplazar algunos de los sistemas de mensajería convencionales como Java Message Service (JMS), Advanced Message Queuing Protocol (AMQP), etc.  Desde el lanzamiento de la versión 0.11.0.0, Kafka ofrece escrituras transaccionales, que proporcionan exactamente un procesamiento de flujo mediante la API Streams.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka admite dos tipos de temas: regulares y compactados.  Los temas regulares se pueden configurar con un tiempo de retención o un límite de espacio.  Si hay registros que son más antiguos que el tiempo de retención especificado o si se excede el límite de espacio para una partición, Kafka puede eliminar datos antiguos para liberar espacio de almacenamiento.  De forma predeterminada, los temas están configurados con un tiempo de retención de 7 días, pero también es posible almacenar datos indefinidamente.  Para los temas compactados, los registros no caducan según límites de tiempo o espacio.  En cambio, Kafka trata los mensajes posteriores como actualizaciones de mensajes más antiguos con la misma clave y garantiza nunca eliminar el mensaje más reciente por clave.  Los usuarios pueden eliminar mensajes por completo escribiendo un mensaje denominado "tombstone" con un valor nulo para una clave específica.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Hay cinco API principales en Kafka:</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">*API de productor.*  Permite que una aplicación publique flujos de registros.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*API del consumidor.*  Permite que una aplicación se suscriba a temas y procese flujos de registros.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">*API de conector.*  Ejecuta las API de productor y consumidor reutilizables que pueden vincular los temas a las aplicaciones existentes.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*API de transmisiones.*  Esta API convierte los flujos de entrada en salida y produce el resultado.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*API de administración.*  Se utiliza para administrar temas de Kafka, intermediarios y otros objetos de Kafka.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">Las API de consumidor y productor se basan en el protocolo de mensajería de Kafka y ofrecen una implementación de referencia para los clientes consumidores y productores de Kafka en Java.  El protocolo de mensajería subyacente es un protocolo binario que los desarrolladores pueden usar para escribir sus propios clientes consumidores o productores en cualquier lenguaje de programación.  Esto desbloquea Kafka del ecosistema de la máquina virtual Java (JVM).  En la wiki de Apache Kafka se mantiene una lista de clientes que no son Java disponibles.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Casos de uso de Apache Kafka</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka es más popular para mensajería, seguimiento de actividad del sitio web, métricas, agregación de registros, procesamiento de transmisiones, abastecimiento de eventos y registro de confirmaciones.</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka ha mejorado el rendimiento, la partición integrada, la replicación y la tolerancia a fallas, lo que lo convierte en una buena solución para aplicaciones de procesamiento de mensajes a gran escala.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka puede reconstruir las actividades de un usuario (visitas de página, búsquedas) en un canal de seguimiento como un conjunto de feeds de publicación y suscripción en tiempo real.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka se utiliza a menudo para datos de seguimiento operativo.  Esto implica agregar estadísticas de aplicaciones distribuidas para producir fuentes centralizadas de datos operativos.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">Muchas personas utilizan Kafka como reemplazo de una solución de agregación de registros.  La agregación de registros generalmente recopila archivos de registro físicos de los servidores y los coloca en un lugar central (por ejemplo, un servidor de archivos o HDFS) para su procesamiento.  Kafka abstrae los detalles de los archivos y proporciona una abstracción más limpia de los datos de registro o eventos como un flujo de mensajes.  Esto permite un procesamiento de menor latencia y un soporte más sencillo para múltiples fuentes de datos y un consumo de datos distribuido.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Muchos usuarios de Kafka procesan datos en canales de procesamiento que constan de varias etapas, en las que los datos de entrada sin procesar se consumen de los temas de Kafka y luego se agregan, enriquecen o transforman de otro modo en nuevos temas para un mayor consumo o procesamiento de seguimiento.  Por ejemplo, un canal de procesamiento para recomendar artículos de noticias podría rastrear el contenido de los artículos desde fuentes RSS y publicarlo en un tema de "artículos".  Un procesamiento posterior podría normalizar o desduplicar este contenido y publicar el contenido del artículo limpio en un nuevo tema, y una etapa de procesamiento final podría intentar recomendar este contenido a los usuarios.  Estos canales de procesamiento crean gráficos de flujos de datos en tiempo real basados en temas individuales.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">El almacenamiento en caché de eventos es un estilo de diseño de aplicaciones para el cual los cambios de estado se registran como una secuencia de registros ordenada en el tiempo.  El soporte de Kafka para datos de registros almacenados de gran tamaño lo convierte en un excelente backend para una aplicación creada en este estilo.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka puede servir como una especie de registro de confirmación externo para un sistema distribuido.  El registro ayuda a replicar datos entre nodos y actúa como un mecanismo de resincronización para que los nodos fallidos restauren sus datos.  La función de compactación de registros en Kafka ayuda a respaldar este caso de uso.</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent Platform es una plataforma preparada para la empresa que completa Kafka con capacidades avanzadas diseñadas para ayudar a acelerar el desarrollo y la conectividad de las aplicaciones, permitir transformaciones a través del procesamiento de flujo, simplificar las operaciones empresariales a escala y cumplir con estrictos requisitos arquitectónicos.  Desarrollado por los creadores originales de Apache Kafka, Confluent amplía los beneficios de Kafka con funciones de nivel empresarial y al mismo tiempo elimina la carga de la administración o el monitoreo de Kafka.  Hoy en día, más del 80% de las empresas Fortune 100 utilizan tecnología de transmisión de datos y la mayoría de ellas utilizan Confluent.</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Confluent Platform le permite centrarse en cómo obtener valor comercial de sus datos en lugar de preocuparse por la mecánica subyacente, como la forma en que se transportan o integran los datos entre sistemas dispares.  En concreto, Confluent Platform simplifica la conexión de fuentes de datos a Kafka, la creación de aplicaciones de transmisión, así como la protección, la supervisión y la gestión de su infraestructura de Kafka.  Hoy en día, Confluent Platform se utiliza para una amplia gama de casos de uso en numerosas industrias, desde servicios financieros, venta minorista omnicanal y automóviles autónomos hasta detección de fraudes, microservicios e IoT.</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">La siguiente figura muestra los componentes de la plataforma Confluent Kafka.</block>
  <block id="4f93c36b7d83350cef38a27356c0d5c9" category="paragraph"><block ref="4f93c36b7d83350cef38a27356c0d5c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95577831087dbd899deb60b296f64a9c" category="section-title">Descripción general de la tecnología de transmisión de eventos de Confluent</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">En el núcleo de la Plataforma Confluent se encuentra<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block> , la plataforma de transmisión distribuida de código abierto más popular.  Las capacidades clave de Kafka son las siguientes:</block>
  <block id="8da3f3354457b244e53f1423a77e8944" category="section-title">Descripción general de las funciones empresariales de la plataforma Confluent</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*Centro de Control de Confluentes.*  Un sistema basado en GUI para administrar y supervisar Kafka.  Le permite administrar fácilmente Kafka Connect y crear, editar y administrar conexiones a otros sistemas.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*Conectores confluentes a Kafka.*  Los conectores utilizan la API de Kafka Connect para conectar Kafka a otros sistemas, como bases de datos, almacenes de clave-valor, índices de búsqueda y sistemas de archivos.  Confluent Hub tiene conectores descargables para las fuentes y receptores de datos más populares, incluidas versiones totalmente probadas y compatibles de estos conectores con Confluent Platform.  Se pueden encontrar más detalles<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*Clústeres autoequilibrados.*  Proporciona equilibrio de carga automatizado, detección de fallas y autorreparación.  Proporciona soporte para agregar o desmantelar corredores según sea necesario, sin necesidad de realizar ajustes manuales.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*Balanceador automático de datos Confluent.*  Supervisa su clúster para conocer la cantidad de intermediarios, el tamaño de las particiones, la cantidad de particiones y la cantidad de líderes dentro del clúster.  Le permite cambiar datos para crear una carga de trabajo uniforme en todo el clúster, al mismo tiempo que limita el tráfico de reequilibrio para minimizar el efecto en las cargas de trabajo de producción durante el reequilibrio.</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY: Carga de trabajo de Apache Spark con solución de almacenamiento de NetApp</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY describe la validación del rendimiento y la funcionalidad de Apache Spark SQL en los sistemas de almacenamiento NetApp NFS AFF .  Se revisa la configuración, la arquitectura y las pruebas de rendimiento en función de varios escenarios, así como recomendaciones para utilizar Spark con el software de gestión de datos NetApp ONTAP .  También cubre los resultados de pruebas basadas en solo un grupo de discos (JBOD) versus el controlador de almacenamiento NetApp AFF A800 .</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">Análisis de datos moderno: diferentes soluciones para diferentes estrategias analíticas</block>
  <block id="139dc952e7e6df2bb7d8000f47a42232" category="paragraph">Este documento técnico describe las estrategias de soluciones de análisis de datos modernos de NetApp .  Incluye detalles sobre los resultados comerciales, los desafíos de los clientes, las tendencias tecnológicas, la arquitectura heredada de la competencia, los flujos de trabajo modernos, los casos de uso, las industrias, la nube, los socios tecnológicos, los transportadores de datos, NetApp Active IQ Digital Advisor (también conocido como Digital Advisor), NetApp DataOps Toolkit, Hadoop a Spark, almacenamiento definido por software con NetApp Trident Protect, contenedores, gestión de datos empresariales, archivado y niveles para lograr los objetivos de IA y análisis, y cómo NetApp y los clientes juntos están modernizando su arquitectura de datos.</block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">En este TR se utilizaron las siguientes referencias:</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Arquitectura y componentes de Apache Spark</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Casos de uso de Apache Spark</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="list-text">BERT</block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">Red profunda y cruzada para predicciones de clics en anuncios</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="54452390cac5f65f3bcec580ba079531" category="list-text">FlexGroup</block>
  <block id="63e6562f5c9bc7c86f115b960762e586" category="paragraph"><block ref="63e6562f5c9bc7c86f115b960762e586" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">ETL de transmisión</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">Soluciones NetApp E-Series para Hadoop</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="list-text">Soluciones de análisis de datos modernos de NetApp</block>
  <block id="105db1e1e5e90ed75dc22390638d6b74" category="inline-link-macro">Soluciones de análisis de datos</block>
  <block id="a1acc25bb8d463a22c069a9ae3d7a581" category="paragraph"><block ref="a1acc25bb8d463a22c069a9ae3d7a581" category="inline-link-macro-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="1ae50adfec05c416d0398e26bea5fc01" category="list-text">Copia y sincronización de BlueXP</block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">Kit de herramientas DataOps</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">Esta página describe los principales casos de uso y arquitecturas de IA, ML y DL con mayor detalle.</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">Principales casos de uso y arquitecturas de IA, ML y DL</block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">Los principales casos de uso y metodología de IA, ML y DL se pueden dividir en las siguientes secciones:</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Canalizaciones de Spark NLP e inferencia distribuida de TensorFlow</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">La siguiente lista contiene las bibliotecas de PNL de código abierto más populares que han sido adoptadas por la comunidad de ciencia de datos en diferentes niveles de desarrollo:</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">Kit de herramientas de lenguaje natural (NLTK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block> . El kit de herramientas completo para todas las técnicas de PNL.  Se mantiene desde principios de la década del 2000.</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">TextoBlob</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block> . Una API de Python de herramientas de PNL fácil de usar construida sobre NLTK y Pattern.</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">PNL de Stanford Core</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block> . Servicios y paquetes de PNL en Java desarrollados por Stanford NLP Group.</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block> . Topic Modelling for Humans comenzó como una colección de scripts de Python para el proyecto de la Biblioteca Checa de Matemáticas Digitales.</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">SpaCy</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block> . Flujos de trabajo de PNL industrial de extremo a extremo con Python y Cython con aceleración de GPU para transformadores.</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">Texto rápido</block>
  <block id="c3ad48f357ddb1f4eb538b483e904fbe" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block> . Una biblioteca de PNL gratuita, liviana y de código abierto para el aprendizaje de incrustaciones de palabras y la clasificación de oraciones creada por el laboratorio de investigación de inteligencia artificial (FAIR) de Facebook.</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">Spark ML</block>
  <block id="16cbab2d9cd08ef0822a3f68f3792982" category="paragraph">Spark NLP es una solución única y unificada para todas las tareas y requisitos de PNL que permite un software escalable, de alto rendimiento y alta precisión impulsado por PNL para casos de uso de producción reales.  Aprovecha el aprendizaje por transferencia e implementa los últimos algoritmos y modelos de última generación en la investigación y en todas las industrias.  Debido a la falta de soporte completo por parte de Spark para las bibliotecas anteriores, Spark NLP se creó sobre<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> aprovechar el motor de procesamiento de datos distribuido en memoria de propósito general de Spark como una biblioteca de PNL de nivel empresarial para flujos de trabajo de producción de misión crítica.  Sus anotadores utilizan algoritmos basados en reglas, aprendizaje automático y TensorFlow para impulsar implementaciones de aprendizaje profundo.  Esto cubre tareas comunes de PNL que incluyen, entre otras, tokenización, lematización, derivación, etiquetado de partes del discurso, reconocimiento de entidades nombradas, corrección ortográfica y análisis de sentimientos.</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">Representaciones de codificador bidireccional a partir de transformadores (BERT) es una técnica de aprendizaje automático basada en transformadores para PNL.  Popularizó el concepto de preentrenamiento y ajuste fino.  La arquitectura del transformador en BERT se originó a partir de la traducción automática, que modela las dependencias a largo plazo mejor que los modelos de lenguaje basados en redes neuronales recurrentes (RNN).  También introdujo la tarea de modelado de lenguaje enmascarado (MLM), donde un 15% aleatorio de todos los tokens se enmascaran y el modelo los predice, lo que permite una verdadera bidireccionalidad.</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">Reuters TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">Frase financiera del banco</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">Explicar el documento DL</block>
  <block id="75396b8f8501a234110f5c2b41e8f2c1" category="paragraph">El análisis del sentimiento financiero es un desafío debido al lenguaje especializado y la falta de datos etiquetados en ese dominio.  FinBERT, un modelo de lenguaje basado en BERT preentrenado, fue adaptado al dominio en<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block> , un corpus financiero, y ajustado con datos etiquetados (<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block> ) para la clasificación del sentimiento financiero.  Los investigadores extrajeron 4.500 frases de artículos de noticias con términos financieros.  Luego, 16 expertos y estudiantes de maestría con experiencia en finanzas etiquetaron las oraciones como positivas, neutrales y negativas.  Creamos un flujo de trabajo Spark de extremo a extremo para analizar el sentimiento de las transcripciones de las llamadas de ganancias de las 10 principales empresas del NASDAQ de 2016 a 2020 utilizando FinBERT y otras dos canalizaciones entrenadas previamente.<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block> ) de Spark NLP.</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">El motor de aprendizaje profundo subyacente para Spark NLP es TensorFlow, una plataforma de código abierto de extremo a extremo para el aprendizaje automático que permite la creación sencilla de modelos, la producción de ML sólida en cualquier lugar y la experimentación potente para la investigación.  Por lo tanto, al ejecutar nuestros pipelines en Spark<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block> En este modo, básicamente estábamos ejecutando TensorFlow distribuido con paralelización de datos y modelos en un nodo maestro y varios nodos de trabajo, así como almacenamiento conectado a la red montado en el clúster.</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Capacitación distribuida de Horovod</block>
  <block id="7a2c7ce5896a9e74083af4e2048bb5a8" category="inline-link">Solución NetApp E-Series para Hadoop</block>
  <block id="bd3eac2bb98f840c3e8ec0d92eb9a66f" category="paragraph">La validación central de Hadoop para el rendimiento relacionado con MapReduce se realiza con TeraGen, TeraSort, TeraValidate y DFSIO (lectura y escritura).  Los resultados de la validación de TeraGen y TeraSort se presentan en<block ref="c276ecb51e19896948b1464a39a504e4" category="inline-link-rx"></block> y en la sección "Niveles de almacenamiento" para AFF.</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Hovorod en Spark</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">Basándonos en las solicitudes de los clientes, consideramos que la capacitación distribuida con Spark es uno de los casos de uso más importantes.  En este documento, utilizamos el<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> para validar el rendimiento de Spark con soluciones locales, nativas de la nube e híbridas de NetApp mediante controladores de almacenamiento NetApp All Flash FAS (AFF), Azure NetApp Files y StorageGRID.</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">El paquete Horovod en Spark proporciona un envoltorio conveniente alrededor de Horovod que simplifica la ejecución de cargas de trabajo de entrenamiento distribuidas en clústeres Spark, lo que permite un ciclo de diseño de modelo ajustado en el que el procesamiento de datos, el entrenamiento del modelo y la evaluación del modelo se realizan en Spark, donde residen los datos de entrenamiento e inferencia.</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Ventas en tiendas Kaggle Rossmann</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Hay dos API para ejecutar Horovod en Spark: una API de estimación de alto nivel y una API de ejecución de nivel inferior.  Aunque ambos utilizan el mismo mecanismo subyacente para ejecutar Horovod en los ejecutores Spark, la API Estimator abstrae el procesamiento de datos, el ciclo de entrenamiento del modelo, los puntos de control del modelo, la recopilación de métricas y el entrenamiento distribuido.  Utilizamos Horovod Spark Estimators, TensorFlow y Keras para un flujo de trabajo de preparación de datos de extremo a extremo y entrenamiento distribuido basado en<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> competencia.</block>
  <block id="85cbe9ee50d80a624a5aacb533195f44" category="paragraph">El guión<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> se puede encontrar en la sección<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> Consta de tres partes:</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">La primera parte realiza varios pasos de preprocesamiento de datos sobre un conjunto inicial de archivos CSV proporcionados por Kaggle y recopilados por la comunidad.  Los datos de entrada se separan en un conjunto de entrenamiento con un<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block> subconjunto y un conjunto de datos de prueba.</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">La segunda parte define un modelo de red neuronal profunda (DNN) Keras con función de activación sigmoidea logarítmica y un optimizador Adam, y realiza un entrenamiento distribuido del modelo utilizando Horovod en Spark.</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">La tercera parte realiza una predicción en el conjunto de datos de prueba utilizando el mejor modelo que minimiza el error absoluto medio general del conjunto de validación.  Luego crea un archivo CSV de salida.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="inline-link-macro">Aprendizaje automático</block>
  <block id="4f57ef43a107778b9d34e7c8fabafb09" category="paragraph">Ver la sección<block ref="c54562cdac0f1ff9f8a09a53f27a34da" category="inline-link-macro-rx"></block> para varios resultados de comparación de tiempo de ejecución.</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">Aprendizaje profundo multitrabajador con Keras para la predicción del CTR</block>
  <block id="d003b4f5bf1fc42082f5817cb6e961dc" category="paragraph">Con los recientes avances en plataformas y aplicaciones de ML, ahora se presta mucha atención al aprendizaje a escala.  La tasa de clics (CTR) se define como el número promedio de clics por cada cien impresiones de anuncios en línea (expresado como porcentaje).  Se adopta ampliamente como una métrica clave en varios sectores industriales y casos de uso, incluidos el marketing digital, el comercio minorista, el comercio electrónico y los proveedores de servicios.  Para obtener más detalles sobre las aplicaciones de CTR y los resultados del rendimiento del entrenamiento distribuido, consulte<block ref="7cd04747490b9545ba139688b057ed31" category="inline-link-macro-rx"></block> sección.</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Conjunto de datos de registros de clics de Criteo en terabytes</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">En este informe técnico utilizamos una variación del<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (ver TR-4904) para el aprendizaje profundo distribuido de múltiples trabajadores que utiliza Keras para crear un flujo de trabajo Spark con modelos de redes profundas y cruzadas (DCN), comparando su desempeño en términos de función de error de pérdida de registro con un modelo de regresión logística Spark ML de referencia.  DCN captura de manera eficiente interacciones de características efectivas de grados limitados, aprende interacciones altamente no lineales, no requiere ingeniería de características manual ni búsqueda exhaustiva y tiene un bajo costo computacional.</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">Los datos para los sistemas de recomendación a escala web son en su mayoría discretos y categóricos, lo que genera un espacio de características grande y escaso que dificulta la exploración de características.  Esto ha limitado la mayoría de los sistemas a gran escala a modelos lineales como la regresión logística.  Sin embargo, la clave para hacer buenas predicciones es identificar características frecuentemente predictivas y, al mismo tiempo, explorar características cruzadas poco comunes o no observadas.  Los modelos lineales son simples, interpretables y fáciles de escalar, pero tienen un poder expresivo limitado.</block>
  <block id="b5353aa08a1306ca5da9e3faacc66b15" category="paragraph">Por otra parte, se ha demostrado que las características cruzadas son significativas para mejorar la expresividad de los modelos.  Lamentablemente, a menudo se requiere ingeniería de características manual o una búsqueda exhaustiva para identificar dichas características.  Generalizar a interacciones de características invisibles suele ser difícil.  El uso de una red neuronal cruzada como DCN evita la ingeniería de características específicas de la tarea al aplicar explícitamente el cruce de características de manera automática.  La red cruzada consta de múltiples capas, donde el mayor grado de interacciones está determinado probablemente por la profundidad de la capa.  Cada capa produce interacciones de orden superior basadas en las existentes y conserva las interacciones de las capas anteriores.</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">Una red neuronal profunda (DNN) promete capturar interacciones muy complejas entre características.  Sin embargo, en comparación con DCN, requiere casi un orden de magnitud más de parámetros, no puede formar características cruzadas de manera explícita y puede fallar en el aprendizaje eficiente de algunos tipos de interacciones de características.  La red cruzada utiliza eficientemente la memoria y es fácil de implementar.  El entrenamiento conjunto de los componentes cruzados y DNN captura de manera eficiente las interacciones de características predictivas y brinda un rendimiento de última generación en el conjunto de datos CTR de Criteo.</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">CTR profundo</block>
  <block id="c024a57f5a6b531b69123f5c78627fb9" category="paragraph">Un modelo DCN comienza con una capa de incrustación y apilamiento, seguida de una red cruzada y una red profunda en paralelo.  A estas, a su vez, les sigue una capa de combinación final que combina las salidas de las dos redes.  Los datos de entrada pueden ser un vector con características dispersas y densas.  En Spark, las bibliotecas contienen el tipo<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> .  Por lo tanto, es importante que los usuarios distingan entre ambos y tengan cuidado al llamar a sus respectivas funciones y métodos.  En los sistemas de recomendación a escala web, como la predicción de CTR, las entradas son principalmente características categóricas, por ejemplo<block ref="f296a99dd35f7e3e83183f98a62982bf" prefix=" " category="inline-code"></block> .  Estas características suelen codificarse como vectores one-hot, por ejemplo,<block ref="05b38799fb2e84c83a72d68e1cb6ff67" prefix=" " category="inline-code"></block> .  Codificación one-hot (OHE) con<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> es útil cuando se trabaja con conjuntos de datos del mundo real con vocabularios en constante cambio y crecimiento.  Modificamos los ejemplos en<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> para procesar vocabularios grandes, creando vectores de incrustación en la capa de incrustación y apilamiento de nuestro DCN.</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Conjunto de datos de anuncios de display de Criteo</block>
  <block id="75253ebc28edb897ef33f95dd995dd58" category="paragraph">El<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> predice la tasa de clics de los anuncios.  Tiene 13 características enteras y 26 características categóricas en las que cada categoría tiene una alta cardinalidad.  Para este conjunto de datos, una mejora de 0,001 en la pérdida logarítmica es prácticamente significativa debido al gran tamaño de entrada.  Una pequeña mejora en la precisión de la predicción para una gran base de usuarios puede conducir potencialmente a un gran aumento en los ingresos de una empresa.  El conjunto de datos contiene 11 GB de registros de usuarios de un período de 7 días, lo que equivale a alrededor de 41 millones de registros.  Usamos Spark<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block> Dividir aleatoriamente los datos para entrenamiento (80%), validación cruzada (10%) y el 10% restante para pruebas.</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN se implementó en TensorFlow con Keras.  Hay cuatro componentes principales en la implementación del proceso de entrenamiento de modelos con DCN:</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*Procesamiento e incrustación de datos.*  Las características de valor real se normalizan aplicando una transformación logarítmica.  Para las características categóricas, integramos las características en vectores densos de dimensión 6×(cardinalidad de categoría)1/4.  La concatenación de todas las incrustaciones da como resultado un vector de dimensión 1026.</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*Mejoramiento.*  Aplicamos optimización estocástica de minilotes con el optimizador Adam.  El tamaño del lote se estableció en 512.  Se aplicó la normalización por lotes a la red profunda y la norma de recorte de gradiente se estableció en 100.</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*Regularización.*  Utilizamos la detención temprana, ya que no se encontró que la regularización o el abandono de L2 fueran efectivos.</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">*Hiperparámetros.*  Informamos los resultados basados en una búsqueda en cuadrícula sobre el número de capas ocultas, el tamaño de la capa oculta, la tasa de aprendizaje inicial y el número de capas cruzadas.  El número de capas ocultas varió entre 2 y 5, con tamaños de capas ocultas que variaron entre 32 y 1024.  Para DCN, el número de capas cruzadas fue de 1 a 6.  La tasa de aprendizaje inicial se ajustó de 0,0001 a 0,001 con incrementos de 0,0001.  Todos los experimentos se detuvieron anticipadamente en el paso de entrenamiento 150 000, más allá del cual comenzó a producirse un sobreajuste.</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">AutoInt</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="edddedbe12bade5d0d47c6600aa7fc40" category="paragraph">Además de DCN, también probamos otros modelos populares de aprendizaje profundo para la predicción de CTR, incluidos<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block> ,<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block> , y<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block> .</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">Arquitecturas utilizadas para la validación</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">Para esta validación, utilizamos cuatro nodos de trabajo y un nodo maestro con un par AFF-A800 HA.  Todos los miembros del clúster estaban conectados a través de conmutadores de red 10GbE.</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">Para esta validación de la solución NetApp Spark, utilizamos tres controladores de almacenamiento diferentes: el E5760, el E5724 y el AFF-A800.  Los controladores de almacenamiento de la Serie E se conectaron a cinco nodos de datos con conexiones SAS de 12 Gbps.  El controlador de almacenamiento de par HA AFF proporciona volúmenes NFS exportados a través de conexiones de 10 GbE a nodos de trabajo de Hadoop.  Los miembros del clúster Hadoop se conectaron a través de conexiones 10GbE en las soluciones Hadoop E-Series, AFF y StorageGRID .</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">Arquitecturas utilizadas para la validación.</block>
  <block id="dbb9fda021247ba28b40c95fcf20d529" category="paragraph"><block ref="dbb9fda021247ba28b40c95fcf20d529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">Un centro de datos empresarial moderno es una nube híbrida que conecta múltiples entornos de infraestructura distribuida a través de un plano de gestión de datos continuo con un modelo operativo consistente, en las instalaciones y/o en múltiples nubes públicas.  Para aprovechar al máximo una nube híbrida, debe poder mover datos sin problemas entre sus entornos locales y de múltiples nubes sin necesidad de realizar conversiones de datos ni refactorizar aplicaciones.</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">Solución de nube híbrida</block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">Los clientes han indicado que comienzan su viaje a la nube híbrida moviendo almacenamiento secundario a la nube para casos de uso como protección de datos o moviendo cargas de trabajo menos críticas para el negocio, como desarrollo de aplicaciones y DevOps a la nube.  Luego pasan a cargas de trabajo más críticas.  El alojamiento web y de contenido, el desarrollo de aplicaciones y DevOps, las bases de datos, los análisis y las aplicaciones en contenedores se encuentran entre las cargas de trabajo de nube híbrida más populares.  La complejidad, el costo y los riesgos de los proyectos de IA empresarial han obstaculizado históricamente la adopción de IA desde la etapa experimental hasta la producción.</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">Con una solución de nube híbrida de NetApp , los clientes se benefician de herramientas integradas de seguridad, gobernanza de datos y cumplimiento con un único panel de control para la gestión de datos y flujo de trabajo en entornos distribuidos, al tiempo que optimizan el costo total de propiedad en función de su consumo.  La siguiente figura es un ejemplo de solución de un socio de servicios en la nube encargado de proporcionar conectividad multi-nube para los datos de análisis de big data de los clientes.</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">Ejemplo de solución de un socio de servicios en la nube.</block>
  <block id="f6eb8b15960b6dcbfd7e927644b45d94" category="paragraph"><block ref="f6eb8b15960b6dcbfd7e927644b45d94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">En este escenario, los datos de IoT recibidos en AWS desde diferentes fuentes se almacenan en una ubicación central en NetApp Private Storage (NPS).  El almacenamiento NPS está conectado a clústeres Spark o Hadoop ubicados en AWS y Azure, lo que permite que las aplicaciones de análisis de big data que se ejecutan en múltiples nubes accedan a los mismos datos.  Los principales requisitos y desafíos para este caso de uso incluyen lo siguiente:</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">Los datos deben recibirse de diferentes fuentes, como entornos locales y en la nube, a través de diferentes sensores y concentradores.</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">La solución debe ser eficiente y rentable.</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">El principal desafío es construir una solución rentable y eficiente que ofrezca servicios de análisis híbridos entre diferentes entornos locales y en la nube.</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">Nuestra solución de protección de datos y conectividad multicloud resuelve el problema de tener aplicaciones de análisis de nube en múltiples hiperescaladores.  Como se muestra en la figura anterior, los datos de los sensores se transmiten y se incorporan al clúster de AWS Spark a través de Kafka.  Los datos se almacenan en un recurso compartido NFS que reside en NPS, que se encuentra fuera del proveedor de la nube dentro de un centro de datos de Equinix.</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">Dado que NetApp NPS está conectado a Amazon AWS y Microsoft Azure a través de conexiones Direct Connect y Express Route respectivamente, los clientes pueden aprovechar el módulo de análisis local para acceder a los datos de los clústeres de análisis de Amazon y AWS.  En consecuencia, dado que tanto el almacenamiento local como el NPS ejecutan el software ONTAP ,<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> Puede reflejar los datos de NPS en el clúster local, lo que proporciona análisis de nube híbrida en las instalaciones locales y en múltiples nubes.</block>
  <block id="bc35f58684dbedfb73dd7ff64a4bd5a8" category="paragraph">Para obtener el mejor rendimiento, NetApp generalmente recomienda utilizar múltiples interfaces de red y conexiones directas o rutas expresas para acceder a los datos desde las instancias de la nube.  Contamos con otras soluciones de transferencia de datos, incluidas:<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> y<block ref="079cab06c3947ff50532e4e825fc7b2c" category="inline-link-rx"></block> para ayudar a los clientes a construir clústeres Spark de nube híbrida que sean rentables, seguros y conscientes de las aplicaciones.</block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">Los siguientes tres scripts de Python corresponden a los tres casos de uso principales probados.  Primero es<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block> .</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">El segundo guión es<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">El tercer guión es<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> .</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp tiene tres carteras de almacenamiento: FAS/ AFF, E-Series y Cloud Volumes ONTAP.  Hemos validado AFF y el sistema de almacenamiento E-Series con ONTAP para soluciones Hadoop con Apache Spark.  La estructura de datos impulsada por NetApp integra servicios y aplicaciones de gestión de datos (bloques estructurales) para el acceso, control, protección y seguridad de los datos.</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">Descripción general de las soluciones Spark de NetApp</block>
  <block id="c7516072fbed3396e6f4c39a5f2356a6" category="paragraph">NetApp tiene tres carteras de almacenamiento: FAS/ AFF, E-Series y Cloud Volumes ONTAP.  Hemos validado AFF y el sistema de almacenamiento E-Series con ONTAP para soluciones Hadoop con Apache Spark.</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">La estructura de datos proporciona servicios y aplicaciones de gestión de datos.</block>
  <block id="6370a459d17d7eda9502b6008ad71b4a" category="paragraph"><block ref="6370a459d17d7eda9502b6008ad71b4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">*Acceso directo a NFS de NetApp .*  Proporciona los últimos clústeres Hadoop y Spark con acceso directo a volúmenes NFS de NetApp sin requisitos de software o controladores adicionales.</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">*Tecnología NetApp SnapMirror .*  Proporciona capacidades de protección de datos entre las instancias locales y las de ONTAP Cloud o NPS.</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">La siguiente figura muestra la solución Spark con almacenamiento NetApp .</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">Solución Spark con almacenamiento NetApp .</block>
  <block id="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="paragraph"><block ref="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58a24b49fbb76272d712aaabf465bf7" category="paragraph">La solución ONTAP Spark utiliza el protocolo de acceso directo NFS de NetApp para análisis locales y flujos de trabajo de IA, ML y DL mediante el acceso a datos de producción existentes.  Los datos de producción disponibles para los nodos Hadoop se exportan para realizar trabajos de análisis y de inteligencia artificial, aprendizaje automático y aprendizaje automático en el lugar.  Puede acceder a los datos para procesarlos en los nodos Hadoop con acceso directo a NetApp NFS o sin él.  En Spark con el independiente o<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Administrador de clústeres, puede configurar un volumen NFS mediante<block ref="806400a5eefaa4811c63e2b45a736984" prefix=" " category="inline-code"></block> .  Validamos tres casos de uso con diferentes conjuntos de datos.  Los detalles de estas validaciones se presentan en la sección "Resultados de las pruebas".  (referencia cruzada)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">La siguiente figura muestra el posicionamiento del almacenamiento Apache Spark/Hadoop de NetApp .</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">Posicionamiento de almacenamiento Apache Spark/Hadoop de NetApp .</block>
  <block id="8e32cf48ce4f12a61f456b3ec41a7e21" category="paragraph"><block ref="8e32cf48ce4f12a61f456b3ec41a7e21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">Identificamos las características únicas de la solución E-Series Spark, la solución AFF/ FAS ONTAP Spark y la solución StorageGRID Spark, y realizamos pruebas y validaciones detalladas.  Con base en nuestras observaciones, NetApp recomienda la solución E-Series para instalaciones nuevas y nuevas implementaciones escalables, y la solución AFF/ FAS para análisis locales, IA, ML y cargas de trabajo de DL utilizando datos NFS existentes, y StorageGRID para IA, ML y DL y análisis de datos modernos cuando se requiere almacenamiento de objetos.</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Soluciones NetApp recomendadas para Spark.</block>
  <block id="32530ebcaeef5cc30a605229e26ea933" category="paragraph"><block ref="32530ebcaeef5cc30a605229e26ea933" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">Un lago de datos es un repositorio de almacenamiento para grandes conjuntos de datos en formato nativo que pueden usarse para trabajos de análisis, inteligencia artificial, aprendizaje automático y aprendizaje automático.  Creamos un repositorio de lago de datos para las soluciones Spark E-Series, AFF/ FAS y StorageGRID SG6060.  El sistema E-Series proporciona acceso HDFS al clúster Hadoop Spark, mientras que se accede a los datos de producción existentes a través del protocolo de acceso directo NFS al clúster Hadoop.  Para los conjuntos de datos que residen en el almacenamiento de objetos, NetApp StorageGRID proporciona acceso seguro S3 y S3a.</block>
  <block id="881214767967db331c99550277ceb793" category="summary">Esta página describe la arquitectura de Splunk, incluidas las definiciones clave, las implementaciones distribuidas de Splunk, Splunk SmartStore, el flujo de datos, los requisitos de hardware y software, los requisitos de sitios únicos y múltiples, etc.</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Arquitectura de Splunk</block>
  <block id="3924240363e47a4a292119abc4a993a1" category="paragraph">Esta sección describe la arquitectura de Splunk, incluidas las definiciones clave, las implementaciones distribuidas de Splunk, Splunk SmartStore, el flujo de datos, los requisitos de hardware y software, los requisitos de sitios únicos y múltiples, etc.</block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">Definiciones clave</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">Las siguientes dos tablas enumeran los componentes de Splunk y NetApp utilizados en la implementación distribuida de Splunk.</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">Esta tabla enumera los componentes de hardware de Splunk para la configuración distribuida de Splunk Enterprise.</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Componente de Splunk</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">Tarea</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">Indexador</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Repositorio de datos de Splunk Enterprise</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">Reenvío universal</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">Responsable de ingerir datos y enviarlos a los indexadores.</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">Cabezal de búsqueda</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">La interfaz de usuario utilizada para buscar datos en los indexadores</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">Maestro del clúster</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">Administra la instalación de indexadores y cabezales de búsqueda de Splunk</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">Consola de monitoreo</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">Herramienta de monitoreo centralizada utilizada en toda la implementación</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">Maestro de licencias</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">El administrador de licencias gestiona las licencias de Splunk Enterprise</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">Servidor de implementación</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">Actualiza las configuraciones y distribuye aplicaciones al componente de procesamiento</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">Componente de almacenamiento</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">AFF de NetApp</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">Almacenamiento totalmente flash utilizado para administrar datos de nivel activo.  También conocido como almacenamiento local.</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">Almacenamiento de objetos S3 utilizado para administrar datos de nivel cálido.  SmartStore lo utiliza para mover datos entre el nivel caliente y el nivel templado.  También conocido como almacenamiento remoto.</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">Esta tabla enumera los componentes de la arquitectura de almacenamiento de Splunk.</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">Componente responsable</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">Tienda inteligente</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">Proporciona a los indexadores la capacidad de organizar datos en niveles desde el almacenamiento local hasta el almacenamiento de objetos.</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">Caliente</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">El lugar de aterrizaje donde los reenvíos universales colocan los datos recién escritos.  El almacenamiento se puede escribir y los datos se pueden buscar.  Este nivel de datos normalmente está compuesto por SSD o discos duros rápidos.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">Administrador de caché</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">Administra el caché local de datos indexados, recupera datos confidenciales del almacenamiento remoto cuando se realiza una búsqueda y expulsa del caché los datos menos utilizados.</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">Cálido</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">Los datos se transfieren de manera lógica al depósito y se renombran primero al nivel cálido desde el nivel caliente.  Los datos dentro de este nivel están protegidos y, al igual que el nivel activo, pueden estar compuestos por SSD o HDD de mayor capacidad.  Se admiten copias de seguridad incrementales y completas mediante soluciones de protección de datos comunes.</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Implementaciones distribuidas de Splunk</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">Para dar soporte a entornos más grandes en los que los datos se originan en muchas máquinas, es necesario procesar grandes volúmenes de datos.  Si muchos usuarios necesitan buscar datos, puede escalar la implementación distribuyendo instancias de Splunk Enterprise en varias máquinas.  Esto se conoce como una implementación distribuida.</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">En una implementación distribuida típica, cada instancia de Splunk Enterprise realiza una tarea especializada y reside en uno de los tres niveles de procesamiento correspondientes a las funciones de procesamiento principales.</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">La siguiente tabla enumera los niveles de procesamiento de Splunk Enterprise.</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">Nivel</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">Componente</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">Descripción</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">Entrada de datos</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">Promotor</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">Un reenvío consume datos y luego los reenvía a un grupo de indexadores.</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">Indexación</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">Un indexador indexa los datos entrantes que normalmente recibe de un grupo de reenvíos.  El indexador transforma los datos en eventos y almacena los eventos en un índice.  El indexador también busca los datos indexados en respuesta a las solicitudes de búsqueda de un cabezal de búsqueda.</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">Gestión de búsquedas</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">Un cabezal de búsqueda sirve como recurso central para la búsqueda.  Los cabezales de búsqueda de un clúster son intercambiables y tienen acceso a las mismas búsquedas, paneles, objetos de conocimiento, etc., desde cualquier miembro del clúster de cabezales de búsqueda.</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">En la siguiente tabla se enumeran los componentes importantes que se utilizan en un entorno distribuido de Splunk Enterprise.</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">Responsabilidad</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">Maestro del clúster de índices</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">Coordina actividades y actualizaciones de un clúster de indexadores</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">Gestión de índices</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">Clúster de índices</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">Grupo de indexadores de Splunk Enterprise que están configurados para replicar datos entre sí</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">Desplegador de cabezal de búsqueda</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">Maneja la implementación y las actualizaciones del maestro del clúster.</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">Gestión de cabezales de búsqueda</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">Grupo de búsqueda de cabezas</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">Grupo de cabezales de búsqueda que sirve como recurso central para la búsqueda</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">Balanceadores de carga</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">Lo utilizan los componentes agrupados para gestionar la creciente demanda de los cabezales de búsqueda, los indexadores y el destino S3 para distribuir la carga entre los componentes agrupados.</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">Gestión de carga para componentes agrupados</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Vea los siguientes beneficios de las implementaciones distribuidas de Splunk Enterprise:</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">Acceder a fuentes de datos diversas o dispersas</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">Proporcionar funcionalidad para gestionar las necesidades de datos de empresas de cualquier tamaño y complejidad.</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">Logre alta disponibilidad y garantice la recuperación ante desastres con replicación de datos e implementación en múltiples sitios</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Tienda inteligente de Splunk</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore es una capacidad de indexación que permite que los almacenes de objetos remotos, como Amazon S3, almacenen datos indexados.  A medida que aumenta el volumen de datos de una implementación, la demanda de almacenamiento generalmente supera la demanda de recursos computacionales.  SmartStore le permite administrar su almacenamiento de indexador y sus recursos computacionales de manera rentable al escalar esos recursos por separado.</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore presenta un nivel de almacenamiento remoto y un administrador de caché.  Estas características permiten que los datos residan localmente en indexadores o en el nivel de almacenamiento remoto.  El administrador de caché administra el movimiento de datos entre el indexador y el nivel de almacenamiento remoto, que está configurado en el indexador.</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">Con SmartStore, puede reducir el espacio de almacenamiento del indexador al mínimo y elegir recursos informáticos optimizados para E/S.  La mayoría de los datos residen en el almacenamiento remoto.  El indexador mantiene un caché local que contiene una cantidad mínima de datos: buckets activos, copias de buckets cálidos que participan en búsquedas activas o recientes y metadatos de buckets.</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Flujo de datos de Splunk SmartStore</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">Cuando los datos provenientes de varias fuentes llegan a los indexadores, estos se indexan y se guardan localmente en un contenedor activo.  El indexador también replica los datos del contenedor activo en los indexadores de destino.  Hasta ahora, el flujo de datos es idéntico al flujo de datos de los índices que no son SmartStore.</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">Cuando el cubo caliente se calienta demasiado, el flujo de datos diverge.  El indexador de origen copia el depósito cálido en el almacén de objetos remoto (nivel de almacenamiento remoto) mientras deja la copia existente en su caché, porque las búsquedas tienden a ejecutarse en datos indexados recientemente.  Sin embargo, los indexadores de destino eliminan sus copias porque el almacén remoto proporciona alta disponibilidad sin mantener múltiples copias locales.  La copia maestra del depósito ahora reside en el almacén remoto.</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">La siguiente imagen muestra el flujo de datos de Splunk SmartStore.</block>
  <block id="d7a63eb40866a66e8bb1fc64387b113e" category="paragraph"><block ref="d7a63eb40866a66e8bb1fc64387b113e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">El administrador de caché del indexador es fundamental para el flujo de datos de SmartStore.  Obtiene copias de depósitos del almacén remoto según sea necesario para manejar solicitudes de búsqueda.  También expulsa del caché copias de los buckets más antiguas o menos buscadas, porque la probabilidad de que participen en búsquedas disminuye con el tiempo.</block>
  <block id="b36837abd403dcb47f93edcd619c14de" category="paragraph">El trabajo del administrador de caché es optimizar el uso del caché disponible y garantizar que las búsquedas tengan acceso inmediato a los segmentos que necesitan.</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">La siguiente tabla enumera los componentes de software necesarios para implementar la solución.  Los componentes de software que se utilizan en cualquier implementación de la solución pueden variar según los requisitos del cliente.</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">Familia de productos</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">Nombre del producto</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">Versión del producto</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="cell">Sistema operativo</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">Almacenamiento de objetos StorageGRID</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11,6</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">n / A</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8,1</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise con SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">Requisitos de un solo sitio y de varios sitios</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">En un entorno de Splunk empresarial (implementaciones medianas y grandes) donde los datos se originan en muchas máquinas y donde muchos usuarios necesitan buscar los datos, puede escalar su implementación distribuyendo instancias de Splunk Enterprise en sitios únicos y múltiples.</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">En la siguiente tabla se enumeran los componentes utilizados en un entorno distribuido de Splunk Enterprise.</block>
  <block id="ee5ff25e83985cc8f46c04780442d06b" category="cell">Grupo de indexadores de Splunk Enterprise que están configurados para replicar los datos de los demás</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">Balanceadores de carga</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">Gestión de carga para componentes agrupados</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">Esta figura muestra un ejemplo de una implementación distribuida en un solo sitio.</block>
  <block id="d929fa57a2db2b79fca2a0c134995344" category="paragraph"><block ref="d929fa57a2db2b79fca2a0c134995344" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">Esta figura muestra un ejemplo de una implementación distribuida en múltiples sitios.</block>
  <block id="aa56e29281a1be8656361637c931faec" category="paragraph"><block ref="aa56e29281a1be8656361637c931faec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">Las siguientes tablas enumeran el número mínimo de componentes de hardware necesarios para implementar la solución.  Los componentes de hardware que se utilizan en implementaciones específicas de la solución pueden variar según los requisitos del cliente.</block>
  <block id="f690a37fe0f7a5932c9eee9dc887f7c7" category="admonition">Independientemente de si ha implementado Splunk SmartStore y StorageGRID en un solo sitio o en varios, todos los sistemas se administran desde StorageGRID GRID Manager en un único panel.  Consulte la sección "Administración simple con Grid Manager" para obtener más detalles.</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">Esta tabla enumera el hardware utilizado para un solo sitio.</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">Disco</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">Capacidad utilizable</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">Nota</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">Nodo de administración y balanceador de carga</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">x48, 8 TB (disco duro NL-SAS)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">Almacenamiento remoto</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">Esta tabla enumera el hardware utilizado para una configuración multisitio (por sitio).</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">Nodo de administración y balanceador de carga</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">Balanceador de carga NetApp StorageGRID : SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">El almacenamiento de objetos requiere el uso de un equilibrador de carga para presentar el espacio de nombres de almacenamiento en la nube.  StorageGRID admite balanceadores de carga de terceros de proveedores líderes como F5 y Citrix, pero muchos clientes eligen el balanceador StorageGRID de nivel empresarial por su simplicidad, resiliencia y alto rendimiento.  El balanceador de carga StorageGRID está disponible como una máquina virtual, un contenedor o un dispositivo especialmente diseñado.</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">StorageGRID SG1000 facilita el uso de grupos de alta disponibilidad (HA) y equilibrio de carga inteligente para conexiones de rutas de datos S3.  Ningún otro sistema de almacenamiento de objetos local proporciona un equilibrador de carga personalizado.</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">El aparato SG1000 ofrece las siguientes características:</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">Un equilibrador de carga y, opcionalmente, funciones de nodo de administración para un sistema StorageGRID</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">El instalador del dispositivo StorageGRID para simplificar la implementación y configuración de nodos</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">Configuración simplificada de puntos finales S3 y SSL</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">Ancho de banda dedicado (en comparación con compartir un balanceador de carga de terceros con otras aplicaciones)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">Ancho de banda Ethernet agregado de hasta 4 x 100 Gbps</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">La siguiente imagen muestra el dispositivo SG1000 Gateway Services.</block>
  <block id="605bc0a01cfe9da48adf3da49367bbdc" category="paragraph"><block ref="605bc0a01cfe9da48adf3da49367bbdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">El dispositivo StorageGRID SG6060 incluye un controlador de cómputo (SG6060) y un estante de controlador de almacenamiento (E-Series E2860) que contiene dos controladores de almacenamiento y 60 unidades.  Este aparato ofrece las siguientes características:</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">Escala hasta 400 PB en un solo espacio de nombres.</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">Ancho de banda Ethernet agregado de hasta 4 x 25 Gbps.</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">Incluye el instalador de dispositivos StorageGRID para simplificar la implementación y configuración de nodos.</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">Cada dispositivo SG6060 puede tener uno o dos estantes de expansión adicionales para un total de 180 unidades.</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">Dos controladores E-Series E2800 (configuración dúplex) para brindar soporte de conmutación por error del controlador de almacenamiento.</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">Estante de unidad de cinco cajones que admite sesenta unidades de 3,5 pulgadas (dos unidades de estado sólido y 58 unidades NL-SAS).</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">La siguiente imagen muestra el dispositivo SG6060.</block>
  <block id="cf84ce9e448fb9e498568b901279526a" category="paragraph"><block ref="cf84ce9e448fb9e498568b901279526a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Diseño de Splunk</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">La siguiente tabla enumera la configuración de Splunk para un solo sitio.</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">Núcleos</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">Sistema operativo</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16 núcleos</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 GB de RAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">Gestiona los datos del usuario</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">La interfaz de usuario busca datos en los indexadores</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">Maneja actualizaciones para grupos de encabezados de búsqueda</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Administra la instalación y los indexadores de Splunk.</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">Consola de monitoreo y maestro de licencias</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Realiza una supervisión centralizada de toda la implementación de Splunk y administra las licencias de Splunk.</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">Las siguientes tablas describen la configuración de Splunk para configuraciones multisitio.</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">Esta tabla enumera la configuración de Splunk para una configuración multisitio (sitio A).</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">Responsable de ingerir datos y enviarlos a los indexadores.</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Realiza la supervisión centralizada de toda la implementación de Splunk y administra las licencias de Splunk.</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">Esta tabla enumera la configuración de Splunk para una configuración multisitio (sitio B).</block>
  <block id="89586ffe0445b81e878d1032f66f2e12" category="summary">Splunk Enterprise es la solución SIEM líder en el mercado que impulsa resultados en los equipos de seguridad, TI y DevOps.</block>
  <block id="4d39837f3e2d893412540b1652c97cbe" category="paragraph">Splunk Enterprise es la solución SIEM líder en el mercado que impulsa resultados en los equipos de seguridad, TI y DevOps.  El uso de Splunk ha aumentado considerablemente en las organizaciones de nuestros clientes.  Por lo tanto, es necesario agregar más fuentes de datos y, al mismo tiempo, conservar los datos durante un período más largo, lo que tensiona la infraestructura de Splunk.</block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">La combinación de Splunk SmartStore y NetApp StorageGRID está diseñada para proporcionar una arquitectura escalable para que las organizaciones logren un mejor rendimiento de ingesta con el almacenamiento de objetos SmartStore y StorageGRID y una mayor escalabilidad para un entorno Splunk en múltiples regiones geográficas.</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="inline-link">Recursos de documentación de NetApp StorageGRID</block>
  <block id="a246b965362984dc941c948da019cebe" category="list-text"><block ref="a246b965362984dc941c948da019cebe" category="inline-link-rx"></block></block>
  <block id="1deabb4a384507a50ad75f7c30954fe6" category="list-text"><block ref="1deabb4a384507a50ad75f7c30954fe6" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="inline-link">Documentación de Splunk Enterprise</block>
  <block id="04e37c317ba66f65142c3479329cc2e3" category="list-text"><block ref="04e37c317ba66f65142c3479329cc2e3" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="inline-link">Splunk Enterprise Acerca de SmartStore</block>
  <block id="fefd29a254418e70038ff08010d7066e" category="list-text"><block ref="fefd29a254418e70038ff08010d7066e" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="inline-link">Manual de implementación distribuida de Splunk Enterprise</block>
  <block id="12c4d056a98e583e653fc125f9f3338d" category="list-text"><block ref="12c4d056a98e583e653fc125f9f3338d" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="inline-link">Splunk Enterprise: administración de indexadores y clústeres de indexadores</block>
  <block id="634ac9166526f20af850f5021155d4c5" category="list-text"><block ref="634ac9166526f20af850f5021155d4c5" category="inline-link-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">Este informe técnico describe el beneficio que NetApp brinda a una solución Splunk SmartStore y al mismo tiempo demuestra un marco para diseñar y dimensionar Splunk SmartStore en su entorno.  El resultado es una solución sencilla, escalable y resistente que ofrece un coste total de propiedad atractivo.</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869: NetApp StorageGRID con Splunk SmartStore</block>
  <block id="fa4442e299e1aa350a002220ee278abc" category="paragraph">Splunk Enterprise es la solución de gestión de eventos e información de seguridad (SIEM) líder en el mercado que impulsa resultados en los equipos de seguridad, TI y DevOps.</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">Descripción general</block>
  <block id="78298f39c2d5411f080a61b3abeb845f" category="paragraph">Los volúmenes de datos continúan creciendo a un ritmo exponencial, lo que crea enormes oportunidades para las empresas que pueden aprovechar este vasto recurso.  Splunk Enterprise continúa ganando adopción en una variedad más amplia de casos de uso.  A medida que crecen los casos de uso, también crece la cantidad de datos que Splunk Enterprise ingiere y procesa.  La arquitectura tradicional de Splunk Enterprise es un diseño de escalamiento distribuido que proporciona excelente acceso y disponibilidad de datos.  Sin embargo, las empresas que utilizan esta arquitectura se enfrentan a costos crecientes asociados con la escalabilidad para satisfacer el rápido crecimiento del volumen de datos.</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">Splunk SmartStore con NetApp StorageGRID resuelve este desafío al ofrecer un nuevo modelo de implementación en el que el cómputo y el almacenamiento están desacoplados.  Esta solución también desbloquea una escala y elasticidad inigualables para los entornos de Splunk Enterprise al permitir a los clientes escalar entre sitios únicos y múltiples, al mismo tiempo que reduce los costos al permitir que el cómputo y el almacenamiento escalen de forma independiente y agrega niveles inteligentes al almacenamiento de objetos S3 basado en la nube rentable.</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">La solución optimiza la cantidad de datos en el almacenamiento local mientras mantiene el rendimiento de la búsqueda, lo que permite escalar el cómputo y el almacenamiento según demanda.  SmartStore evalúa automáticamente los patrones de acceso a los datos para determinar qué datos deben ser accesibles para realizar análisis en tiempo real y qué datos deben residir en el almacenamiento de objetos S3 de menor costo.</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">Este informe técnico describe el beneficio que NetApp brinda a una solución Splunk SmartStore y al mismo tiempo demuestra un marco para diseñar y dimensionar Splunk SmartStore en su entorno.  El resultado es una solución sencilla, escalable y resistente que ofrece un coste total de propiedad atractivo.  StorageGRID proporciona almacenamiento de objetos escalable y rentable basado en el protocolo S3/API, también conocido como almacenamiento remoto, lo que permite a las organizaciones escalar su solución Splunk a un menor costo y al mismo tiempo aumentar la resiliencia.</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore se refiere al almacenamiento de objetos como almacenes remotos o niveles de almacenamiento remoto.</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">Acerca de NetApp StorageGRID</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID es una solución de almacenamiento de objetos definida por software para archivos grandes, repositorios de medios y almacenes de datos web.  Con StorageGRID, NetApp aprovecha dos décadas de experiencia en la entrega de soluciones de innovación y gestión de datos líderes en la industria, al tiempo que ayuda a las organizaciones a administrar y maximizar el valor de su información tanto en sus instalaciones como en implementaciones de nube pública, privada o híbrida.</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID proporciona almacenamiento seguro y duradero para datos no estructurados a escala.  Las políticas de gestión del ciclo de vida integradas y basadas en metadatos optimizan dónde residen sus datos a lo largo de su vida.  El contenido se coloca en el lugar correcto, en el momento correcto y en el nivel de almacenamiento correcto para reducir costos.  El espacio de nombres único permite acceder a los datos a través de una única llamada, independientemente de la ubicación geográfica del almacenamiento StorageGRID .  Los clientes pueden implementar y administrar múltiples instancias de StorageGRID entre centros de datos y en la infraestructura de la nube.</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">Un sistema StorageGRID está compuesto de nodos heterogéneos, redundantes y distribuidos globalmente que pueden integrarse con aplicaciones cliente existentes y de próxima generación.</block>
  <block id="a8bc435c89c3235d62a12e0fb3c5c909" category="paragraph"><block ref="a8bc435c89c3235d62a12e0fb3c5c909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape nombró recientemente a NetApp como líder en el último informe, IDC MarketScape: Evaluación de proveedores de almacenamiento basado en objetos a nivel mundial 2019.  Con casi 20 años de implementaciones de producción en las industrias más exigentes, StorageGRID es un líder reconocido en datos no estructurados.</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">Con StorageGRID, puede lograr lo siguiente:</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">Implemente múltiples instancias de StorageGRID para acceder a datos desde cualquier ubicación entre centros de datos y la nube a través de un único espacio de nombres que escala fácilmente a cientos de petabytes.</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">Proporciona flexibilidad para implementar y administrar de forma centralizada todas las infraestructuras.</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">Proporciona una durabilidad inigualable con quince nueves de durabilidad aprovechando la codificación de borrado en capas (EC).</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Habilite más capacidades de múltiples nubes híbridas con integraciones validadas en Amazon S3 Glacier y Azure Blob.</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">Cumpla con las obligaciones regulatorias y facilite el cumplimiento mediante la retención de datos a prueba de manipulaciones, sin API propietarias ni dependencia de proveedores.</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">Página de inicio de NetApp StorageGRID</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">Para obtener más información sobre cómo StorageGRID puede ayudarlo a resolver sus problemas de administración de datos no estructurados más complejos, consulte<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block> .</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">Acerca de Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise es una plataforma para convertir datos en acciones.  Los datos generados por varias fuentes, como archivos de registro, sitios web, dispositivos, sensores y aplicaciones, se envían y analizan en los indexadores de Splunk, lo que le permite obtener información valiosa de los datos.  Puede identificar violaciones de datos, señalar tendencias de clientes y productos, encontrar oportunidades para optimizar la infraestructura o crear información útil en una amplia variedad de casos de uso.</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">Acerca de Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore amplía los beneficios de la arquitectura de Splunk al tiempo que simplifica su capacidad de escalar de manera rentable.  La disociación de los recursos de cómputo y almacenamiento da como resultado nodos de indexación optimizados para E/S con necesidades de almacenamiento significativamente reducidas porque solo almacenan un subconjunto de datos como caché.  No es necesario agregar procesamiento o almacenamiento adicional cuando solo es necesario uno de esos recursos, lo que le permite obtener ahorros de costos significativos.  Puede utilizar un almacenamiento de objetos basado en S3 rentable y fácilmente escalable, que simplifica aún más el entorno, reduce los costos y le permite mantener un conjunto de datos más masivo.</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore ofrece un valor significativo a las organizaciones, incluido lo siguiente:</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">Reducción de los costos de almacenamiento al trasladar datos no utilizados a un almacenamiento de objetos S3 con costos optimizados</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">Escalabilidad fluida mediante la separación del almacenamiento y la computación</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">Simplificar la continuidad del negocio aprovechando el almacenamiento nativo de la nube resiliente</block>
  <block id="bdcc72fc1bad1a939182ad2bde321f1e" category="summary">Esta página describe el rendimiento de Splunk SmartStore en un controlador NetApp StorageGRID .</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">Rendimiento de SmartStore en un solo sitio</block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">Esta sección describe el rendimiento de Splunk SmartStore en un controlador NetApp StorageGRID .  Splunk SmartStore mueve datos cálidos al almacenamiento remoto, que en este caso es el almacenamiento de objetos StorageGRID en la validación del rendimiento.</block>
  <block id="dd1e8d1bd57ca578a4ba44e789957d0f" category="paragraph"><block ref="dd1e8d1bd57ca578a4ba44e789957d0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">Utilizamos EF600 para almacenamiento en caché/activo y StorageGRID 6060 para almacenamiento remoto.  Utilizamos la siguiente arquitectura para la validación del rendimiento.  Utilizamos dos cabezales de búsqueda, cuatro reenvíos pesados para enviar los datos a los indexadores, siete generadores de eventos Splunk (Eventgens) para generar los datos en tiempo real y 18 indexadores para almacenar los datos.</block>
  <block id="b127bd17913b4ab46912efd5b9a74269" category="paragraph"><block ref="b127bd17913b4ab46912efd5b9a74269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="section-title">Configuración</block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">Esta tabla enumera el hardware utilizado para la validación del rendimiento de SmartStorage.</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">Transportador pesado</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16 núcleos</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">TRINEO 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">El frontend del usuario busca datos en los indexadores</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">Validación del rendimiento de la tienda remota SmartStore</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">En esta validación de rendimiento, configuramos el caché SmartStore en el almacenamiento local en todos los indexadores para 10 días de datos.  Hemos habilitado el<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block> (tamaño de depósito de 750 MB) en el administrador de clústeres de Splunk y envió los cambios a todos los indexadores.  Para medir el rendimiento de carga, ingerimos 10 TB por día durante 10 días y transferimos todos los buckets activos a cálidos al mismo tiempo y capturamos el rendimiento máximo y promedio por instancia y en toda la implementación desde el panel de control de la consola de monitoreo de SmartStore.</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">Esta imagen muestra los datos ingeridos en un día.</block>
  <block id="1c106a39adeca49606809938222599d3" category="paragraph"><block ref="1c106a39adeca49606809938222599d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">Ejecutamos el siguiente comando desde el clúster maestro (el nombre del índice es<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block> ).  Luego, capturamos el rendimiento de carga máximo y promedio por instancia y en toda la implementación a través de los paneles de control de la consola de monitoreo de SmartStore.</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">El maestro del clúster tiene autenticación sin contraseña para todos los indexadores (rtp-idx0001…rtp-idx0018).</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">Para medir el rendimiento de la descarga, eliminamos todos los datos de la memoria caché ejecutando la CLI de desalojo dos veces usando el siguiente comando.</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">Ejecutamos el siguiente comando desde el clúster maestro y ejecutamos la búsqueda desde el cabezal de búsqueda sobre 10 días de datos del almacén remoto de StorageGRID.  Luego capturamos el rendimiento de carga máximo y promedio por instancia y en toda la implementación a través de los paneles de control de la consola de monitoreo de SmartStore.</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">Las configuraciones del indexador se enviaron desde el maestro del clúster SmartStore.  El maestro del clúster tenía la siguiente configuración para el indexador.</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">Ejecutamos la siguiente consulta de búsqueda en el encabezado de búsqueda para recopilar la matriz de rendimiento.</block>
  <block id="71e6150ea19aef0f2e67a79bd131fca8" category="paragraph"><block ref="71e6150ea19aef0f2e67a79bd131fca8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">Recopilamos la información de rendimiento del clúster maestro.  El rendimiento máximo fue de 61,34 GBps.</block>
  <block id="c5e60940f195879f09af22af10f55027" category="paragraph"><block ref="c5e60940f195879f09af22af10f55027" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">El rendimiento promedio fue de aproximadamente 29 GBps.</block>
  <block id="a8eebaef6e6889ddddfe09cfa523009c" category="paragraph"><block ref="a8eebaef6e6889ddddfe09cfa523009c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">Rendimiento de StorageGRID</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">Eventgen</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">El rendimiento de SmartStore se basa en la búsqueda de patrones y cadenas específicos entre grandes cantidades de datos.  En esta validación, los eventos se generan utilizando<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> en un índice de Splunk específico (eventgen-test) a través del cabezal de búsqueda y la solicitud se dirige a StorageGRID para la mayoría de las consultas.  La siguiente imagen muestra los aciertos y errores de los datos de la consulta.  Los datos de aciertos provienen del disco local y los datos de errores provienen del controlador StorageGRID .</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">El color verde muestra los datos de aciertos y el color naranja muestra los datos de errores.</block>
  <block id="5776938ffab0b4f2730d8923c004d57e" category="paragraph"><block ref="5776938ffab0b4f2730d8923c004d57e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">Cuando se ejecuta la consulta para la búsqueda en StorageGRID, el tiempo de recuperación de S3 de StorageGRID se muestra en la siguiente imagen.</block>
  <block id="7393ba7bdc5067b2c80450122c8a2f0d" category="paragraph"><block ref="7393ba7bdc5067b2c80450122c8a2f0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">Uso del hardware de StorageGRID</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">La instancia de StorageGRID tiene un equilibrador de carga y tres controladores StorageGRID .  La utilización de la CPU para los tres controladores es del 75% al 100%.</block>
  <block id="69851341d968a4444c52d6c167608079" category="paragraph"><block ref="69851341d968a4444c52d6c167608079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">SmartStore con controlador de almacenamiento NetApp : beneficios para el cliente</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*Desacoplamiento entre computación y almacenamiento.*  Splunk SmartStore desacopla el procesamiento y el almacenamiento, lo que le ayuda a escalarlos de forma independiente.</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*Datos bajo demanda.*  SmartStore acerca los datos al procesamiento a pedido y brinda elasticidad de procesamiento y almacenamiento y eficiencia de costos para lograr una retención de datos más prolongada a escala.</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*Compatible con API AWS S3.*  SmartStore utiliza la API de AWS S3 para comunicarse con el almacenamiento de restauración, que es un almacén de objetos compatible con AWS S3 y la API de S3, como StorageGRID.</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*Reduce los requisitos y costos de almacenamiento.*  SmartStore reduce los requisitos de almacenamiento para datos antiguos (cálidos/fríos).  Solo necesita una única copia de datos porque el almacenamiento de NetApp brinda protección de datos y se encarga de las fallas y la alta disponibilidad.</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*Fallo de hardware.*  La falla de un nodo en una implementación de SmartStore no hace que los datos sean inaccesibles y tiene una recuperación del indexador mucho más rápida en caso de falla de hardware o desequilibrio de datos.</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">Caché consciente de aplicaciones y datos.</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">Agregar y quitar indexadores y configurar y desmontar clústeres a pedido.</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">El nivel de almacenamiento ya no está vinculado al hardware.</block>
  <block id="c1d2fce5798cdc81a1393206b0332f8a" category="summary">La solución permite agregar recursos de cómputo, almacenamiento activo o S3 para satisfacer la creciente demanda en términos de cantidad de usuarios o tasa de ingesta en implementaciones de sitios únicos o múltiples.</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="doc">Beneficios de esta solución</block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*Actuación.*  La combinación de Splunk SmartStore y NetApp StorageGRID proporciona una migración rápida de datos entre contenedores activos y contenedores tibios mediante almacenamiento de objetos.  StorageGRID potencia el proceso de migración al proporcionar un rendimiento rápido para cargas de trabajo de objetos grandes.</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*Listo para múltiples sitios.*  La arquitectura distribuida de StorageGRID permite a Splunk SmartStore extender las implementaciones en sitios individuales y múltiples a través de un único espacio de nombres global donde se puede acceder a los datos desde cualquier sitio, independientemente de dónde se encuentren.</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*Escalabilidad mejorada.*  Escale los recursos de almacenamiento independientemente de los recursos computacionales para satisfacer las necesidades y demandas cambiantes en su entorno Splunk, proporcionando así un mejor TCO.</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*Capacidad.*  Afronte el rápido crecimiento de los volúmenes en la implementación de Splunk con StorageGRID escalando un único espacio de nombres a más de 560 PB.</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*Disponibilidad de datos.*  Optimice la disponibilidad de datos, el rendimiento, la distribución geográfica, la retención, la protección y los costos de almacenamiento con políticas basadas en metadatos que pueden ajustarse dinámicamente a medida que evoluciona el valor comercial de sus datos.</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Pautas proporcionadas por Splunk</block>
  <block id="3c5d06925a5d5bceedd74c82d3d38c04" category="paragraph">Aumente el rendimiento con el caché SmartStore, que es un componente del indexador que maneja la transferencia de copias de bucket entre el almacenamiento local (activo) y el remoto (tibio).  El dimensionamiento de Splunk para esta solución se basa en<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block> .  La solución permite agregar recursos de cómputo, almacenamiento activo o S3 para satisfacer la creciente demanda en términos de cantidad de usuarios o tasa de ingesta en implementaciones de sitios únicos o múltiples.</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">Esta página describe los componentes utilizados para completar esta solución, incluidos NetApp StorageGRID, Splunk Enterprise y Splunk SmartStore.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">Descripción general de la solución</block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID es una plataforma de almacenamiento de objetos de alto rendimiento y rentable.  Ofrece una gestión de datos global inteligente e impulsada por políticas utilizando una arquitectura de red distribuida basada en nodos.  Simplifica la gestión de petabytes de datos no estructurados y miles de millones de objetos a través de su omnipresente espacio de nombres de objetos globales combinado con sofisticadas funciones de gestión de datos.  El acceso a objetos mediante una sola llamada se extiende a través de los sitios y simplifica las arquitecturas de alta disponibilidad al tiempo que garantiza el acceso continuo a los objetos independientemente de las interrupciones del sitio o la infraestructura.</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">La multitenencia permite que múltiples aplicaciones de datos no estructurados empresariales y en la nube se administren de forma segura dentro de la misma red, lo que aumenta el ROI y los casos de uso de StorageGRID.  Se pueden crear múltiples niveles de servicio con políticas de ciclo de vida de objetos basadas en metadatos, optimizando la durabilidad, la protección, el rendimiento y la localidad en múltiples geografías.  Los usuarios pueden ajustar las políticas y realinear el panorama de datos sin interrupciones a medida que cambian sus requisitos.</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore aprovecha StorageGRID como nivel de almacenamiento remoto y permite a los clientes implementar múltiples sitios distribuidos geográficamente para lograr una disponibilidad y durabilidad sólidas, presentadas como un único espacio de nombres de objetos.  Esto permite que Splunk SmartStore aproveche el alto rendimiento, la capacidad densa y la capacidad de escalar a cientos de nodos en múltiples sitios físicos utilizando una única URL para interactuar con los objetos.  Esta URL única también permite que la expansión del almacenamiento, las actualizaciones y las reparaciones no produzcan interrupciones, incluso más allá de un solo sitio.  El motor de políticas de gestión de datos exclusivo de StorageGRID proporciona niveles optimizados de rendimiento y durabilidad y cumplimiento de los requisitos de localidad de datos.</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk, líder en la recopilación y análisis de datos generados por máquinas, ayuda a simplificar y modernizar la TI a través de sus capacidades de análisis operativo.  También se expande a casos de uso de análisis de negocios, seguridad e IoT.  El almacenamiento es un elemento fundamental para una implementación exitosa del software Splunk.</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">Los datos generados por máquinas son el tipo de big data de más rápido crecimiento.  El formato es impredecible y proviene de muchas fuentes diferentes, a menudo a gran velocidad y en grandes volúmenes.  Estas características de carga de trabajo a menudo se denominan escape digital.  Splunk SmartStore ayuda a dar sentido a estos datos y proporciona una clasificación inteligente de datos para una ubicación optimizada de datos calientes y tibios en el nivel de almacenamiento más rentable.</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore es una capacidad de indexación que utiliza almacenamiento de objetos (también conocido como almacenamiento remoto o niveles de almacenamiento remoto) como StorageGRID para almacenar datos cálidos mediante el protocolo S3.</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">A medida que aumenta el volumen de datos de una implementación, la demanda de almacenamiento generalmente supera la demanda de recursos informáticos.  SmartStore le permite administrar su almacenamiento de indexador y sus recursos computacionales de manera rentable al escalar el procesamiento y el almacenamiento por separado.</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore presenta un nivel de almacenamiento remoto, utilizando el protocolo S3, y un administrador de caché.  Estas características permiten que los datos residan localmente en indexadores o en almacenamiento remoto.  El administrador de caché, que reside en el indexador, administra el movimiento de datos entre el indexador y el nivel de almacenamiento remoto.  Los datos se almacenan en depósitos (calientes y templados) junto con los metadatos del depósito.</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">Con SmartStore, puede reducir el espacio de almacenamiento del indexador al mínimo y elegir recursos informáticos optimizados para E/S porque la mayoría de los datos residen en el nivel de almacenamiento remoto.  El indexador mantiene un caché local, que representa la cantidad mínima de datos necesarios para devolver los resultados solicitados y predichos.  La caché local contiene buckets activos, copias de buckets cálidos que participan en búsquedas activas o recientes y metadatos de buckets.</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">Splunk SmartStore con StorageGRID permite a los clientes escalar de forma incremental el entorno con almacenamiento remoto rentable y de alto rendimiento al tiempo que proporciona un alto grado de elasticidad a la solución general.  Esto permite a los clientes agregar cualquier componente (almacenamiento activo y/o almacenamiento S3 templado) en cualquier cantidad determinada en cualquier momento, ya sea que necesiten más indexadores, cambiar la retención de datos o aumentar la tasa de ingesta sin ninguna interrupción.</block>
  <block id="d919f51e7020fabd237372f4c163a60e" category="summary">StorageGRID tiene una amplia variedad de características que los usuarios pueden aprovechar y personalizar para su entorno en constante cambio.</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Funciones flexibles de StorageGRID para Splunk SmartStore</block>
  <block id="d7ec4db6b0e9313773163a8a2404946e" category="paragraph">StorageGRID tiene una amplia variedad de características que los usuarios pueden aprovechar y personalizar para su entorno en constante cambio.  Desde la implementación hasta la ampliación de su Splunk SmartStore, su entorno exige una rápida adopción de los cambios y no debe interrumpir el funcionamiento de Splunk.  Las políticas de administración de datos flexibles (ILM) y los clasificadores de tráfico (QoS) de StorageGRID le permiten planificar y adaptarse a su entorno.</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager es la interfaz gráfica basada en navegador que le permite configurar, administrar y monitorear su sistema StorageGRID en ubicaciones distribuidas globalmente en un solo panel, como se muestra en la siguiente imagen.</block>
  <block id="b426e35a4f24b1452cf4688598a7429c" category="paragraph"><block ref="b426e35a4f24b1452cf4688598a7429c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Realice las siguientes tareas con la interfaz de Grid Manager:</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">Aplicación NetApp StorageGRID para Splunk</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">La aplicación NetApp StorageGRID para Splunk es una aplicación específica para Splunk Enterprise.  Esta aplicación funciona junto con el complemento NetApp StorageGRID para Splunk.  Proporciona visibilidad sobre el estado de StorageGRID , información de uso de la cuenta, detalles de auditoría de seguridad, uso y monitoreo de recursos, etc.</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">La siguiente imagen muestra la aplicación StorageGRID para Splunk.</block>
  <block id="33e8e06b4bbde24cf3f439a1bd66cf19" category="paragraph"><block ref="33e8e06b4bbde24cf3f439a1bd66cf19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">Políticas de ILM</block>
  <block id="2121ccc9450b2df939a6752c3559486a" category="paragraph">StorageGRID tiene políticas de administración de datos flexibles que incluyen mantener múltiples copias de sus objetos y usar esquemas EC (codificación de borrado) como 2+1 y 4+2 (y muchos otros) para almacenar sus objetos dependiendo de los requisitos específicos de rendimiento y protección de datos.  A medida que las cargas de trabajo y los requisitos cambian con el tiempo, es común que las políticas de ILM también deban cambiar con el tiempo.  La modificación de las políticas de ILM es una característica fundamental que permite a los clientes de StorageGRID adaptarse a su entorno en constante cambio de forma rápida y sencilla.</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID escala el rendimiento agregando más nodos, que pueden ser máquinas virtuales, hardware o dispositivos especialmente diseñados como SG5712, SG5760, SG6060 o SGF6024.  En nuestras pruebas, superamos los requisitos clave de rendimiento de SmartStore con una red de tres nodos de tamaño mínimo utilizando el dispositivo SG6060.  A medida que los clientes amplían su infraestructura Splunk con indexadores adicionales, pueden agregar más nodos de almacenamiento para aumentar el rendimiento y la capacidad.</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">Configuración del balanceador de carga y del punto final</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">Los nodos de administración en StorageGRID proporcionan la interfaz de usuario (IU) de Grid Manager y el punto final de API REST para ver, configurar y administrar su sistema StorageGRID , así como registros de auditoría para rastrear la actividad del sistema.  Para proporcionar un punto final S3 de alta disponibilidad para el almacenamiento remoto Splunk SmartStore, implementamos el balanceador de carga StorageGRID , que se ejecuta como un servicio en los nodos de administración y los nodos de puerta de enlace.  Además, el balanceador de carga también administra el tráfico local y se comunica con GSLB (Global Server Load Balancing) para ayudar con la recuperación ante desastres.</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">Para mejorar aún más la configuración de los puntos finales, StorageGRID proporciona políticas de clasificación de tráfico integradas en el nodo de administración, le permite monitorear el tráfico de su carga de trabajo y aplicar varios límites de calidad de servicio (QoS) a sus cargas de trabajo.  Las políticas de clasificación de tráfico se aplican a los puntos finales del servicio StorageGRID Load Balancer para los nodos de puerta de enlace y los nodos de administración.  Estas políticas pueden ayudar a limitar y monitorear el tráfico.</block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">A medida que los clientes se dan cuenta del poder y la facilidad de usar el análisis de datos de Splunk, naturalmente quieren indexar una cantidad cada vez mayor de datos.  A medida que crece la cantidad de datos, también crece la infraestructura de procesamiento y almacenamiento necesaria para brindarles servicio.</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">Nivelación inteligente y ahorro de costes</block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">A medida que los clientes se dan cuenta del poder y la facilidad de usar el análisis de datos de Splunk, naturalmente quieren indexar una cantidad cada vez mayor de datos.  A medida que crece la cantidad de datos, también crece la infraestructura de procesamiento y almacenamiento necesaria para brindarles servicio.  Como los datos más antiguos se consultan con menos frecuencia, comprometer la misma cantidad de recursos computacionales y consumir el costoso almacenamiento primario se vuelve cada vez más ineficiente.  Para operar a escala, los clientes se benefician al mover datos calientes a un nivel más rentable, liberando capacidad de procesamiento y almacenamiento primario para datos calientes.</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">Splunk SmartStore con StorageGRID ofrece a las organizaciones una solución escalable, de alto rendimiento y rentable.  Debido a que SmartStore reconoce los datos, evalúa automáticamente los patrones de acceso a los datos para determinar qué datos deben ser accesibles para análisis en tiempo real (datos activos) y qué datos deben residir en un almacenamiento a largo plazo de menor costo (datos tibios).  SmartStore utiliza la API AWS S3 estándar de la industria de forma dinámica e inteligente, colocando los datos en el almacenamiento S3 proporcionado por StorageGRID.  La arquitectura de escalamiento flexible de StorageGRID permite que el nivel de datos cálidos crezca de manera rentable según sea necesario.  La arquitectura basada en nodos de StorageGRID garantiza que los requisitos de rendimiento y costos se cumplan de manera óptima.</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">La siguiente imagen ilustra la organización en niveles de Splunk y StorageGRID .</block>
  <block id="f710071dfe9306034297e2bbb442d8bc" category="paragraph"><block ref="f710071dfe9306034297e2bbb442d8bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">La combinación líder en la industria de Splunk SmartStore con NetApp StorageGRID ofrece los beneficios de la arquitectura desacoplada a través de una solución de pila completa.</block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623: NetApp E-Series E5700 y Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn, NetApp</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623 describe la arquitectura integrada del diseño de NetApp E-Series y Splunk.  Optimizado para el equilibrio del almacenamiento del nodo, la confiabilidad, el rendimiento, la capacidad de almacenamiento y la densidad, este diseño emplea el modelo de nodo de índice agrupado de Splunk, con mayor escalabilidad y menor TCO.  Separar el almacenamiento del procesamiento proporciona la capacidad de escalar cada uno por separado, ahorrando el costo de aprovisionar en exceso uno u otro.  Además, este documento resume los resultados de las pruebas de rendimiento obtenidos de una herramienta de simulación de eventos de registro de máquina Splunk.</block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="f1739b1d5d1c44e562a8500d3b80579f" category="summary">Capacidades de IA de NetApp que permiten una gestión fluida de datos y el movimiento de datos a lo largo del flujo de trabajo de IA para entrenamiento, reentrenamiento, ajuste, inferencia y monitoreo de modelos de IA generativos.</block>
  <block id="36cc0281ec7abcd20091f5d39b995cc4" category="doc">IA generativa y valor de NetApp</block>
  <block id="6dbc3469d4924aa631238769172515d8" category="paragraph">La demanda de inteligencia artificial (IA) generativa está generando disrupción en todas las industrias, mejorando la creatividad empresarial y la innovación de productos.</block>
  <block id="40ed4c797a14998a489b495cd8c9a5e0" category="paragraph">Muchas organizaciones están utilizando IA generativa para crear nuevas funciones de productos, mejorar la productividad de ingeniería y crear prototipos de aplicaciones impulsadas por IA que ofrecen mejores resultados y experiencias para los consumidores.  La IA generativa, como los transformadores generativos preentrenados (GPT), utiliza redes neuronales para crear contenido nuevo, tan diverso como texto, audio y video.  Dada la escala extrema y los conjuntos de datos masivos involucrados con los modelos de lenguaje grandes (LLM), es crucial diseñar una infraestructura de IA robusta que aproveche las atractivas características de almacenamiento de datos de las opciones de implementación locales, híbridas y multicloud, y reduzca los riesgos asociados con la movilidad de datos, la protección de datos y la gobernanza antes de que las empresas puedan diseñar soluciones de IA.  En este documento se describen estas consideraciones y las capacidades de IA de NetApp correspondientes que permiten la gestión fluida de datos y el movimiento de datos a lo largo del flujo de datos de IA para entrenar, reentrenar, ajustar e inferir modelos generativos de IA.</block>
  <block id="a573d92b77d430af7e424879baf78e94" category="section-title">Resumen ejecutivo</block>
  <block id="3fed37bedb6b36d52c0c5b3aa0089bfe" category="paragraph">Más recientemente, tras el lanzamiento de ChatGPT, una escisión de GPT-3 en noviembre de 2022, las nuevas herramientas de IA utilizadas para generar texto, código, imágenes o incluso proteínas terapéuticas en respuesta a las indicaciones del usuario han ganado una fama significativa.  Esto indica que los usuarios pueden realizar una solicitud usando lenguaje natural y la IA interpretará y generará texto, como artículos de noticias o descripciones de productos que reflejen la solicitud del usuario o producirán código, música, voz, efectos visuales y activos 3D utilizando algoritmos entrenados con datos ya existentes.  Como resultado, frases como difusión estable, alucinaciones, ingeniería rápida y alineación de valores están surgiendo rápidamente en el diseño de sistemas de IA.  Estos modelos de aprendizaje automático (ML) autosupervisados o semisupervisados se están volviendo ampliamente disponibles como modelos básicos entrenados previamente (FM) a través de proveedores de servicios en la nube y otras empresas proveedoras de IA, que están siendo adoptados por varios establecimientos comerciales en todas las industrias para una amplia gama de tareas posteriores de PNL (procesamiento del lenguaje natural).  Como afirman firmas de análisis de investigación como McKinsey: "El impacto de la IA generativa en la productividad podría agregar billones de dólares en valor a la economía global".  Mientras las empresas están reinventando la IA como un socio intelectual para los humanos y los gerentes de finanzas están ampliando simultáneamente lo que las empresas e instituciones pueden hacer con la IA generativa, las oportunidades para gestionar volúmenes masivos de datos seguirán creciendo.  Este documento presenta información introductoria sobre la IA generativa y los conceptos de diseño en relación con las capacidades de NetApp que aportan valor a los clientes de NetApp , tanto en entornos locales como híbridos o multicloud.</block>
  <block id="8bcfe22a3d7c5edf904444893704a8de" category="paragraph">*Entonces, ¿qué beneficios obtienen los clientes al utilizar NetApp en sus entornos de IA?*  NetApp ayuda a las organizaciones a afrontar las complejidades creadas por el rápido crecimiento de los datos y la nube, la gestión de múltiples nubes y la adopción de tecnologías de última generación, como la IA.  NetApp ha combinado varias capacidades en un software de gestión de datos inteligente y una infraestructura de almacenamiento que están bien equilibradas con un alto rendimiento optimizado para cargas de trabajo de IA.  Las soluciones de IA generativa como LLM necesitan leer y procesar sus conjuntos de datos de origen desde el almacenamiento a la memoria numerosas veces para fomentar la inteligencia.  NetApp ha sido líder en tecnologías de movilidad de datos, gobernanza de datos y seguridad de datos en todo el ecosistema del borde al núcleo y a la nube, ayudando a clientes empresariales a construir soluciones de IA a escala.  NetApp, con una sólida red de socios, ha estado ayudando a los directores de datos, ingenieros de IA, arquitectos empresariales y científicos de datos en el diseño de un flujo de datos libre para la preparación de datos, la protección de datos y las responsabilidades de gestión estratégica de datos del entrenamiento y la inferencia de modelos de IA, optimizando el rendimiento y la escalabilidad del ciclo de vida de IA/ML.  Las tecnologías y capacidades de datos de NetApp , como NetApp ONTAP AI para la canalización de datos de aprendizaje profundo, NetApp SnapMirror para transportar datos de manera fluida y eficiente entre puntos finales de almacenamiento, y NetApp FlexCache para la representación en tiempo real cuando el flujo de datos cambia de lote a tiempo real y la ingeniería de datos ocurre en el momento oportuno, aportan valor a la implementación de modelos de IA generativa en tiempo real.  A medida que las empresas de todo tipo adoptan nuevas herramientas de IA, enfrentan desafíos de datos desde el borde hasta el centro de datos y la nube que exigen soluciones de IA escalables, responsables y explicables.  Como autoridad en datos sobre nubes híbridas y múltiples, NetApp se compromete a construir una red de socios y soluciones conjuntas que puedan ayudar con todos los aspectos de la construcción de una canalización de datos y lagos de datos para el entrenamiento de modelos de IA generativos (preentrenamiento), el ajuste fino, la inferencia basada en el contexto y el monitoreo de la descomposición del modelo de LLM.</block>
  <block id="ba4c46fa4f06702b4667d0b3a6b2bdfe" category="section-title">¿Qué es la IA generativa?</block>
  <block id="11703c9edbc2bf714a8c4be38891fc77" category="paragraph">La IA generativa está cambiando la forma en que creamos contenido, generamos nuevos conceptos de diseño y exploramos composiciones novedosas.  Ilustra marcos de redes neuronales como la red generativa antagónica (GAN), los autocodificadores variacionales (VAE) y los transformadores generativos preentrenados (GPT), que pueden generar contenido nuevo como texto, código, imágenes, audio, video y datos sintéticos.  Los modelos basados en transformadores como Chat-GPT de OpenAI, Bard de Google, BLOOM de Hugging Face y LLaMA de Meta han surgido como la tecnología fundamental que sustenta muchos avances en modelos de lenguaje de gran tamaño.  Del mismo modo, Dall-E de OpenAI, CM3leon de Meta e Imagen de Google son ejemplos de modelos de difusión de texto a imagen que ofrecen a los clientes un grado de fotorrealismo sin precedentes para crear imágenes nuevas y complejas desde cero o editar imágenes existentes para generar imágenes de alta calidad que tengan en cuenta el contexto mediante el aumento de conjuntos de datos y la síntesis de texto a imagen que vincula la semántica textual y visual.  Los artistas digitales están comenzando a aplicar una combinación de tecnologías de renderizado como NeRF (Neural Radiance Field) con IA generativa para convertir imágenes 2D estáticas en escenas 3D inmersivas.  En general, los LLM se caracterizan por cuatro parámetros: (1) Tamaño del modelo (normalmente en miles de millones de parámetros); (2) Tamaño del conjunto de datos de entrenamiento; (3) Costo de entrenamiento, y (4) Rendimiento del modelo después del entrenamiento.  Los LLM también se dividen principalmente en tres arquitecturas de transformadores.  (i) Modelos de sólo codificador.  Por ejemplo, BERT (Google, 2018); (ii) Modelos codificador-decodificador, por ejemplo, BART (Meta, 2020) y (iii) Modelos solo decodificador.  Por ejemplo, LLaMA (Meta, 2023), PaLM-E (Google, 2023).  Dependiendo del requisito comercial, independientemente de la arquitectura que elija una empresa, la cantidad de parámetros del modelo (N) y la cantidad de tokens (D) en el conjunto de datos de entrenamiento generalmente determinan el costo base del entrenamiento (preentrenamiento) o el ajuste de un LLM.</block>
  <block id="d1ddcb04dcb447b3f05fa54e9ab492d0" category="section-title">Casos de uso empresarial y tareas posteriores de PNL</block>
  <block id="a4a7c510156562fb9841dd055348b753" category="paragraph">Las empresas de todos los sectores están descubriendo cada vez más potencial para que la IA extraiga y produzca nuevas formas de valor a partir de datos existentes para operaciones comerciales, ventas, marketing y servicios legales.  Según la información de mercado de IDC (International Data Corporation) sobre casos de uso e inversiones en IA generativa a nivel mundial, la gestión del conocimiento en el desarrollo de software y el diseño de productos será la más afectada, seguida por la creación de historias para marketing y la generación de código para desarrolladores.  En el ámbito sanitario, las organizaciones de investigación clínica están abriendo nuevos caminos en la medicina.  Los modelos preentrenados como ProteinBERT incorporan anotaciones de Gene Ontology (GO) para diseñar rápidamente estructuras de proteínas para medicamentos médicos, lo que representa un hito significativo en el descubrimiento de fármacos, la bioinformática y la biología molecular.  Las empresas de biotecnología han iniciado ensayos en humanos para una medicina generativa descubierta mediante inteligencia artificial, que tiene como objetivo tratar enfermedades como la fibrosis pulmonar (FPI), una enfermedad pulmonar que causa cicatrices irreversibles en el tejido pulmonar.</block>
  <block id="8e5aaca094938e3b1a2e08f48f3db558" category="paragraph">Figura 1: Casos de uso que impulsan la IA generativa</block>
  <block id="8d04a6a1813e89b5849d40e5113b0902" category="paragraph"><block ref="8d04a6a1813e89b5849d40e5113b0902" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605e4f6997ac64a7de35f4e8a02721e9" category="paragraph">El aumento en la adopción de la automatización impulsada por la IA generativa también está cambiando la oferta y la demanda de actividades laborales para muchas ocupaciones.  Según McKinsey, el mercado laboral de EE. UU. (diagrama a continuación) ha atravesado una rápida transición, que solo puede continuar si se tiene en cuenta el impacto de la IA.</block>
  <block id="844d4a4d01e4441540857f7a302f6239" category="paragraph">Fuente: McKinsey &amp; Company</block>
  <block id="14509aeb117a81412dfa4dc27107f735" category="inline-image-macro">Figura 2: Fuente: McKinsey &amp; Company</block>
  <block id="f86a1cf79787f9ca7a0bc2698a14baa8" category="paragraph"><block ref="1cdd0679074896d7373f66c66dc8dda4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="072f966c176c14e4a8ac1b32dff891bc" category="section-title">El papel del almacenamiento en la IA generativa</block>
  <block id="6a352eac97ff84fb6680bea0e3f1582b" category="inline-link-macro">512 MB</block>
  <block id="23f951a15f217f2ce467c5d52e3a74a2" category="paragraph">Los LLM se basan en gran medida en el aprendizaje profundo, las GPU y la computación.  Sin embargo, cuando el búfer de la GPU se llena, los datos deben escribirse rápidamente en el almacenamiento.  Si bien algunos modelos de IA son lo suficientemente pequeños para ejecutarse en la memoria, los LLM requieren IOPS altos y almacenamiento de alto rendimiento para brindar acceso rápido a grandes conjuntos de datos, especialmente si involucran miles de millones de tokens o millones de imágenes.  Para un requisito típico de memoria de GPU de un LLM, la memoria necesaria para entrenar un modelo con mil millones de parámetros podría llegar hasta 80 GB con precisión completa de 32 bits.  En ese caso, LLaMA 2 de Meta, una familia de LLM que varía en escala desde 7 mil millones a 70 mil millones de parámetros, puede requerir 70x80, aproximadamente 5600 GB o 5,6 TB de RAM de GPU.  Además, la cantidad de memoria que necesitas es directamente proporcional al número máximo de tokens que quieras generar.  Por ejemplo, si desea generar resultados de hasta 512 tokens (aproximadamente 380 palabras), necesita<block ref="8b6a924b2b2c8b02d5e56762d0384bc1" category="inline-link-macro-rx"></block> .  Quizás parezca insignificante, pero si quieres procesar lotes más grandes, empieza a sumar.  Por lo tanto, resulta muy costoso para las organizaciones capacitar o ajustar los LLM en memoria, convirtiendo así el almacenamiento en una piedra angular para la IA generativa.</block>
  <block id="b0b4b15d26d559735ca79c547ebcf9b6" category="section-title">Tres enfoques principales para los LLM</block>
  <block id="29ff458fbe275b29aaf5e7dbd636eed4" category="inline-link-macro">Revista de negocios de Harvard</block>
  <block id="b026e17fa592b49ccc86f0f9b718b03b" category="paragraph">Para la mayoría de las empresas, según las tendencias actuales, el enfoque para implementar LLM se puede condensar en tres escenarios básicos.  Como se describe en un artículo reciente<block ref="9b642d86ef84545807d431905b86239d" category="inline-link-macro-rx"></block> Artículo: (1) Capacitación (preentrenamiento) de un LLM desde cero: costosa y requiere habilidades expertas en IA/ML; (2) Ajuste de un modelo de base con datos empresariales: complejo, pero factible; (3) Uso de generación aumentada por recuperación (RAG) para consultar repositorios de documentos, API y bases de datos vectoriales que contienen datos de la empresa.  Cada uno de ellos implica compensaciones entre el esfuerzo, la velocidad de iteración, la relación coste-eficiencia y la precisión del modelo en sus implementaciones, utilizadas para resolver distintos tipos de problemas (diagrama a continuación).</block>
  <block id="c35884049dd0467b68f884a60d4920ea" category="paragraph">Figura 3: Tipos de problemas</block>
  <block id="2ee3234ece3d669efe95dc1a84c67a06" category="paragraph"><block ref="2ee3234ece3d669efe95dc1a84c67a06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff76a02d3da4ad3236fe1704ce7b2a4c" category="section-title">Modelos de Fundación</block>
  <block id="212ec66e09b7b19d2e397c5c04e8543d" category="paragraph">Un modelo de fundación (FM), también conocido como modelo base, es un modelo de IA de gran tamaño (LLM) entrenado en grandes cantidades de datos sin etiquetar, utilizando autosupervisión a escala, generalmente adaptado para una amplia gama de tareas de PNL posteriores.  Dado que los datos de entrenamiento no están etiquetados por humanos, el modelo emerge en lugar de estar codificado explícitamente.  Esto significa que el modelo puede generar historias o una narrativa propia sin estar programado explícitamente para hacerlo.  Por lo tanto, una característica importante del FM es la homogeneización, lo que significa que se utiliza el mismo método en muchos dominios.  Sin embargo, con las técnicas de personalización y ajuste, los FM integrados en los productos que aparecen hoy en día no solo son buenos para generar texto, texto a imágenes y texto a código, sino también para explicar tareas específicas del dominio o depurar código.  Por ejemplo, FM como Codex de OpenAI o Code Llama de Meta pueden generar código en múltiples lenguajes de programación basándose en descripciones en lenguaje natural de una tarea de programación.  Estos modelos son competentes en más de una docena de lenguajes de programación, incluidos Python, C#, JavaScript, Perl, Ruby y SQL.  Entienden la intención del usuario y generan código específico que logra la tarea deseada, útil para el desarrollo de software, la optimización de código y la automatización de tareas de programación.</block>
  <block id="09505640cb74de4ed6c0043b4fd83b62" category="section-title">Ajuste fino, especificidad del dominio y reentrenamiento</block>
  <block id="d70061bb0ac24d99b6a01f537dfc5836" category="inline-link-macro">Llama de Meta 2</block>
  <block id="3983fea9bc2f220141201994aa6cf9de" category="paragraph">Una de las prácticas comunes con la implementación de LLM luego de la preparación y el preprocesamiento de datos es seleccionar un modelo previamente entrenado que haya sido entrenado en un conjunto de datos grande y diverso.  En el contexto del ajuste fino, este puede ser un modelo de lenguaje grande de código abierto como<block ref="40c631914d673c775e5813606a4c652a" category="inline-link-macro-rx"></block> entrenado con 70 mil millones de parámetros y 2 billones de tokens.  Una vez seleccionado el modelo previamente entrenado, el siguiente paso es ajustarlo a los datos específicos del dominio.  Esto implica ajustar los parámetros del modelo y entrenarlo con los nuevos datos para adaptarse a un dominio y una tarea específicos.  Por ejemplo, BloombergGPT, un LLM propietario capacitado en una amplia gama de datos financieros al servicio de la industria financiera.  Los modelos específicos de dominio diseñados y entrenados para una tarea específica generalmente tienen mayor precisión y desempeño dentro de su alcance, pero baja transferibilidad a otras tareas o dominios.  Cuando el entorno empresarial y los datos cambian durante un período, la precisión de predicción del FM podría comenzar a disminuir en comparación con su desempeño durante las pruebas.  Es en este momento cuando el reentrenamiento o ajuste del modelo se vuelve crucial.  El reentrenamiento de modelos en IA/ML tradicional se refiere a la actualización de un modelo de ML implementado con nuevos datos, generalmente realizado para eliminar dos tipos de desviaciones que ocurren.  (1) Deriva de concepto: cuando el vínculo entre las variables de entrada y las variables de destino cambia con el tiempo, dado que la descripción de lo que queremos predecir cambia, el modelo puede producir predicciones inexactas.  (2) Desviación de datos: ocurre cuando las características de los datos de entrada cambian, como cambios en los hábitos o el comportamiento del cliente a lo largo del tiempo y, por lo tanto, la incapacidad del modelo para responder a dichos cambios.  De manera similar, la capacitación se aplica a los FM/LLM, sin embargo, puede ser mucho más costosa (en millones de dólares), por lo que no es algo que la mayoría de las organizaciones podrían considerar.  Se encuentra bajo investigación activa y aún está emergiendo en el ámbito de LLMOps.  Por lo tanto, en lugar de volver a entrenar, cuando se produce un deterioro del modelo en los FM ajustados, las empresas pueden optar por ajustarlo nuevamente (mucho más barato) con un conjunto de datos más nuevo.  Para una perspectiva de costos, a continuación se muestra un ejemplo de una tabla de precios de modelos de Azure-OpenAI Services.  Para cada categoría de tarea, los clientes pueden ajustar y evaluar modelos en conjuntos de datos específicos.</block>
  <block id="95d06c21390dc25827c0fd489dc141e4" category="paragraph">Fuente: Microsoft Azure</block>
  <block id="56307bc010f6f11cf695a4f4a8868ec2" category="paragraph"><block ref="56307bc010f6f11cf695a4f4a8868ec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157d80dbb8ad88a26dfd59594b88e11c" category="section-title">Ingeniería rápida e inferencia</block>
  <block id="e48b39374db0f3e4c1479cb81f7ebd58" category="paragraph">La ingeniería rápida se refiere a los métodos efectivos de cómo comunicarse con los LLM para realizar las tareas deseadas sin actualizar los pesos del modelo.  Tan importante como es el entrenamiento y el ajuste del modelo de IA para las aplicaciones de PNL, es igualmente importante la inferencia, donde los modelos entrenados responden a las indicaciones del usuario.  Los requisitos del sistema para la inferencia generalmente se basan mucho más en el rendimiento de lectura del sistema de almacenamiento de IA que alimenta datos desde los LLM a las GPU, ya que necesita poder aplicar miles de millones de parámetros de modelo almacenados para producir la mejor respuesta.</block>
  <block id="71451daa1205b079e03924f700485fb7" category="section-title">LLMOps, Monitoreo de Modelos y Almacenes de Vectores</block>
  <block id="37dc13dd8c23bd5e417bad0376cb8642" category="paragraph">Al igual que las operaciones de aprendizaje automático tradicionales (MLOps), las operaciones de modelos de lenguaje grandes (LLMOps) también requieren la colaboración de científicos de datos e ingenieros de DevOps con herramientas y mejores prácticas para la gestión de LLM en entornos de producción.  Sin embargo, el flujo de trabajo y la pila tecnológica para los LLM pueden variar de algunas maneras.  Por ejemplo, las canalizaciones LLM creadas utilizando marcos como LangChain unen múltiples llamadas API LLM a puntos finales de incrustación externos, como almacenes de vectores o bases de datos vectoriales.  El uso de un punto final de integración y un almacén de vectores para conectores posteriores (como una base de datos vectorial) representa un avance significativo en la forma en que se almacenan y acceden los datos.  A diferencia de los modelos ML tradicionales que se desarrollan desde cero, los LLM a menudo se basan en el aprendizaje por transferencia, ya que estos modelos comienzan con FM que se ajustan con nuevos datos para mejorar el rendimiento en un dominio más específico.  Por lo tanto, es fundamental que LLMOps brinde capacidades de gestión de riesgos y monitoreo del deterioro del modelo.</block>
  <block id="e1e7449571fe3b65d3a1e689bc700cbc" category="section-title">Riesgos y ética en la era de la IA generativa</block>
  <block id="c12a37efb07149af3ee94636c74b80c5" category="paragraph">"ChatGPT: es ingenioso, pero aun así dice tonterías". – MIT Tech Review.  Basura que entra, basura que sale: ese ha sido siempre el desafío en informática.  La única diferencia con la IA generativa es que se destaca por hacer que la basura sea altamente creíble, lo que conduce a resultados inexactos.  Los LLM son propensos a inventar hechos que se ajusten a la narrativa que están construyendo.  Por lo tanto, las empresas que ven la IA generativa como una gran oportunidad para reducir sus costos con equivalentes de IA necesitan detectar eficientemente las falsificaciones profundas, reducir los sesgos y disminuir los riesgos para mantener los sistemas honestos y éticos.  Una tubería de datos de flujo libre con una infraestructura de IA robusta que respalde la movilidad de los datos, la calidad de los datos, la gobernanza de los datos y la protección de los datos mediante cifrado de extremo a extremo y barandillas de IA es fundamental en el diseño de modelos de IA generativos responsables y explicables.</block>
  <block id="b1c01c916bfeda43bbe010599a3756ef" category="section-title">Escenario del cliente y NetApp</block>
  <block id="d475afb6eaf5d8966136580d55f5a688" category="paragraph">Figura 3: Flujo de trabajo de aprendizaje automático/modelo de lenguaje grande</block>
  <block id="1d5b6314b7c490b3ba00c157c5d73c98" category="paragraph"><block ref="1d5b6314b7c490b3ba00c157c5d73c98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dd90f4ead88ee59ec52f11bac2d164b" category="paragraph">¿Estamos entrenando o afinando?  La cuestión de si (a) entrenar un modelo LLM desde cero, ajustar un FM entrenado previamente o usar RAG para recuperar datos de repositorios de documentos fuera de un modelo base y aumentar las indicaciones, y (b) aprovechar LLM de código abierto (por ejemplo, Llama 2) o FM propietarios (por ejemplo, ChatGPT, Bard, AWS Bedrock) es una decisión estratégica para las organizaciones.  Cada enfoque implica un equilibrio entre la relación coste-eficiencia, la gravedad de los datos, las operaciones, la precisión del modelo y la gestión de los LLM.</block>
  <block id="8c8696e5c9dd013fefe41f5a257ecba6" category="paragraph">NetApp , como empresa, adopta la IA internamente en su cultura de trabajo y en su enfoque de los esfuerzos de diseño e ingeniería de productos.  Por ejemplo, la protección autónoma contra ransomware de NetApp está construida utilizando inteligencia artificial y aprendizaje automático.  Proporciona detección temprana de anomalías del sistema de archivos para ayudar a identificar amenazas antes de que afecten las operaciones.  En segundo lugar, NetApp utiliza IA predictiva para sus operaciones comerciales, como pronósticos de ventas e inventario, y chatbots para ayudar a los clientes en servicios de soporte de productos del centro de llamadas, especificaciones técnicas, garantía, manuales de servicio y más.  En tercer lugar, NetApp aporta valor al cliente en el flujo de trabajo de ML/LLM y en la canalización de datos de IA mediante productos y soluciones que prestan servicios a clientes que crean soluciones de IA predictivas, como previsión de la demanda, imágenes médicas, análisis de sentimientos y soluciones de IA generativa como GAN para la detección de anomalías en imágenes industriales en el sector manufacturero y la detección de fraude y lavado de dinero en servicios bancarios y financieros con productos y capacidades de NetApp como NetApp ONTAP AI, NetApp SnapMirror y NetApp FlexCache.</block>
  <block id="1e79e12b94e448f7c2f614e8ab2794ba" category="section-title">Capacidades de NetApp</block>
  <block id="14560cdfa11223c1b6b5ae41321de6d4" category="paragraph">El movimiento y la gestión de datos en aplicaciones de IA generativa, como chatbots, generación de código, generación de imágenes o expresión de modelos genómicos, pueden abarcar el borde, el centro de datos privado y el ecosistema híbrido de múltiples nubes.  Por ejemplo, un robot de inteligencia artificial en tiempo real que ayuda a un pasajero a mejorar su boleto de avión a clase ejecutiva desde una aplicación de usuario final expuesta a través de API de modelos previamente entrenados como ChatGPT no puede lograr esa tarea por sí solo, ya que la información del pasajero no está disponible públicamente en Internet.  La API requiere acceso a la información personal del pasajero y a la información del boleto de la aerolínea, que puede existir en un ecosistema híbrido o multicloud.  Un escenario similar podría aplicarse a científicos que comparten una molécula de fármaco y datos de pacientes a través de una aplicación de usuario final que utiliza LLM para realizar ensayos clínicos en todo el proceso de descubrimiento de fármacos que involucra de una a muchas instituciones de investigación biomédica.  Los datos confidenciales que se transmiten a los FM o LLM pueden incluir información personal identificable, información financiera, información de salud, datos biométricos, datos de ubicación, datos de comunicaciones, comportamiento en línea e información legal.  En un evento de renderizado en tiempo real, ejecución inmediata e inferencia de borde, hay un movimiento de datos desde la aplicación del usuario final a los puntos finales de almacenamiento a través de modelos LLM propietarios o de código abierto a un centro de datos local o plataformas de nube pública.  En todos estos escenarios, la movilidad y la protección de datos son cruciales para las operaciones de IA que involucran LLM que dependen de grandes conjuntos de datos de entrenamiento y del movimiento de dichos datos.</block>
  <block id="2bf2b67b54f29152ea5e8649dd4b7327" category="paragraph">Figura 4: Canal de datos de IA generativa - LLM</block>
  <block id="206f6329180f9a8251d5f78b853663ab" category="inline-image-macro">Figura 4: Canal de datos generativo de IA-LLM</block>
  <block id="47b42e2c6c693df656a00ec63e39dde3" category="paragraph"><block ref="47b42e2c6c693df656a00ec63e39dde3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc004144b88d4fadbbf7623c57d2c805" category="paragraph">La cartera de infraestructura de almacenamiento, datos y servicios en la nube de NetApp está impulsada por un software de gestión de datos inteligente.</block>
  <block id="7d5e80d61d854ee2e646efedf9f5e72d" category="paragraph">*Preparación de datos*: El primer pilar de la pila tecnológica de LLM prácticamente no se ha visto afectado por la antigua pila tradicional de ML.  El preprocesamiento de datos en la canalización de IA es necesario para normalizar y limpiar los datos antes del entrenamiento o el ajuste.  Este paso incluye conectores para ingerir datos donde sea que residan en forma de un nivel de Amazon S3 o en sistemas de almacenamiento locales, como un almacén de archivos o un almacén de objetos como NetApp StorageGRID.</block>
  <block id="b63aea4b58eede8ed8da27c8b36c34dc" category="paragraph">* NetApp ONTAP* es la tecnología fundamental que sustenta las soluciones de almacenamiento críticas de NetApp en el centro de datos y la nube.  ONTAP incluye varias funciones y capacidades de protección y administración de datos, incluida protección automática contra ransomware contra ciberataques, funciones de transporte de datos integradas y capacidades de eficiencia de almacenamiento para una variedad de arquitecturas, desde locales, híbridas, multicloud en NAS, SAN, objetos y situaciones de almacenamiento definido por software (SDS) de implementaciones LLM.</block>
  <block id="77b83e7426a1ca8eea17df3ff3a421f7" category="paragraph">* NetApp ONTAP AI * para entrenamiento de modelos de aprendizaje profundo.  NetApp ONTAP admite el almacenamiento directo de GPU NVIDIA con el uso de NFS sobre RDMA para clientes de NetApp con clúster de almacenamiento ONTAP y nodos de cómputo NVIDIA DGX.  Ofrece un rendimiento rentable para leer y procesar conjuntos de datos de origen desde el almacenamiento a la memoria numerosas veces para fomentar la inteligencia, lo que permite a las organizaciones capacitación, ajuste y escalamiento del acceso a los LLM.</block>
  <block id="420e9d37fdcde42065e69c7f6d925ab3" category="paragraph">* NetApp FlexCache* es una capacidad de almacenamiento en caché remoto que simplifica la distribución de archivos y almacena en caché solo los datos leídos activamente.  Esto puede ser útil para la capacitación, el reentrenamiento y el ajuste de LLM, aportando valor a los clientes con requisitos comerciales como representación en tiempo real e inferencia de LLM.</block>
  <block id="0aef0293018a6f953acd79d5d6fb52ae" category="paragraph">* NetApp SnapMirror* es una función de ONTAP que replica instantáneas de volumen entre dos sistemas ONTAP .  Esta función transfiere datos de manera óptima desde el borde a su centro de datos local o a la nube.  SnapMirror se puede utilizar para mover datos de forma segura y eficiente entre nubes locales y nubes hiperescalables cuando los clientes desean desarrollar IA generativa en nubes con RAG que contienen datos empresariales.  Transfiere eficientemente solo los cambios, ahorrando ancho de banda y acelerando la replicación, aportando así características esenciales de movilidad de datos durante las operaciones de entrenamiento, reentrenamiento y ajuste de FM o LLM.</block>
  <block id="67e47ad6c891ade32e226f1b046d1168" category="paragraph">* NetApp SnapLock* brinda capacidad de disco inmutable en sistemas de almacenamiento basados en ONTAP para el control de versiones de conjuntos de datos.  La arquitectura de micronúcleos está diseñada para proteger los datos del cliente con el motor FPolicy Zero Trust.  NetApp garantiza que los datos de los clientes estén disponibles al resistir ataques de denegación de servicio (DoS) cuando un atacante interactúa con un LLM de una manera que consume especialmente recursos.</block>
  <block id="6fb00f321c345f8a92148aec8d1359f9" category="paragraph">* NetApp Cloud Data Sense* ayuda a identificar, mapear y clasificar la información personal presente en conjuntos de datos empresariales, implementar políticas, cumplir con los requisitos de privacidad en las instalaciones o en la nube, ayudar a mejorar la postura de seguridad y cumplir con las regulaciones.</block>
  <block id="8bca7c4074d7b3156f8b66e3ad7a5be8" category="paragraph">Clasificación * NetApp BlueXP*, impulsada por Cloud Data Sense.  Los clientes pueden escanear, analizar, categorizar y actuar automáticamente sobre los datos en todo el patrimonio de datos, detectar riesgos de seguridad, optimizar el almacenamiento y acelerar las implementaciones en la nube.  Combina servicios de almacenamiento y datos a través de su plano de control unificado. Los clientes pueden usar instancias de GPU para computación y entornos multicloud híbridos para niveles de almacenamiento en frío y para archivos y copias de seguridad.</block>
  <block id="528fb7334ec5453cef67bca12d29f735" category="paragraph">*Dualidad archivo-objeto de NetApp *.  NetApp ONTAP permite el acceso de protocolo dual para NFS y S3.  Con esta solución, los clientes pueden acceder a datos NFS desde notebooks de Amazon AWS SageMaker a través de buckets S3 desde NetApp Cloud Volumes ONTAP.  Esto ofrece flexibilidad a los clientes que necesitan acceso fácil a fuentes de datos heterogéneas con la capacidad de compartir datos tanto de NFS como de S3.  Por ejemplo, ajustar FMs como los modelos de generación de texto Llama 2 de Meta en SageMaker con acceso a depósitos de objetos de archivo.</block>
  <block id="a2e08866ca50b890089d6b77f640d7b5" category="paragraph">El servicio * NetApp Cloud Sync* ofrece una forma sencilla y segura de migrar datos a cualquier destino, en la nube o en las instalaciones.  Cloud Sync transfiere y sincroniza sin problemas datos entre almacenamiento local o en la nube, NAS y almacenes de objetos.</block>
  <block id="e53b3c8e83c8d94be048ce5801830a49" category="paragraph">* NetApp XCP * es un software cliente que permite migraciones de datos rápidas y confiables de cualquier plataforma a NetApp y de NetApp a NetApp .  XCP también proporciona la capacidad de mover datos masivos de manera eficiente desde sistemas de archivos Hadoop HDFS a ONTAP NFS, S3 o StorageGRID y el análisis de archivos XCP proporciona visibilidad del sistema de archivos.</block>
  <block id="d0d48e5a8fe903e906882461b57dcfd3" category="paragraph">* NetApp DataOps Toolkit * es una biblioteca de Python que permite a los científicos de datos, DevOps e ingenieros de datos realizar fácilmente diversas tareas de administración de datos, como aprovisionamiento, clonación o captura de instantáneas casi instantáneas de un volumen de datos o un espacio de trabajo de JupyterLab respaldados por almacenamiento NetApp de escalamiento horizontal de alto rendimiento.</block>
  <block id="97d451a12ea524d66984cc35758777b4" category="paragraph">*Seguridad del producto de NetApp*.  Los LLM pueden revelar inadvertidamente datos confidenciales en sus respuestas, lo que preocupa a los CISO que estudian las vulnerabilidades asociadas con las aplicaciones de IA que aprovechan los LLM.  Como lo describe OWASP (Proyecto Abierto de Seguridad de Aplicaciones Mundiales), los problemas de seguridad como envenenamiento de datos, fuga de datos, denegación de servicio e inyecciones rápidas dentro de los LLM pueden afectar a las empresas desde la exposición de datos hasta el acceso no autorizado por parte de atacantes.  Los requisitos de almacenamiento de datos deben incluir controles de integridad e instantáneas inmutables para datos estructurados, semiestructurados y no estructurados.  Se utilizan instantáneas de NetApp y SnapLock para el control de versiones de conjuntos de datos.  Ofrece un estricto control de acceso basado en roles (RBAC), así como protocolos seguros y cifrado estándar de la industria para proteger los datos en reposo y en tránsito.  Cloud Insights y Cloud Data Sense juntos ofrecen capacidades para ayudarlo a identificar forensemente la fuente de la amenaza y priorizar qué datos restaurar.</block>
  <block id="0364ee2a32c23b9f35e29f68c79d63e1" category="section-title">* ONTAP AI con DGX BasePOD *</block>
  <block id="c6f1dc673303b79fafb5e05f0c7a97cb" category="paragraph">La arquitectura de referencia de IA de NetApp ONTAP con NVIDIA DGX BasePOD es una arquitectura escalable para cargas de trabajo de aprendizaje automático (ML) e inteligencia artificial (IA).  Para la fase crítica de entrenamiento de los LLM, los datos normalmente se copian del almacenamiento de datos al clúster de entrenamiento a intervalos regulares.  Los servidores que se utilizan en esta fase utilizan GPU para paralelizar los cálculos, lo que crea un enorme apetito por los datos.  Satisfacer las necesidades de ancho de banda de E/S sin procesar es crucial para mantener una alta utilización de la GPU.</block>
  <block id="9a05494b8b259619e21e3e78c47f4dc5" category="section-title">* ONTAP AI con NVIDIA AI Enterprise *</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise es una suite integral de software de inteligencia artificial y análisis de datos nativa de la nube, optimizada, certificada y respaldada por NVIDIA para ejecutarse en VMware vSphere con sistemas certificados NVIDIA.  Este software facilita la implementación, la gestión y el escalamiento simples y rápidos de cargas de trabajo de IA en el entorno de nube híbrida moderno.  NVIDIA AI Enterprise, con tecnología de NetApp y VMware, ofrece gestión de datos y cargas de trabajo de IA de nivel empresarial en un paquete simplificado y familiar.</block>
  <block id="1ad177c0b9d841f941eb7d5322dc9b52" category="section-title">*Plataformas en la nube 1P*</block>
  <block id="0e877c6cfb49f5bbdc17c6d204b4b7cb" category="paragraph">Las ofertas de almacenamiento en la nube totalmente administradas están disponibles de forma nativa en Microsoft Azure como Azure NetApp Files (ANF), en AWS como Amazon FSx for NetApp ONTAP (FSx ONTAP) y en Google como Google Cloud NetApp Volumes (GNCV).  1P es un sistema de archivos administrado y de alto rendimiento que permite a los clientes ejecutar cargas de trabajo de IA de alta disponibilidad con seguridad de datos mejorada en nubes públicas, para ajustar LLM/FM con plataformas de ML nativas de la nube como AWS SageMaker, Azure-OpenAI Services y Vertex AI de Google.</block>
  <block id="64992f0c01704aa99d3bd851b7673bf7" category="section-title">Suite de soluciones para socios de NetApp</block>
  <block id="0e3151175898c0a6687552a854a08b00" category="paragraph">Además de sus principales productos, tecnologías y capacidades de datos, NetApp también colabora estrechamente con una sólida red de socios de IA para brindar valor agregado a los clientes.</block>
  <block id="5c682f526a6d29391ad4d45cd7c7cae9" category="paragraph">* NVIDIA Guardrails * en los sistemas de IA sirven como medidas de protección para garantizar el uso ético y responsable de las tecnologías de IA.  Los desarrolladores de IA pueden elegir definir el comportamiento de las aplicaciones impulsadas por LLM en temas específicos y evitar que participen en discusiones sobre temas no deseados.  Guardrails, un kit de herramientas de código abierto, brinda la posibilidad de conectar un LLM a otros servicios de manera segura y sin inconvenientes para construir sistemas conversacionales LLM confiables y seguros.</block>
  <block id="0b46f95333d136197f1bb757634ebae2" category="paragraph">*Domino Data Lab* ofrece herramientas versátiles y de nivel empresarial para crear y producir IA generativa: de manera rápida, segura y económica, dondequiera que se encuentre en su recorrido hacia la IA.  Con la plataforma Enterprise MLOps de Domino, los científicos de datos pueden usar las herramientas preferidas y todos sus datos, entrenar e implementar modelos fácilmente en cualquier lugar y administrar el riesgo y los costos de manera efectiva, todo desde un centro de control.</block>
  <block id="20350fb42ff163b07d9d4a2636b4a555" category="paragraph">*Modzy para Edge AI*.  NetApp y Modzy se han asociado para brindar IA a escala para cualquier tipo de datos, incluidas imágenes, audio, texto y tablas.  Modzy es una plataforma MLOps para implementar, integrar y ejecutar modelos de IA, que ofrece a los científicos de datos las capacidades de monitoreo de modelos, detección de desviaciones y explicabilidad, con una solución integrada para una inferencia LLM fluida.</block>
  <block id="50841f507614d3540c25e7671dc0cdc0" category="paragraph">*Run:AI* y NetApp se han asociado para demostrar las capacidades únicas de la solución NetApp ONTAP AI con la plataforma de gestión de clústeres Run:AI para simplificar la orquestación de cargas de trabajo de IA.  Divide y une automáticamente los recursos de la GPU, diseñado para escalar sus canales de procesamiento de datos a cientos de máquinas con marcos de integración integrados para Spark, Ray, Dask y Rapids.</block>
  <block id="7f8ef2f7d9a73eb64e35d815049ddd46" category="paragraph">La IA generativa solo puede producir resultados efectivos cuando el modelo se entrena con grandes cantidades de datos de calidad.  Si bien los LLM han alcanzado hitos notables, es fundamental reconocer sus limitaciones, los desafíos de diseño y los riesgos asociados con la movilidad y la calidad de los datos.  Los LLM se basan en conjuntos de datos de entrenamiento grandes y dispares provenientes de fuentes de datos heterogéneas.  Los resultados inexactos o sesgados generados por los modelos pueden poner en peligro tanto a las empresas como a los consumidores.  Estos riesgos pueden corresponder a limitaciones para los LLM que surgen potencialmente de los desafíos de gestión de datos asociados con la calidad de los datos, la seguridad de los datos y la movilidad de los datos.  NetApp ayuda a las organizaciones a afrontar las complejidades creadas por el rápido crecimiento de los datos, la movilidad de los datos, la gestión de múltiples nubes y la adopción de IA.  La infraestructura de IA a gran escala y la gestión eficiente de datos son cruciales para definir el éxito de las aplicaciones de IA como la IA generativa.  Es fundamental que los clientes cubran todos los escenarios de implementación sin comprometer la capacidad de expansión según lo necesiten las empresas y manteniendo al mismo tiempo la rentabilidad, la gobernanza de datos y las prácticas éticas de IA bajo control.  NetApp trabaja constantemente para ayudar a los clientes a simplificar y acelerar sus implementaciones de IA.</block>
  <block id="cea78864209b835e9b37cbe0a2cb862e" category="doc">NVA-1172-DISEÑO: NetApp AIPod con Lenovo para NVIDIA OVX</block>
  <block id="cd270e0e169361bb079873f1cb21e6b5" category="paragraph">Bobby Oommen, Abhinav Singh, Roney Daniel, NetApp</block>
  <block id="999a2bd7b329bd7fe4178352281b558b" category="paragraph">Esta arquitectura de referencia combina servidores Lenovo ThinkSystem OVX con certificación NVIDIA, potenciados por GPU NVIDIA L40S, con redes NVIDIA Spectrum para brindar una solución de infraestructura óptima para optimizar e implementar LLM (modelos de lenguaje grande).  El propósito de este documento es proporcionar orientación relacionada con el almacenamiento para una configuración OVX.  Esta plataforma es adecuada para diversas cargas de trabajo de IA generativa, incluidas RAG (recuperación, generación aumentada), ajuste fino y entrenamiento de modelos livianos.</block>
  <block id="688a655aa25fa96dbcd977348cc95acc" category="inline-link-macro">NVA-1172-DESIGN: Guía de diseño de NetApp AIPod con Lenovo para NVIDIA OVX</block>
  <block id="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="paragraph"><block ref="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="inline-link-macro-rx"></block></block>
  <block id="82b67ae3d50932b0d818b7c3a23b3428" category="summary">NetApp AIPod con sistemas NVIDIA DGX: arquitectura</block>
  <block id="92527686d5dc11342676e296e31b0b51" category="doc">NVA-1173 NetApp AIPod con sistemas NVIDIA DGX H100: Arquitectura de la solución</block>
  <block id="34fc6f8c7d10337be1b911dd98627e40" category="paragraph">Esta sección se centra en la arquitectura de los sistemas NetApp AIPod con NVIDIA DGX.</block>
  <block id="b10a3a95ab83cbad7acc457e6bc13a1b" category="section-title">NetApp AIPod con sistemas DGX</block>
  <block id="990e00b86cef2bb25d2e346df6e7adfe" category="paragraph">Esta arquitectura de referencia aprovecha estructuras separadas para la interconexión de clústeres de cómputo y el acceso al almacenamiento, con conectividad InfiniBand (IB) de 400 Gb/s entre nodos de cómputo.  El siguiente dibujo muestra la topología de la solución general de NetApp AIPod con sistemas DGX H100.</block>
  <block id="5d065d1080de5349462d7a342f622bf3" category="paragraph">_Topología de la solución AIpod de NetApp_</block>
  <block id="552dcf63ade7f6a706107c5da1f5a2a6" category="paragraph"><block ref="552dcf63ade7f6a706107c5da1f5a2a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">Diseño de red</block>
  <block id="57f55a30c80dbf621eb119c782a8b3c5" category="paragraph">En esta configuración, la estructura del clúster de cómputo utiliza un par de conmutadores IB QM9700 de 400 Gb/s, que están conectados entre sí para lograr una alta disponibilidad.  Cada sistema DGX H100 está conectado a los conmutadores mediante ocho conexiones, con los puertos pares conectados a un conmutador y los puertos impares conectados al otro conmutador.</block>
  <block id="8ee4ef799026973266981f7c555ea058" category="paragraph">Para el acceso al sistema de almacenamiento, la gestión en banda y el acceso del cliente, se utiliza un par de conmutadores Ethernet SN4600.  Los conmutadores están conectados con enlaces entre conmutadores y configurados con múltiples VLAN para aislar los distintos tipos de tráfico.  El enrutamiento L3 básico se habilita entre VLAN específicas para permitir múltiples rutas entre interfaces de cliente y almacenamiento en el mismo conmutador, así como entre conmutadores para lograr alta disponibilidad.  Para implementaciones más grandes, la red Ethernet se puede expandir a una configuración de hoja-columna agregando pares de conmutadores adicionales para conmutadores de columna y hojas adicionales según sea necesario.</block>
  <block id="082b01f67d64181611dc998408a2b121" category="inline-link-macro">detalles de implementación</block>
  <block id="41b55cdcb36636c126a5ef6c6e873a08" category="paragraph">Además de la interconexión computacional y las redes Ethernet de alta velocidad, todos los dispositivos físicos también están conectados a uno o más conmutadores Ethernet SN2201 para la administración fuera de banda.  Por favor vea el<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> página para obtener más información sobre la configuración de la red.</block>
  <block id="9eaf2c6f65cf6ad700b387972ddc345e" category="section-title">Descripción general del acceso al almacenamiento para los sistemas DGX H100</block>
  <block id="b1cdc2ac23891a1bf0e697359ffeeef6" category="paragraph">Cada sistema DGX H100 está equipado con dos adaptadores ConnectX-7 de doble puerto para el tráfico de gestión y almacenamiento, y para esta solución ambos puertos de cada tarjeta están conectados al mismo conmutador.  Luego, se configura un puerto de cada tarjeta en un enlace LACP MLAG con un puerto conectado a cada conmutador, y las VLAN para administración en banda, acceso de cliente y acceso de almacenamiento a nivel de usuario se alojan en este enlace.</block>
  <block id="891c72a31ed1199769c3f62cab11e7b4" category="paragraph">El otro puerto de cada tarjeta se utiliza para la conectividad con los sistemas de almacenamiento AFF A90 y se puede utilizar en varias configuraciones según los requisitos de carga de trabajo.  Para las configuraciones que utilizan NFS sobre RDMA para admitir NVIDIA Magnum IO GPUDirect Storage, los puertos se utilizan individualmente con direcciones IP en VLAN separadas.  Para las implementaciones que no requieren RDMA, las interfaces de almacenamiento también se pueden configurar con enlace LACP para brindar alta disponibilidad y ancho de banda adicional.  Con o sin RDMA, los clientes pueden montar el sistema de almacenamiento utilizando NFS v4.1 pNFS y troncalización de sesión para habilitar el acceso paralelo a todos los nodos de almacenamiento en el clúster.  Por favor vea el<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> página para obtener más información sobre la configuración del cliente.</block>
  <block id="c95998835114a4e50f348f8c5e5686ed" category="inline-link-macro">Documentación de NVIDIA BasePOD</block>
  <block id="8660b0a825d671d8855117ae496d3af6" category="paragraph">Para obtener más detalles sobre la conectividad del sistema DGX H100, consulte la<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .</block>
  <block id="42dc99c097c1b9b9af75ba060788e1f1" category="section-title">Diseño de sistemas de almacenamiento</block>
  <block id="61b2fad5f824784462363e1b366833fa" category="paragraph">Cada sistema de almacenamiento AFF A90 está conectado mediante seis puertos de 200 GbE desde cada controlador.  Se utilizan cuatro puertos de cada controlador para el acceso a los datos de carga de trabajo desde los sistemas DGX, y dos puertos de cada controlador se configuran como un grupo de interfaz LACP para admitir el acceso desde los servidores del plano de administración para los artefactos de administración del clúster y los directorios de inicio de los usuarios.  Todo el acceso a los datos del sistema de almacenamiento se proporciona a través de NFS, con una máquina virtual de almacenamiento (SVM) dedicada al acceso a la carga de trabajo de IA y una SVM separada dedicada a los usos de gestión del clúster.</block>
  <block id="6c9aef89eae0fd771909b15623e452df" category="paragraph">La SVM de administración solo requiere un único LIF, que está alojado en los grupos de interfaces de 2 puertos configurados en cada controlador.  Se aprovisionan otros volúmenes FlexGroup en el SVM de administración para albergar artefactos de administración del clúster, como imágenes de nodos del clúster, datos históricos de monitoreo del sistema y directorios de inicio del usuario final.  El dibujo a continuación muestra la configuración lógica del sistema de almacenamiento.</block>
  <block id="995db3e6bdfdd81bd5e1b6a98b33e5b7" category="paragraph">_Configuración lógica del clúster de almacenamiento NetApp A90_</block>
  <block id="1e7a613d4d1ae838806eb303b8f25492" category="paragraph"><block ref="1e7a613d4d1ae838806eb303b8f25492" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6420553f17ebdab39fa9a1825d57651" category="section-title">Servidores del plano de gestión</block>
  <block id="e6391a8600a62f5346ec27d437d43626" category="paragraph">Esta arquitectura de referencia también incluye cinco servidores basados en CPU para usos del plano de gestión.  Dos de estos sistemas se utilizan como nodos principales de NVIDIA Base Command Manager para la implementación y administración de clústeres.  Los otros tres sistemas se utilizan para proporcionar servicios de clúster adicionales, como nodos maestros de Kubernetes o nodos de inicio de sesión para implementaciones que utilizan Slurm para la programación de trabajos.  Las implementaciones que utilizan Kubernetes pueden aprovechar el controlador NetApp Trident CSI para proporcionar aprovisionamiento automatizado y servicios de datos con almacenamiento persistente para cargas de trabajo de administración e IA en el sistema de almacenamiento AFF A900 .</block>
  <block id="108f9bbf932c304dff7d03edbf186c18" category="paragraph">Cada servidor está conectado físicamente a los conmutadores IB y a los conmutadores Ethernet para permitir la implementación y la administración del clúster, y está configurado con montajes NFS en el sistema de almacenamiento a través del SVM de administración para el almacenamiento de artefactos de administración del clúster como se describió anteriormente.</block>
  <block id="19a97f58216292f6ce34aa1a3ad9e96e" category="summary">NetApp AIPod con sistemas NVIDIA DGX: dónde encontrar información adicional</block>
  <block id="43e1c1d93ec30f643ac7004cd6fafc47" category="doc">NVA-1173 NetApp AIPod con sistemas NVIDIA DGX: Conclusión e información adicional</block>
  <block id="7c3d91801a54614f755a9f2897ee42f3" category="paragraph">Esta sección incluye referencias para obtener información adicional sobre los sistemas NetApp AIPod con NVIDIA DGX.</block>
  <block id="bcde7144e6a13836183bd03e403987ef" category="paragraph">La arquitectura DGX BasePOD es una plataforma de aprendizaje profundo de próxima generación que requiere capacidades de almacenamiento y gestión de datos igualmente avanzadas.  Al combinar DGX BasePOD con los sistemas AFF de NetApp , la arquitectura de sistemas NetApp AIPod con DGX se puede implementar en casi cualquier escala.  Combinado con la integración superior en la nube y las capacidades definidas por software de NetApp ONTAP, AFF permite una gama completa de canales de datos que abarcan el borde, el núcleo y la nube para proyectos de DL exitosos.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="section-title">Información adicional</block>
  <block id="68e34599e7058d633da08de84c55032d" category="paragraph">Para obtener más información sobre la información descrita en este documento, consulte los siguientes documentos y/o sitios web:</block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">Software de gestión de datos NetApp ONTAP : biblioteca de información de ONTAP</block>
  <block id="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link"><block ref="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link-rx"></block></block>
  <block id="d99ede023f079413a479e349dcb54616" category="paragraph"><block ref="d99ede023f079413a479e349dcb54616" category="inline-link-rx"></block></block>
  <block id="b8667e5a766c0335e106bdd9b4ea825f" category="list-text">Sistemas de almacenamiento NetApp AFF A90</block>
  <block id="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link"><block ref="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link-rx"></block></block>
  <block id="22ef65e375f266c2889509f939e1ac83" category="paragraph"><block ref="22ef65e375f266c2889509f939e1ac83" category="inline-link-rx"></block></block>
  <block id="29b91fda4bb7baae0176d0ca5870634a" category="list-text">Información de NetApp ONTAP RDMA</block>
  <block id="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-macro"><block ref="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-rx"></block></block>
  <block id="c08c09703d9322a16ef4a93b82ff897e" category="paragraph"><block ref="c08c09703d9322a16ef4a93b82ff897e" category="inline-link-macro-rx"></block></block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="list-text">Trident de NetApp</block>
  <block id="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="paragraph"><block ref="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="inline-link-macro-rx"></block></block>
  <block id="4613e07c94020e7ba8189d048f9d61c1" category="list-text">Blog de almacenamiento GPUDirect de NetApp</block>
  <block id="cf8832fa60205a911c1036fb274f649e" category="inline-link"><block ref="cf8832fa60205a911c1036fb274f649e" category="inline-link-rx"></block></block>
  <block id="0f1f9907ba0a6f040f1fa28d77e74fb8" category="paragraph"><block ref="0f1f9907ba0a6f040f1fa28d77e74fb8" category="inline-link-rx"></block></block>
  <block id="64dc43320ec1a44c390fafb5e2408f4b" category="list-text">NVIDIA DGX BasePOD</block>
  <block id="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link"><block ref="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link-rx"></block></block>
  <block id="0c2cd58ffa7f091c420ae61854a0a8db" category="paragraph"><block ref="0c2cd58ffa7f091c420ae61854a0a8db" category="inline-link-rx"></block></block>
  <block id="e3d6e4bdd7281f2c5d652f6f01825970" category="list-text">Sistemas NVIDIA DGX H100</block>
  <block id="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link"><block ref="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link-rx"></block></block>
  <block id="f4e11a54d0110771220fa05425235763" category="paragraph"><block ref="f4e11a54d0110771220fa05425235763" category="inline-link-rx"></block></block>
  <block id="d90238071267e4279a25de2c6945b227" category="list-text">Redes NVIDIA</block>
  <block id="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link"><block ref="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link-rx"></block></block>
  <block id="a19d7568aa9c7e4c1f3bf3e831367115" category="paragraph"><block ref="a19d7568aa9c7e4c1f3bf3e831367115" category="inline-link-rx"></block></block>
  <block id="a96fecd8b3666b7b60c0bc0a24db79b2" category="list-text">Almacenamiento NVIDIA Magnum IO™ GPUDirect™</block>
  <block id="74079d06fd0015403a15f89699e6bcba" category="inline-link"><block ref="74079d06fd0015403a15f89699e6bcba" category="inline-link-rx"></block></block>
  <block id="110c88150ddcbc728071b2fcd7848bd2" category="paragraph"><block ref="110c88150ddcbc728071b2fcd7848bd2" category="inline-link-rx"></block></block>
  <block id="c7bef72157cc39b6eb7c391a393a20d2" category="list-text">Comando base de NVIDIA</block>
  <block id="bbae10fb46fb1d3604fe601d556f4187" category="inline-link"><block ref="bbae10fb46fb1d3604fe601d556f4187" category="inline-link-rx"></block></block>
  <block id="936c47b696a994feb0ad33a2addb1168" category="paragraph"><block ref="936c47b696a994feb0ad33a2addb1168" category="inline-link-rx"></block></block>
  <block id="b4675c30af15f661c8112c2853f97970" category="list-text">Administrador de comandos base de NVIDIA</block>
  <block id="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link"><block ref="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link-rx"></block></block>
  <block id="6b36fdb81918af4b96afe2ba587a8ae1" category="paragraph"><block ref="6b36fdb81918af4b96afe2ba587a8ae1" category="inline-link-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="list-text">NVIDIA AI Enterprise</block>
  <block id="42c9b161f86365b647172182503d9520" category="inline-link"><block ref="42c9b161f86365b647172182503d9520" category="inline-link-rx"></block></block>
  <block id="f5802e2c53799babc0ac27f6cb392604" category="paragraph"><block ref="f5802e2c53799babc0ac27f6cb392604" category="inline-link-rx"></block></block>
  <block id="9132ee4ebfc1bcccf9be22b87e818413" category="paragraph">Este documento es el trabajo de los equipos de ingeniería de NetApp Solutions y ONTAP : David Arnette, Olga Kornievskaia, Dustin Fischer, Srikanth Kaligotla, Mohit Kumar y Raghuram Sudhaakar.  Los autores también desean agradecer a NVIDIA y al equipo de ingeniería de NVIDIA DGX BasePOD por su continuo apoyo.</block>
  <block id="7c4d674fe3a4532c3ffe553151378a3f" category="summary">NetApp AIPod con sistemas NVIDIA DGX: implementación</block>
  <block id="302db59f0ad2458d76aedcc8a6fdd7be" category="doc">NVA-1173 NetApp AIPod con sistemas NVIDIA DGX: detalles de la implementación</block>
  <block id="c584dd3e1383c7899a434fb7b8e1a341" category="paragraph">Esta sección describe los detalles de implementación utilizados durante la validación de esta solución.  Las direcciones IP utilizadas son ejemplos y deben modificarse según el entorno de implementación.  Para obtener más información sobre los comandos específicos utilizados en la implementación de esta configuración, consulte la documentación del producto correspondiente.</block>
  <block id="b5f0a1ca7b5559b93159bcc11b7b99e9" category="paragraph">El diagrama a continuación muestra información detallada de red y conectividad para 1 sistema DGX H100 y 1 par HA de controladores AFF A90 .  La guía de implementación en las siguientes secciones se basa en los detalles de este diagrama.</block>
  <block id="a1ce9904a2cc7e8a6e1267980553c732" category="paragraph">Configuración de red de NetApp AIpod</block>
  <block id="c4e9bce0ddaf289da0094c0a0560c136" category="paragraph"><block ref="c4e9bce0ddaf289da0094c0a0560c136" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea12591fa7a8663c28086764fc393d35" category="paragraph">La siguiente tabla muestra ejemplos de asignaciones de cableado para hasta 16 sistemas DGX y 2 pares AFF A90 HA.</block>
  <block id="4919e7d6c7a8481619e206520f937aaf" category="cell">Conmutador y puerto</block>
  <block id="e0ac20adce6ffee48c7151b070aa5737" category="cell">Dispositivo</block>
  <block id="e85450f6454a8b84aa3dd8ab4cfe658c" category="cell">Puerto del dispositivo</block>
  <block id="bdbd5451b62f5c0739cd0300b29d0db1" category="cell">puertos 1-16 del switch1</block>
  <block id="b6bf51e15f6d9d931c3ef52dcf7c2e74" category="cell">DGX-H100-01 a -16</block>
  <block id="4d866d6d7dc3628895dbedb26f1bdf96" category="cell">enp170s0f0np0, ranura 1 puerto 1</block>
  <block id="6438dabe67e09d4e0ec2e3d17d7074f9" category="cell">puertos 17-32 del switch1</block>
  <block id="744d517d131df3b9ae1b4bdbdf70b282" category="cell">enp170s0f1np1, ranura 1, puerto 2</block>
  <block id="2914cd4a87277c08ac1f71cafd311de5" category="cell">puertos 33-36 del switch1</block>
  <block id="b08a34f62ae5d3df1c59356cb996a50a" category="cell">AFF-A90-01 a -04</block>
  <block id="3d163afca230cdca293d07b9bce1004f" category="cell">puerto e6a</block>
  <block id="09a5a99bfdac461078765cf577fa36c1" category="cell">puertos 37-40 del switch1</block>
  <block id="67d1565f0da7861ffc787acf0cc159af" category="cell">puerto e11a</block>
  <block id="d350694943ec1acbb17fb85d69fd2aa9" category="cell">puertos 41-44 del switch1</block>
  <block id="44b26214a7c3f5ffe5ec1db0aa3e4f98" category="cell">puerto e2a</block>
  <block id="9e444fba13b3dd8f65bd7deb1b742747" category="cell">puertos 57-64 del switch1</block>
  <block id="7a744922ca20208077a50d69271d15fd" category="cell">ISL a switch2</block>
  <block id="68813ae3b3a11b5b786ffe4305c5d542" category="cell">puertos 57-64</block>
  <block id="9b878f628cccd99408682b50785b3598" category="cell">puertos 1-16 del switch2</block>
  <block id="3cdeea9afe6ab2952bd32f14b371d0c3" category="cell">enp41s0f0np0, ranura 2 puerto 1</block>
  <block id="6a11ad764d8b60d242c533b565b99142" category="cell">puertos 17-32 del switch2</block>
  <block id="e26d3524de049d551125c01b1d65729e" category="cell">enp41s0f1np1, ranura 2 puerto 2</block>
  <block id="59ba8265a302f2fb97997075c8f27f6d" category="cell">puertos 33-36 del switch2</block>
  <block id="9df3af84859046bac07e13013fce0466" category="cell">puerto e6b</block>
  <block id="d9a9acdd71cb92eb03299a9702a84577" category="cell">puertos 37-40 del switch2</block>
  <block id="0b9b24c59934606f5e10f1c15b3a86cb" category="cell">puerto e11b</block>
  <block id="2f4b59b7b40dec7ee6362e6017960380" category="cell">puertos 41-44 del switch2</block>
  <block id="2c635d05e781d03137efe254ee8f86a1" category="cell">puerto e2b</block>
  <block id="67a367a7d31cdd640df71104820055c4" category="cell">puertos 57-64 del switch2</block>
  <block id="ed38d5a59568aa5dd0a40c94574cf056" category="cell">ISL para cambiar 1</block>
  <block id="c470336f17afce51494a7db95c91de92" category="paragraph">La siguiente tabla muestra las versiones de software de los distintos componentes utilizados en esta validación.</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">Versión del software</block>
  <block id="b1c079bf2940033fab8f8dffbf4a5ff2" category="cell">Conmutadores NVIDIA SN4600</block>
  <block id="90db213df8a0c782abe8388881fce336" category="cell">Cumulus Linux v5.9.1</block>
  <block id="18cf8e6ece8a122dba390f844981b900" category="cell">Sistema NVIDIA DGX</block>
  <block id="cfba00e4a4b4df8f6a7ebf83cfd81c4c" category="cell">Sistema operativo DGX v6.2.1 (Ubuntu 22.04 LTS)</block>
  <block id="857ecbf3846b57d505e2a1b49da67f65" category="cell">Mellanox OFED</block>
  <block id="38aa87e1c845f13e459d6a71f7049cac" category="cell">24,01</block>
  <block id="3eb4233634d4c27ee1a1ddf72619b98d" category="cell">NetApp AFF A90</block>
  <block id="6944cefb93932417ed3a50959c66a9c5" category="cell">NetApp ONTAP 9.14.1</block>
  <block id="93fb68f81a2ad999b6aae02d586c4ef4" category="section-title">Configuración de la red de almacenamiento</block>
  <block id="84814a12bbb8397e0a8f1357446c94e5" category="inline-link-macro">Documentación de NVIDIA Cumulus Linux</block>
  <block id="5d27fc003227b21f0392098a85eb18c2" category="paragraph">Esta sección describe detalles clave para la configuración de la red de almacenamiento Ethernet.  Para obtener información sobre cómo configurar la red informática InfiniBand, consulte la<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .  Para obtener más detalles sobre la configuración del conmutador, consulte la<block ref="5e4d481e02111d80d9871bbc3802a082" category="inline-link-macro-rx"></block> .</block>
  <block id="57719be20908b73e68d37637555b97d6" category="paragraph">A continuación se describen los pasos básicos utilizados para configurar los conmutadores SN4600.  Este proceso supone que el cableado y la configuración básica del conmutador (administración de direcciones IP, licencias, etc.) están completos.</block>
  <block id="e55cea47183e18fc2e2e86a5dcee8ec7" category="list-text">Configurar el enlace ISL entre los conmutadores para habilitar la agregación de múltiples enlaces (MLAG) y el tráfico de conmutación por error</block>
  <block id="72a998485758ede34cc727692eda3bd2" category="list-text">Esta validación utilizó 8 enlaces para proporcionar un ancho de banda más que suficiente para la configuración de almacenamiento bajo prueba.</block>
  <block id="3051c0af523b2627a57ce2bf1e587655" category="list-text">Para obtener instrucciones específicas sobre cómo habilitar MLAG, consulte la documentación de Cumulus Linux.</block>
  <block id="8ae9a0f6054b5fb4a974e1f0d735ff8d" category="list-text">Configurar LACP MLAG para cada par de puertos de cliente y puertos de almacenamiento en ambos conmutadores</block>
  <block id="3c81bce81a92df032d58d66eb88265b0" category="list-text">puerto swp17 en cada conmutador para DGX-H100-01 (enp170s0f1np1 y enp41s0f1np1), puerto swp18 para DGX-H100-02, etc. (bond1-16)</block>
  <block id="563a9dfd999aa71e1b86c22188243c2b" category="list-text">puerto swp41 en cada conmutador para AFF-A90-01 (e2a y e2b), puerto swp42 para AFF-A90-02, etc. (bond17-20)</block>
  <block id="44f6b0b1ffb3c7d26ff370ef2db934bb" category="list-text">nv establece interfaz bondX miembro de enlace swpX</block>
  <block id="e88a9fc1fac9e835ce4f94863fa6c017" category="list-text">nv establecer interfaz bondx enlace mlag id X</block>
  <block id="53e5d1cb8672703c6d9c6468088afa1a" category="list-text">Agregue todos los puertos y enlaces MLAG al dominio de puente predeterminado</block>
  <block id="e196c3365de079c5ab9127511e0dd99c" category="list-text">nv set int swp1-16,33-40 dominio de puente br_default</block>
  <block id="807ec963a7ac91bb05d484cf2aedb28c" category="list-text">nv set int bond1-20 dominio de puente br_default</block>
  <block id="812bc6c1e22132212f3bd611d2be624b" category="list-text">Habilitar RoCE en cada conmutador</block>
  <block id="5b474542c656a524ee80214d547f357f" category="list-text">nv establece el modo roce sin pérdida</block>
  <block id="e1ddeeabdb3c578a39e7f7457c83adcb" category="list-text">Configurar VLAN: 2 para puertos de cliente, 2 para puertos de almacenamiento, 1 para administración, 1 para conmutador L3 a conmutador</block>
  <block id="e8c935d4b4d1ac2ba8e60a311d4dd3e3" category="list-text">interruptor 1-</block>
  <block id="d0dbd46c5b3822649194130f76e47a74" category="list-text">VLAN 3 para enrutamiento de conmutador L3 a conmutador en caso de falla de la NIC del cliente</block>
  <block id="4d0ddcd703c2db59dd2b93a0864f348e" category="list-text">VLAN 101 para el puerto de almacenamiento 1 en cada sistema DGX (enp170s0f0np0, ranura 1, puerto 1)</block>
  <block id="988d3fe9d9a9c24bdfaf0d1e8c04c718" category="list-text">VLAN 102 para el puerto e6a y e11a en cada controlador de almacenamiento AFF A90</block>
  <block id="8534bf29bf68cf0b3a4ef8fc1c8367ef" category="list-text">VLAN 301 para la gestión mediante las interfaces MLAG para cada sistema DGX y controlador de almacenamiento</block>
  <block id="decdf257b13a488f92fa3c1f3c758e26" category="list-text">interruptor 2-</block>
  <block id="9d406d38f0c9d262294560c3ffe601e6" category="list-text">VLAN 201 para el puerto de almacenamiento 2 en cada sistema DGX (enp41s0f0np0, ranura 2, puerto 1)</block>
  <block id="ad80d15b1164d5cda913549da61e6aa3" category="list-text">VLAN 202 para los puertos e6b y e11b en cada controlador de almacenamiento AFF A90</block>
  <block id="09417c9a09b9c4ceb39f1b21b0c805ce" category="list-text">Asigne puertos físicos a cada VLAN según corresponda, por ejemplo, puertos de cliente en VLAN de cliente y puertos de almacenamiento en VLAN de almacenamiento</block>
  <block id="30add6fef18e27847f71d245bce4adf2" category="list-text">nv set int &lt;swpX&gt; dominio de puente br_default acceso &lt;id de VLAN&gt;</block>
  <block id="8c088863d87c4744d16775f50bd22826" category="list-text">Los puertos MLAG deben permanecer como puertos troncales para habilitar múltiples VLAN a través de las interfaces vinculadas según sea necesario.</block>
  <block id="dc7dbdf7949b0253d64542d3a6648b53" category="list-text">Configurar interfaces virtuales de conmutador (SVI) en cada VLAN para que actúen como puerta de enlace y habilitar el enrutamiento L3</block>
  <block id="bbc11fb8434953cf5f8a56090594c94e" category="list-text">nv set int vlan3 dirección IP 100.127.0.0/31</block>
  <block id="56a4338a8bbb720e395dea767276043e" category="list-text">nv set int vlan101 dirección IP 100.127.101.1/24</block>
  <block id="c88e27e83683371775c79ed4db025a42" category="list-text">nv set int vlan102 dirección IP 100.127.102.1/24</block>
  <block id="c8e18763efa8332ade09b61ec6c43e79" category="list-text">nv set int vlan3 dirección IP 100.127.0.1/31</block>
  <block id="d39015045c0b670844a63ea89a0558e1" category="list-text">nv set int vlan201 dirección IP 100.127.201.1/24</block>
  <block id="72caedfc84ea977b468f72cc81db5b0f" category="list-text">nv set int vlan202 dirección IP 100.127.202.1/24</block>
  <block id="4d86d7ad33785bddc3f3227d7cfe8c00" category="list-text">Crear rutas estáticas</block>
  <block id="957e71bdd90bad3e445176749a6e839a" category="list-text">Las rutas estáticas se crean automáticamente para las subredes en el mismo conmutador</block>
  <block id="ba77f5caf647fd0155f2edd382f4c005" category="list-text">Se requieren rutas estáticas adicionales para el enrutamiento de conmutador a conmutador en caso de una falla en el enlace del cliente</block>
  <block id="cb6543cc4fa221dc0cadbcce30a3d708" category="list-text">nv establece vrf enrutador predeterminado estático 100.127.128.0/17 a través de 100.127.0.1</block>
  <block id="3616a5e3448d387e297a217363fcd491" category="list-text">nv establece vrf enrutador predeterminado estático 100.127.0.0/17 a través de 100.127.0.0</block>
  <block id="2139fe384d5ae165545994dff01961d9" category="section-title">Configuración del sistema de almacenamiento</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">Documentación de ONTAP</block>
  <block id="6c077f840844078f56944a0699577ff6" category="paragraph">Esta sección describe detalles clave para la configuración del sistema de almacenamiento A90 para esta solución.  Para obtener más detalles sobre la configuración de los sistemas ONTAP , consulte la<block ref="c9be69f343f12523b36264fad0c62551" category="inline-link-macro-rx"></block> .  El siguiente diagrama muestra la configuración lógica del sistema de almacenamiento.</block>
  <block id="a2720bc0a2d05de970087a0c7fad9311" category="paragraph">A continuación se describen los pasos básicos utilizados para configurar el sistema de almacenamiento.  Este proceso supone que se ha completado la instalación básica del clúster de almacenamiento.</block>
  <block id="a65ed1368170b15ddddd6ee0b2408084" category="list-text">Configurar 1 agregado en cada controlador con todas las particiones disponibles menos 1 de repuesto</block>
  <block id="104afbbbf990a88bdaee0bb7222c4b8e" category="list-text">aggr crear -nodo &lt;nodo&gt; -agregado &lt;nodo&gt;_data01 -diskcount &lt;47&gt;</block>
  <block id="40531cd604f58d3ba347b865243c7e48" category="list-text">Configurar ifgrps en cada controlador</block>
  <block id="f72dfa57e15677b92e70b5a144e0b5f9" category="list-text">net port ifgrp create -node &lt;nodo&gt; -ifgrp a1a -mode multimode_lacp -distr-function port</block>
  <block id="55be7178bd14f4153f1b019457ede4a9" category="list-text">puerto de red ifgrp add-port -node &lt;nodo&gt; -ifgrp &lt;ifgrp&gt; -ports &lt;nodo&gt;:e2a,&lt;nodo&gt;:e2b</block>
  <block id="b13faeadb39006cbcc1d3c2e50344bf1" category="list-text">Configurar el puerto VLAN de administración en ifgrp en cada controlador</block>
  <block id="e6e28ccd055fb443d6dd14a9a6eb7d1a" category="list-text">puerto de red vlan crear -nodo aff-a90-01 -puerto a1a -vlan-id 31</block>
  <block id="f740c9ebcb9caacb0b5d819655c488ed" category="list-text">puerto de red vlan crear -nodo aff-a90-02 -puerto a1a -vlan-id 31</block>
  <block id="5d71abf584a26ed36de342533bc6b11f" category="list-text">puerto de red vlan crear -nodo aff-a90-03 -puerto a1a -vlan-id 31</block>
  <block id="21e3a0fbbbf79005355b371bbcdd44e6" category="list-text">puerto de red vlan crear -nodo aff-a90-04 -puerto a1a -vlan-id 31</block>
  <block id="cd002818e71e3e15ea7d845a92b82053" category="list-text">Crear dominios de difusión</block>
  <block id="060c8e724635c9585153496e36c5fe64" category="list-text">dominio de difusión crear -dominio de difusión vlan21 -mtu 9000 -puertos aff-a90-01:e6a,aff-a90-01:e11a,aff-a90-02:e6a,aff-a90-02:e11a,aff-a90-03:e6a,aff-a90-03:e11a,aff-a90-04:e6a,aff-a90-04:e11a</block>
  <block id="f0375c78fd286627e0ea2e893298127b" category="list-text">dominio de difusión crear -dominio de difusión vlan22 -mtu 9000 -puertos aaff-a90-01:e6b,aff-a90-01:e11b,aff-a90-02:e6b,aff-a90-02:e11b,aff-a90-03:e6b,aff-a90-03:e11b,aff-a90-04:e6b,aff-a90-04:e11b</block>
  <block id="46bd5a85171233df8aad89e1ea34eca2" category="list-text">dominio de difusión crear -dominio de difusión vlan31 -mtu 9000 -puertos aff-a90-01:a1a-31,aff-a90-02:a1a-31,aff-a90-03:a1a-31,aff-a90-04:a1a-31</block>
  <block id="623ea6b05fb05729ffd64b3aecd6e969" category="list-text">Crear SVM de gestión *</block>
  <block id="5619023db11b9124790191d573fd6c9a" category="list-text">Configurar la gestión SVM</block>
  <block id="a085de8c20c0316efb0b620d42f96f5d" category="list-text">crear LIF</block>
  <block id="f2a8aff28094374e836aba88837e4ecd" category="list-text">net int create -vserver basepod-mgmt -lif vlan31-01 -nodo-local aff-a90-01 -puerto-local a1a-31 -dirección 192.168.31.X -máscara-de-red 255.255.255.0</block>
  <block id="025643e2f4f3d8255f6a74703e817f10" category="list-text">crear volúmenes FlexGroup</block>
  <block id="ff251de7d10dfd4d224adb00c9771d80" category="list-text">vol create -vserver basepod-mgmt -volume home -size 10T -auto-provision-as flexgroup -junction-path /home</block>
  <block id="7eadd281ac9fa05f29dd10931c800b73" category="list-text">vol create -vserver basepod-mgmt -volume cm -size 10T -auto-provision-as flexgroup -junction-path /cm</block>
  <block id="4daa96de5bcd998457adea84b3b0d3f2" category="list-text">crear una política de exportación</block>
  <block id="0224cbf10aded53062d1c33a00ed3f00" category="list-text">regla de política de exportación crear -vserver basepod-mgmt -policy predeterminado -client-match 192.168.31.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="d5c522a3ee4c4fb65fcbe94d031d0a08" category="list-text">Crear datos SVM *</block>
  <block id="6310e0b69ca3cd6447bec629307180b7" category="list-text">Configurar datos SVM</block>
  <block id="8aa04063c0eff21564b4943f7c5bd0af" category="list-text">Configurar SVM para compatibilidad con RDMA</block>
  <block id="f67ee8861066661a87085502a485f642" category="list-text">vserver nfs modificar -vserver basepod-data -rdma habilitado</block>
  <block id="f29cc71670e3362a894e54ea9924917c" category="list-text">crear LIF</block>
  <block id="3df4cfdffe24b83cba807ded784fb107" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif1 -nodo-local aff-a90-01 -puerto-local e6a -dirección 100.127.102.101 -máscara-de-red 255.255.255.0</block>
  <block id="26a6d29a1530006b710e49ad940bc64a" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif2 -nodo-local aff-a90-01 -puerto-local e6a -dirección 100.127.102.102 -máscara-de-red 255.255.255.0</block>
  <block id="985d0d4d212dc0238d9f101fee0a3418" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif1 -nodo-local aff-a90-01 -puerto-local e6b -dirección 100.127.202.101 -máscara-de-red 255.255.255.0</block>
  <block id="07f93d0815d9e298cb8b02049c677706" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif2 -nodo-local aff-a90-01 -puerto-local e6b -dirección 100.127.202.102 -máscara-de-red 255.255.255.0</block>
  <block id="2d977106413211171eefeeb51af2bdf7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif1 -nodo-local aff-a90-01 -puerto-local e11a -dirección 100.127.102.103 -máscara-de-red 255.255.255.0</block>
  <block id="10d75b950d2d9634a2804a1ed92f0df7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif2 -nodo-local aff-a90-01 -puerto-local e11a -dirección 100.127.102.104 -máscara-de-red 255.255.255.0</block>
  <block id="7e3ec60a178738ba9ac6680a6bf6340d" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif1 -nodo-local aff-a90-01 -puerto-local e11b -dirección 100.127.202.103 -máscara-de-red 255.255.255.0</block>
  <block id="b14efeaf4c17d63f2e6011dc35f5722c" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif2 -nodo-local aff-a90-01 -puerto-local e11b -dirección 100.127.202.104 -máscara-de-red 255.255.255.0</block>
  <block id="74c24c93e98c023e9fe31988005f6735" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif1 -nodo-local aff-a90-02 -puerto-local e6a -dirección 100.127.102.105 -máscara-de-red 255.255.255.0</block>
  <block id="d00b578414c1bb9f219c72ef1262d701" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif2 -nodo-local aff-a90-02 -puerto-local e6a -dirección 100.127.102.106 -máscara-de-red 255.255.255.0</block>
  <block id="c49b52997695ebd048410b0b8f9f19f2" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif1 -nodo-local aff-a90-02 -puerto-local e6b -dirección 100.127.202.105 -máscara-de-red 255.255.255.0</block>
  <block id="912c10c91d670dee279852756245a063" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif2 -nodo-local aff-a90-02 -puerto-local e6b -dirección 100.127.202.106 -máscara-de-red 255.255.255.0</block>
  <block id="031724ef6867c2ff3771e70c8520b1d0" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif1 -nodo-local aff-a90-02 -puerto-local e11a -dirección 100.127.102.107 -máscara-de-red 255.255.255.0</block>
  <block id="8b417c98283cde9dc265541e2455e2f5" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif2 -nodo-local aff-a90-02 -puerto-local e11a -dirección 100.127.102.108 -máscara-de-red 255.255.255.0</block>
  <block id="f129b43cd7a26c7049c4340ac4ef86e1" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif1 -nodo-local aff-a90-02 -puerto-local e11b -dirección 100.127.202.107 -máscara-de-red 255.255.255.0</block>
  <block id="5a6d6f4dbbb1d6f8f5558b1c36f5e671" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif2 -nodo-local aff-a90-02 -puerto-local e11b -dirección 100.127.202.108 -máscara-de-red 255.255.255.0</block>
  <block id="057f5c63653dacba830db83ad6ad78ee" category="list-text">Configurar LIF para el acceso RDMA</block>
  <block id="ea7a0f026442b56683f1e50cb21a0d06" category="list-text">Para las implementaciones con ONTAP 9.15.1, la configuración de QoS de RoCE para la información física requiere comandos de nivel de sistema operativo que no están disponibles en la CLI de ONTAP .  Comuníquese con el soporte de NetApp para obtener ayuda con la configuración de puertos para compatibilidad con RoCE.  NFS sobre RDMA funciona sin problemas</block>
  <block id="2e94a4ea05164067f4cb6f27639c8b7a" category="list-text">A partir de ONTAP 9.16.1, las interfaces físicas se configurarán automáticamente con las configuraciones adecuadas para el soporte de RoCE de extremo a extremo.</block>
  <block id="95f5fd496607048d9a2d17c6c6577aa2" category="list-text">net int modificar -vserver basepod-data -lif * -rdma-protocols roce</block>
  <block id="29789a25d415e0f3b5d8cef38626fadc" category="list-text">Configurar parámetros NFS en el SVM de datos</block>
  <block id="37013073e580c7f2ed500849958f49cd" category="list-text">nfs modificar -vserver basepod-data -v4.1 habilitado -v4.1-pnfs habilitado -v4.1-trunking habilitado -tcp-max-transfer-size 262144</block>
  <block id="8f7c2b974d2b68275b99738f2db92da7" category="list-text">Crear volúmenes FlexGroup</block>
  <block id="375a2038f90b0da452502ee281313fdd" category="list-text">vol create -vserver basepod-data -volume data -size 100T -auto-provision-as flexgroup -junction-path /data</block>
  <block id="48e79d83943623a53289accfc05a7108" category="list-text">Crear una política de exportación</block>
  <block id="f36c67518ab2b84b8b81ef59c8d30976" category="list-text">regla de política de exportación crear -vserver basepod-data -policy predeterminado -client-match 100.127.101.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="738b25d5c96222859fa0d9f34e585e1d" category="list-text">regla de política de exportación crear -vserver basepod-data -policy predeterminado -client-match 100.127.201.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="14f424e270715fb6e8bf7277cb075650" category="list-text">crear rutas</block>
  <block id="086c700f168ee8ad618b80e189d3ab75" category="list-text">ruta agregar -vserver basepod_data -destino 100.127.0.0/17 -puerta de enlace 100.127.102.1 métrica 20</block>
  <block id="e6bf4bcbe9f12d429928fe014e660008" category="list-text">ruta agregar -vserver basepod_data -destino 100.127.0.0/17 -puerta de enlace 100.127.202.1 métrica 30</block>
  <block id="35dc59e7fce425d44a0f407fcd227c43" category="list-text">ruta agregar -vserver basepod_data -destino 100.127.128.0/17 -puerta de enlace 100.127.202.1 métrica 20</block>
  <block id="50a387548848ab61afe342aa18b992c7" category="list-text">ruta agregar -vserver basepod_data -destino 100.127.128.0/17 -puerta de enlace 100.127.102.1 métrica 30</block>
  <block id="dc8a99ae9ee0b79d432c8eac1124edb5" category="section-title">Configuración de DGX H100 para acceso al almacenamiento RoCE</block>
  <block id="206274d0712987318a4f897f7e6ae75c" category="inline-link-macro">Documentación de BCM</block>
  <block id="0448e5984ca30c8aeeb162534801fe92" category="paragraph">Esta sección describe detalles clave para la configuración de los sistemas DGX H100.  Muchos de estos elementos de configuración pueden incluirse en la imagen del sistema operativo implementada en los sistemas DGX o implementarse mediante Base Command Manager en el momento del arranque.  Se enumeran aquí como referencia; para obtener más información sobre la configuración de nodos e imágenes de software en BCM, consulte la<block ref="21b53d84e45529faee31545df8020d3b" category="inline-link-macro-rx"></block> .</block>
  <block id="12211cca460b22741ca0d08e3f60fb0c" category="list-text">Instalar paquetes adicionales</block>
  <block id="0df162aa5e7703fc2c2a77a7d1d5a1fe" category="list-text">herramienta ipmi</block>
  <block id="e08cb560fa0fac340ce6e958daaf5e4d" category="list-text">python3-pip</block>
  <block id="8cd5d0cdb86cde9f0dc88352811817ec" category="list-text">Instalar paquetes de Python</block>
  <block id="32760a760ea625ddb856e92f3b089802" category="list-text">paramiko</block>
  <block id="f02113237a5a5fff03e34c9eeeb46640" category="list-text">matplotlib</block>
  <block id="9b162ba267ba83b0a5f5cb6cdbe972dd" category="list-text">Reconfigurar dpkg después de la instalación del paquete</block>
  <block id="a8bc68a93f8c901b4a33e27af2f21da0" category="list-text">dpkg --configure -a</block>
  <block id="0243e3d81be4d79f622d517c103c3ae0" category="list-text">Instalar MOFED</block>
  <block id="08c24ffe86544b752cd2764895595237" category="list-text">Establecer valores mst para optimizar el rendimiento</block>
  <block id="d5bedef65a3750cb3c0a2b86f80a11e4" category="list-text">mstconfig -y -d &lt;aa:00.0,29:00.0&gt; establecer CONFIGURACIÓN_PCI_AVANZADA=1 NÚMERO_DE_VFS=0 LECTURA_MÁXIMA_ACC_SALIDA=44</block>
  <block id="bdacbd6c214d3cc42e1d1f8305ef92c9" category="list-text">Restablecer los adaptadores después de modificar la configuración</block>
  <block id="9af48ffdb9436775e220fda80ded47ad" category="list-text">mlxfwreset -d &lt;aa:00.0,29:00.0&gt; -y restablecer</block>
  <block id="c7cb0d4934d36b9bb0816b3a5c49f0b1" category="list-text">Establecer MaxReadReq en dispositivos PCI</block>
  <block id="1a252b6a7629ccb0f15527f8ca5f627c" category="list-text">setpci -s &lt;aa:00.0,29:00.0&gt; 68.W=5957</block>
  <block id="29aaf92306610006fe7ce7d8c90411ca" category="list-text">Establecer el tamaño del búfer de anillo RX y TX</block>
  <block id="3d789bdc86cf1d51f9b23d11b808ddd5" category="list-text">ethtool -G &lt;enp170s0f0np0,enp41s0f0np0&gt; rx 8192 tx 8192</block>
  <block id="a0340fb71fb195f79ce47dabe6242f8e" category="list-text">Establezca PFC y DSCP mediante mlnx_qos</block>
  <block id="6537005ab5e42cbee146ce9b17d892d8" category="list-text">mlnx_qos -i &lt;enp170s0f0np0,enp41s0f0np0&gt; --pfc 0,0,0,1,0,0,0,0 --trust=dscp --cable_len=3</block>
  <block id="a277efb29c974f8ae6d1925383335b05" category="list-text">Establecer ToS para el tráfico RoCE en los puertos de red</block>
  <block id="8c1e8c1481d777723e305f147f16012d" category="list-text">echo 106 &gt; /sys/class/infiniband/&lt;mlx5_7,mlx5_1&gt;/tc/1/traffic_class</block>
  <block id="05dae9ad2cfb95dc1f78bc696aa0d6a4" category="list-text">Configure cada NIC de almacenamiento con una dirección IP en la subred adecuada</block>
  <block id="fa2bddc64b24b8cd13f0be734ce934ca" category="list-text">100.127.101.0/24 para almacenamiento NIC 1</block>
  <block id="945382c87aa13867b8b36da66c8ae8fc" category="list-text">100.127.201.0/24 para almacenamiento NIC 2</block>
  <block id="ed769c091c9112ad2d1a5c89de5c0c65" category="list-text">Configurar puertos de red en banda para la conexión LACP (enp170s0f1np1,enp41s0f1np1)</block>
  <block id="af487da74a6eeea9aa52d90c5c8cd04d" category="list-text">Configurar rutas estáticas para rutas primarias y secundarias a cada subred de almacenamiento</block>
  <block id="593c13037333a6722527c42d1d0b156c" category="list-text">ruta add –net 100.127.0.0/17 gw 100.127.101.1 métrica 20</block>
  <block id="8656e83d4d88a713f09d848f3cc09702" category="list-text">ruta add –net 100.127.0.0/17 gw 100.127.201.1 métrica 30</block>
  <block id="85f6d08b3d54f8d8785ef6f36f7c61c3" category="list-text">ruta add –net 100.127.128.0/17 gw 100.127.201.1 métrica 20</block>
  <block id="d70120de1b67fd20affa2557aca990ef" category="list-text">ruta add –net 100.127.128.0/17 gw 100.127.101.1 métrica 30</block>
  <block id="7fc2f78e0bd34dcefec071f2a70514c2" category="list-text">Volumen de montaje/inicio</block>
  <block id="9ff7402ee00f4969ccc4395a7241c47c" category="list-text">montaje -o vers=3,nconnect=16,rsize=262144,wsize=262144 192.168.31.X:/inicio /inicio</block>
  <block id="152cd866abad6e43429948eb4715b973" category="list-text">Volumen de datos de montaje</block>
  <block id="1cd39f0089800bb9511317cc53d73557" category="list-text">Se utilizaron las siguientes opciones de montaje al montar el volumen de datos:</block>
  <block id="bcd39ebb3417a185678d6de2189af4b9" category="list-text">vers=4.1 # habilita pNFS para acceso paralelo a múltiples nodos de almacenamiento</block>
  <block id="5cd472c72f4b3a3c75cbdb77edc30528" category="list-text">proto=rdma # establece el protocolo de transferencia a RDMA en lugar del TCP predeterminado</block>
  <block id="f8553c0c0cde0245d779c37090c093a7" category="list-text">max_connect=16 # habilita el enlace troncal de sesión NFS para agregar el ancho de banda del puerto de almacenamiento</block>
  <block id="f8a3438d5712d48a22100c8109ea556e" category="list-text">write=eager # mejora el rendimiento de escritura de las escrituras almacenadas en búfer</block>
  <block id="42fdb382646439a01d661ce9d2127a1c" category="list-text">rsize=262144,wsize=262144 # establece el tamaño de transferencia de E/S a 256k</block>
  <block id="7f86b6f2a05fc6e5c5931f73e9af29fd" category="summary">NetApp AIPod con sistemas NVIDIA DGX: componentes de hardware</block>
  <block id="7c451f18f811f88a48907bf86377cdd8" category="doc">NVA-1173 NetApp AIPod con sistemas NVIDIA DGX - Componentes de hardware</block>
  <block id="bd6e083031bf15817a67b63cc58a211c" category="paragraph">Esta sección se centra en los componentes de hardware para los sistemas NetApp AIPod con NVIDIA DGX.</block>
  <block id="68674fa5fbd6fb83969183d07d48b8cd" category="section-title">Sistemas de almacenamiento NetApp AFF</block>
  <block id="3b6d33ce139758ecf9b0b83f9ecce001" category="paragraph">Los sistemas de almacenamiento de última generación NetApp AFF permiten a los departamentos de TI satisfacer los requisitos de almacenamiento empresarial con un rendimiento líder en la industria, flexibilidad superior, integración en la nube y la mejor gestión de datos de su clase.  Diseñados específicamente para flash, los sistemas AFF ayudan a acelerar, administrar y proteger datos críticos para el negocio.</block>
  <block id="d1d40f451fb75b4e7160785e64a75da3" category="section-title">Sistemas de almacenamiento AFF A90</block>
  <block id="df7df1dd54ea101ca8a417ee258e2693" category="paragraph">El NetApp AFF A90 con tecnología de software de gestión de datos NetApp ONTAP proporciona protección de datos integrada, capacidades antiransomware opcionales y el alto rendimiento y la resiliencia necesarios para soportar las cargas de trabajo comerciales más críticas.  Elimina las interrupciones en las operaciones de misión crítica, minimiza el ajuste del rendimiento y protege sus datos de los ataques de ransomware.  Ofrece: • Rendimiento líder en la industria • Seguridad de datos sin concesiones • Actualizaciones simplificadas y sin interrupciones</block>
  <block id="6bd43dd4b56bb5bfe362d48a0d5219e0" category="paragraph">_Sistema de almacenamiento NetApp AFF A90</block>
  <block id="df3fd00dc667f05e52f1e05b8dedfd55" category="paragraph"><block ref="df3fd00dc667f05e52f1e05b8dedfd55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1863aa82dcf92831635aa05e975d399d" category="section-title">Rendimiento líder en la industria</block>
  <block id="a261fc6acbe5e140d750bc3f1dd8c7a7" category="paragraph">El AFF A90 administra fácilmente cargas de trabajo de próxima generación, como aprendizaje profundo, IA y análisis de alta velocidad, así como bases de datos empresariales tradicionales como Oracle, SAP HANA, Microsoft SQL Server y aplicaciones virtualizadas.  Mantiene las aplicaciones críticas para el negocio funcionando a máxima velocidad con hasta 2,4 millones de IOPS por par HA y una latencia tan baja como 100 µs, y aumenta el rendimiento hasta en un 50 % con respecto a los modelos anteriores de NetApp .  Con NFS sobre RDMA, pNFS y Session Trunking, los clientes pueden lograr el alto nivel de rendimiento de red requerido para aplicaciones de próxima generación utilizando la infraestructura de red del centro de datos existente.  Los clientes también pueden escalar y crecer con soporte multiprotocolo unificado para SAN, NAS y almacenamiento de objetos y brindar máxima flexibilidad con el software de gestión de datos ONTAP unificado y único, para datos locales o en la nube.  Además, la salud del sistema se puede optimizar con análisis predictivos basados en IA proporcionados por Active IQ y Cloud Insights.</block>
  <block id="773efff7a0bbe1582ceff936530b5ae3" category="section-title">Seguridad de datos sin concesiones</block>
  <block id="b867e6aa9b3e46766f55ab250eb69715" category="paragraph">Los sistemas AFF A90 contienen un conjunto completo de software de protección de datos integrado y consistente con las aplicaciones de NetApp .  Proporciona protección de datos incorporada y soluciones antiransomware de vanguardia para prevención y recuperación posterior al ataque.  Se pueden bloquear los archivos maliciosos para evitar que se escriban en el disco y las anormalidades de almacenamiento se pueden monitorear fácilmente para obtener información.</block>
  <block id="f6353452ddd71a9ef0e4d8578d7dc7e3" category="section-title">Actualizaciones simplificadas y sin interrupciones</block>
  <block id="4015e152c676ca730da1d797ef1e9993" category="paragraph">El AFF A90 está disponible como una actualización dentro del chasis sin interrupciones para los clientes existentes del A800.  NetApp simplifica la actualización y la eliminación de interrupciones en operaciones de misión crítica a través de nuestras capacidades avanzadas de confiabilidad, disponibilidad, capacidad de servicio y capacidad de administración (RASM).  Además, NetApp aumenta aún más la eficiencia operativa y simplifica las actividades diarias de los equipos de TI porque el software ONTAP aplica automáticamente actualizaciones de firmware para todos los componentes del sistema.</block>
  <block id="13ab18b8510a80a65aefbf9a56e3b3d3" category="paragraph">Para las implementaciones más grandes, los sistemas AFF A1K ofrecen las mayores opciones de capacidad y rendimiento, mientras que otros sistemas de almacenamiento de NetApp , como AFF A70 y AFF C800, ofrecen opciones para implementaciones más pequeñas a costos más bajos.</block>
  <block id="3ebd416d1b3232ef4125025ab8f437a9" category="paragraph">NVIDIA DGX BasePOD es una solución integrada que consta de componentes de hardware y software NVIDIA , soluciones MLOps y almacenamiento de terceros.  Al aprovechar las mejores prácticas de diseño de sistemas de escalamiento horizontal con productos NVIDIA y soluciones de socios validadas, los clientes pueden implementar una plataforma eficiente y manejable para el desarrollo de IA.  La Figura 1 destaca los distintos componentes de NVIDIA DGX BasePOD.</block>
  <block id="76d810a9cb0440f2de2c7104493e266f" category="paragraph">_Solución NVIDIA DGX BasePOD_</block>
  <block id="559d10ed60e21f546209442a6aade09d" category="paragraph"><block ref="559d10ed60e21f546209442a6aade09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a5f31a2eea3b274409614f4eb63433c" category="section-title">Sistemas NVIDIA DGX H100</block>
  <block id="2cdfa62855978fa129d36e4602f41e0b" category="paragraph">El sistema NVIDIA DGX H100™ es una potencia de IA acelerada por el rendimiento innovador de la GPU NVIDIA H100 Tensor Core.</block>
  <block id="4a8da04b1b7a51ad2e9c77e221e0d9d9" category="paragraph">_Sistema NVIDIA DGX H100_</block>
  <block id="b9ab32cd1976da02bb3c074578d491c3" category="paragraph"><block ref="b9ab32cd1976da02bb3c074578d491c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93b775e18b65e433d85d83ad863c1797" category="paragraph">Las especificaciones clave del sistema DGX H100 son: • Ocho GPU NVIDIA H100.  • 80 GB de memoria GPU por GPU, para un total de 640 GB.  • Cuatro chips NVIDIA NVSwitch.  • Procesadores duales Intel Xeon Platinum 8480 de 56 núcleos con soporte PCIe 5.0.  • 2 TB de memoria del sistema DDR5.  • Cuatro puertos OSFP que dan servicio a ocho adaptadores NVIDIA ConnectX-7 (InfiniBand/Ethernet) de puerto único y dos adaptadores NVIDIA ConnectX-7 (InfiniBand/Ethernet) de puerto doble.  • Dos unidades M.2 NVMe de 1,92 TB para DGX OS, ocho unidades U.2 NVMe de 3,84 TB para almacenamiento/caché.  • Potencia máxima de 10,2 kW.  Los puertos traseros de la bandeja de la CPU DGX H100 se muestran a continuación.  Cuatro de los puertos OSFP sirven a ocho adaptadores ConnectX-7 para la estructura informática InfiniBand.  Cada par de adaptadores ConnectX-7 de doble puerto proporciona rutas paralelas a las estructuras de almacenamiento y administración.  El puerto fuera de banda se utiliza para el acceso a BMC .</block>
  <block id="1811b955f76e78d806cc9f89eca9365d" category="paragraph">_Panel trasero de la NVIDIA DGX H100_</block>
  <block id="7d94d25261d22723cf1dcbc550472562" category="paragraph"><block ref="7d94d25261d22723cf1dcbc550472562" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e64325a640583a5afbe8ce27e88608e" category="section-title">Conmutador NVIDIA Quantum-2 QM9700</block>
  <block id="96e834f144fffd019191dee8b2e3fa9e" category="paragraph">Conmutador NVIDIA Quantum-2 QM9700 InfiniBand</block>
  <block id="02e6cd41035da9c303b4223fcb954c57" category="paragraph"><block ref="02e6cd41035da9c303b4223fcb954c57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58e83b10341e2ec3a48b164715b6ba34" category="paragraph">Los conmutadores NVIDIA Quantum-2 QM9700 con conectividad InfiniBand de 400 Gb/s potencian la estructura informática en configuraciones NVIDIA Quantum-2 InfiniBand BasePOD.  Los adaptadores de puerto único ConnectX-7 se utilizan para la estructura informática InfiniBand.  Cada sistema NVIDIA DGX tiene conexiones duales a cada conmutador QM9700, lo que proporciona múltiples rutas de alto ancho de banda y baja latencia entre los sistemas.</block>
  <block id="88f086b3f05858ad120601108f0821a7" category="section-title">Conmutador NVIDIA Spectrum-3 SN4600</block>
  <block id="69dc0a65b1f9cc56bf9d1b38913e279e" category="paragraph">Conmutador NVIDIA Spectrum-3 SN4600</block>
  <block id="a5317e31cdc481b4371010e9f47b541d" category="paragraph"><block ref="a5317e31cdc481b4371010e9f47b541d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df2b71117642b0bdbf87a4e9d643c47e" category="paragraph">Los conmutadores NVIDIA Spectrum™-3 SN4600 ofrecen 128 puertos en total (64 por conmutador) para proporcionar conectividad redundante para la gestión en banda del DGX BasePOD.  El conmutador NVIDIA SN4600 puede proporcionar velocidades entre 1 GbE y 200 GbE.  Para los dispositivos de almacenamiento conectados a través de Ethernet, también se utilizan los conmutadores NVIDIA SN4600.  Los puertos de los adaptadores NVIDIA DGX ConnectX-7 de doble puerto se utilizan tanto para la administración en banda como para la conectividad de almacenamiento.</block>
  <block id="9bc83d36ebb307eef9521860d72d6a83" category="section-title">Conmutador NVIDIA Spectrum SN2201</block>
  <block id="0a58d2e4f07c9b74c7b9f0f643df366e" category="paragraph">_Conmutador NVIDIA Spectrum SN2201_</block>
  <block id="63573ea3854985f600f8cc8c44aa5bea" category="paragraph"><block ref="63573ea3854985f600f8cc8c44aa5bea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6714f3120a26d6eb7222fbbd52715a6c" category="paragraph">Los conmutadores NVIDIA Spectrum SN2201 ofrecen 48 puertos para proporcionar conectividad para la administración fuera de banda.  La administración fuera de banda proporciona conectividad de administración consolidada para todos los componentes en DGX BasePOD.</block>
  <block id="82e5da407cc33e26189f053503aa2bf6" category="section-title">Adaptador NVIDIA ConnectX-7</block>
  <block id="74baf984365e15a6f92345e68021621a" category="paragraph">Adaptador NVIDIA ConnectX-7</block>
  <block id="062446821e85b6d2c053705d69b2c037" category="paragraph"><block ref="062446821e85b6d2c053705d69b2c037" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f31835004684d86091e359c9a240e92" category="paragraph">El adaptador NVIDIA ConnectX-7 puede proporcionar un rendimiento de 25/50/100/200/400 G.  Los sistemas NVIDIA DGX utilizan adaptadores ConnectX-7 de puerto único y doble para brindar flexibilidad en las implementaciones de DGX BasePOD con InfiniBand y Ethernet de 400 Gb/s.</block>
  <block id="9f68b039fbd3ecc8729ee9a4be7903ea" category="summary">NetApp AIPod con sistemas NVIDIA DGX es una arquitectura de referencia lista para la empresa basada en NVIDIA BasePOD para aprendizaje profundo e inteligencia artificial que utiliza sistemas de almacenamiento NetApp ONTAP AFF y sistemas de redes y DGX de NVIDIA .</block>
  <block id="9b07efa8439fb4859742ace8bb15c070" category="doc">NVA-1173 NetApp AIPod con sistemas NVIDIA DGX: Introducción</block>
  <block id="03a5dba0ba7f06a853319a59ab10f1db" category="inline-image-macro">200,200,Error: Falta imagen gráfica</block>
  <block id="540456658a35dff79ec59aa1338d398e" category="paragraph"><block ref="540456658a35dff79ec59aa1338d398e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="217432d0ec5a422d97fdd8082983c438" category="paragraph">Ingeniería de soluciones de NetApp</block>
  <block id="617f17b8f2c8c0557ec9f79c918464eb" category="paragraph">El AIPod de NetApp con sistemas NVIDIA DGX y los sistemas de almacenamiento conectados a la nube de NetApp simplifican las implementaciones de infraestructura para cargas de trabajo de aprendizaje automático (ML) e inteligencia artificial (IA) al eliminar la complejidad del diseño y las conjeturas.  Basado en el diseño NVIDIA DGX BasePOD™ para brindar un rendimiento computacional excepcional para cargas de trabajo de próxima generación, AIPod con sistemas NVIDIA DGX agrega sistemas de almacenamiento NetApp AFF que permiten a los clientes comenzar de a poco y crecer sin interrupciones mientras administran de manera inteligente los datos desde el borde hasta el núcleo, la nube y viceversa.  NetApp AIPod es parte de la cartera más amplia de soluciones de inteligencia artificial de NetApp , que se muestra en la siguiente figura.</block>
  <block id="194ff09c8e869017b4ffe91887dde829" category="paragraph">_Cartera de soluciones de IA de NetApp_</block>
  <block id="629225e0ba0d0325f35ee6fcfd7ebf4e" category="paragraph"><block ref="629225e0ba0d0325f35ee6fcfd7ebf4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff9a398ccda9f0fc1e44521cf40ca977" category="paragraph">Este documento describe los componentes clave de la arquitectura de referencia AIPod , la conectividad del sistema y la información de configuración, los resultados de las pruebas de validación y la guía para el dimensionamiento de la solución.  Este documento está dirigido a los ingenieros de soluciones de NetApp y sus socios, así como a los tomadores de decisiones estratégicas de clientes interesados en implementar una infraestructura de alto rendimiento para cargas de trabajo de ML/DL y análisis.</block>
  <block id="77f2324c2483df30f029d522599f882e" category="summary">NetApp AIPod con sistemas NVIDIA DGX: componentes de software</block>
  <block id="751547b5efb176a435e672a4015bb7e9" category="doc">NVA-1173 NetApp AIPod con sistemas NVIDIA DGX - Componentes de software</block>
  <block id="c3d68fb38e0db372152f5a3a84fed148" category="paragraph">Esta sección se centra en los componentes de software del NetApp AIPod con sistemas NVIDIA DGX.</block>
  <block id="5475410ded0787143601d2206a245532" category="section-title">Software de NVIDIA</block>
  <block id="96a0475a5e6d02d46b5b8d7f1327a530" category="paragraph">NVIDIA Base Command™ potencia cada DGX BasePOD, lo que permite a las organizaciones aprovechar lo mejor de la innovación del software NVIDIA .  Las empresas pueden aprovechar todo el potencial de su inversión con una plataforma probada que incluye orquestación de nivel empresarial y gestión de clústeres, bibliotecas que aceleran la infraestructura de computación, almacenamiento y red, y un sistema operativo (SO) optimizado para cargas de trabajo de IA.</block>
  <block id="f30878d7bf93bf61a8d0a25e397a8583" category="paragraph">_Solución NVIDIA BaseCommand_</block>
  <block id="26997aefe36f4fb8a168ede0ec7189e1" category="paragraph"><block ref="26997aefe36f4fb8a168ede0ec7189e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">Nube de GPU NVIDIA (NGC)</block>
  <block id="5cbbb9592d14a268aacbc5ecd838a166" category="paragraph">NVIDIA NGC proporciona software para satisfacer las necesidades de científicos de datos, desarrolladores e investigadores con distintos niveles de experiencia en IA.  El software alojado en NGC se somete a análisis contra un conjunto agregado de vulnerabilidades y exposiciones comunes (CVE), criptomonedas y claves privadas.  Está probado y diseñado para escalar a múltiples GPU y, en muchos casos, a múltiples nodos, lo que garantiza que los usuarios maximicen su inversión en sistemas DGX.</block>
  <block id="d19c3b09db45ed579ed1aa2895637b7d" category="paragraph">_Nube de GPU de NVIDIA_</block>
  <block id="c46997ba8e7fdf0cb96f12b451129203" category="paragraph"><block ref="c46997ba8e7fdf0cb96f12b451129203" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b4d69ee10ecec0ac3d21aba6691dc53" category="paragraph">NVIDIA AI Enterprise es la plataforma de software de extremo a extremo que pone la IA generativa al alcance de todas las empresas, proporcionando el tiempo de ejecución más rápido y eficiente para los modelos básicos de IA generativa optimizados para ejecutarse en la plataforma NVIDIA DGX.  Con seguridad, estabilidad y capacidad de gestión de nivel de producción, agiliza el desarrollo de soluciones de IA generativa.  NVIDIA AI Enterprise se incluye con DGX BasePOD para que los desarrolladores empresariales accedan a modelos previamente entrenados, marcos optimizados, microservicios, bibliotecas aceleradas y soporte empresarial.</block>
  <block id="9aeccfb63defa46cb78ffa3611d362c6" category="section-title">Software de NetApp</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9, la última generación de software de gestión de almacenamiento de NetApp, permite a las empresas modernizar la infraestructura y realizar la transición a un centro de datos preparado para la nube.  Al aprovechar las capacidades de gestión de datos líderes en la industria, ONTAP permite la gestión y protección de datos con un único conjunto de herramientas, independientemente de dónde residan esos datos.  También puede mover datos libremente a donde sea necesario: el borde, el núcleo o la nube.  ONTAP 9 incluye numerosas características que simplifican la gestión de datos, aceleran y protegen datos críticos y habilitan capacidades de infraestructura de próxima generación en arquitecturas de nube híbrida.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">Acelerar y proteger los datos</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP ofrece niveles superiores de rendimiento y protección de datos y amplía estas capacidades de las siguientes maneras:</block>
  <block id="7c282a19ff405710e49738f9d0a03a85" category="list-text">Rendimiento y menor latencia.  ONTAP ofrece el mayor rendimiento posible con la menor latencia posible, incluido soporte para NVIDIA GPUDirect Storage (GDS) usando NFS sobre RDMA, NFS paralelo (pNFS) y troncalización de sesiones NFS.</block>
  <block id="b2d0aaf645ff5747fbe1e0aec0cf528c" category="list-text">Protección de datos.  ONTAP ofrece capacidades de protección de datos integradas y la garantía antiransomware más sólida de la industria con administración común en todas las plataformas.</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">Cifrado de volumen de NetApp (NVE).  ONTAP ofrece cifrado nativo a nivel de volumen con soporte para administración de claves interna y externa.</block>
  <block id="651928f77d87184265ec1be1ab0b8aff" category="list-text">Almacenamiento multiinquilino y autenticación multifactor.  ONTAP permite compartir recursos de infraestructura con los más altos niveles de seguridad.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">Simplificar la gestión de datos</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">La gestión de datos es crucial para las operaciones de TI de la empresa y los científicos de datos, de modo que se utilicen los recursos adecuados para las aplicaciones de IA y el entrenamiento de conjuntos de datos de IA/ML.  La siguiente información adicional sobre las tecnologías de NetApp está fuera del alcance de esta validación, pero podría ser relevante según su implementación.</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">El software de gestión de datos ONTAP incluye las siguientes características para optimizar y simplificar las operaciones y reducir el costo total de operación:</block>
  <block id="621721e0b0144695aabce4090fa40eed" category="list-text">Las instantáneas y los clones permiten la colaboración, la experimentación paralela y una mejor gobernanza de datos para los flujos de trabajo de ML/DL.</block>
  <block id="b1932ff070760d4f32c0a3701982558d" category="list-text">SnapMirror permite el movimiento de datos sin inconvenientes en entornos de nube híbrida y de múltiples sitios, entregando datos dónde y cuándo se necesitan.</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">Compactación de datos en línea y deduplicación ampliada.  La compactación de datos reduce el espacio desperdiciado dentro de los bloques de almacenamiento y la deduplicación aumenta significativamente la capacidad efectiva.  Esto se aplica a los datos almacenados localmente y a los datos almacenados en la nube.</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">Calidad de servicio mínima, máxima y adaptativa (AQoS).  Los controles granulares de calidad de servicio (QoS) ayudan a mantener los niveles de rendimiento de las aplicaciones críticas en entornos altamente compartidos.</block>
  <block id="74959a361bdb223dafbb94226dd84e3e" category="list-text">Los FlexGroups de NetApp permiten la distribución de datos entre todos los nodos del clúster de almacenamiento, proporcionando una capacidad masiva y un mayor rendimiento para conjuntos de datos extremadamente grandes.</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598: Prácticas recomendadas de FabricPool</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">FabricPool de NetApp .  Proporciona niveles automáticos de datos fríos en opciones de almacenamiento en la nube pública y privada, incluidas Amazon Web Services (AWS), Azure y la solución de almacenamiento NetApp StorageGRID .  Para obtener más información sobre FabricPool, consulte<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block> .</block>
  <block id="eec4aeb85db42cd9055b9aba24052c7e" category="list-text">FlexCache de NetApp .  Proporciona capacidades de almacenamiento en caché de volumen remoto que simplifican la distribución de archivos, reducen la latencia de la WAN y disminuyen los costos de ancho de banda de la WAN.  FlexCache permite el desarrollo distribuido de productos en múltiples sitios, así como el acceso acelerado a conjuntos de datos corporativos desde ubicaciones remotas.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">Infraestructura a prueba de futuro</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP ayuda a satisfacer necesidades comerciales exigentes y en constante cambio con las siguientes características:</block>
  <block id="483e92f76323d9d7b2d7f2ec6d4c0590" category="list-text">Escalabilidad perfecta y operaciones sin interrupciones.  ONTAP admite la incorporación en línea de capacidad a controladores existentes y la ampliación horizontal de clústeres.  Los clientes pueden actualizar a las últimas tecnologías, como NVMe y FC de 32 Gb, sin migraciones de datos costosas ni interrupciones.</block>
  <block id="96cf8f94fadb527d958ae5373082d6d7" category="list-text">Conexión a la nube.  ONTAP es el software de gestión de almacenamiento más conectado a la nube, con opciones para almacenamiento definido por software (ONTAP Select) e instancias nativas de la nube (Google Cloud NetApp Volumes) en todas las nubes públicas.</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">Integración con aplicaciones emergentes.  ONTAP ofrece servicios de datos de nivel empresarial para plataformas y aplicaciones de próxima generación, como vehículos autónomos, ciudades inteligentes e Industria 4.0, utilizando la misma infraestructura que respalda las aplicaciones empresariales existentes.</block>
  <block id="2c7194a99a4f7de8ffbf3ba400a92df8" category="paragraph">NetApp DataOps Toolkit es una herramienta basada en Python que simplifica la gestión de espacios de trabajo de desarrollo/entrenamiento y servidores de inferencia respaldados por almacenamiento NetApp de alto rendimiento y escalabilidad horizontal.  El kit de herramientas DataOps puede funcionar como una utilidad independiente y es aún más efectivo en entornos Kubernetes que aprovechan NetApp Trident para automatizar las operaciones de almacenamiento.  Las capacidades clave incluyen:</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">Aprovisione rápidamente nuevos espacios de trabajo JupyterLab de alta capacidad respaldados por almacenamiento NetApp de alto rendimiento y escalabilidad horizontal.</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">Aprovisione rápidamente nuevas instancias de NVIDIA Triton Inference Server respaldadas por almacenamiento NetApp de clase empresarial.</block>
  <block id="44ce48cceac53b351ab54ca5685fcf55" category="list-text">Clonación casi instantánea de espacios de trabajo de JupyterLab de alta capacidad para permitir la experimentación o la iteración rápida.</block>
  <block id="b47bad7e2a479b14e613be5ba1af90a0" category="list-text">Instantáneas casi instantáneas de espacios de trabajo de JupyterLab de alta capacidad para realizar copias de seguridad y/o trazabilidad/establecimiento de referencia.</block>
  <block id="afe9b022bbe49ebc232dc11679a61bb4" category="list-text">Aprovisionamiento, clonación e instantáneas casi instantáneos de volúmenes de datos de alto rendimiento y alta capacidad.</block>
  <block id="b242f57e51b5f507797a088899c22df7" category="paragraph">Trident es un orquestador de almacenamiento de código abierto totalmente compatible con contenedores y distribuciones de Kubernetes, incluido Anthos. Trident funciona con todo el portafolio de almacenamiento de NetApp , incluido NetApp ONTAP, y también admite conexiones NFS, NVMe/TCP e iSCSI. Trident acelera el flujo de trabajo de DevOps al permitir que los usuarios finales aprovisionen y administren almacenamiento desde sus sistemas de almacenamiento NetApp sin necesidad de la intervención de un administrador de almacenamiento.</block>
  <block id="1efc1a71dad2451e243efa783d9aaba0" category="summary">NetApp AIPod con sistemas NVIDIA DGX: validación de soluciones y guía de dimensionamiento</block>
  <block id="1baf67b0ad3fef1cc60370bda6ebc7f9" category="doc">NVA-1173 NetApp AIPod con sistemas NVIDIA DGX: validación de soluciones y guía de dimensionamiento</block>
  <block id="d2fb9fca0fa09d949a54ae42e337c891" category="paragraph">Esta sección se centra en la validación de la solución y la orientación sobre el dimensionamiento de los sistemas NetApp AIPod con NVIDIA DGX.</block>
  <block id="773a9689ba6682deeabffa6746d64105" category="section-title">Validación de la solución</block>
  <block id="364bed9cbf28e51b3a87b1cece482054" category="paragraph">La configuración de almacenamiento en esta solución se validó utilizando una serie de cargas de trabajo sintéticas utilizando la herramienta de código abierto FIO.  Estas pruebas incluyen patrones de E/S de lectura y escritura destinados a simular la carga de trabajo de almacenamiento generada por los sistemas DGX que realizan trabajos de entrenamiento de aprendizaje profundo.  La configuración de almacenamiento se validó utilizando un clúster de servidores de CPU de 2 sockets que ejecutaban las cargas de trabajo FIO simultáneamente para simular un clúster de sistemas DGX.  Cada cliente se configuró con la misma configuración de red descrita anteriormente, con el agregado de los siguientes detalles.</block>
  <block id="5c553fedff3f40a2af76bb0c410b404f" category="paragraph">Se utilizaron las siguientes opciones de montaje para esta validación:</block>
  <block id="cb8472643b1176f8340370ce5a0b204d" category="cell">versión=4.1</block>
  <block id="893b3a13ba8b6b5a60094306461bc370" category="cell">permite pNFS para acceso paralelo a múltiples nodos de almacenamiento</block>
  <block id="1df213ce94ed5cdef706c9350768f0c2" category="cell">proto=rdma</block>
  <block id="42cc89ba8e1299f3640ad771a94abfaa" category="cell">Establece el protocolo de transferencia a RDMA en lugar del TCP predeterminado</block>
  <block id="9b7b56ffe75ec2daff44ba8923725d27" category="cell">puerto=20049</block>
  <block id="52c223170500f2f347a266328f0c4216" category="cell">especifique el puerto correcto para el servicio RDMA NFS</block>
  <block id="5b75616cf8bcd004a7fb0c78bcf4cb1e" category="cell">conexión máxima=16</block>
  <block id="82264615e17e10dec975d19de56f7e01" category="cell">Permite la conexión troncal de sesiones NFS para agregar el ancho de banda del puerto de almacenamiento</block>
  <block id="b0b79785aa490d51befbe60046fe59a6" category="cell">escribir=ansioso</block>
  <block id="27d6ebb9c804f9228e43f1362d2ad502" category="cell">mejora el rendimiento de escritura de las escrituras almacenadas en búfer</block>
  <block id="df2285a23b7de4affb43985a03a9b955" category="cell">tamaño r=262144, tamaño w=262144</block>
  <block id="226cf9c18b16f30e1381d76500dcd2c3" category="cell">Establece el tamaño de transferencia de E/S a 256k</block>
  <block id="1275e87e965ab2e83ee1a3d508393bb1" category="paragraph">Además, los clientes se configuraron con un valor NFS max_session_slots de 1024.  Como la solución se probó utilizando NFS sobre RDMA, los puertos de redes de almacenamiento se configuraron con un enlace activo/pasivo.  Para esta validación se utilizaron los siguientes parámetros de enlace:</block>
  <block id="dc2f1400a2999b58888391b52366d42d" category="cell">modo=copia de seguridad activa</block>
  <block id="ceafe9fbea6d2853c0ef101fde263114" category="cell">Establece el vínculo en modo activo/pasivo</block>
  <block id="0772e25cb688aaddbfcafe9a95042ae0" category="cell">principal=&lt;nombre de la interfaz&gt;</block>
  <block id="126d68b093e92a0eeafa0ea632b5dee2" category="cell">Las interfaces principales para todos los clientes se distribuyeron entre los conmutadores</block>
  <block id="cbfd831ae9cd4bbc2c5955b278fc1464" category="cell">intervalo del monitor mii=100</block>
  <block id="ef530a18c3e08c2e1454d98413c8995a" category="cell">especifica un intervalo de monitorización de 100 ms</block>
  <block id="4a7a0a399fdd09cc77725d4bca22c5d2" category="cell">política de conmutación por error de mac=activa</block>
  <block id="1cddea1ebc0f8a54ddb9d1b5d3701199" category="cell">especifica que la dirección MAC del enlace activo es la MAC del enlace.  Esto es necesario para el correcto funcionamiento de RDMA a través de la interfaz vinculada.</block>
  <block id="13e766ae456cff38288a10e042da1460" category="paragraph">El sistema de almacenamiento se configuró como se describe con dos pares A900 HA (4 controladores) con dos estantes de discos NS224 de 24 unidades de disco NVMe de 1,9 TB conectados a cada par HA.  Como se señaló en la sección de arquitectura, la capacidad de almacenamiento de todos los controladores se combinó mediante un volumen FlexGroup y los datos de todos los clientes se distribuyeron entre todos los controladores del clúster.</block>
  <block id="4534545218c3df22ad30ec5ab0466128" category="section-title">Guía de dimensionamiento del sistema de almacenamiento</block>
  <block id="e58e8ec46be51c65fb6895529b19620c" category="paragraph">NetApp ha completado con éxito la certificación DGX BasePOD y los dos pares A90 HA probados pueden soportar fácilmente un clúster de dieciséis sistemas DGX H100.  Para implementaciones más grandes con mayores requisitos de rendimiento de almacenamiento, se pueden agregar sistemas AFF adicionales al clúster NetApp ONTAP hasta 12 pares de HA (24 nodos) en un solo clúster.  Al utilizar la tecnología FlexGroup descrita en esta solución, un clúster de 24 nodos puede proporcionar más de 79 PB y hasta 552 GBps de rendimiento en un solo espacio de nombres.  Otros sistemas de almacenamiento de NetApp , como AFF A400, A250 y C800, ofrecen opciones de menor rendimiento y/o mayor capacidad para implementaciones más pequeñas a menores costos.  Debido a que ONTAP 9 admite clústeres de modelos mixtos, los clientes pueden comenzar con un espacio inicial más pequeño y agregar más sistemas de almacenamiento o más grandes al clúster a medida que aumentan los requisitos de capacidad y rendimiento.  La siguiente tabla muestra una estimación aproximada de la cantidad de GPU A100 y H100 compatibles con cada modelo AFF .</block>
  <block id="d151e6348ab5291d10caeda2db802b75" category="paragraph">_Guía de dimensionamiento del sistema de almacenamiento NetApp_</block>
  <block id="c61d72d95f504983715ce76fcfdfb864" category="paragraph"><block ref="c61d72d95f504983715ce76fcfdfb864" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28e8b3e83af233fe7085ba954fc6fd36" category="doc">BeeGFS en NetApp con almacenamiento de la serie E</block>
  <block id="e8afe31a21b6aae9717484d865743dae" category="paragraph">BeeGFS en NetApp con almacenamiento E-Series es una solución integrada y probada con una infraestructura HPC simple, confiable, escalable y rentable que sigue el ritmo de sus cargas de trabajo más extremas.</block>
  <block id="d18d454d6ae7128c6b49bf41c9ea2cf4" category="paragraph"><block ref="d18d454d6ae7128c6b49bf41c9ea2cf4" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-DEPLOY: Guía de implementación de sistemas Quantum StorNext con NetApp E-Series</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">Ryan Rodine, NetApp</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">Este documento proporciona detalles sobre cómo implementar una solución de sistema de archivos paralelo StorNext con sistemas de almacenamiento NetApp E-Series.  Esta solución cubre la matriz all-flash EF280 de NetApp , la matriz all-flash NVMe EF300 de NetApp , la matriz all-flash NVMe EF600 de NetApp y el sistema híbrido E5760 de NetApp .  Ofrece una caracterización del rendimiento basada en la evaluación comparativa de Frametest, una herramienta ampliamente utilizada para pruebas en la industria de los medios y el entretenimiento.</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-DESIGN: Guía de diseño de sistemas Quantum StorNext con NetApp E-Series</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">Este documento proporciona detalles sobre cómo diseñar una solución de sistema de archivos paralelo StorNext con sistemas de almacenamiento NetApp E-Series.  Esta solución cubre la matriz all-flash EF280 de NetApp , la matriz all-flash NVMe EF300 de NetApp , la matriz all-flash NVMe EF600 y el sistema híbrido E5760 de NetApp .  Ofrece una caracterización del rendimiento basada en la evaluación comparativa de Frametest, una herramienta ampliamente utilizada para pruebas en la industria de los medios y el entretenimiento.</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859: Implementación de IBM Spectrum Scale con almacenamiento NetApp E-Series: instalación y validación</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">Chris Seirer, NetApp</block>
  <block id="06bd55c4b576fd1f13eb5e25a1415bba" category="paragraph">TR-4859 describe el proceso de implementación de una solución de sistema de archivos paralelo completo basada en la pila de software Spectrum Scale de IBM.  TR-4859 está diseñado para proporcionar detalles sobre cómo instalar Spectrum Scale, validar la infraestructura y administrar la configuración.</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="3026654be6be955b54735554371ee5a0" category="summary">Esta arquitectura verificada de NetApp describe el diseño del NVIDIA DGX SuperPOD con bloques de construcción NetApp BeeGFS.  Esta solución es una plataforma de centro de datos de pila completa que está validada en un clúster de aceptación dedicado en NVIDIA.</block>
  <block id="85505186d8e84ecff8e7e71596423747" category="doc">NVIDIA DGX SuperPOD con NetApp : Guía de diseño</block>
  <block id="49ba6c0ee9149acc4bdb6fac5165b7b0" category="paragraph">Esta arquitectura verificada de NetApp describe el diseño del NVIDIA DGX SuperPOD con bloques de construcción NetApp BeeGFS.  Esta solución es una plataforma de centro de datos de pila completa validada en un clúster de aceptación dedicado en NVIDIA.</block>
  <block id="adb0b7d6a9d5c0af32d1c6fe9a103229" category="inline-image-macro">200.200</block>
  <block id="0a8dfa4d72d5f9b29ce5ac529286b37f" category="paragraph"><block ref="0a8dfa4d72d5f9b29ce5ac529286b37f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a7225e9429ab905378b45f3aa288040" category="paragraph">Amine Bennani, Christian Whiteside, David Arnette y Sathish Thyagarajan, NetApp</block>
  <block id="7919e821dc18f3e88c0201e01bf6a240" category="section-title">Resumen ejecutivo</block>
  <block id="d83b5adf97fe549e1dc83bb95e6f2cdf" category="paragraph">En el panorama tecnológico actual en rápida evolución, la IA está revolucionando las experiencias de los consumidores e impulsando la innovación en todas las industrias.  Sin embargo, también presenta desafíos importantes para los departamentos de TI, que están bajo presión para implementar soluciones de computación de alto rendimiento (HPC) capaces de manejar las intensas demandas de las cargas de trabajo de IA.  A medida que las organizaciones compiten por aprovechar el poder de la IA, crece la urgencia de contar con una solución que sea fácil de implementar, escalar y administrar.</block>
  <block id="2e93342ec6458064edd50d209383c787" category="paragraph">NVIDIA DGX SuperPOD es una plataforma de infraestructura de centro de datos de IA entregada como una solución llave en mano para TI para respaldar las cargas de trabajo de IA más complejas que enfrentan las empresas actuales.  En el núcleo de cualquier modelo de aprendizaje profundo (DL) preciso hay grandes volúmenes de datos, lo que requiere una solución de almacenamiento de alto rendimiento que pueda servir y re-servir estos datos de manera eficiente.  La solución NetApp BeeGFS, que consta de matrices de almacenamiento NetApp EF600 con el sistema de archivos paralelo BeeGFS, permite que NVIDIA DGX SuperPOD libere toda su capacidad.  La solución NetApp BeeGFS ha sido validada por NVIDIA para integrarse y escalar con la arquitectura SuperPOD.  El resultado es una implementación y gestión simplificadas del centro de datos de IA al tiempo que ofrece una escalabilidad prácticamente ilimitada en términos de rendimiento y capacidad.</block>
  <block id="77e585eeb67a682a6445c0154fd9a028" category="paragraph">La solución NetApp BeeGFS, impulsada por los sistemas de almacenamiento NetApp EF600 NVMe de alto rendimiento y el sistema de archivos paralelos BeeGFS escalable, ofrece una base de almacenamiento sólida y eficiente para cargas de trabajo de IA exigentes.  Su arquitectura de disco compartido garantiza una alta disponibilidad, manteniendo un rendimiento y una accesibilidad consistentes, incluso ante desafíos del sistema.  Esta solución proporciona una arquitectura escalable y flexible que se puede personalizar para satisfacer diversos requisitos de almacenamiento.  Los clientes pueden ampliar fácilmente su rendimiento y capacidad de almacenamiento integrando bloques de almacenamiento adicionales para manejar incluso las cargas de trabajo más exigentes.</block>
  <block id="1ad3f73d04f7a3d0b225d62bf707c034" category="list-text">NVIDIA DGX SuperPOD aprovecha los sistemas DGX H100 y H200 con un almacenamiento compartido externo validado:</block>
  <block id="8dc89fa0c821b38b2ab07d3f5dd4385f" category="list-text">Cada unidad escalable (SU) DGX SuperPOD consta de 32 sistemas DGX y es capaz de alcanzar 640 petaFLOPS de rendimiento de IA con precisión FP8.  NetApp recomienda dimensionar la solución de almacenamiento NetApp BeeGFS con al menos 2 bloques de construcción para una única configuración DGX SuperPOD.</block>
  <block id="0aa799745475dedefbc0785863494b75" category="paragraph">_Una visión de alto nivel de la solución_</block>
  <block id="0e06b8493198d6e7d8d53d9201ddd9bc" category="inline-image-macro">Figura que muestra una descripción general de alto nivel de la solución NetApp BeeGFS con un NVIDIA DGX SuperPOD.</block>
  <block id="6bfc1196652f29c394bdbe8e2807a4a0" category="paragraph"><block ref="6bfc1196652f29c394bdbe8e2807a4a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="949e06b94ff43763386683593267b5d3" category="list-text">Los bloques de construcción NetApp BeeGFS constan de dos matrices NetApp EF600 y dos servidores x86:</block>
  <block id="53a59094fc8cf61c8ceb5488c68798f9" category="list-text">Con las matrices all-flash NetApp EF600 en la base de NVIDIA DGX SuperPOD, los clientes obtienen una base de almacenamiento confiable respaldada por seis nueves de tiempo de actividad.</block>
  <block id="23830778b135794055062035d895d122" category="list-text">La capa del sistema de archivos entre los sistemas NetApp EF600 y NVIDIA DGX es el sistema de archivos paralelo BeeGFS.  BeeGFS fue creado por el Centro Fraunhofer de Computación de Alto Rendimiento en Alemania para resolver los problemas de los sistemas de archivos paralelos heredados.  El resultado es un sistema de archivos con una arquitectura de espacio de usuario moderna que ahora desarrolla y distribuye ThinkParQ y que utilizan muchos entornos de supercomputación.</block>
  <block id="d6dbc9a4d449d8584f1bc7766a233055" category="list-text">El soporte de NetApp para BeeGFS alinea la excelente organización de soporte de NetApp con los requisitos del cliente en cuanto a rendimiento y tiempo de actividad.  Los clientes obtienen acceso a recursos de soporte superiores, acceso anticipado a las versiones de BeeGFS y acceso a funciones empresariales seleccionadas de BeeGFS, como cumplimiento de cuotas y alta disponibilidad (HA).</block>
  <block id="06723075d010c851032e77543613704f" category="list-text">La combinación de las SU NVIDIA SuperPOD y los bloques de construcción BeeGFS de NetApp proporciona una solución de IA ágil en la que el cómputo o el almacenamiento se escalan de manera fácil y sin inconvenientes.</block>
  <block id="e0d00c6a1325f01dc14822163a1d43fe" category="paragraph">_Bloque de construcción BeeGFS de NetApp_</block>
  <block id="f2ccf42799ed738590ee8a95c9a2e5c9" category="inline-image-macro">Figura que muestra un solo bloque de construcción BeeGFS de NetApp .</block>
  <block id="9390da63574f67fe268b45392cf0ec3e" category="paragraph"><block ref="9390da63574f67fe268b45392cf0ec3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df07b47923825d5392c14e80cea2d72a" category="section-title">Resumen del caso de uso</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">Esta solución se aplica a los siguientes casos de uso:</block>
  <block id="30e31e5dc6388c3434cea1711261b743" category="list-text">Inteligencia artificial (IA), que incluye aprendizaje automático (ML), aprendizaje profundo (DL), procesamiento del lenguaje natural (NLP), comprensión del lenguaje natural (NLU) e IA generativa (GenAI).</block>
  <block id="c21f50752fbbe8f54e46848c0f9ce70a" category="list-text">Entrenamiento de IA a escala media y grande</block>
  <block id="137c3bef49af695737b7c23000204b5c" category="list-text">Modelos de visión artificial, habla, audio y lenguaje</block>
  <block id="15ed9179636b107f0a88e83f782e6cec" category="list-text">HPC incluye aplicaciones aceleradas por la interfaz de paso de mensajes (MPI) y otras técnicas de computación distribuida</block>
  <block id="90b7289b464ec4d544bf5a9eacbaf7f0" category="list-text">Cargas de trabajo de aplicaciones caracterizadas por lo siguiente:</block>
  <block id="c9ccfce7935790c9fd0d9ccf98da5177" category="list-text">Leer o escribir en archivos de más de 1 GB</block>
  <block id="680e47afa4860ce2ac4a078a0d466121" category="list-text">Lectura o escritura en el mismo archivo por varios clientes (decenas, centenas y millares)</block>
  <block id="af7aa0607b7f1d728a529edd21a52763" category="list-text">Conjuntos de datos multiterabyte o multipetabyte</block>
  <block id="efc155766b6000aefdf459d6ff3ecd75" category="list-text">Entornos que necesitan un único espacio de almacenamiento optimizable para una combinación de archivos grandes y pequeños</block>
  <block id="dcbd8f687e2ef904380c2b6c942c989e" category="paragraph">Esta sección cubre los requisitos tecnológicos para la solución NVIDIA DGX SuperPOD con NetApp .</block>
  <block id="b95d6ba22cd7d0fb6a3c655d4c24d180" category="inline-link">Arquitectura de referencia NVIDIA DGX H100 SuperPOD</block>
  <block id="02399dc2f4ffe6e6772456736a8522d7" category="inline-link">NVA-1164-DISEÑO: BeeGFS en el diseño de NVA de NetApp</block>
  <block id="5425be0e2232456057166446265f9a88" category="paragraph">En la Tabla 1 a continuación se enumeran los componentes de hardware necesarios para implementar la solución para una sola SU.  El dimensionamiento de la solución comienza con 32 sistemas NVIDIA DGX H100 y dos o tres bloques de construcción NetApp BeeGFS.  Un solo bloque de construcción NetApp BeeGFS consta de dos matrices NetApp EF600 y dos servidores x86.  Los clientes pueden agregar bloques de construcción adicionales a medida que aumenta el tamaño de la implementación.  Para obtener más información, consulte la<block ref="55ded0354bf42e7e117b50dda2359a8a" category="inline-link-rx"></block> y<block ref="de7b61948f391c0bb69985cc0357d2a5" category="inline-link-rx"></block> .</block>
  <block id="5aa595c84818428979f9fa2d99bb6f83" category="cell">NVIDIA DGX H100 o H200</block>
  <block id="6364d3f0f495b6ab9dcf8d3b5c6e0b01" category="cell">32</block>
  <block id="eef6c1a81c81a43f02e2b7749d260ef5" category="cell">Conmutadores NVIDIA Quantum QM9700</block>
  <block id="34a2c495ed1b62db3e0fffd75420aca5" category="cell">8 hojas, 4 lomos</block>
  <block id="be3accc5713b4d53186215779c2deeed" category="cell">Bloques de construcción BeeGFS de NetApp</block>
  <block id="0dbcb15fd014d19061fb2910f0a1ab0e" category="paragraph">En la Tabla 2 a continuación se enumeran los componentes de software necesarios para implementar la solución.  Los componentes de software que se utilizan en cualquier implementación particular de la solución pueden variar según los requisitos del cliente.</block>
  <block id="b9e807b01f3ef86c9dfed350c8c3d49f" category="cell">Pila de software NVIDIA DGX</block>
  <block id="32ac4a04c126e4e450b2f93ae6cfd3a7" category="cell">Sistema de archivos paralelo ThinkParQ BeeGFS</block>
  <block id="dc140913e754c7554bc598a02951fa66" category="section-title">Verificación de la solución</block>
  <block id="f95f7879d178879af0b5a728259ce9a3" category="inline-link">NVIDIA DGX SuperPOD: Arquitectura de referencia NetApp EF600 y BeeGFS</block>
  <block id="24e45924f52e38078756fd5fb1d83668" category="paragraph">NVIDIA DGX SuperPOD con NetApp se validó en un clúster de aceptación dedicado en NVIDIA mediante el uso de bloques de construcción BeeGFS de NetApp .  Los criterios de aceptación se basaron en una serie de pruebas de aplicación, rendimiento y estrés realizadas por NVIDIA. Para obtener más información, consulte la<block ref="2ffc6657f5234f1aed913433d4ce09f3" category="inline-link-rx"></block> .</block>
  <block id="b7f81445ff8908f0aa2a3356e8231f05" category="paragraph">NetApp y NVIDIA tienen una larga trayectoria de colaboración para ofrecer una cartera de soluciones de IA al mercado.  NVIDIA DGX SuperPOD con la matriz all-flash NetApp EF600 es una solución probada y validada que los clientes pueden implementar con confianza.  Esta arquitectura llave en mano totalmente integrada elimina el riesgo de la implementación y pone a cualquiera en el camino para ganar la carrera hacia el liderazgo en IA.</block>
  <block id="dcd86a18e8aa77675f1b2f792cb6ba5c" category="inline-link-macro">Arquitectura de referencia NVIDIA DGX SuperPOD</block>
  <block id="98d56828382118fe5dcd8ef673b93afb" category="list-text"><block ref="98d56828382118fe5dcd8ef673b93afb" category="inline-link-macro-rx"></block></block>
  <block id="4fafe9ef5c2efce123913e9ac744f4d6" category="inline-link-macro">Guía de referencia de diseño de centros de datos NVIDIA DGX SuperPOD</block>
  <block id="473bfb82bbec433a8f08fa15c67e0c08" category="list-text"><block ref="473bfb82bbec433a8f08fa15c67e0c08" category="inline-link-macro-rx"></block></block>
  <block id="6f698ddb1773933b8e41b2ed16297ce7" category="inline-link-macro">NVIDIA DGX SuperPOD: NetApp EF600 y BeeGFS</block>
  <block id="a552f45479fc3484a4356ed78090fa76" category="list-text"><block ref="7f25f2868948e2fffc54c32cf9c33644" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">La automatización impulsada por IA y la computación de borde son un enfoque líder para ayudar a las organizaciones comerciales a lograr la transformación digital y maximizar la eficiencia y la seguridad operativa.  Con la computación de borde, los datos se procesan mucho más rápido porque no tienen que viajar hacia y desde un centro de datos.  Por lo tanto, se reduce el coste asociado al envío de datos de ida y vuelta a los centros de datos o a la nube.</block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">La automatización impulsada por IA y la computación de borde son un enfoque líder para ayudar a las organizaciones comerciales a lograr la transformación digital y maximizar la eficiencia y la seguridad operativa.  Con la computación de borde, los datos se procesan mucho más rápido porque no tienen que viajar hacia y desde un centro de datos.  Por lo tanto, se reduce el coste asociado al envío de datos de ida y vuelta a los centros de datos o a la nube.  Una menor latencia y una mayor velocidad pueden ser beneficiosas cuando las empresas deben tomar decisiones casi en tiempo real utilizando modelos de inferencia de IA implementados en el borde.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">Los sistemas de almacenamiento de NetApp ofrecen el mismo rendimiento o uno mejor que el almacenamiento SSD local y ofrecen los siguientes beneficios a científicos de datos, ingenieros de datos, desarrolladores de IA/ML y tomadores de decisiones comerciales o de TI:</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">Intercambio de datos sin esfuerzo entre sistemas de IA, análisis y otros sistemas comerciales críticos.  Este intercambio de datos reduce la sobrecarga de infraestructura, mejora el rendimiento y agiliza la gestión de datos en toda la empresa.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">Computación y almacenamiento escalables de forma independiente para minimizar costos y mejorar el uso de recursos.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">Flujos de trabajo de desarrollo e implementación optimizados mediante copias Snapshot y clones integrados para espacios de trabajo de usuario instantáneos y que ahorran espacio, control de versiones integrado e implementación automatizada.</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">Protección de datos de nivel empresarial para recuperación ante desastres y continuidad comercial.  La solución de NetApp y Lenovo presentada en este documento es una arquitectura flexible y escalable que es ideal para implementaciones de inferencia de IA de nivel empresarial en el borde.</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">Expresiones de gratitud</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">JJ  Falkanger, director sénior de soluciones HPC e IA, Lenovo</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, ingeniero de marketing técnico, NetApp</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, director técnico de soluciones de IA de la serie E, NetApp</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman, ingeniero de control de calidad, NetApp</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">Para obtener más información sobre la información descrita en este documento, consulte los siguientes documentos y/o sitios web:</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">Página de producto de matrices NetApp AFF Serie A</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">Software de gestión de datos NetApp ONTAP: biblioteca de información ONTAP 9</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727: Introducción a la serie EF de NetApp</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">Hoja de datos del software SANtricity de la serie E de NetApp</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">Almacenamiento persistente de NetApp para contenedores: NetApp Trident</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="list-text">MLPerf</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">Prueba de referencia de TensorFlow</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="list-text">Servidor perimetral Lenovo ThinkSystem SE350</block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Matriz de almacenamiento flash unificada Lenovo ThinkSystem DM5100F</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="a4113bc79b3920d11274d7bf9cfafe10" category="paragraph"><block ref="a4113bc79b3920d11274d7bf9cfafe10" category="inline-link-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">Esta sección describe las configuraciones probadas, la infraestructura de red, el servidor SE350 y los detalles de aprovisionamiento de almacenamiento.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">Configuración de prueba</block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">La siguiente figura muestra la configuración de la prueba.  Utilizamos el sistema de almacenamiento NetApp AFF C190 y dos servidores Lenovo ThinkSystem SE350 (cada uno con un acelerador NVIDIA T4).  Estos componentes están conectados a través de un conmutador de red 10GbE.  El almacenamiento en red contiene conjuntos de datos de validación/prueba y modelos previamente entrenados.  Los servidores proporcionan capacidad computacional y se accede al almacenamiento a través del protocolo NFS.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">Esta sección describe las configuraciones probadas, la infraestructura de red, el servidor SE350 y los detalles de aprovisionamiento de almacenamiento.  En la siguiente tabla se enumeran los componentes básicos para la arquitectura de la solución.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="cell">Servidores Lenovo ThinkSystem</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2 servidores SE350 cada uno con una tarjeta GPU NVIDIA T4</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">Cada servidor contiene una CPU Intel Xeon D-2123IT con cuatro núcleos físicos que funcionan a 2,20 GHz y 128 GB de RAM.</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">Sistema de almacenamiento NetApp AFF de nivel básico (par HA)</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">Software NetApp ONTAP 9</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24 SSD de 960 GB</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">Protocolo NFS</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">Un grupo de interfaces por controlador, con cuatro direcciones IP lógicas para puntos de montaje</block>
  <block id="e2921b0ff5efef521f662303c467e27f" category="paragraph"><block ref="e2921b0ff5efef521f662303c467e27f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">La siguiente tabla enumera la configuración de almacenamiento: AFF C190 con 2RU, 24 ranuras de unidad.</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">Controladora</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Agregar</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">Volumen de FlexGroup</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">Tamaño agregado</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">Tamaño del volumen</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">Punto de montaje del sistema operativo</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Controller1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Aggr1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netapplenovo_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Controller2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Aggr2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">La carpeta /netappLenovo_AI_fg contiene los conjuntos de datos utilizados para la validación del modelo.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">La siguiente figura muestra la configuración de la prueba.  Utilizamos el sistema de almacenamiento NetApp EF280 y dos servidores Lenovo ThinkSystem SE350 (cada uno con un acelerador NVIDIA T4).  Estos componentes están conectados a través de un conmutador de red 10GbE.  El almacenamiento en red contiene conjuntos de datos de validación/prueba y modelos previamente entrenados.  Los servidores proporcionan capacidad computacional y se accede al almacenamiento a través del protocolo NFS.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">La siguiente tabla enumera la configuración de almacenamiento para EF280.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">Grupo de volúmenes</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">Volumen</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">Tamaño DDP</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">Método de conexión</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">Volumen 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 a iSCSI LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">Volumen 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 a iSCSI LUN 1</block>
  <block id="7192b14affaba8b38680e0cd3749622e" category="paragraph"><block ref="7192b14affaba8b38680e0cd3749622e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">Este documento describe una arquitectura de computación y almacenamiento para implementar inferencia de inteligencia artificial (IA) basada en GPU en controladores de almacenamiento NetApp y servidores Lenovo ThinkSystem en un entorno de borde que satisface escenarios de aplicaciones emergentes.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886: Inferencia de IA en el borde - NetApp con Lenovo ThinkSystem - Diseño de soluciones</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="290612199861c31d1036b185b4e69b75" category="section-title">Resumen</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">Varios escenarios de aplicación emergentes, como los sistemas avanzados de asistencia al conductor (ADAS), la Industria 4.0, las ciudades inteligentes y la Internet de las cosas (IoT), requieren el procesamiento de flujos de datos continuos con una latencia cercana a cero.  Este documento describe una arquitectura de computación y almacenamiento para implementar inferencia de inteligencia artificial (IA) basada en GPU en controladores de almacenamiento NetApp y servidores Lenovo ThinkSystem en un entorno de borde que cumple con estos requisitos.  Este documento también proporciona datos de rendimiento para el punto de referencia de inferencia MLPerf, estándar de la industria, que evalúa varias tareas de inferencia en servidores perimetrales equipados con GPU NVIDIA T4.  Investigamos el rendimiento de escenarios de inferencia fuera de línea, de flujo único y de múltiples flujos y demostramos que la arquitectura con un sistema de almacenamiento en red compartido rentable tiene un gran rendimiento y proporciona un punto central para la gestión de datos y modelos para múltiples servidores de borde.</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">Las empresas generan cada vez más volúmenes masivos de datos en el borde de la red.  Para obtener el máximo valor de los sensores inteligentes y los datos de IoT, las organizaciones buscan una solución de transmisión de eventos en tiempo real que permita la computación de borde.  Por lo tanto, los trabajos que requieren un alto nivel de exigencia computacional se realizan cada vez más en el borde, fuera de los centros de datos.  La inferencia de IA es uno de los impulsores de esta tendencia.  Los servidores de borde proporcionan suficiente potencia computacional para estas cargas de trabajo, especialmente cuando se utilizan aceleradores, pero el almacenamiento limitado suele ser un problema, especialmente en entornos de múltiples servidores.  En este documento mostramos cómo se puede implementar un sistema de almacenamiento compartido en el entorno de borde y cómo beneficia las cargas de trabajo de inferencia de IA sin imponer una penalización en el rendimiento.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">Este documento describe una arquitectura de referencia para la inferencia de IA en el borde.  Combina varios servidores edge Lenovo ThinkSystem con un sistema de almacenamiento NetApp para crear una solución fácil de implementar y administrar.  Se pretende que sea una guía de base para implementaciones prácticas en diversas situaciones, como en el área de producción con múltiples cámaras y sensores industriales, sistemas de puntos de venta (POS) en transacciones minoristas o sistemas de conducción autónoma total (FSD) que identifican anomalías visuales en vehículos autónomos.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">Este documento cubre las pruebas y la validación de una configuración de cómputo y almacenamiento que consta de un servidor Lenovo ThinkSystem SE350 Edge y un sistema de almacenamiento NetApp AFF y EF-Series de nivel básico.  Las arquitecturas de referencia brindan una solución eficiente y rentable para implementaciones de IA al mismo tiempo que brindan servicios de datos integrales, protección de datos integrada, escalabilidad perfecta y almacenamiento de datos conectado a la nube con el software de gestión de datos NetApp ONTAP y NetApp SANtricity .</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">Este documento está dirigido a los siguientes públicos:</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">Líderes empresariales y arquitectos empresariales que desean convertir la IA en un producto en el borde.</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">Científicos de datos, ingenieros de datos, investigadores de IA/aprendizaje automático (ML) y desarrolladores de sistemas de IA.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">Arquitectos empresariales que diseñan soluciones para el desarrollo de modelos y aplicaciones de IA/ML.</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">Científicos de datos e ingenieros de IA que buscan formas eficientes de implementar modelos de aprendizaje profundo (DL) y ML.</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">Administradores de dispositivos perimetrales y administradores de servidores perimetrales responsables de la implementación y la administración de modelos de inferencia perimetral.</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">Arquitectura de la solución</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">Esta solución de almacenamiento NetApp ONTAP o NetApp SANtricity y servidor Lenovo ThinkSystem está diseñada para manejar la inferencia de IA en grandes conjuntos de datos utilizando la potencia de procesamiento de las GPU junto con las CPU tradicionales.  Esta validación demuestra un alto rendimiento y una gestión óptima de datos con una arquitectura que utiliza uno o varios servidores perimetrales Lenovo SR350 interconectados con un único sistema de almacenamiento NetApp AFF , como se muestra en las dos figuras siguientes.</block>
  <block id="f21cce3e60a01cff1e8e221c6536fe78" category="paragraph"><block ref="f21cce3e60a01cff1e8e221c6536fe78" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94aa1b43a547a9dd2c4d023dbc98322b" category="paragraph"><block ref="94aa1b43a547a9dd2c4d023dbc98322b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">La descripción general de la arquitectura lógica en la siguiente figura muestra las funciones de los elementos de cómputo y almacenamiento en esta arquitectura.  En concreto, muestra lo siguiente:</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">Dispositivos informáticos de borde que realizan inferencias sobre los datos que reciben de cámaras, sensores, etc.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">Un elemento de almacenamiento compartido que sirve para múltiples propósitos:</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">Proporciona una ubicación central para los modelos de inferencia y otros datos necesarios para realizar la inferencia.  Los servidores de cómputo acceden directamente al almacenamiento y utilizan modelos de inferencia en toda la red sin necesidad de copiarlos localmente.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">Los modelos actualizados se envían aquí.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">Archiva datos de entrada que los servidores perimetrales reciben para su posterior análisis.  Por ejemplo, si los dispositivos de borde están conectados a cámaras, el elemento de almacenamiento mantiene los vídeos capturados por las cámaras.</block>
  <block id="3c5974fb92ca4b40257a58c213d0f137" category="paragraph"><block ref="3c5974fb92ca4b40257a58c213d0f137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">rojo</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">azul</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Sistema informático Lenovo</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">Sistema de almacenamiento NetApp AFF</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">Dispositivos de borde que realizan inferencias sobre las entradas de cámaras, sensores, etc.</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">Almacenamiento compartido que contiene modelos de inferencia y datos de dispositivos perimetrales para su posterior análisis.</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">Esta solución de NetApp y Lenovo ofrece los siguientes beneficios clave:</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">Computación acelerada por GPU en el borde.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">Implementación de múltiples servidores de borde respaldados y administrados desde un almacenamiento compartido.</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">Protección de datos robusta para cumplir con objetivos de punto de recuperación (RPO) bajos y objetivos de tiempo de recuperación (RTO) sin pérdida de datos.</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">Gestión de datos optimizada con copias y clones de NetApp Snapshot para agilizar los flujos de trabajo de desarrollo.</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">Cómo utilizar esta arquitectura</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">Este documento valida el diseño y el rendimiento de la arquitectura propuesta.  Sin embargo, no hemos probado ciertas piezas a nivel de software, como la gestión de contenedores, cargas de trabajo o modelos y la sincronización de datos con la nube o el centro de datos local, porque son específicas de un escenario de implementación.  Aquí existen múltiples opciones.</block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="inline-link-macro">Plano de control de IA de NetApp</block>
  <block id="bfbeeaf5d09672568692829ade4ca556" category="paragraph">A nivel de gestión de contenedores, la gestión de contenedores de Kubernetes es una buena opción y cuenta con un buen soporte tanto en una versión totalmente upstream (Canonical) como en una versión modificada adecuada para implementaciones empresariales (Red Hat).  El<block ref="cba35aa1f9d4aeed351c50bd57559a4d" category="inline-link-macro-rx"></block> que utiliza NetApp Trident y el recién agregado<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> Proporciona trazabilidad integrada, funciones de gestión de datos, interfaces y herramientas para que los científicos e ingenieros de datos se integren con el almacenamiento de NetApp .  Kubeflow, el kit de herramientas de ML para Kubernetes, proporciona capacidades de IA adicionales junto con soporte para control de versiones de modelos y KFServing en varias plataformas como TensorFlow Serving o NVIDIA Triton Inference Server.  Otra opción es la plataforma NVIDIA EGX, que proporciona gestión de carga de trabajo junto con acceso a un catálogo de contenedores de inferencia de IA habilitados para GPU.  Sin embargo, estas opciones pueden requerir un esfuerzo y una experiencia importantes para ponerlas en producción y pueden requerir la asistencia de un consultor o proveedor de software independiente (ISV).</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">Áreas de solución</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">El beneficio clave de la inferencia de IA y la computación de borde es la capacidad de los dispositivos de calcular, procesar y analizar datos con un alto nivel de calidad sin latencia.  Hay demasiados ejemplos de casos de uso de computación de borde para describirlos en este documento, pero aquí hay algunos destacados:</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">Automóviles: vehículos autónomos</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">El ejemplo clásico de computación de borde se encuentra en los sistemas avanzados de asistencia al conductor (ADAS) en vehículos autónomos (AV).  La IA de los coches sin conductor debe procesar rápidamente una gran cantidad de datos de cámaras y sensores para ser un conductor seguro y exitoso.  Tomar demasiado tiempo para interpretar la diferencia entre un objeto y un humano puede significar vida o muerte, por lo tanto, poder procesar esos datos lo más cerca posible del vehículo es crucial.  En este caso, uno o más servidores informáticos de borde manejan la entrada de cámaras, RADAR, LiDAR y otros sensores, mientras que el almacenamiento compartido contiene modelos de inferencia y almacena datos de entrada de los sensores.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">Atención sanitaria: Monitorización de pacientes</block>
  <block id="bace962401fe7f588dcfdc4444fa9cfd" category="paragraph">Uno de los mayores impactos de la IA y la computación de borde es su capacidad para mejorar el monitoreo continuo de pacientes con enfermedades crónicas tanto en atención domiciliaria como en unidades de cuidados intensivos (UCI).  Los datos de los dispositivos periféricos que monitorean los niveles de insulina, la respiración, la actividad neurológica, el ritmo cardíaco y las funciones gastrointestinales requieren un análisis instantáneo de datos que se deben procesar de inmediato porque hay tiempo limitado para actuar y salvar la vida de alguien.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">Comercio minorista: Pago sin cajero</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">La computación de borde puede potenciar la IA y el ML para ayudar a los minoristas a reducir el tiempo de pago y aumentar el tráfico peatonal.  Los sistemas sin cajero admiten varios componentes, como los siguientes:</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">Autenticación y acceso.  Conectar al comprador físico a una cuenta validada y permitir el acceso al espacio minorista.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">Monitoreo de inventario.  Utilizando sensores, etiquetas RFID y sistemas de visión artificial para ayudar a confirmar la selección o deselección de artículos por parte de los compradores.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">Aquí, cada uno de los servidores perimetrales gestiona cada mostrador de pago y el sistema de almacenamiento compartido sirve como punto de sincronización central.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">Servicios financieros: seguridad humana en los quioscos y prevención del fraude</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">Las organizaciones bancarias están utilizando inteligencia artificial y computación de borde para innovar y crear experiencias bancarias personalizadas.  Los quioscos interactivos que utilizan análisis de datos en tiempo real e inferencia de inteligencia artificial ahora permiten a los cajeros automáticos no solo ayudar a los clientes a retirar dinero, sino también monitorear de manera proactiva los quioscos a través de las imágenes capturadas por las cámaras para identificar riesgos para la seguridad humana o comportamiento fraudulento.  En este escenario, los servidores informáticos de borde y los sistemas de almacenamiento compartido están conectados a quioscos y cámaras interactivas para ayudar a los bancos a recopilar y procesar datos con modelos de inferencia de IA.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">Manufactura: Industria 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">La cuarta revolución industrial (Industria 4.0) ha comenzado, junto con tendencias emergentes como Smart Factory y la impresión 3D.  Para prepararse para un futuro basado en datos, la comunicación de máquina a máquina (M2M) a gran escala y la IoT se integran para una mayor automatización sin necesidad de intervención humana.  La fabricación ya está altamente automatizada y agregar funciones de IA es una continuación natural de la tendencia a largo plazo.  La IA permite automatizar operaciones que pueden automatizarse con la ayuda de la visión artificial y otras capacidades de IA.  Puede automatizar el control de calidad o las tareas que dependen de la visión humana o la toma de decisiones para realizar análisis más rápidos de los materiales en las líneas de ensamblaje de las fábricas para ayudar a las plantas de fabricación a cumplir con los estándares ISO requeridos de seguridad y gestión de calidad.  Aquí, cada servidor de borde computacional está conectado a una serie de sensores que monitorean el proceso de fabricación y los modelos de inferencia actualizados se envían al almacenamiento compartido, según sea necesario.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">Telecomunicaciones: Detección de óxido, inspección de torres y optimización de redes</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">La industria de las telecomunicaciones utiliza técnicas de visión artificial e inteligencia artificial para procesar imágenes que detectan automáticamente el óxido e identifican las torres de telefonía celular que contienen corrosión y, por lo tanto, requieren una inspección más profunda.  El uso de imágenes de drones y modelos de IA para identificar regiones distintas de una torre para analizar el óxido, las grietas superficiales y la corrosión ha aumentado en los últimos años.  La demanda de tecnologías de IA que permitan inspeccionar eficientemente la infraestructura de telecomunicaciones y las torres de telefonía celular, evaluarlas periódicamente para detectar degradación y repararlas rápidamente cuando sea necesario continúa creciendo.</block>
  <block id="d88e40cd850f8bd6b5e737761a1786fd" category="paragraph">Además, otro caso de uso emergente en telecomunicaciones es el uso de algoritmos de IA y ML para predecir patrones de tráfico de datos, detectar dispositivos con capacidad 5G y automatizar y aumentar la gestión de energía de múltiples entradas y múltiples salidas (MIMO).  El hardware MIMO se utiliza en torres de radio para aumentar la capacidad de la red; sin embargo, esto implica costos de energía adicionales.  Los modelos ML para el "modo de suspensión MIMO" implementados en sitios celulares pueden predecir el uso eficiente de las radios y ayudar a reducir los costos de consumo de energía para los operadores de redes móviles (MNO).  Las soluciones de inferencia de IA y computación de borde ayudan a los MNO a reducir la cantidad de datos transmitidos entre centros de datos, disminuir su TCO, optimizar las operaciones de red y mejorar el rendimiento general para los usuarios finales.</block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">Este documento sigue el código de MLPerf Inference v0.7, el código y las reglas de MLPerf Inference v1.1.  Ejecutamos puntos de referencia diseñados para la inferencia en el borde tal como se define en las tablas presentadas en esta sección.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">Plan de pruebas</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">código</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">normas</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">Este documento sigue la inferencia MLPerf v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> Inferencia MLPerf v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> , y<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block> .  Ejecutamos puntos de referencia MLPerf diseñados para la inferencia en el borde como se define en la siguiente tabla.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">Área</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">Modelo</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">Conjunto de datos</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">Tamaño de QSL</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">Calidad</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">Restricción de latencia de múltiples transmisiones</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">Visión</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">Clasificación de imágenes</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet (224x224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">99% de FP32</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 ms</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">Detección de objetos (grandes)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD-ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">COCO (1200x1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 ms</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">Detección de objetos (pequeños)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD - MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">COCO (300x300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">Segmentación de imágenes médicas</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">BraTS 2019 (224x224x160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">99% y 99,9% de FP32</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">Discurso</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">Conversión de voz a texto</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">Enfermera registrada</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Librispeech dev-clean</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">Idioma</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">Procesamiento del lenguaje</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">Escuadrón v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">La siguiente tabla presenta escenarios de referencia de Edge.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">Escenarios</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">Clasificación de imágenes</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">Transmisión única, sin conexión, transmisión múltiple</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">Transmisión única, sin conexión</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">Conversión de voz a texto</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">Realizamos estas pruebas de referencia utilizando la arquitectura de almacenamiento en red desarrollada en esta validación y comparamos los resultados con los de ejecuciones locales en los servidores de borde enviados previamente a MLPerf.  La comparación sirve para determinar cuánto impacto tiene el almacenamiento compartido en el rendimiento de la inferencia.</block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">Esta sección describe los procedimientos de prueba utilizados para validar esta solución.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">Procedimiento de prueba</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">Configuración del sistema operativo y de la inferencia de IA</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">Para AFF C190, usamos Ubuntu 18.04 con controladores NVIDIA y Docker con soporte para GPU NVIDIA y usamos MLPerf<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> disponible como parte del envío de Lenovo a MLPerf Inference v0.7.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">Para EF280, usamos Ubuntu 20.04 con controladores NVIDIA y Docker con soporte para GPU NVIDIA y MLPerf<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> disponible como parte del envío de Lenovo a MLPerf Inference v1.1.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">Para configurar la inferencia de IA, siga estos pasos:</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">Descargue los conjuntos de datos que requieren registro, el conjunto de validación ImageNet 2012, el conjunto de datos Criteo Terabyte y el conjunto de entrenamiento BraTS 2019 y luego descomprima los archivos.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">Cree un directorio de trabajo con al menos 1 TB y defina una variable ambiental<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block> haciendo referencia al directorio.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">Debe compartir este directorio en el almacenamiento compartido para el caso de uso de almacenamiento en red, o en el disco local cuando realice pruebas con datos locales.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">Ejecutar la marca<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block> comando, que construye y lanza el contenedor Docker para las tareas de inferencia requeridas.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">Los siguientes comandos se ejecutan todos desde dentro del contenedor Docker en ejecución:</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">Descargue modelos de IA preentrenados para tareas de inferencia de MLPerf:<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">Descargue conjuntos de datos adicionales que se pueden descargar gratuitamente:<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">Preprocesar los datos: hacer<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">Correr:<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block> .</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">Cree motores de inferencia optimizados para la GPU en servidores de cómputo:<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">Para ejecutar cargas de trabajo de inferencia, ejecute lo siguiente (un comando):</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">Ejecuciones de inferencia de IA</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">Se ejecutaron tres tipos de carreras:</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">Inferencia de IA de un solo servidor mediante almacenamiento local</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">Inferencia de IA de un solo servidor mediante almacenamiento en red</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">Inferencia de IA multiservidor mediante almacenamiento en red</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">Se realizaron multitud de pruebas para evaluar el rendimiento de la arquitectura propuesta.  Hay seis cargas de trabajo diferentes (clasificación de imágenes, detección de objetos [pequeños], detección de objetos [grandes], imágenes médicas, conversión de voz a texto y procesamiento del lenguaje natural [PLN]), que puede ejecutar en tres escenarios diferentes: sin conexión, transmisión única y transmisión múltiple.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">Resultados de la prueba</block>
  <block id="a274daca2deace9b89099b24f248715c" category="paragraph">Se realizaron multitud de pruebas para evaluar el rendimiento de la arquitectura propuesta.</block>
  <block id="37bf74d7f686cd395d40af1cc2ed7c55" category="paragraph">Hay seis cargas de trabajo diferentes (clasificación de imágenes, detección de objetos [pequeños], detección de objetos [grandes], imágenes médicas, conversión de voz a texto y procesamiento del lenguaje natural [PLN]), que puede ejecutar en tres escenarios diferentes: sin conexión, transmisión única y transmisión múltiple.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">El último escenario se implementa solo para la clasificación de imágenes y la detección de objetos.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">Esto da 15 cargas de trabajo posibles, todas ellas probadas en tres configuraciones diferentes:</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">Servidor único/almacenamiento local</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">Almacenamiento en red/servidor único</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">Almacenamiento en red/multiservidor</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">Los resultados se describen en las siguientes secciones.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">Inferencia de IA en un escenario fuera de línea para AFF</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">En este escenario, todos los datos estaban disponibles en el servidor y se midió el tiempo que tardaba en procesar todas las muestras.  Informamos los anchos de banda en muestras por segundo como resultados de las pruebas.  Cuando se utilizó más de un servidor de cómputo, informamos el ancho de banda total sumado entre todos los servidores.  Los resultados para los tres casos de uso se muestran en la siguiente figura.  Para el caso de dos servidores, informamos el ancho de banda combinado de ambos servidores.</block>
  <block id="50c1d1baa999e0997ecc5b2fb7ce848c" category="paragraph"><block ref="50c1d1baa999e0997ecc5b2fb7ce848c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">Los resultados muestran que el almacenamiento en red no afecta negativamente el rendimiento: el cambio es mínimo y, para algunas tareas, no se encuentra ninguno.  Al agregar el segundo servidor, el ancho de banda total se duplica exactamente o, en el peor de los casos, el cambio es inferior al 1 %.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">Inferencia de IA en un escenario de flujo único para AFF</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">Este punto de referencia mide la latencia.  Para el caso de servidores computacionales múltiples, informamos la latencia promedio.  Los resultados para el conjunto de tareas se muestran en la siguiente figura.  Para el caso de dos servidores, informamos la latencia promedio de ambos servidores.</block>
  <block id="e3a127ece515b351ac983cdc09f48eb3" category="paragraph"><block ref="e3a127ece515b351ac983cdc09f48eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">Los resultados muestran nuevamente que el almacenamiento en red es suficiente para manejar las tareas.  La diferencia entre el almacenamiento local y el almacenamiento en red en el caso de un servidor es mínima o nula.  De manera similar, cuando dos servidores usan el mismo almacenamiento, la latencia en ambos servidores permanece igual o cambia en una cantidad muy pequeña.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">Inferencia de IA en un escenario multisecuencia para AFF</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">En este caso, el resultado es la cantidad de transmisiones que el sistema puede manejar mientras satisface la restricción de QoS.  Por tanto, el resultado es siempre un número entero.  Para más de un servidor, informamos el número total de transmisiones sumadas en todos los servidores.  No todas las cargas de trabajo admiten este escenario, pero hemos ejecutado las que sí lo hacen. Los resultados de nuestras pruebas se resumen en la siguiente figura.  Para el caso de dos servidores, informamos el número combinado de transmisiones de ambos servidores.</block>
  <block id="79bd7075b14462178ff1e836cefd5d04" category="paragraph"><block ref="79bd7075b14462178ff1e836cefd5d04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">Los resultados muestran un rendimiento perfecto de la configuración: el almacenamiento local y en red dan los mismos resultados y agregar el segundo servidor duplica la cantidad de transmisiones que la configuración propuesta puede manejar.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">Resultados de la prueba de EF</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">Se realizaron multitud de pruebas para evaluar el rendimiento de la arquitectura propuesta.  Hay seis cargas de trabajo diferentes (clasificación de imágenes, detección de objetos [pequeños], detección de objetos [grandes], imágenes médicas, conversión de voz a texto y procesamiento del lenguaje natural [PLN]), que se ejecutaron en dos escenarios diferentes: fuera de línea y en flujo único.  Los resultados se describen en las siguientes secciones.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">Inferencia de IA en un escenario fuera de línea para EF</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">En este escenario, todos los datos estaban disponibles en el servidor y se midió el tiempo que tardaba en procesar todas las muestras.  Informamos los anchos de banda en muestras por segundo como resultados de las pruebas.  Para ejecuciones de un solo nodo, informamos el promedio de ambos servidores, mientras que para ejecuciones de dos servidores, informamos el ancho de banda total sumado de todos los servidores.  Los resultados de los casos de uso se muestran en la siguiente figura.</block>
  <block id="063dd3a1aadafc5ef1c52be7451bda1d" category="paragraph"><block ref="063dd3a1aadafc5ef1c52be7451bda1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">Inferencia de IA en un escenario de flujo único para EF</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">Este punto de referencia mide la latencia.  Para todos los casos, informamos la latencia promedio en todos los servidores involucrados en las ejecuciones.  Se dan los resultados para el conjunto de tareas.</block>
  <block id="bcd5a75126c6cafd37838b2f3c6e138b" category="paragraph"><block ref="bcd5a75126c6cafd37838b2f3c6e138b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">Los resultados muestran nuevamente que el almacenamiento en red es suficiente para manejar las tareas.  La diferencia entre el almacenamiento local y el de red en el caso de un servidor es mínima o nula.  De manera similar, cuando dos servidores usan el mismo almacenamiento, la latencia en ambos servidores permanece igual o cambia en una cantidad muy pequeña.</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">Puede ajustar la configuración utilizada para la validación para que se adapte a otros casos de uso.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">Opciones de dimensionamiento de la arquitectura</block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">Servidor de cómputo</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">Utilizamos una CPU Intel Xeon D-2123IT, que es el nivel más bajo de CPU compatible con SE350, con cuatro núcleos físicos y TDP de 60 W.  Si bien el servidor no admite el reemplazo de CPU, es posible solicitarlo con una CPU más potente.  La CPU superior compatible es Intel Xeon D-2183IT con 16 núcleos, 100 W funcionando a 2,20 GHz.  Esto aumenta considerablemente la capacidad de cálculo de la CPU.  Si bien la CPU no fue un cuello de botella para ejecutar las cargas de trabajo de inferencia en sí, ayuda con el procesamiento de datos y otras tareas relacionadas con la inferencia.  Actualmente, NVIDIA T4 es la única GPU disponible para casos de uso perimetral; por lo tanto, actualmente no es posible actualizar o degradar la GPU.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">Almacenamiento compartido</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">Para las pruebas y la validación, se utilizó el sistema NetApp AFF C190 , que tiene una capacidad de almacenamiento máxima de 50,5 TB, un rendimiento de 4,4 GBps para lecturas secuenciales y 230 000 IOPS para lecturas aleatorias pequeñas, para el propósito de este documento y ha demostrado ser adecuado para cargas de trabajo de inferencia de borde.</block>
  <block id="44114b1635cead15f56735bad0467251" category="inline-link">NetApp EF300</block>
  <block id="043774815e3806ded716086e0c8c3d03" category="paragraph">Sin embargo, si necesita más capacidad de almacenamiento o velocidades de red más rápidas, debe utilizar los sistemas de almacenamiento NetApp AFF A220 o NetApp AFF A250 .  Además, para la validación de esta solución también se utilizó el sistema NetApp EF280, que tiene una capacidad máxima de 1,5 PB y un ancho de banda de 10 GBps.  Si prefiere más capacidad de almacenamiento con mayor ancho de banda,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> puede ser utilizado</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">Esta sección describe la base tecnológica de esta solución de IA.</block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">Sistemas AFF de NetApp</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">Los sistemas de almacenamiento AFF de última generación de NetApp permiten implementaciones de inferencia de IA en el borde para satisfacer los requisitos de almacenamiento empresarial con un rendimiento líder en la industria, flexibilidad superior, integración en la nube y la mejor gestión de datos de su clase.  Diseñados específicamente para flash, los sistemas AFF de NetApp ayudan a acelerar, administrar y proteger datos críticos para el negocio.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">Los sistemas de almacenamiento AFF de nivel básico de NetApp se basan en hardware FAS2750 y medios flash SSD.</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">Dos controladores en configuración HA</block>
  <block id="b2ed189fbf328f509ec4ca77960d3e1a" category="paragraph"><block ref="b2ed189fbf328f509ec4ca77960d3e1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">Los sistemas de almacenamiento AFF C190 de nivel de entrada de NetApp admiten las siguientes características:</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">Un número máximo de unidades de 24 SSD de 960 GB</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">Dos configuraciones posibles:</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">Ethernet (10GbE): 4 puertos 10GBASE-T (RJ-45)</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">Unificado (16 Gb FC o 10 GbE): 4 puertos de adaptador de destino unificado 2 (UTA2)</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">Una capacidad efectiva máxima de 50,5 TB</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">Para cargas de trabajo NAS, un único sistema AFF C190 de nivel de entrada admite un rendimiento de 4,4 GBps para lecturas secuenciales y 230 000 IOPS para lecturas aleatorias pequeñas con latencias de 1 ms o menos.</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp también ofrece otros sistemas de almacenamiento de nivel de entrada que brindan mayor rendimiento y escalabilidad para implementaciones de mayor escala.  Para cargas de trabajo NAS, un único sistema AFF A220 de nivel básico admite:</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">Rendimiento de 6,2 GBps para lecturas secuenciales</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375 000 IOPS para pequeñas lecturas aleatorias con latencias de 1 ms o menos</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">Cantidad máxima de unidades: 144 SSD de 960 GB, 3,8 TB o 7,6 TB</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 escala a más de 1 PB de capacidad efectiva</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">La capacidad efectiva máxima es de 35 PB con una escalabilidad máxima de 2 a 24 nodos (12 pares de alta disponibilidad)</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">Proporciona un aumento de rendimiento ≥ 45% con respecto a AFF A220</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440k IOPS lecturas aleatorias a 1 ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">Basado en la última versión de NetApp ONTAP : ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">Aprovecha dos Ethernet de 25 Gb para alta disponibilidad e interconexión de clústeres</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">Sistemas EF de la serie E de NetApp</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">La serie EF es una familia de matrices de almacenamiento SAN all-flash de nivel básico y rango medio que pueden acelerar el acceso a sus datos y ayudarlo a obtener valor de ellos más rápidamente con el software SANtricity de NetApp .  Estos sistemas ofrecen almacenamiento flash SAS y NVMe y le brindan IOPS asequibles a extremos, tiempos de respuesta inferiores a 100 microsegundos y un ancho de banda de hasta 44 GBps, lo que los hace ideales para cargas de trabajo mixtas y aplicaciones exigentes como inferencia de IA y computación de alto rendimiento (HPC).</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">La siguiente figura muestra el sistema de almacenamiento NetApp EF280.</block>
  <block id="94bb9af4c6eb62dbf44f691e2565e77e" category="paragraph"><block ref="94bb9af4c6eb62dbf44f691e2565e77e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">Compatibilidad con FC de 32 Gb/16 Gb, iSCSI de 25 Gb/10 Gb y SAS de 12 Gb</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">La capacidad efectiva máxima es de 96 unidades que suman un total de 1,5 PB.</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">Rendimiento de 10 GBps (lecturas secuenciales)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300 000 IOP (lecturas aleatorias)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">El NetApp EF280 es la matriz all-flash (AFA) de menor costo en la cartera de NetApp</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24 unidades SSD NVMe para una capacidad total de 367 TB</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">Opciones de expansión que suman 240 HDD NL-SAS, 96 SSD SAS o una combinación</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">NVMe/IB de 100 Gb, NVMe/RoCE, iSER/IB y SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">NVME/FC de 32 Gb, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">iSCSI de 25 Gb</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20 GBps (lecturas secuenciales)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670 000 IOP (lecturas aleatorias)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">Hoja de datos de las matrices all-flash EF600, F300, EF570 y EF280 de la serie EF de NetApp</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">Para obtener más información, consulte la<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block> .</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1, la última generación de software de gestión de almacenamiento de NetApp, permite a las empresas modernizar la infraestructura y realizar la transición a un centro de datos preparado para la nube.  Al aprovechar las capacidades de gestión de datos líderes en la industria, ONTAP permite la gestión y protección de datos con un único conjunto de herramientas, independientemente de dónde residan esos datos.  También puede mover datos libremente a donde sea necesario: el borde, el núcleo o la nube.  ONTAP 9.8.1 incluye numerosas características que simplifican la gestión de datos, aceleran y protegen datos críticos y habilitan capacidades de infraestructura de próxima generación en arquitecturas de nube híbrida.</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">La gestión de datos es crucial para las operaciones de TI de la empresa, de modo que se utilicen los recursos adecuados para las aplicaciones y los conjuntos de datos.  ONTAP incluye las siguientes características para agilizar y simplificar las operaciones y reducir el costo total de operación:</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*Compactación de datos en línea y deduplicación ampliada.*  La compactación de datos reduce el espacio desperdiciado dentro de los bloques de almacenamiento y la deduplicación aumenta significativamente la capacidad efectiva.  Esto se aplica a los datos almacenados localmente y a los datos almacenados en la nube.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*Calidad de servicio mínima, máxima y adaptativa (AQoS).*  Los controles granulares de calidad de servicio (QoS) ayudan a mantener los niveles de rendimiento de las aplicaciones críticas en entornos altamente compartidos.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool.*  Esta función proporciona niveles automáticos de datos fríos en opciones de almacenamiento en la nube pública y privada, incluidas Amazon Web Services (AWS), Azure y la solución de almacenamiento NetApp StorageGRID .  Para obtener más información sobre FabricPool, consulte<block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block> .</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 ofrece niveles superiores de rendimiento y protección de datos y amplía estas capacidades de las siguientes maneras:</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*Rendimiento y menor latencia.*  ONTAP ofrece el mayor rendimiento posible con la menor latencia posible.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*Protección de datos.*  ONTAP proporciona capacidades de protección de datos integradas con gestión común en todas las plataformas.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* Cifrado de volumen de NetApp (NVE).*  ONTAP ofrece cifrado nativo a nivel de volumen con soporte para administración de claves interna y externa.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*Autenticación multiinquilino y multifactor.*  ONTAP permite compartir recursos de infraestructura con los más altos niveles de seguridad.</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 ayuda a satisfacer necesidades comerciales exigentes y en constante cambio con las siguientes características:</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*Escalamiento sin inconvenientes y operaciones sin interrupciones.*  ONTAP admite la incorporación de capacidad sin interrupciones a controladores existentes y a clústeres de escalamiento horizontal.  Los clientes pueden actualizar a las últimas tecnologías, como NVMe y FC de 32 Gb, sin migraciones de datos costosas ni interrupciones.</block>
  <block id="7d97721ced74a2279b6645f506722980" category="list-text">*Conexión a la nube.*  ONTAP es el software de gestión de almacenamiento más conectado a la nube, con opciones para almacenamiento definido por software (ONTAP Select) e instancias nativas de la nube (Google Cloud NetApp Volumes) en todas las nubes públicas.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*Integración con aplicaciones emergentes.*  ONTAP ofrece servicios de datos de nivel empresarial para plataformas y aplicaciones de próxima generación, como vehículos autónomos, ciudades inteligentes e Industria 4.0, utilizando la misma infraestructura que respalda las aplicaciones empresariales existentes.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">SANtricity de NetApp</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">Hoja de datos del software SANtricity de la serie E de NetApp</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity está diseñado para brindar rendimiento, confiabilidad y simplicidad líderes en la industria a las matrices flash híbridas Serie E y totalmente flash Serie EF.  Logre el máximo rendimiento y utilización de sus matrices flash híbridas Serie E y matrices flash completas Serie EF para aplicaciones de carga de trabajo pesada, incluidos análisis de datos, videovigilancia y copias de seguridad y recuperación.  Con SANtricity, se pueden realizar ajustes de configuración, mantenimiento, expansión de capacidad y otras tareas mientras el almacenamiento permanece en línea.  SANtricity también ofrece protección de datos superior, monitoreo proactivo y seguridad certificada, todo accesible a través de la interfaz del Administrador del sistema incorporada y fácil de usar.  Para obtener más información, consulte el<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block> .</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">Rendimiento optimizado</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">El software SANtricity optimizado para el rendimiento entrega datos (con altas IOP, alto rendimiento y baja latencia) a todas sus aplicaciones de análisis de datos, videovigilancia y respaldo.  Acelere el rendimiento para aplicaciones de alta IOPS, baja latencia y aplicaciones de alto ancho de banda y alto rendimiento.</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">Maximizar el tiempo de actividad</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">Complete todas sus tareas de administración mientras el almacenamiento permanece en línea.  Modifique configuraciones, realice mantenimiento o amplíe la capacidad sin interrumpir la E/S.  Obtenga la mejor confiabilidad de su clase con funciones automatizadas, configuración en línea, tecnología de grupos de discos dinámicos (DPP) de última generación y más.</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">Descansa tranquilo</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">El software SANtricity ofrece protección de datos superior, monitoreo proactivo y seguridad certificada, todo a través de la interfaz System Manager incluida y fácil de usar.  Simplifique las tareas de gestión del almacenamiento.  Obtenga la flexibilidad que necesita para el ajuste avanzado de todos los sistemas de almacenamiento de la Serie E.  Administre su sistema NetApp E-Series en cualquier momento y en cualquier lugar.  Nuestra interfaz web incorporada optimiza su flujo de trabajo de gestión.</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block>NetApp es un orquestador de almacenamiento dinámico de código abierto para Docker y Kubernetes que simplifica la creación, la administración y el consumo de almacenamiento persistente.  Trident, una aplicación nativa de Kubernetes, se ejecuta directamente dentro de un clúster de Kubernetes.  Trident permite a los clientes implementar sin problemas imágenes de contenedores DL en el almacenamiento de NetApp y brinda una experiencia de nivel empresarial para implementaciones de contenedores de IA.  Los usuarios de Kubernetes (como desarrolladores de ML y científicos de datos) pueden crear, administrar y automatizar la orquestación y la clonación para aprovechar las capacidades avanzadas de administración de datos de NetApp impulsadas por la tecnología de NetApp .</block>
  <block id="9b6334cb865bfb3ae702677852339a38" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>Es un servicio de NetApp para la sincronización de datos rápida y segura.  Ya sea que necesite transferir archivos entre recursos compartidos de archivos NFS o SMB locales, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage o IBM Cloud Object Storage, BlueXP Copy and Sync mueve los archivos donde los necesita de forma rápida y segura.  Una vez transferidos los datos, estarán totalmente disponibles para su uso tanto en el origen como en el destino.  BlueXP Copy and Sync sincroniza continuamente los datos, según su programación predefinida, moviendo solo los deltas, por lo que se minimiza el tiempo y el dinero gastados en la replicación de datos.  BlueXP Copy and Sync es una herramienta de software como servicio (SaaS) extremadamente sencilla de configurar y utilizar.  Las transferencias de datos que se activan mediante BlueXP Copy and Sync se llevan a cabo a través de corredores de datos.  Puede implementar agentes de datos de BlueXP Copy and Sync en AWS, Azure, Google Cloud Platform o en las instalaciones locales.</block>
  <block id="8eb0c6a27656d04de6abfc6d24a1a8d5" category="paragraph">Los servidores Lenovo ThinkSystem cuentan con hardware, software y servicios innovadores que resuelven los desafíos de los clientes hoy y ofrecen un enfoque de diseño modular, evolutivo y adaptado a sus necesidades para abordar los desafíos del mañana.  Estos servidores aprovechan las mejores tecnologías estándar de la industria junto con las innovaciones diferenciadas de Lenovo para brindar la mayor flexibilidad posible en servidores x86.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Las principales ventajas de implementar servidores Lenovo ThinkSystem incluyen:</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">Diseños modulares altamente escalables para crecer con su negocio</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">Resiliencia líder en la industria para ahorrar horas de costosos tiempos de inactividad no programados</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">Tecnologías flash rápidas para latencias más bajas, tiempos de respuesta más rápidos y una gestión de datos más inteligente en tiempo real</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">En el área de IA, Lenovo está adoptando un enfoque práctico para ayudar a las empresas a comprender y adoptar los beneficios del aprendizaje automático y la IA para sus cargas de trabajo.  Los clientes de Lenovo pueden explorar y evaluar las ofertas de IA de Lenovo en los Centros de innovación de IA de Lenovo para comprender completamente el valor para su caso de uso particular.  Para mejorar el tiempo necesario para obtener valor, este enfoque centrado en el cliente ofrece a los clientes una prueba de concepto para plataformas de desarrollo de soluciones que están listas para usar y optimizadas para IA.</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">La computación de borde permite analizar los datos de los dispositivos IoT en el borde de la red antes de enviarlos al centro de datos o la nube.  El Lenovo ThinkSystem SE350, como se muestra en la figura a continuación, está diseñado para los requisitos únicos de implementación en el borde, con un enfoque en la flexibilidad, la conectividad, la seguridad y la capacidad de administración remota en un formato compacto, reforzado y resistente al medio ambiente.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">Con el procesador Intel Xeon D y la flexibilidad para soportar la aceleración de cargas de trabajo de IA de borde, el SE350 está diseñado específicamente para abordar el desafío de las implementaciones de servidores en una variedad de entornos fuera del centro de datos.</block>
  <block id="c45cd4236e9fecc47291c206c4aac70a" category="paragraph"><block ref="c45cd4236e9fecc47291c206c4aac70a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16bb0d66e42a8bb99cbefc63c53bcfdc" category="paragraph"><block ref="16bb0d66e42a8bb99cbefc63c53bcfdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">Inferencia MLPerf v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf es el conjunto de referencia líder en la industria para evaluar el rendimiento de la IA.  Cubre muchas áreas de IA aplicada, incluida la clasificación de imágenes, la detección de objetos, las imágenes médicas y el procesamiento del lenguaje natural (PLN).  En esta validación, utilizamos cargas de trabajo de Inferencia v0.7, que es la última iteración de Inferencia MLPerf al finalizar esta validación.  El<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> La suite incluye cuatro nuevos puntos de referencia para centros de datos y sistemas de borde:</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*BERT.*  Representación del codificador bidireccional de transformadores (BERT) optimizada para responder preguntas mediante el uso del conjunto de datos SQuAD.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM.*  El modelo de recomendación de aprendizaje profundo (DLRM) es un modelo de personalización y recomendación que está entrenado para optimizar las tasas de clics (CTR).</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*3D U-Net.*  La arquitectura 3D U-Net está entrenada en el conjunto de datos de segmentación de tumores cerebrales (BraTS).</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T.* El transductor de red neuronal recurrente (RNN-T) es un modelo de reconocimiento automático de voz (ASR) que se entrena en un subconjunto de LibriSpeech.  Los resultados y el código de inferencia de MLPerf están disponibles públicamente y se publican bajo licencia Apache.  MLPerf Inference tiene una división Edge, que admite los siguientes escenarios:</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*Transmisión única.*  Este escenario imita sistemas donde la capacidad de respuesta es un factor crítico, como las consultas de IA sin conexión realizadas en teléfonos inteligentes.  Las consultas individuales se envían al sistema y se registran los tiempos de respuesta.  La latencia del percentil 90 de todas las respuestas se informa como resultado.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*Multitransmisión.*  Este punto de referencia es para sistemas que procesan entradas de múltiples sensores.  Durante la prueba, las consultas se envían en un intervalo de tiempo fijo.  Se impone una restricción de QoS (latencia máxima permitida).  La prueba informa la cantidad de transmisiones que el sistema puede procesar mientras cumple con la restricción de QoS.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*Desconectado.*  Este es el escenario más simple que cubre aplicaciones de procesamiento por lotes y la métrica es el rendimiento en muestras por segundo.  Todos los datos están disponibles para el sistema y el benchmark mide el tiempo que lleva procesar todas las muestras.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="13176cbb826705821e77b735791d29d4" category="paragraph">Lenovo ha publicado las puntuaciones de inferencia de MLPerf para SE350 con T4, el servidor utilizado en este documento.  Vea los resultados en<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> en la sección "Borde, División Cerrada" en la entrada #0.7-145.</block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">La configuración utilizada para la validación se puede ajustar para adaptarse a otros casos de uso.</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">Ajustes de arquitectura</block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">La configuración utilizada para esta validación se puede ajustar para adaptarse a otros casos de uso.</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">Ajustes de la CPU</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">Utilizamos un procesador Skylake Intel Xeon Platinum 8360Y para esta validación, según lo recomendado por Lenovo.  Esperamos que la CPU Cascade Lake equivalente, un procesador Intel Xeon Gold 6330, ofrezca un rendimiento similar porque esta carga de trabajo no está limitada por la CPU.</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">Aumento de la capacidad de almacenamiento</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">Según sus necesidades de capacidad de almacenamiento, puede aumentar el almacenamiento compartido (volumen NFS) a pedido, siempre que tenga estantes de discos y modelos de controlador adicionales.  Puede hacerlo desde la CLI o desde la interfaz web de NetApp del controlador de almacenamiento como usuario administrador.</block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">Esta solución de NetApp y Lenovo es una arquitectura de escalamiento flexible que es ideal para ingresar a la IA empresarial de nivel medio.  El almacenamiento de NetApp ofrece el mismo rendimiento o uno mejor que el almacenamiento SSD local y ofrece los siguientes beneficios a los científicos de datos, ingenieros de datos y tomadores de decisiones de TI.</block>
  <block id="994c1f46e0860094a86d2a822416646b" category="paragraph">La solución de NetApp y Lenovo validada aquí es una arquitectura de escalamiento flexible que es ideal para ingresar a la IA empresarial de nivel medio.</block>
  <block id="bcbfcce438abee9a9a41cb7e588eb4de" category="paragraph">El almacenamiento de NetApp ofrece el mismo rendimiento o mejor que el almacenamiento SSD local y ofrece los siguientes beneficios a los científicos de datos, ingenieros de datos y tomadores de decisiones de TI:</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">Computación y almacenamiento escalables de forma independiente para minimizar costos y mejorar la utilización de recursos.</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">Flujos de trabajo de desarrollo e implementación optimizados mediante instantáneas y clones integrados para espacios de trabajo de usuario instantáneos y que ahorran espacio, control de versiones integrado e implementación automatizada.</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">Protección de datos de nivel empresarial para recuperación ante desastres y continuidad del negocio.</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam, ingeniero de marketing técnico, NetApp</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton, administrador, sistemas de laboratorio de IA, Lenovo</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">Página de productos de matrices all-flash de NetApp</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">Página de NetApp AFF A400</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">Página del producto del software de gestión de datos NetApp ONTAP</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI (nvidia-smi)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">Esta sección describe las configuraciones probadas, la infraestructura de red, el servidor SR670 V2 y los detalles de aprovisionamiento de almacenamiento.</block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">Esta sección describe las configuraciones probadas, la infraestructura de red, el servidor SR670 V2 y los detalles de aprovisionamiento de almacenamiento de NetApp .</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">Para esta validación utilizamos los componentes de la solución enumerados en la siguiente tabla.</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">Dos servidores SR670 V2, cada uno con ocho tarjetas GPU NVIDIA A100 de 80 GB</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">Cada servidor contiene 2 CPU Intel Xeon Platinum 8360Y (28 núcleos físicos) y 1 TB de RAM</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux (Ubuntu – 20.04 con CUDA 11.8)</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">Sistema de almacenamiento NetApp AFF (par HA)</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">Software NetApp ONTAP 9.10.1</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">1 grupo de interfaz (ifgrp) por controlador, con cuatro direcciones IP lógicas para puntos de montaje</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">En esta validación, utilizamos ResNet v2.0 con la base ImageNet establecida según lo especificado por MLPerf v2.0.  El conjunto de datos se almacena en un sistema de almacenamiento NetApp AFF con el protocolo NFS.  Los SR670 se conectaron al sistema de almacenamiento NetApp AFF A400 a través de un conmutador 100 GbE.</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet es un conjunto de datos de imágenes utilizado con frecuencia.  Contiene casi 1,3 millones de imágenes para un tamaño total de 144 GB.  El tamaño promedio de la imagen es 108 KB.</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">La siguiente figura muestra la topología de red de la configuración probada.</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">Este gráfico muestra la capa de cómputo, un Lenovo ThinkSystem SR670 V2, la capa de red, un conmutador Ethernet Lenovo, y la capa de almacenamiento, un controlador de almacenamiento NetApp AFF A400 .  Todas las conexiones de red están incluidas.</block>
  <block id="74ae44f09af988f16e87e4e2e31ef81a" category="paragraph"><block ref="74ae44f09af988f16e87e4e2e31ef81a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">La siguiente tabla enumera la configuración de almacenamiento.</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">Tamaño del agregado</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">Tamaño del volumen</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">Punto de montaje del sistema operativo</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9,9 TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19 TB</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">La carpeta /a400-100g contiene el conjunto de datos utilizado para la validación de ResNet.</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">Esta sección describe los resultados detallados del procedimiento de prueba.</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">Procedimiento de prueba y resultados detallados</block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">Entrenamiento de reconocimiento de imágenes utilizando ResNet en ONTAP</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">Ejecutamos la prueba de rendimiento ResNet50 con uno y dos servidores SR670 V2.  Esta prueba utilizó el contenedor NGC MXNet 22.04-py3 para ejecutar el entrenamiento.</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">Utilizamos el siguiente procedimiento de prueba en esta validación:</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">Limpiamos la memoria caché del host antes de ejecutar el script para asegurarnos de que los datos no estuvieran ya almacenados en caché:</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">Ejecutamos el script de referencia con el conjunto de datos ImageNet en el almacenamiento del servidor (almacenamiento SSD local) así como en el sistema de almacenamiento NetApp AFF .</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">Validamos el rendimiento de la red y el almacenamiento local utilizando el<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> dominio.</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">Para la ejecución de un solo nodo, utilizamos el siguiente comando:</block>
  <block id="cf9a86ba8909a23b4d67d509b389a080" category="list-text">Para las ejecuciones distribuidas, utilizamos el modelo de paralelización del servidor de parámetros.  Utilizamos dos servidores de parámetros por nodo y configuramos el número de épocas para que sea el mismo que para la ejecución de un solo nodo.  Hicimos esto porque el entrenamiento distribuido a menudo toma más épocas debido a la sincronización imperfecta entre los procesos.  El diferente número de épocas puede sesgar las comparaciones entre casos de nodo único y casos distribuidos.</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">Velocidad de lectura de datos: almacenamiento local versus almacenamiento en red</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">La velocidad de lectura se probó utilizando el<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> comando en uno de los archivos del conjunto de datos ImageNet.  En concreto, ejecutamos los siguientes comandos para datos locales y de red:</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">Ambos valores son similares, lo que demuestra que el almacenamiento en red puede entregar datos a una velocidad similar al almacenamiento local.</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">Caso de uso compartido: Trabajos múltiples, independientes y simultáneos</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">Esta prueba simuló el caso de uso esperado para esta solución: entrenamiento de IA de múltiples trabajos y múltiples usuarios.  Cada nodo ejecutó su propio entrenamiento mientras usaba el almacenamiento de red compartido.  Los resultados se muestran en la siguiente figura, que muestra que el caso de la solución proporcionó un rendimiento excelente con todos los trabajos ejecutándose esencialmente a la misma velocidad que los trabajos individuales.  El rendimiento total se escala linealmente con el número de nodos.</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">Esta figura muestra las imágenes agregadas por segundo.</block>
  <block id="568b99e77256e0aa65f03e3612709ffc" category="paragraph"><block ref="568b99e77256e0aa65f03e3612709ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">Esta figura muestra el tiempo de ejecución en minutos.</block>
  <block id="c8a726b6eb44bab6b01c319420a7605a" category="paragraph"><block ref="c8a726b6eb44bab6b01c319420a7605a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">Estos gráficos presentan el tiempo de ejecución en minutos y las imágenes agregadas por segundo para los nodos de cómputo que utilizaron ocho GPU de cada servidor en una red de cliente de 100 GbE, combinando el modelo de entrenamiento simultáneo y el modelo de entrenamiento único.  El tiempo de ejecución promedio del modelo de entrenamiento fue de 35 minutos y 9 segundos.  Los tiempos de ejecución individuales fueron 34 minutos y 32 segundos, 36 minutos y 21 segundos, 34 minutos y 37 segundos, 35 minutos y 25 segundos y 34 minutos y 31 segundos.  Las imágenes promedio por segundo para el modelo de entrenamiento fueron 22.573, y las imágenes individuales por segundo fueron 21.764; 23.438; 22.556; 22.564; y 22.547.</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">Según nuestra validación, un modelo de entrenamiento independiente con un tiempo de ejecución de datos de NetApp fue de 34 minutos y 54 segundos con 22 231 imágenes/seg.  Un modelo de entrenamiento independiente con un tiempo de ejecución de datos locales (DAS) fue de 34 minutos y 21 segundos con 22 102 imágenes/seg.  Durante esas ejecuciones, la utilización promedio de la GPU fue del 96%, como se observó en nvidia-smi.  Tenga en cuenta que este promedio incluye la fase de prueba, durante la cual no se utilizaron GPU, mientras que la utilización de la CPU fue del 40 %, según lo medido por mpstat.  Esto demuestra que la velocidad de entrega de datos es suficiente en cada caso.</block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">Esta solución se centra en la arquitectura de clúster de nivel de entrada y de rango medio utilizando almacenamiento NetApp y servidores Lenovo optimizados para cargas de trabajo de inteligencia artificial.  Está destinado a equipos pequeños y medianos para los cuales la mayoría de los trabajos de cómputo son de un solo nodo (una o varias GPU) o están distribuidos en unos pocos nodos de cómputo.  Esto no es una limitación importante, porque la mayoría de los trabajos diarios de entrenamiento de IA son de un solo nodo.</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810: NetApp AFF A400 con Lenovo ThinkSystem SR670 V2 para entrenamiento de modelos de IA y ML</block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan, David Arnette, NetApp Mircea Troaca, Lenovo</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">Esta solución presenta una arquitectura de clúster de rango medio que utiliza almacenamiento NetApp y servidores Lenovo optimizados para cargas de trabajo de inteligencia artificial (IA).  Está destinado a empresas de tamaño pequeño a mediano para las que la mayoría de los trabajos de computación son de un solo nodo (una o varias GPU) o están distribuidos en unos pocos nodos de computación.  Esta solución se alinea con la mayoría de los trabajos diarios de capacitación en IA para muchas empresas.</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">Este documento cubre las pruebas y la validación de una configuración de cómputo y almacenamiento que consta de servidores Lenovo SR670V2 de ocho GPU, un sistema de almacenamiento NetApp AFF A400 de rango medio y un conmutador de interconexión de 100 GbE.  Para medir el rendimiento, utilizamos ResNet50 con el conjunto de datos ImageNet, un tamaño de lote de 408, precisión media, CUDA y cuDNN.  Esta arquitectura proporciona una solución eficiente y rentable para organizaciones pequeñas y medianas que recién comienzan con iniciativas de IA que requieren las capacidades de nivel empresarial del almacenamiento de datos conectado a la nube NetApp ONTAP .</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">Científicos de datos, ingenieros de datos, administradores de datos y desarrolladores de sistemas de IA</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">Arquitectos empresariales que diseñan soluciones para el desarrollo de modelos de IA</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">Científicos de datos e ingenieros de datos que buscan formas eficientes de lograr objetivos de desarrollo de aprendizaje profundo (DL) y aprendizaje automático (ML)</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">Líderes empresariales y tomadores de decisiones de OT/IT que desean lograr el tiempo de comercialización más rápido posible para iniciativas de IA</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">Esta solución con servidores Lenovo ThinkSystem y NetApp ONTAP con almacenamiento AFF está diseñada para manejar el entrenamiento de IA en grandes conjuntos de datos utilizando la potencia de procesamiento de las GPU junto con las CPU tradicionales.  Esta validación demuestra un alto rendimiento y una gestión óptima de datos con una arquitectura de escalamiento horizontal que utiliza uno, dos o cuatro servidores Lenovo SR670 V2 junto con un único sistema de almacenamiento NetApp AFF A400 .  La siguiente figura proporciona una descripción general de la arquitectura.</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">Esta imagen muestra un conmutador Ethernet rodeado por el servidor de administración, cuatro SR670 V2 con ocho GPU cada uno y un sistema de almacenamiento NetApp ONTAP .</block>
  <block id="98230d6fe5f2e966446d65810c888228" category="paragraph"><block ref="98230d6fe5f2e966446d65810c888228" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">Rendimiento altamente eficiente y rentable al ejecutar múltiples trabajos de capacitación en paralelo</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">Rendimiento escalable basado en diferentes cantidades de servidores Lenovo y diferentes modelos de controladores de almacenamiento NetApp</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">Protección de datos robusta para cumplir con objetivos de punto de recuperación (RPO) bajos y objetivos de tiempo de recuperación (RTO) sin pérdida de datos</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">Gestión de datos optimizada con instantáneas y clones para agilizar los flujos de trabajo de desarrollo</block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">En esta validación, realizamos entrenamiento de reconocimiento de imágenes según lo especificado por MLPerf v2.0.  Específicamente, entrenamos el modelo ResNet v2.0 con el conjunto de datos ImageNet.  La métrica principal es el tiempo para alcanzar la precisión deseada.  También informamos el ancho de banda de entrenamiento en imágenes por segundo para evaluar mejor la eficiencia del escalamiento.</block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">En esta validación, realizamos entrenamiento de reconocimiento de imágenes según lo especificado por MLPerf v2.0.  En concreto, entrenamos el modelo ResNet v2.0 con el conjunto de datos ImageNet hasta alcanzar una precisión del 76,1%.  La métrica principal es el tiempo para alcanzar la precisión deseada.  También informamos el ancho de banda de entrenamiento en imágenes por segundo para evaluar mejor la eficiencia del escalamiento.</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">El caso de prueba principal evaluó múltiples procesos de entrenamiento independientes (uno por nodo) que se ejecutaban simultáneamente.  Esto simula el caso de uso principal, un sistema compartido utilizado por múltiples científicos de datos.  El segundo caso de prueba evaluó la eficiencia de escalamiento.</block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">Esta sección resume los resultados de las pruebas en esta solución.</block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">La siguiente tabla resume los resultados de todas las pruebas realizadas para esta solución.</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">Descripción de la prueba</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">Resumen de resultados</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">Entrenamiento de reconocimiento de imágenes: múltiples trabajos simultáneos</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">Rendimiento altamente eficiente.  Todos los trabajos se ejecutaron a máxima velocidad incluso cuando el clúster estaba completamente utilizado.  Los sistemas de almacenamiento de NetApp brindaron un rendimiento de entrenamiento comparable al almacenamiento SSD local y al mismo tiempo permitieron compartir datos fácilmente entre servidores.</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">Entrenamiento de reconocimiento de imágenes: escalamiento horizontal</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">Altamente eficiente para hasta cuatro nodos.  En ese momento, la ampliación horizontal era menos eficiente, pero aún factible.  El uso de una red computacional de mayor velocidad mejora la escalabilidad.  El sistema de almacenamiento NetApp ofreció un rendimiento de entrenamiento comparable al almacenamiento SSD local y al mismo tiempo permitió compartir datos fácilmente entre servidores.</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">Esta sección presenta los componentes principales de esta solución con mayor detalle.</block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">Los sistemas de almacenamiento AFF de NetApp permiten a las empresas satisfacer los requisitos de almacenamiento empresarial con un rendimiento líder en la industria, flexibilidad superior, integración en la nube y la mejor gestión de datos de su clase.  Diseñados específicamente para flash, los sistemas AFF ayudan a acelerar, administrar y proteger datos críticos para el negocio.</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">Este gráfico muestra el frente del controlador de almacenamiento NetApp AFF A400 .</block>
  <block id="f150868d2ce410023c5087a2a86bf51e" category="paragraph"><block ref="f150868d2ce410023c5087a2a86bf51e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">Este gráfico muestra la parte posterior del controlador de almacenamiento NetApp AFF A400 .</block>
  <block id="11540913656d83142b2b0f7aed3df7e4" category="paragraph"><block ref="11540913656d83142b2b0f7aed3df7e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32fbd740c28afd94422aeceef5424762" category="paragraph">NetApp AFF A400 es un sistema de almacenamiento flash NVMe de gama media que incluye las siguientes características:</block>
  <block id="4b78ed4e994ac9de0ed2b09e38067a6a" category="list-text">Capacidad efectiva máxima: ~20 PB</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">Escalabilidad máxima: 2-24 nodos (12 pares de alta disponibilidad)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">Compatibilidad con host FC de 25 GbE y 16 Gb</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">Conectividad RDMA de 100 GbE sobre Ethernet convergente (RoCE) a estantes de almacenamiento de expansión NVMe</block>
  <block id="e9038c807b352c2a4dcfd8cf1ac2cdd4" category="list-text">Los puertos RoCE de 100 GbE se pueden usar para la conexión a la red del host si los estantes NVMe no están conectados</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">Estantes de almacenamiento con expansión de conectividad SAS de 12 Gbps completos</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">Disponible en dos configuraciones:</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">Ethernet: 4 puertos Ethernet de 25 Gb (SFP28)</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">Canal de fibra: 4 puertos FC (SFP+) de 16 Gb</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100% lectura aleatoria de 8 KB a 0,4 ms 400 000 IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">Las características de NetApp AFF A250 para implementaciones de IA/ML de nivel básico incluyen lo siguiente:</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">Capacidad efectiva máxima: 35 PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">Escalabilidad máxima: 2-24 nodos (12 pares de alta disponibilidad)</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">Basado en la última versión de NetApp ONTAP ONTAP 9.8 o posterior</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">Dos puertos Ethernet de 25 Gb para alta disponibilidad e interconexión de clústeres</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">NetApp también ofrece otros sistemas de almacenamiento, como AFF A800 y AFF A700, que brindan mayor rendimiento y escalabilidad para implementaciones de IA/ML a mayor escala.</block>
  <block id="3f0cb8a376b551c058cd6886f68bceb0" category="paragraph">ONTAP 9, la última generación de software de gestión de almacenamiento de NetApp, permite a las empresas modernizar la infraestructura y realizar la transición a un centro de datos preparado para la nube.  Al aprovechar las capacidades de gestión de datos líderes en la industria, ONTAP permite la gestión y protección de datos con un único conjunto de herramientas, independientemente de dónde residan esos datos.  Los datos también se pueden mover libremente a donde sea necesario: el borde, el núcleo o la nube.  ONTAP 9 incluye numerosas características que simplifican la gestión de datos, aceleran y protegen datos críticos y preparan la infraestructura para el futuro en arquitecturas de nube híbrida.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*Calidad de servicio (QoS) mínima, máxima y adaptativa.*  Los controles granulares de QoS ayudan a mantener los niveles de rendimiento de las aplicaciones críticas en entornos altamente compartidos.</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">* ONTAP FabricPool.*  Esta función clasifica automáticamente los datos fríos en opciones de almacenamiento en la nube pública y privada, incluidos Amazon Web Services (AWS), Azure y el almacenamiento de objetos NetApp StorageGRID .</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">*Rendimiento y menor latencia.*  ONTAP ofrece el mayor rendimiento posible con la menor latencia posible.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* Cifrado de volumen de NetApp .*  ONTAP ofrece cifrado nativo a nivel de volumen con soporte de administración de claves tanto interna como externa.</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9 ayuda a satisfacer necesidades comerciales exigentes y en constante cambio:</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*Escalamiento sin inconvenientes y operaciones sin interrupciones.*  ONTAP admite la incorporación de capacidad sin interrupciones a controladores existentes, así como a clústeres de escalamiento horizontal.  Los clientes pueden actualizar a las últimas tecnologías, como NVMe y FC de 32 Gb, sin migraciones de datos costosas ni interrupciones.</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*Integración con aplicaciones emergentes.*  ONTAP ofrece servicios de datos de nivel empresarial para plataformas y aplicaciones de próxima generación como OpenStack, Hadoop y MongoDB, utilizando la misma infraestructura que respalda las aplicaciones empresariales existentes.</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">Volúmenes de NetApp FlexGroup</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">Los conjuntos de datos de entrenamiento suelen ser una colección de potencialmente miles de millones de archivos.  Los archivos pueden incluir texto, audio, video y otras formas de datos no estructurados que deben almacenarse y procesarse para poder leerse en paralelo.  El sistema de almacenamiento debe almacenar muchos archivos pequeños y debe leer esos archivos en paralelo para realizar E/S secuenciales y aleatorias.</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">Un volumen FlexGroup (la siguiente figura) es un espacio de nombres único formado por múltiples volúmenes miembros constituyentes que se administra y actúa como un FlexVol volume de NetApp para los administradores de almacenamiento.  Los archivos de un volumen FlexGroup se asignan a volúmenes miembro individuales y no se distribuyen entre volúmenes o nodos.  Permiten las siguientes capacidades:</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">Hasta 20 petabytes de capacidad y baja latencia predecible para cargas de trabajo con muchos metadatos</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">Hasta 400 mil millones de archivos en el mismo espacio de nombres</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">Operaciones paralelizadas en cargas de trabajo NAS en CPU, nodos, agregados y volúmenes FlexVol constituyentes</block>
  <block id="55f5279d0b1378eee63af77d4c7ac7bd" category="inline-image-macro">Esta imagen muestra un par HA de controladores de almacenamiento que contienen muchos volúmenes con archivos principales dentro de un FlexGroup.</block>
  <block id="27f19cee54b11d13039a99839ca83e4c" category="paragraph"><block ref="27f19cee54b11d13039a99839ca83e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">Portafolio Lenovo ThinkSystem</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">Las principales ventajas de implementar servidores Lenovo ThinkSystem incluyen las siguientes:</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">Diseños modulares altamente escalables que crecen con su negocio</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">En el área de IA, Lenovo está adoptando un enfoque práctico para ayudar a las empresas a comprender y adoptar los beneficios del aprendizaje automático y la IA para sus cargas de trabajo.  Los clientes de Lenovo pueden explorar y evaluar las ofertas de IA de Lenovo en los Centros de innovación de IA de Lenovo para comprender completamente el valor para su caso de uso particular.  Para mejorar el tiempo necesario para obtener valor, este enfoque centrado en el cliente ofrece a los clientes pruebas de concepto para plataformas de desarrollo de soluciones que están listas para usar y optimizadas para IA.</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">Lenovo SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">El servidor en rack Lenovo ThinkSystem SR670 V2 ofrece un rendimiento óptimo para inteligencia artificial acelerada y computación de alto rendimiento (HPC).  El SR670 V2 admite hasta ocho GPU y es adecuado para los requisitos de carga de trabajo computacionalmente intensivos de ML, DL e inferencia.</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">Esta imagen muestra tres configuraciones del SR670.  El primero muestra cuatro GPU SXM con ocho unidades HS de 2,5 pulgadas y 2 ranuras de E/S PCIe.  El segundo muestra cuatro ranuras para GPU de ancho doble u ocho de ancho simple y dos ranuras de E/S PCIe con ocho unidades HS de 2,5 pulgadas o cuatro de 3,5 pulgadas.  El tercero muestra ocho ranuras de GPU de doble ancho con seis unidades EDSFF HS y dos ranuras de E/S PCIe.</block>
  <block id="20b8a0ab50b43efab313a63b4c461c6e" category="paragraph"><block ref="20b8a0ab50b43efab313a63b4c461c6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">Con las últimas CPU Intel Xeon escalables que admiten GPU de alta gama (incluida la GPU NVIDIA A100 80GB PCIe 8x), el ThinkSystem SR670 V2 ofrece un rendimiento optimizado y acelerado para cargas de trabajo de IA y HPC.</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">Debido a que más cargas de trabajo utilizan el rendimiento de los aceleradores, la demanda de densidad de GPU ha aumentado.  Industrias como el comercio minorista, los servicios financieros, la energía y la atención médica están utilizando GPU para extraer más información e impulsar la innovación con técnicas de ML, DL e inferencia.</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">ThinkSystem SR670 V2 es una solución optimizada de nivel empresarial para implementar cargas de trabajo de HPC e IA aceleradas en producción, maximizando el rendimiento del sistema y manteniendo la densidad del centro de datos para clústeres de supercomputación con plataformas de próxima generación.</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">Otras características incluyen:</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">Soporte para E/S RDMA directa de GPU en el que los adaptadores de red de alta velocidad se conectan directamente a las GPU para maximizar el rendimiento de E/S.</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">Soporte para almacenamiento directo de GPU en el que las unidades NVMe se conectan directamente a las GPU para maximizar el rendimiento del almacenamiento.</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf es el conjunto de referencia líder en la industria para evaluar el rendimiento de la IA.  En esta validación, utilizamos su punto de referencia de clasificación de imágenes con MXNet, uno de los marcos de IA más populares.  El script de entrenamiento MXNet_benchmarks se utilizó para impulsar el entrenamiento de IA.  El script contiene implementaciones de varios modelos convencionales populares y está diseñado para ser lo más rápido posible.  Puede ejecutarse en una sola máquina o ejecutarse en modo distribuido en múltiples hosts.</block>
  <block id="75c1d09e56fd67f885464b85c424c1a6" category="summary">Este documento presenta un diseño de referencia validado de NetApp AIPod para Enterprise RAG con tecnologías y capacidades combinadas de procesadores Intel Xeon 6 y soluciones de gestión de datos de NetApp .  La solución demuestra una aplicación ChatQnA que aprovecha un modelo de lenguaje amplio y brinda respuestas precisas y contextualmente relevantes a usuarios simultáneos.  Las respuestas se recuperan del repositorio de conocimiento interno de una organización a través de una tubería de inferencia RAG con espacio de aire.</block>
  <block id="98082f297da0ed06e10c426d26145b83" category="doc">NetApp AIPod Mini: Inferencia RAG empresarial con NetApp e Intel</block>
  <block id="f7b06c1111212ddff169549b5e723f7d" category="inline-image-macro">Logotipo de Intel</block>
  <block id="0e15068b5c1105ba9f4537e00817149b" category="paragraph"><block ref="0e15068b5c1105ba9f4537e00817149b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c6562cf6ae61e882bf5b2ce4cfcba9d" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp</block>
  <block id="609170132b6430c9060811e3315d482b" category="paragraph">Un número cada vez mayor de organizaciones están aprovechando aplicaciones de generación aumentada por recuperación (RAG) y modelos de lenguaje grandes (LLM) para interpretar las indicaciones de los usuarios y generar respuestas para aumentar la productividad y el valor comercial.  Estas indicaciones y respuestas pueden incluir texto, código, imágenes o incluso estructuras de proteínas terapéuticas recuperadas de la base de conocimiento interna de una organización, lagos de datos, repositorios de código y repositorios de documentos.  Este documento cubre el diseño de referencia de la solución NetApp AIPod Mini, que comprende almacenamiento y servidores NetApp AFF con procesadores Intel Xeon 6.  Incluye el software de gestión de datos NetApp ONTAP combinado con Intel Advanced Matrix Extensions (Intel AMX) y el software Intel AI for Enterprise Retrieval-augmented Generation (RAG) integrado en Open Platform for Enterprise AI (OPEA).  El AIPod Mini de NetApp para RAG empresarial permite a las organizaciones ampliar un LLM público a una solución de inferencia de inteligencia artificial generativa (GenAI) privada.  La solución demuestra una inferencia RAG eficiente y rentable a escala empresarial, diseñada para mejorar la confiabilidad y brindarle un mejor control sobre su información confidencial.</block>
  <block id="ad17078c7a931a9c4e7e96f485d5a504" category="section-title">Validación de socios de almacenamiento de Intel</block>
  <block id="56f2eda910ca62395eb64d1a789a0edd" category="paragraph">Los servidores equipados con procesadores Intel Xeon 6 están diseñados para manejar cargas de trabajo de inferencia de IA exigentes, utilizando Intel AMX para lograr el máximo rendimiento.  Para permitir un rendimiento y una escalabilidad de almacenamiento óptimos, la solución se ha validado con éxito utilizando NetApp ONTAP, lo que permite a las empresas satisfacer las necesidades de las aplicaciones RAG.  Esta validación se realizó en servidores con procesadores Intel Xeon 6.  Intel y NetApp tienen una sólida asociación centrada en ofrecer soluciones de IA optimizadas, escalables y alineadas con los requisitos comerciales del cliente.</block>
  <block id="679a14435daad5bf55fe65cf54175466" category="section-title">Ventajas de ejecutar sistemas RAG con NetApp</block>
  <block id="320696921fb4cab1e55c519f97302d91" category="paragraph">Las aplicaciones RAG implican la recuperación de conocimiento de los repositorios de documentos de las empresas en varios tipos, como PDF, texto, CSV, Excel o gráficos de conocimiento.  Estos datos normalmente se almacenan en soluciones como un almacenamiento de objetos S3 o NFS local como fuente de datos.  NetApp ha sido líder en tecnologías de gestión de datos, movilidad de datos, gobernanza de datos y seguridad de datos en todo el ecosistema de borde, centro de datos y nube.  La gestión de datos de NetApp ONTAP proporciona almacenamiento de nivel empresarial para soportar varios tipos de cargas de trabajo de IA, incluidas inferencias por lotes y en tiempo real, y ofrece algunos de los siguientes beneficios:</block>
  <block id="18fb2614ff78418dcaae1e9141862c62" category="list-text">Velocidad y escalabilidad.  Puede manejar grandes conjuntos de datos a alta velocidad para el control de versiones con la capacidad de escalar el rendimiento y la capacidad de forma independiente.</block>
  <block id="71861e9c8f9e5be0d026ab6bdf1a8a1a" category="list-text">Acceso a datos.  La compatibilidad con múltiples protocolos permite que las aplicaciones cliente lean datos mediante los protocolos de intercambio de archivos S3, NFS y SMB.  Los buckets NAS de ONTAP S3 pueden facilitar el acceso a los datos en escenarios de inferencia LLM multimodal.</block>
  <block id="27a2888f3fc62ef093e756c75c45081e" category="list-text">Confiabilidad y confidencialidad.  ONTAP proporciona protección de datos, protección autónoma contra ransomware (ARP) de NetApp integrada y aprovisionamiento dinámico de almacenamiento, y ofrece cifrado basado en software y hardware para mejorar la confidencialidad y la seguridad.  ONTAP cumple con FIPS 140-2 para todas las conexiones SSL.</block>
  <block id="104d96e571b334e50365e35ae17299d9" category="paragraph">Este documento está dirigido a tomadores de decisiones de IA, ingenieros de datos, líderes empresariales y ejecutivos departamentales que desean aprovechar una infraestructura diseñada para brindar soluciones empresariales RAG y GenAI.  El conocimiento previo de inferencia de IA, LLM, Kubernetes, redes y sus componentes ayudará durante la fase de implementación.</block>
  <block id="63b41ad25402b4d0e25695e062bb14ad" category="section-title">Tecnologías de inteligencia artificial de Intel</block>
  <block id="d8f5efc84f626ba14a7b3cf5ec1b06c7" category="inline-link">Procesador Xeon 6</block>
  <block id="9dc22cb886e2ea682197d9ab3292ba79" category="paragraph">Con Xeon 6 como CPU host, los sistemas acelerados se benefician de un alto rendimiento de un solo subproceso, mayor ancho de banda de memoria, confiabilidad, disponibilidad y capacidad de servicio (RAS) mejoradas y más líneas de E/S.  Intel AMX acelera la inferencia para INT8 y BF16 y ofrece soporte para modelos entrenados con FP16, con hasta 2048 operaciones de punto flotante por ciclo por núcleo para INT8 y 1024 operaciones de punto flotante por ciclo por núcleo para BF16/FP16.  Para implementar una solución RAG utilizando procesadores Xeon 6, generalmente se recomienda una RAM mínima de 250 GB y 500 GB de espacio en disco.  Sin embargo, esto depende en gran medida del tamaño del modelo LLM.  Para obtener más información, consulte Intel<block ref="5d6ada86cc7a762cca0505b98060c709" category="inline-link-rx"></block> Descripción del producto.</block>
  <block id="c3f5f2ae46fce3305ec2b138111a93b9" category="inline-image-macro">300.300</block>
  <block id="1e2eb4a765ee46d2a2a5ec4ace0544fc" category="paragraph">Figura 1 - Servidor de cómputo con procesadores Intel Xeon 6<block ref="791fbab5dd410f620397cbb8a7265767" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7c9993f09f717fcec0e1d09837e1efc" category="section-title">Almacenamiento AFF de NetApp</block>
  <block id="969e81477626b41849d992785dfcd02d" category="paragraph">Los sistemas NetApp AFF Serie A de nivel básico y medio ofrecen mayor rendimiento, densidad y eficiencia.  Los sistemas NetApp AFF A20, AFF A30 y AFF A50 proporcionan un verdadero almacenamiento unificado que admite bloques, archivos y objetos, basado en un único sistema operativo que puede administrar, proteger y movilizar datos sin problemas para aplicaciones RAG al menor costo en la nube híbrida.</block>
  <block id="f89af68595f296408d40bf9a33b8df16" category="paragraph">Figura 2 - Sistema NetApp AFF Serie A.<block ref="f19ab1d9dc0e27bd83c8759fade26d2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*Hardware*</block>
  <block id="ddcac68770926479de530a8b7b73319e" category="cell">*Cantidad*</block>
  <block id="9bdc480955b350f1fe8089392ad36cbe" category="cell">*Comentario*</block>
  <block id="f0ef78c28754fd06e4d1d893f113852d" category="cell">Servidor basado en Intel Xeon 6</block>
  <block id="3e18c872662c63bcc37a4934b1161411" category="cell">Nodos de inferencia RAG: con procesadores Intel Xeon serie 6900 o Intel Xeon serie 6700 de doble zócalo y de 250 GB a 3 TB de RAM con DDR5 (6400 MHz) o MRDIMM (8800 MHz).  Servidor 2U.</block>
  <block id="e5cb14453a0aa5c9218e9b6f4a2468d1" category="cell">Servidor de plano de control con procesador Intel</block>
  <block id="f5aa1aa461d9a8bb35210fb241f42cda" category="cell">Plano de control de Kubernetes/servidor 1U.</block>
  <block id="5a0cd1929a98cebd107b65ee74abdd78" category="cell">Elección de conmutador Ethernet de 100 Gb</block>
  <block id="8bfef0f2ef10319beae9f37e53900e5a" category="cell">Conmutador de centro de datos.</block>
  <block id="7a2bdeec28cc635e8de5bbcea81978e1" category="cell">NetApp AFF A20 (o AFF A30; AFF A50)</block>
  <block id="4e42b39bc940168c6df430c647a36a11" category="cell">Capacidad máxima de almacenamiento: 9.3PB.  Nota: Redes: puertos 10/25/100 GbE.</block>
  <block id="44959688d91c76b11d501b550db01844" category="paragraph">Para la validación de este diseño de referencia se utilizaron servidores con procesadores Intel Xeon 6 de Supermicro (222HA-TN-OTO-37) y un switch 100GbE de Arista (7280R3A).</block>
  <block id="aa6ecfe41f4b8c352896cd6cf7bc99f7" category="section-title">Plataforma abierta para IA empresarial</block>
  <block id="6fbfd0726b7202aebde976680ced22c4" category="paragraph">La Plataforma Abierta para IA Empresarial (OPEA) es una iniciativa de código abierto liderada por Intel en colaboración con socios del ecosistema.  Proporciona una plataforma modular de bloques de construcción componibles diseñados para acelerar el desarrollo de sistemas de IA generativa de vanguardia, con un fuerte enfoque en RAG.  OPEA incluye un marco integral que incluye LLM, almacenes de datos, motores de solicitud, planos arquitectónicos RAG y un método de evaluación de cuatro pasos que evalúa los sistemas de IA generativa en función del rendimiento, las características, la confiabilidad y la preparación empresarial.</block>
  <block id="cbe45632fbbac4e94036260c2653169b" category="paragraph">En esencia, la OPEA consta de dos componentes clave:</block>
  <block id="4293e41be4afaf5127828398b7c550da" category="list-text">GenAIComps: un conjunto de herramientas basado en servicios compuesto por componentes de microservicios</block>
  <block id="b93ca66f4736b98ad6d348c3b08a6806" category="list-text">Ejemplos de GenAI: soluciones listas para implementar como ChatQnA que demuestran casos de uso prácticos</block>
  <block id="de3c6a3259d3e324c7703889f55a4dde" category="inline-link">Documentación del proyecto OPEA</block>
  <block id="95a35f38b1c8257e521a361226ddc22d" category="paragraph">Para más detalles, consulte la<block ref="61827ec0b891f01987001b685543f04f" category="inline-link-rx"></block></block>
  <block id="515b4067e1d91f462d68de8996b254f6" category="section-title">Inferencia de Intel AI para empresas impulsada por OPEA</block>
  <block id="36a128563cdcf54e3a3e0bfe9a0952a5" category="paragraph">OPEA para Intel AI for Enterprise RAG simplifica la transformación de los datos de su empresa en información útil.  Equipado con procesadores Intel Xeon, integra componentes de socios de la industria para ofrecer un enfoque optimizado para la implementación de soluciones empresariales.  Se escala sin problemas con marcos de orquestación probados, brindando la flexibilidad y la elección que su empresa necesita.</block>
  <block id="9cc188487c3944246ae7f6c5402d3c53" category="paragraph">Basándose en la base de OPEA, Intel AI for Enterprise RAG amplía esta base con características clave que mejoran la escalabilidad, la seguridad y la experiencia del usuario.  Estas características incluyen capacidades de malla de servicio para una integración perfecta con arquitecturas modernas basadas en servicios, validación lista para producción para la confiabilidad de la canalización y una interfaz de usuario rica en funciones para RAG como servicio, lo que permite una fácil administración y monitoreo de los flujos de trabajo.  Además, el soporte de Intel y sus socios brinda acceso a un amplio ecosistema de soluciones, combinado con gestión de identidad y acceso (IAM) integrada con interfaz de usuario y aplicaciones para operaciones seguras y compatibles.  Las barandillas programables brindan un control detallado sobre el comportamiento de las tuberías, lo que permite configuraciones personalizadas de seguridad y cumplimiento.</block>
  <block id="1671448a75b3c116c61a1ac925267b0b" category="inline-link">Obtenga más información sobre la configuración de ONTAP S3</block>
  <block id="90c6a896851e2b2d442ba1cd9d8de55a" category="paragraph">NetApp ONTAP es la tecnología fundamental que sustenta las soluciones de almacenamiento de datos críticos de NetApp.  ONTAP incluye varias funciones de gestión y protección de datos, como protección automática contra ransomware contra ciberataques, funciones de transporte de datos integradas y capacidades de eficiencia de almacenamiento.  Estos beneficios se aplican a una variedad de arquitecturas, desde locales hasta multicloud híbrido en NAS, SAN, objetos y almacenamiento definido por software para implementaciones LLM.  Puede utilizar un servidor de almacenamiento de objetos ONTAP S3 en un clúster ONTAP para implementar aplicaciones RAG, aprovechando la eficiencia de almacenamiento y la seguridad de ONTAP, proporcionada a través de usuarios autorizados y aplicaciones cliente.  Para obtener más información, consulte<block ref="5ba5b9c5717eb24d2b5fdfe0fd9cfc0e" category="inline-link-rx"></block></block>
  <block id="c1b379b8a85b20135cbeae3496ac9cb9" category="inline-link">NetApp Trident en Git</block>
  <block id="05ff24c52b7f489f2df6dab1ac93a444" category="paragraph">El software NetApp Trident es un orquestador de almacenamiento de código abierto y totalmente compatible con contenedores y distribuciones de Kubernetes, incluido Red Hat OpenShift.  Trident funciona con todo el portafolio de almacenamiento de NetApp , incluido NetApp ONTAP y también admite conexiones NFS e iSCSI.  Para obtener más información, consulte<block ref="b09494428fb81fc17c232fdf3cd6ebfd" category="inline-link-rx"></block></block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*Software*</block>
  <block id="45cc01ab5f209e8760027e9c30097025" category="cell">*Versión*</block>
  <block id="b968b232dc718c194c40c140b496647a" category="cell">OPEA para Intel AI para Enterprise RAG</block>
  <block id="522c33efdda0b8dc6ce90c991beb9666" category="cell">1.1.2</block>
  <block id="cec6a9b163aa2911c259a1fd129fafec" category="cell">Plataforma RAG empresarial basada en microservicios OPEA</block>
  <block id="7b02c13e31cd24ff2d950fc29a8f9d53" category="cell">Interfaz de almacenamiento de contenedores (controlador CSI)</block>
  <block id="a821a7b77c7f65a585f8b5e2b6679cd3" category="cell">NetApp Trident 25.02</block>
  <block id="4d437b953db79f111d6140d4d62384e4" category="cell">Permite el aprovisionamiento dinámico, copias Snapshot de NetApp y volúmenes.</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="5e3add1fd258bd782aade74ed9a9877d" category="cell">22.04.5</block>
  <block id="d63705a0c12ee1eea0e9fa2f30be636d" category="cell">Sistema operativo en un clúster de dos nodos</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">Orquestación de contenedores</block>
  <block id="307ea69c7c6931f75ee51c5349fefb05" category="cell">Kubernetes 1.31.4</block>
  <block id="382fc90b48fccde9d59f816ea9dc9b4a" category="cell">Entorno para ejecutar el marco RAG</block>
  <block id="6f72c11338419e7cbef5d90da27338b1" category="cell">ONTAP 9.16.1P4</block>
  <block id="345ec8aa297f872cecdbf6b3c0e32bfd" category="cell">Sistema operativo de almacenamiento en AFF A20.  Cuenta con Vscan y ARP.</block>
  <block id="77e4d80ae2f4257081e17476b146608a" category="section-title">Implementación de la solución</block>
  <block id="e137b1b38be73f6e2bb5d628d2325215" category="section-title">Pila de software</block>
  <block id="4b9b3f178d68004f22177def38ac1a0a" category="paragraph">La solución se implementa en un clúster de Kubernetes que consta de nodos de aplicaciones basados en Intel Xeon.  Se requieren al menos tres nodos para implementar alta disponibilidad básica para el plano de control de Kubernetes.  Validamos la solución utilizando el siguiente diseño de clúster.</block>
  <block id="9a5c044d129dc6879fa0ab37fdf1da36" category="paragraph">Tabla 3: Disposición del clúster de Kubernetes</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Node</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">Role</block>
  <block id="f6deba375b4908f8ab44946cb1ac15ec" category="cell">Servidores con procesadores Intel Xeon 6 y 1 TB de RAM</block>
  <block id="5e13dbdc232ae09e4bcf3ca30f51de88" category="cell">Nodo de aplicación, nodo de plano de control</block>
  <block id="c8b75ba615f900ff258046bb36a7fc62" category="cell">Servidor genérico</block>
  <block id="6f8f92d5847446fe4b0ae5b71badd7cd" category="cell">Nodo del plano de control</block>
  <block id="b1ee6de34c23dd606b6401a06907e658" category="inline-image-macro">600.600</block>
  <block id="13c96942dd3c3b3bdb84e02b2a303778" category="paragraph">La siguiente figura muestra una "vista de la pila de software" de la solución.<block ref="841e6c807fed1e7947a5b7ebff264e4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8388066510b59c8d3387373b6969a7af" category="section-title">Pasos de implementación</block>
  <block id="6c00804e5ebc94e7610086e3e0f7e581" category="section-title">Implementar el dispositivo de almacenamiento ONTAP</block>
  <block id="ec6e72d1c4bb7dccdc62b6caf35c95f7" category="inline-link">Documentación de los sistemas de hardware de ONTAP</block>
  <block id="c5ba881390fd2c8d5f9d0fb165ad1049" category="paragraph">Implemente y aprovisione su dispositivo de almacenamiento NetApp ONTAP .  Consulte la<block ref="8f6fc8fb2a7bb6f821a0fddf6c335b91" category="inline-link-rx"></block> Para más detalles.</block>
  <block id="9df0c5d4eab5f45fac1c5ad20e8fdade" category="section-title">Configurar una SVM de ONTAP para acceso NFS y S3</block>
  <block id="b0e271f740ae6f03e699c988b5b7c576" category="paragraph">Configure una máquina virtual de almacenamiento ONTAP (SVM) para acceso NFS y S3 en una red a la que puedan acceder sus nodos de Kubernetes.</block>
  <block id="05ef9b22209f0e35efc9b6f875ad3c55" category="inline-link">Documentación de ONTAP .</block>
  <block id="a647bfcaa1b11c3008439f5c2a0a888f" category="paragraph">Para crear una SVM usando ONTAP System Manager, navegue a Almacenamiento &gt; Máquinas virtuales de almacenamiento y haga clic en el botón + Agregar.  Al habilitar el acceso S3 para su SVM, elija la opción para utilizar un certificado firmado por una CA externa (autoridad de certificación), no un certificado generado por el sistema.  Puede utilizar un certificado autofirmado o un certificado firmado por una CA de confianza pública.  Para obtener más detalles, consulte la<block ref="9162972b1d9e1d587a9c620aa7cb22be" category="inline-link-rx"></block></block>
  <block id="59ea3be65306f9546fb9ed8da06a4fc4" category="paragraph">La siguiente captura de pantalla muestra la creación de una SVM utilizando ONTAP System Manager.  Modifique los detalles según sea necesario en función de su entorno.</block>
  <block id="ba045795e96e030beb3430fdc0bcf388" category="paragraph">Figura 4 – Creación de SVM utilizando ONTAP System Manager.<block ref="eddc39049915c5d642c02b97b2cbe95e" category="inline-image-macro-rx" type="image"></block> <block ref="d6e1134442a83aae943e8555fe42f14e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e98de7098944681485c37173696a48b" category="section-title">Configurar permisos de S3</block>
  <block id="9e677f1fe64f248526596041ab78f505" category="paragraph">Configure los ajustes de usuario/grupo S3 para la SVM que creó en el paso anterior.  Asegúrese de tener un usuario con acceso completo a todas las operaciones de API S3 para esa SVM.  Consulte la documentación de ONTAP S3 para obtener más detalles.</block>
  <block id="8182eb49f0464e8a5b6d2e7b642a6da5" category="paragraph">Nota: Este usuario será necesario para el servicio de ingesta de datos de la aplicación Intel AI for Enterprise RAG.  Si creó su SVM usando ONTAP System Manager, System Manager habrá creado automáticamente un usuario llamado<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> y una política denominada<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> cuando creó su SVM, pero no se le habrán asignado permisos<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> .</block>
  <block id="c00a2800b71457eb0e0cabb2511b615a" category="paragraph">Para editar los permisos de este usuario, vaya a Almacenamiento &gt; Máquinas virtuales de almacenamiento, haga clic en el nombre de la SVM que creó en el paso anterior, haga clic en Configuración y, luego, haga clic en el ícono de lápiz junto a "S3".  Dar<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> acceso completo a todas las operaciones de la API de S3, crear un nuevo grupo que asocie<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> con el<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> política como se muestra en la siguiente captura de pantalla.</block>
  <block id="229c665cb2b8cb2576229fea9470bfe6" category="paragraph">Figura 5 – Permisos de S3.</block>
  <block id="3ce7236b065597bbadf2a14e9845558e" category="paragraph"><block ref="3ce7236b065597bbadf2a14e9845558e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cc27c397bf2aa7589869b84e048e24c" category="section-title">Crear un bucket S3</block>
  <block id="bd31776e6efcf27fc82ed6ba0862c4fb" category="paragraph">Crea un bucket S3 dentro del SVM que creaste anteriormente.  Para crear una SVM usando ONTAP System Manager, navegue a Almacenamiento &gt; Cubos y haga clic en el botón + Agregar.  Para obtener detalles adicionales, consulte la documentación de ONTAP S3.</block>
  <block id="0b755fcdfc7b6b61938269f21db3f841" category="paragraph">La siguiente captura de pantalla muestra la creación de un depósito S3 mediante ONTAP System Manager.</block>
  <block id="9568e70889a07b151a91a53d10969aed" category="paragraph">Figura 6 – Crear un bucket S3.<block ref="06e84b109f1e09150cd4d15502f0a16d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="847d5eae44750df0abbb4d655d69c6a7" category="section-title">Configurar los permisos del bucket S3</block>
  <block id="c23ccda8191e76cb192f1bd40cae534b" category="paragraph">Configure los permisos para el depósito S3 que creó en el paso anterior.  Asegúrese de que el usuario que configuró en un paso anterior tenga los siguientes permisos:<block ref="82cabf6bd017130caa599103617f61df" prefix=" " category="inline-code"></block></block>
  <block id="c3bf5d608f066a6b405a40012a2fc10c" category="inline-link">Documentación de ONTAP S3</block>
  <block id="cc944a7541814572eb9767d03e306277" category="paragraph">Para editar los permisos de un depósito S3 mediante ONTAP System Manager, navegue a Almacenamiento &gt; Depósitos, haga clic en el nombre de su depósito, haga clic en Permisos y, luego, haga clic en Editar.  Consulte la<block ref="3c678e24d354397cff48df8b3cf3f717" category="inline-link-rx"></block> Para más detalles.</block>
  <block id="0d1bf17e818c5b150c239afaa05e5f17" category="paragraph">La siguiente captura de pantalla muestra los permisos de depósito necesarios en ONTAP System Manager.</block>
  <block id="54bf7776c2d0b7f0ee45097aaad50403" category="paragraph">Figura 7 – Permisos del bucket S3.<block ref="cc0f8d7f1fe9cc3d53404327451495be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="000356058e153b3be211db974d645a75" category="section-title">Crear una regla de uso compartido de recursos de origen cruzado de bucket</block>
  <block id="004935665424a8d10e5e54b7140e97e1" category="paragraph">Con la CLI de ONTAP , cree una regla de uso compartido de recursos de origen cruzado (CORS) para el depósito que creó en un paso anterior:</block>
  <block id="51704d982c17dad72393ced89212b5ca" category="paragraph">Esta regla permite que la aplicación web OPEA para Intel AI for Enterprise RAG interactúe con el depósito desde un navegador web.</block>
  <block id="d2a899c39e099bd681cfe52af554b20c" category="section-title">Implementar servidores</block>
  <block id="fa3bc02ffb34d7c680db187aa209dddd" category="paragraph">Implemente sus servidores e instale Ubuntu 22.04 LTS en cada servidor.  Después de instalar Ubuntu, instale las utilidades NFS en cada servidor.  Para instalar las utilidades NFS, ejecute el siguiente comando:</block>
  <block id="5ed0c66dfa2ac395ad8e9830aa5964aa" category="section-title">Instalar Kubernetes</block>
  <block id="7a21958624d0a70f3a6b70bcf03ba09a" category="inline-link">Documentación de Kubespray</block>
  <block id="eb6273ed753aae187941e09aa142f02a" category="paragraph">Instale Kubernetes en sus servidores usando Kubespray.  Consulte la<block ref="1d9598782a4be0d8f1003429c1865811" category="inline-link-rx"></block> Para más detalles.</block>
  <block id="b0583213f3e2e379b7dd549fd41f909f" category="section-title">Instalar el controlador Trident CSI</block>
  <block id="c17b9b6d3e5d228bcc6c08edc3438f7f" category="inline-link">Documentación de instalación de Trident</block>
  <block id="1ba254856621ddad1eb72d0beee0001c" category="paragraph">Instale el controlador CSI Trident de NetApp en su clúster de Kubernetes.  Consulte la<block ref="0fa543c14587a20e022922b0d6d40500" category="inline-link-rx"></block> Para más detalles.</block>
  <block id="cca56b6e3954004aac402213ce3054e6" category="section-title">Crear un back end de Trident</block>
  <block id="f95ebb45354495c835f81296b11e95c1" category="inline-link">Documentación del backend de Trident</block>
  <block id="31f53fbd09b24f455b372567da98766f" category="paragraph">Cree un back end Trident para el SVM que creó anteriormente.  Al crear su back end, utilice el<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> conductor.  Consulte la<block ref="4b8fa33525637fa26acc3e336d80affb" category="inline-link-rx"></block> Para más detalles.</block>
  <block id="14f4c7abe09c4481722f1fa6563f2604" category="section-title">Crear una clase de almacenamiento</block>
  <block id="bdecb047bffb568e0e8e84eeca503f89" category="paragraph">Cree una clase de almacenamiento de Kubernetes correspondiente al back end de Trident que creó en el paso anterior.  Consulte la documentación de la clase de almacenamiento Trident para obtener más detalles.</block>
  <block id="6a61b11e836f0eeccddb33643f7aa4cd" category="inline-link">Implementación de Intel AI for Enterprise RAG</block>
  <block id="ba489bb61012c1097c380a06f7b20cbe" category="paragraph">Instale OPEA para Intel AI for Enterprise RAG en su clúster de Kubernetes.  Consulte la<block ref="d6f70ce0ce5c9ddf0b1e28a93f0968a7" category="inline-link-rx"></block> documentación para más detalles.  Asegúrese de tomar nota de las modificaciones necesarias del archivo de configuración que se describen más adelante en este documento.  Debe realizar estas modificaciones antes de ejecutar el manual de instalación para que la aplicación Intel AI for Enterprise RAG funcione correctamente con su sistema de almacenamiento ONTAP .</block>
  <block id="cd806c912d9a85a913016682326e17bc" category="section-title">Habilitar el uso de ONTAP S3</block>
  <block id="4a65f719a33b2a0cdefdd371bc5b4aa9" category="paragraph">Al instalar OPEA para Intel AI for Enterprise RAG, edite su archivo de configuración principal para habilitar el uso de ONTAP S3 como su repositorio de datos de origen.</block>
  <block id="3bbecd0884a5e013f45ca28fdee8daf4" category="paragraph">Para habilitar el uso de ONTAP S3, configure los siguientes valores dentro del<block ref="ed9bdb883dd5d0bf37bd5d208a17fadc" prefix=" " category="inline-code"></block> sección.</block>
  <block id="799685b83814ceb35225cd15c9221159" category="paragraph">Nota: De forma predeterminada, la aplicación Intel AI for Enterprise RAG ingiere datos de todos los depósitos existentes en su SVM.  Si tiene varios depósitos en su SVM, puede modificarlos<block ref="50d6f108d2717f6e9be4eae460e94414" prefix=" " category="inline-code"></block> campo para que los datos se ingieran solo desde ciertos grupos.</block>
  <block id="533e38d744354d370be3e86bd8fe8b28" category="section-title">Configurar los ajustes de sincronización programada</block>
  <block id="ad99b73b01de134452a17a0dfa32cec2" category="paragraph">Al instalar la aplicación OPEA para Intel AI for Enterprise RAG, habilite<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> para que la aplicación ingiera automáticamente archivos nuevos o actualizados desde sus depósitos S3.</block>
  <block id="c64dcda39c59bb872461bbb0e651a561" category="paragraph">Cuando<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> está habilitado, la aplicación verifica automáticamente sus buckets S3 de origen en busca de archivos nuevos o actualizados.  Cualquier archivo nuevo o actualizado que se encuentre como parte de este proceso de sincronización se incorpora automáticamente y se agrega a la base de conocimiento de RAG.  La aplicación verifica sus depósitos de origen según un intervalo de tiempo preestablecido.  El intervalo de tiempo predeterminado es de 60 segundos, lo que significa que la aplicación comprueba si hay cambios cada 60 segundos.  Es posible que desee cambiar este intervalo para adaptarlo a sus necesidades específicas.</block>
  <block id="6d6914305f62085b3a9f416c96b4d127" category="paragraph">Para habilitar<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> y establezca el intervalo de sincronización, configure los siguientes valores en<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="b9edd7aa680f588a01b814c4969d387b" category="section-title">Cambiar los modos de acceso al volumen</block>
  <block id="2fe889d552298c286373b708cafda8e7" category="paragraph">En<block ref="cd37fd54d9ac25bbfe45a164824d6194" prefix=" " category="inline-code"></block> , para cada volumen en el<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> lista, cambiar el<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> a<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> .</block>
  <block id="edad21c5950d7e773534103192f18dd8" category="section-title">(Opcional) Deshabilitar la verificación del certificado SSL</block>
  <block id="6aaadab147a2227d76985e7ef0fc2680" category="paragraph">Si utilizó un certificado autofirmado al habilitar el acceso S3 para su SVM, debe deshabilitar la verificación del certificado SSL.  Si utilizó un certificado firmado por una CA de confianza pública, puede omitir este paso.</block>
  <block id="2bb2c1d3d614a1de0e2e1e97fe3ac3c1" category="paragraph">Para deshabilitar la verificación del certificado SSL, configure los siguientes valores en<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="dd88285a7105f2f3e6756070ae0535e2" category="section-title">Acceda a OPEA para Intel AI para la interfaz de usuario RAG empresarial</block>
  <block id="123b51539e81bc36af05f29733939680" category="inline-link">Documentación de implementación de Intel AI for Enterprise RAG</block>
  <block id="c1b501f6d4c8c6a8616b9ca35cd2fc45" category="paragraph">Acceda a la interfaz de usuario RAG de OPEA para Intel AI for Enterprise.  Consulte la<block ref="746fad554462625e79393992880c7bc6" category="inline-link-rx"></block> Para más detalles.</block>
  <block id="922ca547bcfcab30994177a3c1d383ae" category="paragraph">Figura 8: UI de OPEA para Intel AI para Enterprise RAG.<block ref="4cedb9bc094b7a9f8925870620118f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71b202e61cbdf7d879691cc22fff5944" category="section-title">Ingerir datos para RAG</block>
  <block id="1e5926c65c9a0919b7d73b19b2df9d53" category="paragraph">Ahora puede ingerir archivos para incluirlos en la ampliación de consultas basada en RAG.  Existen múltiples opciones para ingerir archivos.  Elija la opción adecuada a sus necesidades.</block>
  <block id="36dc767aab6b2ad698f45815826a1a29" category="paragraph">Nota: después de ingerir un archivo, la aplicación OPEA para Intel AI for Enterprise RAG busca automáticamente actualizaciones del archivo y las ingiere según corresponda.</block>
  <block id="39ba5d380c5ff87759539eee68e65d99" category="paragraph">*Opción 1: Cargar directamente a su bucket S3 Para ingerir muchos archivos a la vez, le recomendamos cargar los archivos a su bucket S3 (el bucket que creó anteriormente) utilizando el cliente S3 de su elección.  Los clientes S3 populares incluyen AWS CLI, Amazon SDK para Python (Boto3), s3cmd, S3 Browser, Cyberduck y Commander One.  Si los archivos son de un tipo compatible, cualquier archivo que cargue en su bucket S3 será ingerido automáticamente por la aplicación OPEA para Intel AI for Enterprise RAG.</block>
  <block id="e8c9e1c06420b69e589d260def731d88" category="paragraph">Nota: al momento de escribir este artículo, se admiten los siguientes tipos de archivos: PDF, HTML, TXT, DOC, DOCX, PPT, PPTX, MD, XML, JSON, JSONL, YAML, XLS, XLSX, CSV, TIFF, JPG, JPEG, PNG y SVG.</block>
  <block id="bc974fb6199b9073fbf1026bd2d236d2" category="paragraph">Puede utilizar la interfaz de usuario RAG de OPEA para Intel AI for Enterprise para confirmar que sus archivos se ingirieron correctamente.  Consulte la documentación de la interfaz de usuario de Intel AI for Enterprise RAG para obtener más detalles.  Tenga en cuenta que la aplicación puede tardar un tiempo en procesar una gran cantidad de archivos.</block>
  <block id="25ce0ebd12d3573d98440a5151efd06e" category="paragraph">*Opción 2: Cargar usando la interfaz de usuario Si necesita ingerir solo una pequeña cantidad de archivos, puede ingerirlos usando la interfaz de usuario RAG de OPEA para Intel AI for Enterprise.  Consulte la documentación de la interfaz de usuario de Intel AI for Enterprise RAG para obtener más detalles.</block>
  <block id="aad57997fffb9169edca9049f6c408fc" category="paragraph">Figura 9 – Interfaz de usuario de ingesta de datos.<block ref="55969be455b6eb9c434a32c9edf9a19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aab14042462d545cbc81ccbd5144183" category="section-title">Ejecutar consultas de chat</block>
  <block id="37afbf2924fcb8ec313cd060eae9317c" category="paragraph">Ahora puedes "chatear" con la aplicación OPEA para Intel AI for Enterprise RAG mediante la interfaz de usuario de chat incluida.  Al responder a sus consultas, la aplicación realiza RAG utilizando sus archivos ingeridos.  Esto significa que la aplicación busca automáticamente información relevante dentro de los archivos ingeridos e incorpora esta información al responder a sus consultas.</block>
  <block id="2ed19e65997a81f69c25a47d5bf28407" category="paragraph">Como parte de nuestro esfuerzo de validación, realizamos pruebas de rendimiento en coordinación con Intel.  Esta prueba dio como resultado la guía de tamaño que se describe en la siguiente tabla.</block>
  <block id="b0e166baec472090eb9b8fe69dd5736a" category="cell">Caracterizaciones</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Valor</block>
  <block id="a48c8e3a66454b67fa81ad9e940c8b27" category="cell">Tamaño del modelo</block>
  <block id="4f4ccdf1d741c3c95db91bbc2930fb82" category="cell">20 mil millones de parámetros</block>
  <block id="9be9211aab4b7a1e7b93895b22cac265" category="cell">Llama-8B, Llama-13B, Mistral 7B, Qwen 14B, DeepSeek Distill 8B</block>
  <block id="5b176800a4fa5f818733bbc47bf50c58" category="cell">Tamaño de entrada</block>
  <block id="5da438d3d127ea08ac04b3ad27565f86" category="cell">~2k tokens</block>
  <block id="ec110f5087b1200011dcf2f34914001b" category="cell">~4 páginas</block>
  <block id="2e422b9da98e2d0a7b8c31aa22986312" category="cell">Tamaño de salida</block>
  <block id="0de7dbc3b2f780207078fda7fe5f5312" category="cell">Usuarios concurrentes</block>
  <block id="2dda44ea1754f4e550f1a5cc97bd2f88" category="cell">"Usuarios concurrentes" se refiere a solicitudes que envían consultas al mismo tiempo.</block>
  <block id="e8d9bc5e8e6b28217a5661b56a0ce38d" category="paragraph">_Nota: La guía de tamaño presentada anteriormente se basa en la validación del rendimiento y en los resultados de pruebas recopilados utilizando procesadores Intel Xeon 6 con 96 núcleos.  Para clientes con tokens de E/S y requisitos de tamaño de modelo similares, recomendamos utilizar servidores con procesadores Xeon 6 con 96 o 128 núcleos.</block>
  <block id="d83a33143fe76973b5528ae0d2b5750c" category="paragraph">Los sistemas RAG empresariales y LLM son tecnologías que trabajan juntas para ayudar a las organizaciones a brindar respuestas precisas y adaptadas al contexto.  Estas respuestas implican la recuperación de información basada en una vasta colección de datos empresariales privados e internos.  Al utilizar RAG, API, incrustaciones vectoriales y sistemas de almacenamiento de alto rendimiento para consultar repositorios de documentos que contienen datos de la empresa, los datos se procesan de forma más rápida y segura.  NetApp AIPod Mini combina la infraestructura de datos inteligente de NetApp con las capacidades de gestión de datos de ONTAP y los procesadores Intel Xeon 6, Intel AI for Enterprise RAG y la pila de software OPEA para ayudar a implementar aplicaciones RAG de alto rendimiento y poner a las organizaciones en el camino hacia el liderazgo en IA.</block>
  <block id="37bea4d3bbce78210e52efa42aff98fc" category="section-title">Reconocimiento</block>
  <block id="9d17f4dbd111838ecf2ecb0306f6c255" category="paragraph">Este documento es trabajo de Sathish Thyagarajan y Michael Ogelsby, miembros del equipo de ingeniería de soluciones de NetApp .  Los autores también desean agradecer al equipo de productos de inteligencia artificial empresarial de Intel (Ajay Mungara, Mikolaj Zyczynski, Igor Konopko, Ramakrishna Karamsetty, Michal Prostko, Shreejan Mistry y Ned Fiori) y a otros miembros del equipo de NetApp(Lawrence Bunka, Bobby Oommen y Jeff Liborio) por su continuo apoyo y ayuda durante la validación de esta solución.</block>
  <block id="638409a97591a74cbaf8ecaac7bc356a" category="section-title">Lista de materiales</block>
  <block id="faf3c2849bae24ab9045ae5add024400" category="paragraph">La siguiente fue la lista de materiales utilizada para la validación funcional de esta solución y puede usarse como referencia.  Se podría utilizar cualquier servidor o componente de red (o incluso una red existente con un ancho de banda preferiblemente de 100 GbE) que se ajuste a la siguiente configuración.</block>
  <block id="74953ad13674266e8135ca232d6d7d5d" category="paragraph">Para el servidor de aplicaciones:</block>
  <block id="6737192650f0c3a81629128ea7774174" category="cell">*Número de pieza*</block>
  <block id="eb6fa4e6fed41e388b4d654a174c1b82" category="cell">*Descripción del Producto*</block>
  <block id="a3b91229cc5a5eb0d50908cc956824b3" category="cell">222HA-TN-OTO-37</block>
  <block id="2302a4ae44cddff506100b112f4645c6" category="cell">Hyper SuperServer SYS-222HA-TN /2U</block>
  <block id="e53619c1fe611a51eeeb8d148ba6e532" category="cell">RAM</block>
  <block id="673b9923dda6787459c6a0ae7f711593" category="cell">MEM-DR564MC-ER64(x16) 64 GB DDR5-6400 2RX4 (16 GB) ECC RDIMM</block>
  <block id="0be247e8eaad16189d4e7ce0829add7a" category="cell">HDS-M2N4-960G0-E1-TXD-NON-080(x2) SSD M.2 NVMe PCIe4 960GB 1DWPD TLC D, 80 mm</block>
  <block id="c3ca791a9361b57a8fa217067084b891" category="cell">Fuente de alimentación de salida única redundante WS-1K63A-1R(x2)1U 692W/1600W.  Disipación de calor de 2361 BTU/hora con temperatura máxima de 59 C (aprox.)</block>
  <block id="7d83e48371fe2b2bd396527bf08497f1" category="paragraph">Para el servidor de control:</block>
  <block id="4bf51ddd79708218d2ca40addbf3f2fb" category="cell">511R-M-OTO-17</block>
  <block id="870f227b084b6f0c047a533d218e9874" category="cell">OPTIMIZADO HASTA 1U X13SCH-SYS, CSE-813MF2TS-R0RCNBP, PWS-602A-1R</block>
  <block id="7c3e6ed807c306444b3bddd7fc90cb2a" category="cell">MEM-DR516MB-EU48(x2)16GB DDR5-4800 1Rx8 (16Gb) ECC UDIMM</block>
  <block id="c104b47ab1794697f8c929d251599740" category="paragraph">Para el conmutador de red:</block>
  <block id="1bf595c07879a3e4909b5196570ee253" category="cell">DCS-7280CR3A</block>
  <block id="60e4b729f0a2b5471a6c6209bc49aac5" category="cell">Arista 7280R3A 28x100 GbE</block>
  <block id="40f46282e86b9c228e0cce6e2011f35c" category="paragraph">Almacenamiento AFF de NetApp :</block>
  <block id="39ff721f18a3edbb373a8c8f54cd3f14" category="cell">AFF-A20A-100-C</block>
  <block id="c133ed5a1928378c2f6a29bf6b6f1135" category="cell">Sistema AFF A20 HA, -C</block>
  <block id="52b142796a871ab98369e293ae4d91c2" category="cell">X800-42U-R6-C</block>
  <block id="c6b0cc56d77c17a08efb3742ab92e776" category="cell">Cable de puente, en cabina, C13-C14, -C</block>
  <block id="128bdeded7a535e68b0f98e463111407" category="cell">X97602A-C</block>
  <block id="f14bf71f2d74fbf0d0560b5a355bbf63" category="cell">Fuente de alimentación, 1600 W, titanio, -C</block>
  <block id="2a0cfc5d71abb55759a510240510f87a" category="cell">X66211B-2-N-C</block>
  <block id="d50feb7d1470a9fb63d75f5a39b4b8bd" category="cell">Cable, 100 GbE, QSFP28-QSFP28, Cu, 2 m, -C</block>
  <block id="9d4b1f9c3df948f2260e6332be9d5aed" category="cell">X66240A-05-N-C</block>
  <block id="7229ff7ba1f700db7ec3bd4b5221db26" category="cell">Cable, 25 GbE, SFP28-SFP28, Cu, 0,5 m, -C</block>
  <block id="1ab2d2badc8592e1d029782bd25632a5" category="cell">X5532A-N-C</block>
  <block id="4688dd909d449010ca4b23347351a707" category="cell">Riel, 4 postes, delgado, agujero redondo/cuadrado, pequeño, ajustable, 24-32, -C</block>
  <block id="b24ac50247ba189d666fdae929cede64" category="cell">X4024A-2-A-C</block>
  <block id="25630a46b821a822994c9b1e0dd238d5" category="cell">Paquete de unidades 2X1,92 TB, NVMe4, SED, -C</block>
  <block id="326b6bb4ee61f9700e237d78e0a70b27" category="cell">X60130A-C</block>
  <block id="f2acaac754bf0c08463a09096b25ebd5" category="cell">Módulo de E/S, 2PT, 100 GbE, -C</block>
  <block id="826f0d850b56b5bcd6026118ee4048b5" category="cell">X60132A-C</block>
  <block id="f567279f3d616d5bcfbd134b1e39b047" category="cell">Módulo de E/S, 4 PT, 10/25 GbE, -C</block>
  <block id="7090ee7c22ea0bf45e028538870d276f" category="cell">SW-ONTAPB-FLASH-A20-C</block>
  <block id="c2375e9a630d78f92c99f36859f2dc63" category="cell">SW, paquete básico de ONTAP , por TB, Flash, A20, -C</block>
  <block id="37693cfc748049e45d87b8c7d8b9aacd" category="cell">23</block>
  <block id="1006bcc3d9e9f1297760c57c62541267" category="paragraph"><block ref="1006bcc3d9e9f1297760c57c62541267" category="inline-link-rx"></block></block>
  <block id="9bf497d692d0e146d05a76e3a34ae95f" category="inline-link-macro">Proyecto OPEA</block>
  <block id="feeb32cac2847bc01bfab8eb7dfbbbfe" category="paragraph"><block ref="feeb32cac2847bc01bfab8eb7dfbbbfe" category="inline-link-macro-rx"></block></block>
  <block id="a64127d2271b6c8ff07ae84c3a53c90c" category="inline-link">Manual de implementación de OPEA Enterprise RAG</block>
  <block id="3d766654d6f2d85f314e655c63e91d81" category="paragraph"><block ref="3d766654d6f2d85f314e655c63e91d81" category="inline-link-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851: Lago de datos NetApp StorageGRID para cargas de trabajo de conducción autónoma: diseño de la solución</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">David Arnette, NetApp</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851 demuestra el uso del almacenamiento de objetos NetApp StorageGRID como repositorio de datos y sistema de gestión para el desarrollo de software de aprendizaje automático (ML) y aprendizaje profundo (DL).  Este artículo describe el flujo de datos y los requisitos en el desarrollo de software de vehículos autónomos y las características de StorageGRID que optimizan el ciclo de vida de los datos.  Esta solución se aplica a cualquier flujo de trabajo de canalización de datos de múltiples etapas que es típico en los procesos de desarrollo de ML y DL.</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Avisos legales</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">Los avisos legales proporcionan acceso a declaraciones de derechos de autor, marcas comerciales, patentes y más.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Copyright</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marcas comerciales</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP, el logotipo de NETAPP y las marcas enumeradas en la página de Marcas comerciales de NetApp son marcas comerciales de NetApp, Inc. Otros nombres de empresas y productos pueden ser marcas comerciales de sus respectivos propietarios.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Patentes</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Puede encontrar una lista actualizada de las patentes propiedad de NetApp en:</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Política de privacidad</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">Para esta validación, realizamos una inferencia para un caso de uso de detección de imágenes utilizando un conjunto de imágenes sin procesar.  Luego realizamos la misma tarea de inferencia en el mismo conjunto de imágenes con la ofuscación de Protopia agregada antes de la inferencia.  Repetimos la tarea utilizando diferentes valores de ALPHA para el componente de ofuscación de Protopia.</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">Comparación de la precisión de inferencia</block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">Para esta validación, realizamos una inferencia para un caso de uso de detección de imágenes utilizando un conjunto de imágenes sin procesar.  Luego realizamos la misma tarea de inferencia en el mismo conjunto de imágenes con la ofuscación de Protopia agregada antes de la inferencia.  Repetimos la tarea utilizando diferentes valores de ALPHA para el componente de ofuscación de Protopia.  En el contexto de la ofuscación de Protopia, el valor ALPHA representa la cantidad de ofuscación que se aplica, siendo un valor ALPHA más alto el que representa un mayor nivel de ofuscación.  Luego comparamos la precisión de la inferencia en estas diferentes ejecuciones.</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">Las siguientes dos tablas proporcionan detalles sobre nuestro caso de uso y describen los resultados.</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia trabaja directamente con los clientes para determinar el valor ALPHA apropiado para un caso de uso específico.</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoxes (PyTorch) -</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">Conjunto de datos FDDB</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">Ofuscación de protopia</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">ALFA</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">Exactitud</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">No</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">N/A</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0,9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Sí</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0,05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0,9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0,1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0,9024301009661478</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0,2</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0,9081836283186224</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0,4</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0,9073066107482036</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0,6</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0,8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0,8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0,8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0,9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0,8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0,95</block>
  <block id="cf285ec96f684d6597b7ffbbfcf16197" category="doc">Dónde encontrar información adicional y agradecimientos</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia AI—Inferencia confidencial</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="list-text">Servidor de inferencia NVIDIA Triton</block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">Documentación del servidor de inferencia NVIDIA Triton</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">FaceBoxes en PyTorch</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">Mark Cates, gerente principal de productos, NetApp</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad, ingeniero de marketing técnico, NetApp</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Hadi Esmaeilzadeh, director de tecnología y profesor de Protopia AI</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">Los datos existen en tres estados: en reposo, en tránsito y en proceso de cálculo.  Una parte importante de cualquier servicio de inferencia de IA debe ser la protección de los datos contra amenazas durante todo el proceso.  La protección de datos durante la inferencia es fundamental porque el proceso puede exponer información privada sobre los clientes externos y la empresa que proporciona el servicio de inferencia.</block>
  <block id="cd9ef21e97d9c9e701bfc6d1a77634d5" category="paragraph">Los datos existen en tres estados: en reposo, en tránsito y en procesamiento.  Una parte importante de cualquier servicio de inferencia de IA debe ser la protección de los datos contra amenazas durante todo el proceso.  La protección de datos durante la inferencia es fundamental porque el proceso puede exponer información privada sobre los clientes externos y la empresa que proporciona el servicio de inferencia.  Protopia AI es una solución de software no intrusiva para la inferencia de IA confidencial en el mercado actual.  Con Protopia, la IA se alimenta únicamente de la información transformada en los registros de datos que es esencial para llevar a cabo la tarea de IA/ML en cuestión y nada más.  Esta transformación estocástica no es una forma de enmascaramiento y se basa en cambiar matemáticamente la representación de los datos mediante el uso de ruido curado.</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">Los sistemas de almacenamiento de NetApp con capacidades ONTAP ofrecen el mismo rendimiento o uno mejor que el almacenamiento SSD local y, combinados con NetApp DataOps Toolkit, ofrecen los siguientes beneficios a científicos de datos, ingenieros de datos, desarrolladores de IA/ML y tomadores de decisiones de TI empresariales o comerciales:</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">Protección de datos de nivel empresarial y gobernanza de datos para recuperación ante desastres, continuidad comercial y requisitos regulatorios.</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">Invocación simplificada de operaciones de gestión de datos; tome rápidamente copias instantáneas de los espacios de trabajo de los científicos de datos para realizar copias de seguridad y trazabilidad desde el kit de herramientas NetApp DataOps en cuadernos Jupyter.</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">La solución de NetApp y Protopia proporciona una arquitectura flexible y escalable que es ideal para implementaciones de inferencia de IA de nivel empresarial.  Permite la protección de datos y brinda privacidad a la información confidencial donde los requisitos de inferencia de IA confidenciales pueden cumplirse con prácticas de IA responsables en implementaciones locales e híbridas.</block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">Esta sección describe el entorno de validación del diseño de la solución.</block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">La siguiente tabla describe el entorno de validación del diseño de la solución.</block>
  <block id="30136395f01879792198317c11831ea4" category="cell">Kubernetes</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="8b2b11d27dd7d347de30cae2db2ab86d" category="cell">Controlador CSI Trident de NetApp</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">Kit de herramientas de NetApp DataOps para Kubernetes</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">Este documento describe una solución de diseño validada en tres escenarios diferentes con y sin ofuscación de imágenes relevantes para preservar la privacidad e implementar una solución de IA responsable.</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928: IA responsable e inferencia confidencial - IA de NetApp con Protopia Image and Data Transformation</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp Byung Hoon Ahn, Jennifer Cwagenberg, Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">Las interpretaciones visuales se han convertido en una parte integral de la comunicación con el surgimiento de la captura y el procesamiento de imágenes.  La inteligencia artificial (IA) en el procesamiento de imágenes digitales brinda nuevas oportunidades comerciales, como en el campo médico para la identificación del cáncer y otras enfermedades, en el análisis visual geoespacial para estudiar riesgos ambientales, en el reconocimiento de patrones, en el procesamiento de video para combatir el crimen, etc.  Sin embargo, esta oportunidad también conlleva responsabilidades extraordinarias.</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">Cuanto más decisiones ponen las organizaciones en manos de la IA, más aceptan riesgos relacionados con la privacidad y la seguridad de los datos y con cuestiones legales, éticas y regulatorias.  La IA responsable posibilita una práctica que permite a las empresas y organizaciones gubernamentales generar confianza y gobernanza, lo cual es crucial para la IA a escala en grandes empresas.  Este documento describe una solución de inferencia de IA validada por NetApp en tres escenarios diferentes mediante el uso de tecnologías de gestión de datos de NetApp con el software de ofuscación de datos Protopia para privatizar datos confidenciales y reducir riesgos y preocupaciones éticas.</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">Cada día, tanto los consumidores como las entidades comerciales generan millones de imágenes con diversos dispositivos digitales.  La consiguiente explosión masiva de datos y carga de trabajo computacional hace que las empresas recurran a plataformas de computación en la nube para lograr escalabilidad y eficiencia.  Mientras tanto, las preocupaciones sobre la privacidad de la información sensible contenida en los datos de imágenes surgen con la transferencia a una nube pública.  La falta de garantías de seguridad y privacidad se convierte en la principal barrera para la implementación de sistemas de IA de procesamiento de imágenes.</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">derecho de supresión</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">Ley de Privacidad</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">Además, existe la<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> por el RGPD, el derecho de un individuo a solicitar que una organización borre todos sus datos personales.  También existe la<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block> , que establece un código de prácticas justas de información.  Las imágenes digitales, como las fotografías, pueden constituir datos personales según el RGPD, que regula cómo deben recopilarse, procesarse y borrarse los datos.  No hacerlo constituye un incumplimiento del RGPD, lo que podría dar lugar a fuertes multas por incumplimiento que pueden ser gravemente perjudiciales para las organizaciones.  Los principios de privacidad son la columna vertebral de la implementación de una IA responsable que garantice la imparcialidad en las predicciones de los modelos de aprendizaje automático (ML) y aprendizaje profundo (DL) y reduzca los riesgos asociados con la violación de la privacidad o el cumplimiento normativo.</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">Este documento describe una solución de diseño validada en tres escenarios diferentes con y sin ofuscación de imágenes relevantes para preservar la privacidad e implementar una solución de IA responsable:</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*Escenario 1.*  Inferencia a pedido dentro del cuaderno Jupyter.</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*Escenario 2.*  Inferencia por lotes en Kubernetes.</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*Escenario 3.*  Servidor de inferencia NVIDIA Triton.</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">Para esta solución, utilizamos el Face Detection Data Set and Benchmark (FDDB), un conjunto de datos de regiones faciales diseñado para estudiar el problema de la detección de rostros sin restricciones, combinado con el marco de aprendizaje automático PyTorch para la implementación de FaceBoxes.  Este conjunto de datos contiene las anotaciones de 5171 caras en un conjunto de 2845 imágenes de varias resoluciones.  Además, este informe técnico presenta algunas de las áreas de solución y casos de uso relevantes recopilados de clientes e ingenieros de campo de NetApp en situaciones donde esta solución es aplicable.</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">Este informe técnico está dirigido a los siguientes públicos:</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">Líderes empresariales y arquitectos empresariales que quieran diseñar e implementar IA responsable y abordar cuestiones de privacidad y protección de datos relacionadas con el procesamiento de imágenes faciales en espacios públicos.</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">Científicos de datos, ingenieros de datos, investigadores de IA/aprendizaje automático (ML) y desarrolladores de sistemas de IA/ML que tienen como objetivo proteger y preservar la privacidad.</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">Arquitectos empresariales que diseñan soluciones de ofuscación de datos para modelos y aplicaciones de IA/ML que cumplen con estándares regulatorios como GDPR, CCPA o la Ley de Privacidad del Departamento de Defensa (DoD) y organizaciones gubernamentales.</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">Científicos de datos e ingenieros de IA que buscan formas eficientes de implementar modelos de inferencia de aprendizaje profundo (DL) e IA/ML/DL que protejan la información confidencial.</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">Esta solución está diseñada para gestionar cargas de trabajo de IA de inferencia en tiempo real y por lotes en grandes conjuntos de datos mediante el uso de la potencia de procesamiento de las GPU junto con las CPU tradicionales.  Esta validación demuestra la inferencia de preservación de la privacidad para el aprendizaje automático y la gestión óptima de datos requerida por las organizaciones que buscan implementaciones de IA responsables.  Esta solución proporciona una arquitectura adecuada para una plataforma Kubernetes de uno o varios nodos para computación en el borde y en la nube interconectada con NetApp ONTAP AI en el núcleo local, NetApp DataOps Toolkit y el software de ofuscación Protopia mediante interfaces Jupyter Lab y CLI.  La siguiente figura muestra la descripción general de la arquitectura lógica de la estructura de datos impulsada por NetApp con DataOps Toolkit y Protopia.</block>
  <block id="28afcbd6e097b781313de9c75adccb13" category="paragraph"><block ref="28afcbd6e097b781313de9c75adccb13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">El software de ofuscación Protopia se ejecuta sin problemas sobre NetApp DataOps Toolkit y transforma los datos antes de salir del servidor de almacenamiento.</block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">Esta sección proporciona una descripción general de los tres escenarios validados en esta solución.</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">Plan de pruebas y validación</block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">Para este diseño de solución se validaron los siguientes tres escenarios:</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Una tarea de inferencia, con y sin ofuscación de Protopia, dentro de un espacio de trabajo de JupyterLab que se organizó mediante el kit de herramientas NetApp DataOps para Kubernetes.</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Un trabajo de inferencia por lotes, con y sin ofuscación de Protopia, en Kubernetes con un volumen de datos que se organizó mediante NetApp DataOps Toolkit para Kubernetes.</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Una tarea de inferencia que utiliza una instancia de NVIDIA Triton Inference Server que se organizó mediante el kit de herramientas NetApp DataOps para Kubernetes.  Aplicamos la ofuscación de Protopia a la imagen antes de invocar la API de inferencia Triton para simular el requisito común de que cualquier dato que se transmita a través de la red debe estar ofuscado.  Este flujo de trabajo es aplicable a casos de uso en los que los datos se recopilan dentro de una zona confiable pero deben pasarse fuera de esa zona confiable para realizar inferencias.  Sin la ofuscación de Protopia, no es posible implementar este tipo de flujo de trabajo sin que los datos confidenciales salgan de la zona de confianza.</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">Esta sección describe las tareas necesarias para completar la validación.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Prerrequisitos</block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">Para ejecutar las tareas descritas en esta sección, debe tener acceso a un host Linux o macOS con las siguientes herramientas instaladas y configuradas:</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl (configurado para acceder a un clúster de Kubernetes existente)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">Las instrucciones de instalación y configuración se pueden encontrar<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block> .</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">Las instrucciones de instalación se pueden encontrar<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block> .</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">Escenario 1: Inferencia bajo demanda en JupyterLab</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">Cree un espacio de nombres de Kubernetes para cargas de trabajo de inferencia de IA/ML.</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">Utilice el kit de herramientas NetApp DataOps para aprovisionar un volumen persistente para almacenar los datos en los que realizará la inferencia.</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">Utilice el kit de herramientas NetApp DataOps para crear un nuevo espacio de trabajo de JupyterLab.  Monte el volumen persistente que se creó en el paso anterior utilizando el<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block> opción.  Asigne GPU NVIDIA al espacio de trabajo según sea necesario mediante el uso de<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block> opción.</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">En el siguiente ejemplo, el volumen persistente<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block> está montado en el contenedor del espacio de trabajo de JupyterLab en<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block> .  Al utilizar imágenes de contenedor oficiales del Proyecto Jupyter,<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block> se presenta como el directorio de nivel superior dentro de la interfaz web de JupyterLab.</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">Acceda al espacio de trabajo de JupyterLab utilizando la URL especificada en la salida del<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block> dominio.  El directorio de datos representa el volumen persistente que se montó en el espacio de trabajo.</block>
  <block id="87209231def3204e4e4d9a18544294dd" category="paragraph"><block ref="87209231def3204e4e4d9a18544294dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">Abrir el<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> directorio y cargar los archivos sobre los cuales se realizará la inferencia.  Cuando se cargan archivos en el directorio de datos, se almacenan automáticamente en el volumen persistente que se montó en el espacio de trabajo.  Para cargar archivos, haga clic en el ícono Cargar archivos, como se muestra en la siguiente imagen.</block>
  <block id="e3b5f0c1efdf69526c759b1d33d05e5b" category="paragraph"><block ref="e3b5f0c1efdf69526c759b1d33d05e5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">Regrese al directorio de nivel superior y cree un nuevo cuaderno.</block>
  <block id="8c8d84a9a1e17bebaa40920247f46e13" category="paragraph"><block ref="8c8d84a9a1e17bebaa40920247f46e13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">Añade código de inferencia al cuaderno.  El siguiente ejemplo muestra el código de inferencia para un caso de uso de detección de imágenes.</block>
  <block id="cf7a1e02f4be1c22e175847fae951746" category="paragraph"><block ref="cf7a1e02f4be1c22e175847fae951746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fa1b8c326d7c59c16ba99f22361e9e4" category="paragraph"><block ref="9fa1b8c326d7c59c16ba99f22361e9e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">Agregue la ofuscación de Protopia a su código de inferencia.  Protopia trabaja directamente con los clientes para proporcionar documentación específica de cada caso de uso y está fuera del alcance de este informe técnico.  El siguiente ejemplo muestra el código de inferencia para un caso de uso de detección de imágenes con ofuscación de Protopia agregada.</block>
  <block id="a782d09a204dcf45c8852abf7684c340" category="paragraph"><block ref="a782d09a204dcf45c8852abf7684c340" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b937401d5d173ae3750bccadcff9481e" category="paragraph"><block ref="b937401d5d173ae3750bccadcff9481e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">Escenario 2: Inferencia por lotes en Kubernetes</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">Rellene el nuevo volumen persistente con los datos sobre los que realizará la inferencia.</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">Capacidades de NetApp DataOps Toolkit S3 Data Mover</block>
  <block id="685f44c17611b1391b579c696f310b98" category="paragraph">Existen varios métodos para cargar datos en un PVC.  Si sus datos están actualmente almacenados en una plataforma de almacenamiento de objetos compatible con S3, como NetApp StorageGRID o Amazon S3, puede utilizar<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block> .  Otro método simple es crear un espacio de trabajo de JupyterLab y luego cargar archivos a través de la interfaz web de JupyterLab, como se describe en los pasos 3 a 5 en la sección "<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> . "</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">Cree un trabajo de Kubernetes para su tarea de inferencia por lotes.  El siguiente ejemplo muestra un trabajo de inferencia por lotes para un caso de uso de detección de imágenes.  Este trabajo realiza inferencias en cada imagen de un conjunto de imágenes y escribe métricas de precisión de inferencia en stdout.</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">Confirme que el trabajo de inferencia se completó correctamente.</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">Agregue la ofuscación de Protopia a su trabajo de inferencia.  Puede encontrar instrucciones específicas de casos de uso para agregar la ofuscación de Protopia directamente desde Protopia, lo cual está fuera del alcance de este informe técnico.  El siguiente ejemplo muestra un trabajo de inferencia por lotes para un caso de uso de detección de rostros con ofuscación de Protopia agregada mediante un valor ALPHA de 0,8.  Este trabajo aplica la ofuscación de Protopia antes de realizar la inferencia para cada imagen en un conjunto de imágenes y luego escribe métricas de precisión de inferencia en stdout.</block>
  <block id="babeb9cd0280f29f38c9a4c3029f7ba0" category="inline-link-macro">Comparación de precisión de inferencia.</block>
  <block id="f4d99d417d0adde7f8d0f1a70caac126" category="paragraph">Repetimos este paso para los valores ALPHA 0,05, 0,1, 0,2, 0,4, 0,6, 0,8, 0,9 y 0,95.  Puedes ver los resultados en<block ref="b3380bdc8f9311566c95bcb62c7aea42" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">Escenario 3: Servidor de inferencia NVIDIA Triton</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">Utilice NetApp DataOps Toolkit para aprovisionar un volumen persistente para utilizarlo como repositorio de modelos para el servidor de inferencia NVIDIA Triton.</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">formato</block>
  <block id="898dfcda591317ac60dd8d6af3aff189" category="list-text">Almacene su modelo en el nuevo volumen persistente en un<block ref="2001a6caf72de652d98c6c64bc75a4e8" category="inline-link-rx"></block> que es reconocido por el servidor de inferencia NVIDIA Triton.</block>
  <block id="23ed8d1b8cbc461ebdbedcdb67ee7718" category="paragraph">Existen varios métodos para cargar datos en un PVC.  Un método simple es crear un espacio de trabajo de JupyterLab y luego cargar archivos a través de la interfaz web de JupyterLab, como se describe en los pasos 3 a 5 en "<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> .  "</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">Utilice NetApp DataOps Toolkit para implementar una nueva instancia de NVIDIA Triton Inference Server.</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Utilice un SDK de cliente Triton para realizar una tarea de inferencia.  El siguiente extracto de código Python utiliza el SDK del cliente Python de Triton para realizar una tarea de inferencia para un caso de uso de detección de rostros.  Este ejemplo llama a la API Triton y pasa una imagen para inferir.  Luego, el servidor de inferencia Triton recibe la solicitud, invoca el modelo y devuelve el resultado de la inferencia como parte de los resultados de la API.</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">Agregue la ofuscación de Protopia a su código de inferencia.  Puede encontrar instrucciones específicas de casos de uso para agregar la ofuscación de Protopia directamente desde Protopia; sin embargo, este proceso está fuera del alcance de este informe técnico.  El siguiente ejemplo muestra el mismo código Python que se muestra en el paso 5 anterior, pero con la ofuscación de Protopia agregada.</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">Tenga en cuenta que la ofuscación de Protopia se aplica a la imagen antes de pasarla a la API de Triton.  De esta manera la imagen no ofuscada nunca sale de la máquina local.  Sólo la imagen ofuscada pasa a través de la red.  Este flujo de trabajo es aplicable a casos de uso en los que los datos se recopilan dentro de una zona confiable pero luego deben pasarse fuera de esa zona confiable para realizar inferencias.  Sin la ofuscación de Protopia, no es posible implementar este tipo de flujo de trabajo sin que los datos confidenciales salgan de la zona confiable.</block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">Para esta validación, aplicamos la ofuscación Protopia a una imagen de 1920 x 1080 píxeles cinco veces y medimos el tiempo que tardaba el paso de ofuscación en completarse cada vez.</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">Velocidad de ofuscación</block>
  <block id="6977bb3543f8de6dcfa78f7970349ba1" category="paragraph">Utilizamos PyTorch ejecutándose en una sola GPU NVIDIA V100 para aplicar la ofuscación y borramos el caché de la GPU entre ejecuciones.  El paso de ofuscación tardó 5,47 ms, 5,27 ms, 4,54 ms, 5,24 ms y 4,84 ms respectivamente en completarse en las cinco ejecuciones.  La velocidad media fue de 5,072ms.</block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">Esta sección proporciona una descripción general de los diversos componentes técnicos necesarios para completar esta solución.</block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">Protopía</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI ofrece una solución discreta, basada únicamente en software, para inferencia confidencial en el mercado actual.  La solución Protopia ofrece una protección incomparable para los servicios de inferencia al minimizar la exposición de información confidencial.  La IA sólo se alimenta con la información del registro de datos que es verdaderamente esencial para realizar la tarea en cuestión y nada más.  La mayoría de las tareas de inferencia no utilizan toda la información que existe en cada registro de datos.  Independientemente de si su IA consume imágenes, voz, video o incluso datos tabulares estructurados, Protopia ofrece solo lo que el servicio de inferencia necesita.  La tecnología central patentada utiliza ruido curado matemáticamente para transformar estocásticamente los datos y distorsionar la información que no necesita un servicio de ML determinado.  Esta solución no enmascara los datos, sino que cambia su representación mediante el uso de ruido aleatorio seleccionado.</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">La solución Protopia formula el problema de cambiar la representación como un método de maximización de perturbación basado en gradientes que aún conserva la información pertinente en el espacio de características de entrada con respecto a la funcionalidad del modelo.  Este proceso de descubrimiento se ejecuta como un paso de ajuste al final del entrenamiento del modelo ML.  Después de que el pase genera automáticamente un conjunto de distribuciones de probabilidad, una transformación de datos con baja sobrecarga aplica muestras de ruido de estas distribuciones a los datos, ofuscándolos antes de pasarlos al modelo para su inferencia.</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">Inteligencia artificial de NetApp ONTAP</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">La arquitectura de referencia NetApp ONTAP AI, impulsada por sistemas DGX A100 y sistemas de almacenamiento conectados a la nube de NetApp , fue desarrollada y verificada por NetApp y NVIDIA.  Proporciona a las organizaciones de TI una arquitectura que proporciona los siguientes beneficios:</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">Elimina las complejidades del diseño</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">Permite el escalado independiente del cómputo y el almacenamiento.</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">Permite a los clientes comenzar de a poco y escalar sin problemas</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">Ofrece una gama de opciones de almacenamiento para distintos puntos de rendimiento y costo.</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI integra estrechamente los sistemas DGX A100 y los sistemas de almacenamiento NetApp AFF A800 con redes de última generación.  ONTAP AI simplifica las implementaciones de IA al eliminar la complejidad del diseño y las conjeturas.  Los clientes pueden comenzar de a poco y crecer sin interrupciones mientras administran de manera inteligente los datos desde el borde hasta el núcleo, la nube y viceversa.</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">La siguiente figura muestra varias variaciones en la familia de soluciones ONTAP AI con sistemas DGX A100.  El rendimiento del sistema AFF A800 se verifica con hasta ocho sistemas DGX A100.  Al agregar pares de controladores de almacenamiento al clúster ONTAP , la arquitectura puede escalar a múltiples racks para soportar muchos sistemas DGX A100 y petabytes de capacidad de almacenamiento con rendimiento lineal.  Este enfoque ofrece la flexibilidad de alterar las relaciones de cómputo a almacenamiento de forma independiente en función del tamaño de los modelos DL que se utilizan y las métricas de rendimiento requeridas.</block>
  <block id="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="paragraph"><block ref="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153: NetApp ONTAP AI con sistemas NVIDIA DGX A100 y conmutadores Ethernet Mellanox Spectrum.</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">Para obtener información adicional sobre ONTAP AI, consulte<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11, la última generación de software de gestión de almacenamiento de NetApp, permite a las empresas modernizar la infraestructura y realizar la transición a un centro de datos preparado para la nube.  Al aprovechar las capacidades de gestión de datos líderes en la industria, ONTAP permite la gestión y protección de datos con un único conjunto de herramientas, independientemente de dónde residan esos datos.  También puede mover datos libremente a donde sea necesario: el borde, el núcleo o la nube.  ONTAP 9.11 incluye numerosas características que simplifican la gestión de datos, aceleran y protegen datos críticos y habilitan capacidades de infraestructura de próxima generación en arquitecturas de nube híbrida.</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps Toolkit es una biblioteca de Python que permite a los desarrolladores, científicos de datos, ingenieros de DevOps e ingenieros de datos realizar fácilmente diversas tareas de gestión de datos, como el aprovisionamiento casi instantáneo de un nuevo volumen de datos o espacio de trabajo de JupyterLab, la clonación casi instantánea de un volumen de datos o espacio de trabajo de JupyterLab y la toma casi instantánea de instantáneas de un volumen de datos o espacio de trabajo de JupyterLab para trazabilidad o creación de líneas de base.  Esta biblioteca de Python puede funcionar como una utilidad de línea de comandos o como una biblioteca de funciones que puedes importar a cualquier programa de Python o cuaderno Jupyter.</block>
  <block id="2dcb054d023d8770b9ba0125434b8f20" category="paragraph">NVIDIA Triton Inference Server es un software de servicio de inferencia de código abierto que ayuda a estandarizar la implementación y ejecución de modelos para ofrecer una IA rápida y escalable en producción.  Triton Inference Server optimiza la inferencia de IA al permitir que los equipos implementen, ejecuten y escalen modelos de IA entrenados desde cualquier marco en cualquier infraestructura basada en GPU o CPU.  Triton Inference Server es compatible con los principales marcos, como TensorFlow, NVIDIA TensorRT, PyTorch, MXNet, OpenVINO, etc.  Triton se integra con Kubernetes para la orquestación y el escalamiento que puede utilizar en todas las principales plataformas de IA y Kubernetes en la nube pública.  También está integrado con muchas soluciones de software MLOps.</block>
  <block id="6532191b754c006509ce4006a972990e" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block>Es un marco de aprendizaje automático de código abierto.  Es una biblioteca tensorial optimizada para aprendizaje profundo que utiliza GPU y CPU.  El paquete PyTorch contiene estructuras de datos para tensores multidimensionales que proporcionan muchas utilidades para la serialización eficiente de tensores, entre otras utilidades útiles.  También tiene una contraparte CUDA que le permite ejecutar sus cálculos tensoriales en una GPU NVIDIA con capacidad de cómputo.  En esta validación, utilizamos la biblioteca OpenCV-Python (cv2) para validar nuestro modelo mientras aprovechamos los conceptos de visión artificial más intuitivos de Python.</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">Rendimiento y menor latencia.  ONTAP ofrece el mayor rendimiento posible con la menor latencia posible.</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">Protección de datos.  ONTAP proporciona capacidades de protección de datos integradas con gestión común en todas las plataformas.</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">Autenticación multitenencia y multifactor.  ONTAP permite compartir recursos de infraestructura con los más altos niveles de seguridad.</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">Escalabilidad fluida y operaciones sin interrupciones.  ONTAP admite la incorporación de capacidad sin interrupciones a controladores existentes y a clústeres de escalamiento horizontal.  Los clientes pueden actualizar a las últimas tecnologías, como NVMe y FC de 32 Gb, sin migraciones de datos costosas ni interrupciones.</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">Control de Astra de NetApp</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Servicio de control de Astra</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">La familia de productos NetApp Astra ofrece servicios de gestión de datos y almacenamiento conscientes de las aplicaciones para aplicaciones Kubernetes locales y en la nube pública, impulsados por tecnologías de gestión de datos y almacenamiento de NetApp .  Le permite realizar copias de seguridad de aplicaciones de Kubernetes fácilmente, migrar datos a un clúster diferente y crear instantáneamente clones de aplicaciones funcionales.  Si necesita administrar aplicaciones de Kubernetes que se ejecutan en una nube pública, consulte la documentación para<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block> .  Astra Control Service es un servicio administrado NetApp que proporciona administración de datos consciente de las aplicaciones de clústeres de Kubernetes en Google Kubernetes Engine (GKE) y Azure Kubernetes Service (AKS).</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> NetApp es un orquestador de almacenamiento dinámico de código abierto para Docker y Kubernetes que simplifica la creación, la administración y el consumo de almacenamiento persistente.  Trident, una aplicación nativa de Kubernetes, se ejecuta directamente dentro de un clúster de Kubernetes.  Trident permite a los clientes implementar sin problemas imágenes de contenedores DL en el almacenamiento de NetApp y brinda una experiencia de nivel empresarial para implementaciones de contenedores de IA.  Los usuarios de Kubernetes (desarrolladores de ML, científicos de datos, etc.) pueden crear, administrar y automatizar la orquestación y la clonación para aprovechar las capacidades avanzadas de administración de datos impulsadas por la tecnología de NetApp .</block>
  <block id="45a189f17e7eec44ce720f6a979e501e" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>Es un servicio de NetApp para la sincronización de datos rápida y segura.  Ya sea que necesite transferir archivos entre recursos compartidos de archivos NFS o SMB locales, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage o IBM Cloud Object Storage, BlueXP Copy and Sync mueve los archivos donde los necesita de forma rápida y segura.  Una vez transferidos los datos, estarán totalmente disponibles para su uso tanto en el origen como en el destino.  BlueXP Copy and Syncc sincroniza continuamente los datos según un cronograma predefinido, moviendo solo los deltas, de modo que se minimiza el tiempo y el dinero gastados en la replicación de datos.  BlueXP Copy and Sync es una herramienta de software como servicio (SaaS) extremadamente sencilla de configurar y utilizar.  Las transferencias de datos que se activan mediante BlueXP Copy and Sync se llevan a cabo a través de corredores de datos.  Puede implementar agentes de datos de BlueXP Copy and Sync en AWS, Azure, Google Cloud Platform o en las instalaciones locales.</block>
  <block id="b8bc3287c1345ab1a36c796d2de0aaa2" category="section-title">Clasificación de NetApp BlueXP</block>
  <block id="196f1872673d3381d912260929325605" category="paragraph">Impulsado por potentes algoritmos de IA,<block ref="860dd213c65646bc2292a7454f4cfbac" category="inline-link-rx"></block> Proporciona controles automatizados y gobernanza de datos en todo su patrimonio de datos.  Puede identificar fácilmente ahorros de costos, identificar problemas de cumplimiento y privacidad y encontrar oportunidades de optimización.  El panel de clasificación de BlueXP le brinda la información necesaria para identificar datos duplicados para eliminar redundancia, mapear datos personales, no personales y confidenciales, y activar alertas para datos confidenciales y anomalías.</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">El procesamiento de imágenes digitales conlleva muchas ventajas y permite a muchas organizaciones aprovechar al máximo los datos asociados a las representaciones visuales.  Esta solución de NetApp y Protopia proporciona un diseño de inferencia de IA único para proteger y privatizar los datos de IA/ML en todo el ciclo de vida de ML/DL.  Permite a los clientes conservar la propiedad de datos confidenciales, utilizar modelos de implementación de nube pública o híbrida para lograr escala y eficiencia al aliviar las preocupaciones relacionadas con la privacidad e implementar inferencias de IA en el borde.</block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">Inteligencia ambiental</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">Hay muchas formas en que las industrias pueden aprovechar el análisis geoespacial en las áreas de riesgos ambientales.  Los gobiernos y el departamento de obras públicas pueden obtener información útil sobre la salud pública y las condiciones climáticas para asesorar mejor al público durante una pandemia o un desastre natural, como los incendios forestales.  Por ejemplo, se puede identificar a un paciente positivo a COVID en espacios públicos, como aeropuertos u hospitales, sin comprometer la privacidad del individuo afectado y alertar a las autoridades respectivas y al público en los alrededores para que tomen las medidas de seguridad necesarias.</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">Dispositivos portátiles de borde</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">En el ámbito militar y en los campos de batalla, se puede utilizar la inferencia de IA en el borde como dispositivos portátiles para rastrear la salud de los soldados, monitorear el comportamiento del conductor y alertar a las autoridades sobre la seguridad y los riesgos asociados al acercarse a vehículos militares mientras se preserva y protege la privacidad de los soldados.  El futuro de las fuerzas armadas se está volviendo de alta tecnología con la Internet de las cosas del campo de batalla (IoBT) y la Internet de las cosas militares (IoMT) para equipos de combate portátiles que ayudan a los soldados a identificar enemigos y desempeñarse mejor en la batalla mediante el uso de computación de borde rápida.  Proteger y preservar los datos visuales recopilados desde dispositivos periféricos, como drones y equipos portátiles, es crucial para mantener a raya a los piratas informáticos y al enemigo.</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">Operaciones de evacuación de no combatientes</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">Las operaciones de evacuación de no combatientes (NEOs) son llevadas a cabo por el Departamento de Defensa para ayudar a evacuar a ciudadanos y nacionales estadounidenses, personal civil del Departamento de Defensa y personas designadas (nacionales de países anfitriones (HN) y de terceros países (TCN)) cuyas vidas están en peligro a un refugio seguro apropiado.  Los controles administrativos establecidos utilizan en gran medida procesos manuales de selección de evacuados.  Sin embargo, la precisión, la seguridad y la velocidad de la identificación de los evacuados, su seguimiento y la detección de amenazas podrían mejorarse potencialmente mediante el uso de herramientas de IA/ML altamente automatizadas combinadas con tecnologías de ofuscación de vídeo de IA/ML.</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">Investigación biomédica y sanitaria</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">El procesamiento de imágenes se utiliza para diagnosticar patologías para la planificación quirúrgica a partir de imágenes 3D obtenidas por tomografía computarizada (TC) o resonancia magnética (RM).  Las normas de privacidad de HIPAA rigen cómo las organizaciones deben recopilar, procesar y borrar toda la información personal e imágenes digitales como fotografías.  Para que los datos califiquen como compartibles según las regulaciones de puerto seguro de HIPAA, se deben eliminar las imágenes fotográficas de rostro completo y cualquier imagen comparable.  Las técnicas automatizadas como los algoritmos de desidentificación o de extracción del cráneo utilizados para ocultar los rasgos faciales de un individuo en las imágenes de TC/RM estructurales se han convertido en una parte esencial del proceso de intercambio de datos para las instituciones de investigación biomédica.</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">Migración a la nube de análisis de IA/ML</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">protección de datos</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">Los clientes empresariales tradicionalmente han entrenado e implementado modelos de IA/ML en sus instalaciones.  Por razones de economías de escala y eficiencia, estos clientes se están expandiendo para trasladar funciones de IA/ML a implementaciones de nube pública, híbrida o multinube.  Sin embargo, están limitados por qué datos pueden exponerse a otras infraestructuras.  Las soluciones de NetApp abordan una gama completa de amenazas de ciberseguridad necesarias para<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> y evaluación de seguridad y, cuando se combina con la transformación de datos de Protopia, minimiza los riesgos asociados con la migración de cargas de trabajo de IA/ML de procesamiento de imágenes a la nube.</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link-macro">TR-4886 Inferencia de IA en el borde</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">Inteligencia versus privacidad</block>
  <block id="7c93429acdde399d280f2e20425ac745" category="paragraph">Para conocer casos de uso adicionales para la computación de borde y la inferencia de IA en otras industrias, consulte<block ref="c2ef3f1fa710d59c08d58b9025616182" category="inline-link-macro-rx"></block> y el blog de IA de NetApp ,<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block> .</block>
  <block id="59a6ec9eb2075dc5ac847799c3c9b4e0" category="summary">MLOps multicloud híbrido con Domino Data Lab y NetApp : dónde encontrar información adicional</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">Dónde encontrar información adicional</block>
  <block id="44997fb529c7b7d20853c30af9ad918a" category="list-text">Laboratorio de datos de Domino</block>
  <block id="1182c61de35b31af3e72f77e61442c77" category="inline-link-macro"><block ref="1182c61de35b31af3e72f77e61442c77" category="inline-link-rx"></block></block>
  <block id="bd0007c3dcc92207ee01f0427da0a4be" category="paragraph"><block ref="bd0007c3dcc92207ee01f0427da0a4be" category="inline-link-macro-rx"></block></block>
  <block id="d7574cd2803b94ddaa90cab193a19ba2" category="list-text">Domino Nexus</block>
  <block id="2703dd45bd40545fb60997c2d3afe208" category="inline-link-macro"><block ref="2703dd45bd40545fb60997c2d3afe208" category="inline-link-rx"></block></block>
  <block id="14a3e5a8d5046236b5959a8860c405eb" category="paragraph"><block ref="14a3e5a8d5046236b5959a8860c405eb" category="inline-link-macro-rx"></block></block>
  <block id="1273c8a63109161e6fd1f18d6998523f" category="list-text">NetApp BlueXP</block>
  <block id="43e196fd7d1a86adce26084a27e3d664" category="inline-link-macro"><block ref="43e196fd7d1a86adce26084a27e3d664" category="inline-link-rx"></block></block>
  <block id="2edabab990aa6b9914f978e6885781f2" category="paragraph"><block ref="2edabab990aa6b9914f978e6885781f2" category="inline-link-macro-rx"></block></block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="list-text">Software de gestión de datos NetApp ONTAP</block>
  <block id="5b8aea48f614361f60f00e194e1b0976" category="inline-link-macro"><block ref="5b8aea48f614361f60f00e194e1b0976" category="inline-link-rx"></block></block>
  <block id="59f3782142c74894e9aa57873085e394" category="paragraph"><block ref="59f3782142c74894e9aa57873085e394" category="inline-link-macro-rx"></block></block>
  <block id="13ed1686110be86a2aeef6d76d4ec65e" category="list-text">Soluciones de IA de NetApp</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-macro"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="501b3e03ab68e967ec7e74647ece575b" category="paragraph"><block ref="501b3e03ab68e967ec7e74647ece575b" category="inline-link-macro-rx"></block></block>
  <block id="5acaa2031a97473b7a185dc30ce9e62d" category="list-text">Josh Mineroff, director de SA para alianzas tecnológicas, Domino Data Lab</block>
  <block id="ed2311020217442776d108d1f99b7521" category="list-text">Nicholas Jablonski, director de tecnología de campo, Domino Data Lab</block>
  <block id="5c38b0c6106b026873b5212202e5eb20" category="list-text">Prabu Arjunan, arquitecto de soluciones, NetApp</block>
  <block id="958996b71437140af7dadceec3c0acf1" category="list-text">Brian Young, Director de Alianza Global, Socios de Alianza Tecnológica, NetApp</block>
  <block id="182f685e8ff46f3bde7c8c63a6d3e8eb" category="summary">MLOps multicloud híbrido con Domino Data Lab y NetApp - Arquitectura</block>
  <block id="22a02f1b77fcd49462c4d58a6e2425fb" category="paragraph">Esta solución combina las capacidades de programación de carga de trabajo multicloud híbrida de Domino Nexus con los servicios de datos de NetApp para crear una plataforma MLOps de nube híbrida unificada.  Consulte la siguiente tabla para obtener más detalles.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">Ambiente</block>
  <block id="1a01eb6a884a288b667e023501d09eea" category="cell">Plano de control MLOps</block>
  <block id="51c0d15bebbbdb19d5e1bde9bf2bc1ba" category="inline-link-macro">Plataforma de inteligencia artificial empresarial de Domino con Domino Nexus</block>
  <block id="a0133d74aa4167bee7ec6bb2830b32ab" category="cell"><block ref="a0133d74aa4167bee7ec6bb2830b32ab" category="inline-link-macro-rx"></block></block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="cell">AWS</block>
  <block id="dedb71b645ad83baa13a64e834ea32a3" category="cell">Entornos informáticos de la plataforma MLOps</block>
  <block id="1f26213ee3d03d1bce28558ef8ff15ff" category="inline-link-macro">Planos de datos de Domino Nexus</block>
  <block id="f2d3c460a5a76b316899ec775650d7ea" category="cell"><block ref="f2d3c460a5a76b316899ec775650d7ea" category="inline-link-macro-rx"></block></block>
  <block id="89f5a1a21bf30d5f2db943911b2d22f2" category="cell">AWS, centro de datos local</block>
  <block id="1698863d644408b6fdc41803a6a1c234" category="cell">Plataforma informática local</block>
  <block id="2c02a900da9ea696e0b13c405974ca0b" category="cell"><block ref="e08fa5b25dd32bed0a8727bee0e3fdd0" category="inline-link-macro-rx"></block>con<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="59f10558cba0587bc03fb56826f8cd4b" category="cell">Centro de datos local</block>
  <block id="29e13ea538f81a8bf3cea3900519c8a1" category="cell">Plataforma de computación en la nube</block>
  <block id="480c9b5f979d1ce95ea2a58b09826d1b" category="inline-link-macro">Servicio Amazon Elastic Kubernetes (EKS)</block>
  <block id="ff969739d0750911a50d47ea892fad80" category="cell"><block ref="4ecdb2c4c840fbc0e496687cc8bf58fe" category="inline-link-macro-rx"></block>con<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="cd3aefaae18f11e3ecc3de62739183f3" category="cell">Plataforma de datos local</block>
  <block id="e16a11bc6041db3c2b26ef054c8b8847" category="inline-link-macro">Dispositivo de almacenamiento NetApp</block>
  <block id="b331d50869bea7c3b019d322cffc1f03" category="cell"><block ref="ea0807fcd7c8182254e93c3bfdf94abc" category="inline-link-macro-rx"></block>Desarrollado por<block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="0c9ae535d9e81d6e268c0ea087be535f" category="cell">Plataforma de datos en la nube</block>
  <block id="35f7c29efc923e8a7920a0b331095d71" category="inline-link-macro">Amazon FSx ONTAP</block>
  <block id="2a9165a68b73a53b924deda7b9ec0251" category="cell"><block ref="2a9165a68b73a53b924deda7b9ec0251" category="inline-link-macro-rx"></block></block>
  <block id="b497a71f092b521e07c06ade7296c159" category="paragraph"><block ref="b497a71f092b521e07c06ade7296c159" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f92651ef1a171bf24e3a0279a4f656f" category="summary">MLOps multicloud híbridos con Domino Data Lab y NetApp : acceda a los mismos datos en diferentes entornos</block>
  <block id="2167fcd754f38c037a8a5fc219634638" category="doc">Acceda a los mismos datos en diferentes entornos</block>
  <block id="2b2213cc89a71238bd2629046704d311" category="paragraph">Esta sección describe las tareas que deben realizarse para acceder a los mismos datos en diferentes entornos informáticos.  En la plataforma Domino MLOps, los entornos computacionales se denominan "planos de datos".  Siga las tareas descritas en esta sección si sus datos residen en un volumen de NetApp en un plano de datos, pero necesita acceder a ellos en otro plano de datos.  Este tipo de escenario a menudo se denomina "bursting" o, cuando el entorno de destino es la nube, "cloud bursting".  Esta capacidad suele ser necesaria cuando se trabaja con recursos informáticos limitados o sobrecargados.  Por ejemplo, si su clúster de cómputo local tiene exceso de solicitudes, es posible que desee programar cargas de trabajo en la nube, donde se puedan iniciar de inmediato.</block>
  <block id="8e259831056b970e9e9ad97044e756ea" category="paragraph">Hay dos opciones recomendadas para acceder a un volumen de NetApp que reside en un plano de datos diferente.  Estas opciones se describen en las subsecciones siguientes.  Elija una de estas opciones según sus necesidades específicas.  Los beneficios y desventajas de las dos opciones se describen en la siguiente tabla.</block>
  <block id="054b4f3ea543c990f6b125f41af6ebf7" category="cell">Opción</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="cell">Beneficios</block>
  <block id="0cfc0523189294ac086e11c8e286ba2d" category="cell">Desventajas</block>
  <block id="a5a315a3bc09fc65d5b92a61203e604b" category="cell">Opción 1 - Caché</block>
  <block id="542d0200f163f8f3533463dd59fe0270" category="cell">- Flujo de trabajo más simple - Capacidad de almacenar en caché un subconjunto de datos según las necesidades - Capacidad de volver a escribir datos en la fuente - No hay copia remota para administrar</block>
  <block id="7426e3bde1c62fb806a70f18c6134316" category="cell">- Mayor latencia en el acceso inicial a los datos a medida que se hidrata la caché.</block>
  <block id="aaa4d30d61e64cea712b7c05c68eb117" category="cell">Opción 2 - Espejo</block>
  <block id="cbefd7ef29f92291b21681c43ba469b7" category="cell">- Copia completa del volumen de origen - Sin aumento de latencia debido a la hidratación de la caché (una vez completada la operación de duplicación)</block>
  <block id="03dab0d003c274e0f366cd0df3efb059" category="cell">- Debe esperar a que se complete la operación de espejo antes de acceder a los datos - Debe administrar una copia remota - No hay capacidad para volver a escribir en la fuente</block>
  <block id="f794ea935b3f3b976964bf0990d05005" category="section-title">Opción 1: Crear una caché de un volumen que reside en un plano de datos diferente</block>
  <block id="79849c69657d54d5bfdd901f71375897" category="inline-link-macro">Tecnología NetApp FlexCache</block>
  <block id="a816bf9775484a9a7049d55ece7f5396" category="paragraph">Con<block ref="bb0419306e9b544a3e597acbf1d444f1" category="inline-link-macro-rx"></block> , puede crear un caché de un volumen de NetApp que resida en un plano de datos diferente.  Por ejemplo, si tiene un volumen de NetApp en su plano de datos local y necesita acceder a ese volumen en su plano de datos de AWS, puede crear un caché del volumen en AWS.  En esta sección se describen las tareas que deben realizarse para crear un caché de un volumen de NetApp que reside en un plano de datos diferente.</block>
  <block id="d93488703b54616875bcacc4afd140a7" category="section-title">Crear un volumen FlexCache en el entorno de destino</block>
  <block id="5d03f3f921e1e11afbd6bc02646a4b6f" category="admonition">Si el entorno de destino es su centro de datos local, creará el volumen FlexCache en su sistema ONTAP local.  Si el entorno de destino es AWS, creará el volumen FlexCache en su instancia de Amazon FSx ONTAP .</block>
  <block id="a53f62411ee21cbe84822e3eba531ca4" category="paragraph">Primero, debe crear un volumen FlexCache en el entorno de destino.</block>
  <block id="671e0b00bec7311fe1a27ae3b1374868" category="inline-link-macro">Documentación de BlueXP volume caching</block>
  <block id="25d1d7fbc173abf20974acc2fd19014b" category="paragraph">Recomendamos utilizar BlueXP para crear el volumen FlexCache .  Para crear un volumen FlexCache con BlueXP, siga las instrucciones descritas en la<block ref="13882193b90946980fb2e14f0dc3f833" category="inline-link-macro-rx"></block> .</block>
  <block id="597fd5f01aeae294735b75c08203b6dd" category="paragraph">Si prefiere no utilizar BlueXP, puede utilizar el Administrador del sistema ONTAP o la CLI de ONTAP para crear el volumen FlexCache .  Para crear un volumen FlexCache con el Administrador del sistema, consulte las instrucciones descritas en la<block ref="01bbf1f7353a360c52874272bfd82e21" category="inline-link-macro-rx"></block> .  Para crear un volumen FlexCache con la CLI de ONTAP , consulte las instrucciones descritas en la<block ref="91e4088944fb7c016c63d36e00422b16" category="inline-link-macro-rx"></block> .</block>
  <block id="e4de6f9df9cd48ef525131de3cb21481" category="inline-link-macro">API de BlueXP</block>
  <block id="0ec641cfacd36c8e22a334135e2abdac" category="inline-link-macro">API REST de ONTAP</block>
  <block id="ebf440be7bdce857e55ec25910ae837b" category="inline-link-macro">Colección Ansible de ONTAP</block>
  <block id="dd7a007ea7e610e168238b6d6ab542a1" category="paragraph">Si desea automatizar este proceso, puede utilizar el<block ref="f07bcb7e875f8bb20680b339fb58364a" category="inline-link-macro-rx"></block> , el<block ref="0966e902a53f3a5becbd165bbdc18e79" category="inline-link-macro-rx"></block> , o el<block ref="62c3d824298cc8f488bda82279b91e73" category="inline-link-macro-rx"></block> .</block>
  <block id="2f37e297d79532f437d3ab48727a61c0" category="admonition">El Administrador del sistema no está disponible en Amazon FSx ONTAP.</block>
  <block id="20f99b2a7f22945f3d769fa1def1e403" category="section-title">Exponer el volumen FlexCache a Domino</block>
  <block id="c9743d6f9b7fcd7047ce3eb9d1f2a273" category="inline-link-macro">Sección 'Exponer volúmenes NetApp existentes a Domino'</block>
  <block id="82a25bd099304632e33529b36f2ac5de" category="paragraph">A continuación, debe exponer el volumen FlexCache a la plataforma Domino MLOps.  Para exponer el volumen FlexCache a Domino, siga las instrucciones descritas en la subsección 'Exponer volúmenes NFS existentes que no fueron aprovisionados por Trident' del documento.<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> de esta solución.</block>
  <block id="1d25e828bd3386ce7ef8b97572c88781" category="paragraph">Ahora, podrá montar el volumen FlexCache al iniciar trabajos y espacios de trabajo en el plano de datos de destino como se muestra en las siguientes capturas de pantalla.</block>
  <block id="edaa69742537cd645340e6ec55f0e7c2" category="section-title">Antes de crear el volumen FlexCache</block>
  <block id="7708950a83e2f559b43ad1d7bc08a440" category="paragraph"><block ref="7708950a83e2f559b43ad1d7bc08a440" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7bf27913e6097a43d318c500146c1e1" category="section-title">Después de exponer el volumen FlexCache a Domino</block>
  <block id="acacf35ed5b32878a29f6d32e6a11ffe" category="paragraph"><block ref="acacf35ed5b32878a29f6d32e6a11ffe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9be78ccf5bdf4dc10f0e5d25b893eeb" category="section-title">Opción 2: replicar un volumen que reside en un plano de datos diferente</block>
  <block id="0e6ab030c4eacec9efa80d3df6cd643b" category="inline-link-macro">Tecnología de replicación de datos SnapMirror de NetApp</block>
  <block id="124468d30e8b5047c5fe1b160b4fcbd2" category="paragraph">Con<block ref="ebe914c00393f99bd92af5cffa8376b0" category="inline-link-macro-rx"></block> , puede crear una copia de un volumen de NetApp que resida en un plano de datos diferente.  Por ejemplo, si tiene un volumen de NetApp en su plano de datos local y necesita acceder a ese volumen en su plano de datos de AWS, puede crear una copia del volumen en AWS.  En esta sección se describen las tareas que deben realizarse para crear una copia de un volumen de NetApp que reside en un plano de datos diferente.</block>
  <block id="050a227810327b3bcfd311be38b7d202" category="section-title">Crear una relación SnapMirror</block>
  <block id="fef6b7d4f88331bab85d2eb944d43e9b" category="paragraph">Primero, debe crear una relación SnapMirror entre su volumen de origen y un nuevo volumen de destino en el entorno de destino.  Tenga en cuenta que el volumen de destino se creará como parte del proceso de creación de la relación SnapMirror .</block>
  <block id="62390de09bd56fbb6d4533a188f4f201" category="inline-link-macro">Documentación de BlueXP replication</block>
  <block id="6fbd84bba212db826d8a94b992bd6324" category="paragraph">Recomendamos utilizar BlueXP para crear la relación SnapMirror .  Para crear una relación SnapMirror con BlueXP, siga las instrucciones que se describen en la<block ref="b08e4ece79f7d1aa7f110b298b659fae" category="inline-link-macro-rx"></block> .</block>
  <block id="052be79cbb457a1391bb0a6839e610d3" category="paragraph">Si prefiere no utilizar BlueXP, puede utilizar el Administrador del sistema ONTAP o la CLI de ONTAP para crear la relación SnapMirror .  Para crear una relación SnapMirror con el Administrador del sistema, consulte las instrucciones descritas en la<block ref="665d2354c4ea508e65993c5ec9dc3fa1" category="inline-link-macro-rx"></block> .  Para crear una relación SnapMirror con la CLI de ONTAP , consulte las instrucciones descritas en la<block ref="bf03311f5c6980a3d817528b27741438" category="inline-link-macro-rx"></block> .</block>
  <block id="805b58c51fa6bf98d530bbc76f317e74" category="section-title">Romper la relación de SnapMirror</block>
  <block id="9ee42869e01344256cee7824a61c3f00" category="paragraph">A continuación, debe romper la relación SnapMirror para activar el volumen de destino para el acceso a los datos.  Espere hasta que se complete la replicación inicial antes de realizar este paso.</block>
  <block id="c16b6b1cdf70d97ab9f143b23f304ee5" category="admonition">Puede determinar si la replicación está completa o no verificando el estado del espejo en BlueXP, el Administrador del sistema ONTAP o la CLI de ONTAP .  Cuando se complete la replicación, el estado del espejo será "snapmirrored".</block>
  <block id="acab4369131a8c646dc85deedc5c4abb" category="paragraph">Recomendamos utilizar BlueXP para romper la relación SnapMirror .  Para romper una relación de SnapMirror con BlueXP, siga las instrucciones que se describen en la<block ref="eb8fade3a2fe398b39f82043fade1a22" category="inline-link-macro-rx"></block> .</block>
  <block id="96009cd50e3918957734c7c1dbe9bbb1" category="paragraph">Si prefiere no utilizar BlueXP, puede utilizar el Administrador del sistema ONTAP o la CLI de ONTAP para romper la relación de SnapMirror .  Para romper una relación de SnapMirror con el Administrador del sistema, consulte las instrucciones descritas en la<block ref="2feb8ad9799acf2d659fb0cab9f5c802" category="inline-link-macro-rx"></block> .  Para romper una relación de SnapMirror con la CLI de ONTAP , consulte las instrucciones descritas en la<block ref="a5d68b350f5308762130d0f350fbb93c" category="inline-link-macro-rx"></block> .</block>
  <block id="67a1a8de2d55c1b2a31ec40db952c0cf" category="section-title">Exponer el volumen de destino a Domino</block>
  <block id="0de56c363db9af31c3fe36cd53b5deaf" category="paragraph">A continuación, debe exponer el volumen de destino a la plataforma Domino MLOps.  Para exponer el volumen de destino a Domino, siga las instrucciones descritas en la subsección 'Exponer volúmenes NFS existentes que no fueron aprovisionados por Trident' del documento.<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> de esta solución.</block>
  <block id="aa4e6b2b0a9165bbe6adb64ff972dbb0" category="paragraph">Ahora, podrá montar el volumen de destino al iniciar trabajos y espacios de trabajo en el plano de datos de destino como se muestra en las siguientes capturas de pantalla.</block>
  <block id="6c2d9f4c43e6e539a1b0bf3be24de513" category="section-title">Antes de crear la relación SnapMirror</block>
  <block id="800f74671431bfc6b9efb2f7e294020f" category="section-title">Después de exponer el volumen de destino a Domino</block>
  <block id="a2207225ebdd3d675188d927e34ace5a" category="summary">Domino Nexus es un panel único que le permite ejecutar cargas de trabajo de ciencia de datos y aprendizaje automático en cualquier clúster de cómputo, en cualquier nube, región o local.</block>
  <block id="1882311bf64ae464a0b9653b463c8584" category="doc">MLOps multicloud híbridos con Domino Data Lab y NetApp</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">Mike Oglesby, NetApp</block>
  <block id="c716184d878cbe2fda94903e01c21291" category="paragraph">Actualmente, organizaciones de todo el mundo están adoptando IA para transformar sus negocios y procesos.  Debido a esto, la infraestructura informática preparada para IA suele ser escasa.  Las empresas están adoptando arquitecturas MLOps multicloud híbridas para aprovechar los entornos informáticos disponibles en diferentes regiones, centros de datos y nubes, equilibrando costos, disponibilidad y rendimiento.</block>
  <block id="542493ebb9768d33d834c6edcade57dc" category="paragraph">Domino Nexus, de Domino Data Lab, es un plano de control MLOps unificado que le permite ejecutar cargas de trabajo de ciencia de datos y aprendizaje automático en cualquier clúster de cómputo, en cualquier nube, región o local.  Unifica los silos de ciencia de datos en toda la empresa, de modo que usted tiene un solo lugar para crear, implementar y monitorear modelos.  Asimismo, las capacidades de gestión de datos en nube híbrida de NetApp le permiten llevar sus datos a sus trabajos y espacios de trabajo, sin importar dónde se estén ejecutando.  Al combinar Domino Nexus con NetApp, tiene la flexibilidad de programar cargas de trabajo en diferentes entornos sin tener que preocuparse por la disponibilidad de los datos.  En otras palabras, tiene la capacidad de enviar sus cargas de trabajo y sus datos al entorno computacional apropiado, lo que le permite acelerar sus implementaciones de IA mientras navega por las regulaciones sobre privacidad y soberanía de los datos.</block>
  <block id="3eb3ace35104f92d82777b3219f769d7" category="paragraph">Esta solución demuestra la implementación de un plano de control MLOps unificado que incorpora un clúster de Kubernetes local y un clúster de Elastic Kubernetes Service (EKS) que se ejecuta en Amazon Web Services (AWS).</block>
  <block id="5be0395276ff3840daa0a0cb7643b68d" category="summary">MLOps multicloud híbrido con Domino Data Lab y NetApp : configuración inicial</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">Configuración inicial</block>
  <block id="ef81709626b455fffcd99d9f67085d18" category="paragraph">Esta sección describe las tareas de configuración inicial que deben realizarse para utilizar Domino Nexus con los servicios de datos de NetApp en un entorno híbrido que incorpora un centro de datos local y AWS.</block>
  <block id="87b13b0a04193ccc830f23d041d6f3ba" category="paragraph">Antes de realizar los pasos que se describen en esta sección, asumimos que ya ha realizado las siguientes tareas:</block>
  <block id="677ae9330aedf715db07a33be39cbbeb" category="list-text">Ya ha implementado y configurado su plataforma de almacenamiento NetApp ONTAP local. Para obtener más información, consulte la <block ref="077b296918e9131d07388450dbd7a243" category="inline-link-macro-rx"></block> .</block>
  <block id="8f117f8e1e04a7113b95048bd0077b28" category="inline-link-macro">Página del producto Amazon FSx ONTAP</block>
  <block id="837adf3f87eb8a7f5893e4b6a6f7cee5" category="list-text">Ya ha aprovisionado una instancia de Amazon FSx ONTAP en AWS. Para obtener más información, consulte la <block ref="88e07f6417e37f8ff711e34864e5d89c" category="inline-link-macro-rx"></block> .</block>
  <block id="6bd1aa1204077ccb610d72dbc07f11b1" category="inline-link-macro">Guía de administración de Domino</block>
  <block id="83a12488d43dae9419d61f6f83fa014a" category="list-text">Ya ha aprovisionado un clúster de Kubernetes en su centro de datos local. Para obtener más información, consulte la <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="6b59c41a4554c4e0f63a7da5ad17b347" category="list-text">Ya ha aprovisionado un clúster de Amazon EKS en AWS. Para obtener más información, consulte la <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link-macro">Documentación de NetApp Trident</block>
  <block id="1ac8e4f74be6c2aad80e2d33e0bdef83" category="list-text">Ha instalado NetApp Trident en su clúster de Kubernetes local.  Además, ha configurado esta instancia de Trident para utilizar su plataforma de almacenamiento NetApp ONTAP local al aprovisionar y administrar recursos de almacenamiento. Para obtener más información, consulte la <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="6c45529675023ab110b59c01a71b6038" category="list-text">Ha instalado NetApp Trident en su clúster de Amazon EKS.  Además, ha configurado esta instancia de Trident para utilizar su instancia de Amazon FSx ONTAP al aprovisionar y administrar recursos de almacenamiento. Para obtener más información, consulte la <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="f8090d27d981a98d65c4401bdd84b3bf" category="inline-link-macro">Documentación de la red privada virtual (VPN) de Amazon</block>
  <block id="c09961db559c7c906d851ebf8ba40ac5" category="list-text">Debe tener conectividad de red bidireccional entre su centro de datos local y su nube privada virtual (VPC) en AWS.  Para obtener más detalles sobre las distintas opciones para implementar esto, consulte la<block ref="f5c50c4f502917d968e827ba0a3b9d8e" category="inline-link-macro-rx"></block> .</block>
  <block id="077b7144cc60353e8c8fdc9663398f24" category="section-title">Instalar la plataforma de inteligencia artificial empresarial Domino en AWS</block>
  <block id="5e1251e5d0134550a0ea5f1f02c14c3a" category="paragraph">Para instalar la plataforma Domino Enterprise MLOps en AWS, siga las instrucciones que se describen en<block ref="7ebd1f818144f08a887fe5d8dbad016a" category="inline-link-macro-rx"></block> .  Debe implementar Domino en el mismo clúster de Amazon EKS que aprovisionó anteriormente.  Además, NetApp Trident ya debe estar instalado y configurado en este clúster EKS, y debe especificar una clase de almacenamiento administrada por Trident como la clase de almacenamiento compartido en su archivo de configuración de instalación domino.yml.</block>
  <block id="feee67bbfd0f30a09eeb08ca21cdf38d" category="inline-link-macro">Guía de referencia de configuración de instalación de Domino</block>
  <block id="8facc83d9ba07b807b37a1cf4c7f8a74" category="admonition">Consulte la<block ref="ace9eaa491d11b57c3774d7e21b1cd72" category="inline-link-macro-rx"></block> para obtener detalles sobre cómo especificar una clase de almacenamiento compartido en su archivo de configuración de instalación domino.yml.</block>
  <block id="11f21d6309deb4cfcdc7f2cdb4fd0839" category="inline-link-macro">Informe técnico TR-4952</block>
  <block id="78dd0d0a7a9f103f53daa672d459adb9" category="admonition"><block ref="3de90155c2505cad82b61f16af3049bc" category="inline-link-macro-rx"></block>recorre la implementación de Domino en AWS con Amazon FSx ONTAP y puede ser una referencia útil para solucionar cualquier problema que surja.</block>
  <block id="aa2a36e425ea068322a0e37b07481ba8" category="section-title">Habilitar Domino Nexus</block>
  <block id="1a942f929d8ad029b828b8e738a86a07" category="paragraph">A continuación, debes habilitar Domino Nexus.  Consulte la<block ref="31b0fd9bf4991ddcfdb80d02c1415fe4" category="inline-link-macro-rx"></block> Para más detalles.</block>
  <block id="fa64dcf7a96dbbcd90b8729d4d59ab2f" category="section-title">Implemente un plano de datos de Domino en su centro de datos local</block>
  <block id="4ad85753a09f6b6e21cf6089aa28f2b2" category="paragraph">A continuación, debe implementar un Domino Data Plane en su centro de datos local.  Debe implementar este plano de datos en el clúster de Kubernetes local que aprovisionó previamente.  Además, NetApp Trident ya debe estar instalado y configurado en este clúster de Kubernetes.  Consulte la<block ref="d46974ff7fcd2c0e55b6b55f2aa698e1" category="inline-link-macro-rx"></block> Para más detalles.</block>
  <block id="9fac4fc4e1be67e589c110f0c4647f2e" category="summary">MLOps multicloud híbridos con Domino Data Lab y NetApp : descripción general de la tecnología</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">Descripción general de la tecnología</block>
  <block id="f0bbbdb43782a17fdb1b5541f4c2d25f" category="paragraph">Esta sección proporciona una descripción general de la tecnología para MLOps multicloud híbrido con Domino Data Lab y NetApp.</block>
  <block id="4e00c35efcd0578992f4821557db1c9e" category="paragraph">Domino Data Lab potencia las empresas basadas en modelos con su plataforma líder de inteligencia artificial empresarial en la que confía más del 20 % de las empresas Fortune 100.  Domino acelera el desarrollo y la implementación del trabajo de ciencia de datos al tiempo que aumenta la colaboración y la gobernanza.  Con Domino, las empresas de todo el mundo pueden desarrollar mejores medicamentos, cultivar cosechas más productivas, construir mejores automóviles y mucho más.  Fundada en 2013, Domino cuenta con el respaldo de Coatue Management, Great Hill Partners, Highland Capital, Sequoia Capital y otros inversores líderes.</block>
  <block id="582cc4e2654a5d265b3a9c8960a43e88" category="paragraph">Domino permite a las empresas y sus científicos de datos construir, implementar y gestionar IA en una plataforma unificada de extremo a extremo, de manera rápida, responsable y rentable.  Los equipos pueden acceder a todos los datos, herramientas, cálculos, modelos y proyectos que necesitan en cualquier entorno, de modo que pueden colaborar, reutilizar trabajos anteriores, realizar un seguimiento de modelos en producción para mejorar la precisión, estandarizar con las mejores prácticas y hacer que la IA sea responsable y esté gobernada.</block>
  <block id="79aba99e2c2c50a4d5627b787bde8eae" category="list-text">*Abierto y flexible:* Acceda al ecosistema más amplio de herramientas y recursos comerciales y de código abierto, e infraestructura, para acceder a las mejores innovaciones y sin ataduras a ningún proveedor.</block>
  <block id="720b80ab9ad18c5e500ae8203bb712f2" category="list-text">*Sistema de registro:* Centro central para operaciones y conocimiento de IA en toda la empresa, que permite mejores prácticas, colaboración multifuncional, innovación más rápida y eficiencia.</block>
  <block id="8d89627678490a8b88c851ea2fac357d" category="list-text">*Integrado:* Los flujos de trabajo y la automatización integrados, diseñados para procesos, controles y gobernanza empresariales, satisfacen sus necesidades normativas y de cumplimiento.</block>
  <block id="9e390a9660aa9f11963ef8d4ebe9b58a" category="list-text">*Multicloud híbrido:* Ejecute cargas de trabajo de IA cerca de sus datos en cualquier lugar (local, híbrido, en cualquier nube o multinube) para lograr un menor costo, un rendimiento óptimo y cumplimiento.</block>
  <block id="5bfd375703bc2df982ba9c5193150b90" category="paragraph"><block ref="5bfd375703bc2df982ba9c5193150b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80603873e677eebf28ec5645b40f7453" category="paragraph">Domino Nexus es un panel único que le permite ejecutar cargas de trabajo de ciencia de datos y aprendizaje automático en cualquier clúster de cómputo, en cualquier nube, región o local.  Unifica los silos de ciencia de datos en toda la empresa, de modo que usted tiene un solo lugar para crear, implementar y monitorear modelos.</block>
  <block id="991a53642be15661dc9369ee1ae2085c" category="paragraph">NetApp BlueXP unifica todos los servicios de almacenamiento y datos de NetApp en una única herramienta que le permite crear, proteger y gobernar su patrimonio de datos multicloud híbrido.  Ofrece una experiencia unificada para servicios de almacenamiento y datos en entornos locales y en la nube, y permite la simplicidad operativa a través del poder de AIOps, con los parámetros de consumo flexibles y la protección integrada necesarios para el mundo actual liderado por la nube.</block>
  <block id="8814f8d780d4b85a940aa27445d68549" category="list-text">Conexión a la nube.  ONTAP es el software de gestión de almacenamiento más conectado a la nube, con opciones para almacenamiento definido por software e instancias nativas de la nube en todas las nubes públicas.</block>
  <block id="5dbf44a3195cc10e2873e76a30df05ac" category="section-title">Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="bca10fd5d70f83556ba989ecf392df97" category="paragraph">Amazon FSx ONTAP es un servicio de AWS totalmente administrado y de primera mano que proporciona almacenamiento de archivos altamente confiable, escalable, de alto rendimiento y rico en funciones, creado sobre el popular sistema de archivos ONTAP de NetApp. FSx ONTAP combina las características, el rendimiento, las capacidades y las operaciones API familiares de los sistemas de archivos NetApp con la agilidad, la escalabilidad y la simplicidad de un servicio de AWS completamente administrado.</block>
  <block id="193e0bb6f3a76822b629d0fae08bdb7e" category="paragraph">Trident permite el consumo y la gestión de recursos de almacenamiento en todas las plataformas de almacenamiento NetApp más populares, en la nube pública o en las instalaciones, incluidas ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), el software Element (NetApp HCI, SolidFire), el servicio Azure NetApp Files y Google Cloud NetApp Volumes en Google Cloud.  Trident es un orquestador de almacenamiento dinámico compatible con la interfaz de almacenamiento de contenedores (CSI) que se integra de forma nativa con Kubernetes.</block>
  <block id="978ecccb92a71c90363dfd222ebdfe77" category="paragraph">Kubernetes es una plataforma de orquestación de contenedores distribuida y de código abierto que fue diseñada originalmente por Google y ahora es mantenida por la Cloud Native Computing Foundation (CNCF).  Kubernetes permite la automatización de funciones de implementación, administración y escalamiento para aplicaciones en contenedores, y es la plataforma de orquestación de contenedores dominante en entornos empresariales.</block>
  <block id="b2a7a79ed7fe83cbfb6fe2140e6fb60a" category="paragraph">Amazon Elastic Kubernetes Service (Amazon EKS) es un servicio de Kubernetes administrado en la nube de AWS.  Amazon EKS administra automáticamente la disponibilidad y la escalabilidad de los nodos del plano de control de Kubernetes responsables de programar contenedores, administrar la disponibilidad de las aplicaciones, almacenar datos del clúster y otras tareas clave.  Con Amazon EKS, puede aprovechar todo el rendimiento, la escala, la confiabilidad y la disponibilidad de la infraestructura de AWS, así como las integraciones con los servicios de redes y seguridad de AWS.</block>
  <block id="7bdb77faa0d23db500f55d38c7812837" category="summary">MLOps multicloud híbridos con Domino Data Lab y NetApp : exponga los volúmenes existentes de NetApp a Domino</block>
  <block id="5f385895d8f69d19670414fea115c17e" category="doc">Exponer volúmenes NetApp existentes a Domino</block>
  <block id="012942ee2856a3a30e386d999ab4decd" category="paragraph">En esta sección se describen las tareas que deben realizarse para exponer los volúmenes NFS de NetApp ONTAP existentes a la plataforma Domino MLOps.  Estos mismos pasos se aplican tanto en las instalaciones locales como en AWS.</block>
  <block id="216745145dbb2663dd8ef64d1e7b70ce" category="section-title">¿Por qué exponer volúmenes de NetApp ONTAP a Domino?</block>
  <block id="4f49bbf1791537d3f9cea32729bcf171" category="paragraph">El uso de volúmenes NetApp junto con Domino proporciona los siguientes beneficios:</block>
  <block id="bdf339cbdff188396b615acb6642682f" category="list-text">Puede ejecutar cargas de trabajo en conjuntos de datos extremadamente grandes aprovechando las capacidades de escalamiento horizontal de NetApp ONTAP.</block>
  <block id="ad859808af9509052afa68845ee13abf" category="list-text">Puede ejecutar cargas de trabajo en múltiples nodos de cómputo sin tener que copiar sus datos en los nodos individuales.</block>
  <block id="3019efb93cfae9d2074cee3ecba248ce" category="list-text">Puede aprovechar las capacidades de sincronización y movimiento de datos multicloud híbridos de NetApp para acceder a sus datos en múltiples centros de datos y/o nubes.</block>
  <block id="72410fa7689169a336be6540fbab04cb" category="list-text">Desea poder crear de forma rápida y sencilla un caché de sus datos en un centro de datos o nube diferente.</block>
  <block id="6d4734babb6928dd0a6f21c21a95be6a" category="section-title">Exponer volúmenes NFS existentes que no fueron aprovisionados por Trident</block>
  <block id="908d8e50ed4f87ffd16293ce7689ffa3" category="paragraph">Si su volumen NFS NetApp ONTAP existente no fue aprovisionado por Trident, siga los pasos descritos en esta subsección.</block>
  <block id="b0604699a0737b4da7a79ed81a611605" category="section-title">Crear PV y PVC en Kubernetes</block>
  <block id="0b8e803956828c77b5f9c0745c726ca8" category="admonition">Para los volúmenes locales, cree el PV y el PVC en su clúster de Kubernetes local.  Para los volúmenes de Amazon FSx ONTAP , cree el PV y el PVC en Amazon EKS.</block>
  <block id="7ea686752cd0065765a1f236f52b6a86" category="inline-link-macro">Ejemplo de NFS PV/PVC</block>
  <block id="21daa905ac0fe45b36e98c4b7c6cbfaf" category="paragraph">Primero, debe crear un volumen persistente (PV) y un reclamo de volumen persistente (PVC) en su clúster de Kubernetes.  Para crear el PV y el PVC, utilice el<block ref="a25b642a6322d7659714e6bd71e7cd4f" category="inline-link-macro-rx"></block> de la guía de administración de Domino y actualice los valores para reflejarlos en su entorno.  Asegúrese de especificar los valores correctos para el<block ref="89801e9e98979062e84647433a8ed3e9" prefix=" " category="inline-code"></block> ,<block ref="0a087fd97387c110f029a7a2550ff280" prefix=" " category="inline-code"></block> , y<block ref="34ae7d3a708b57f81af8fcfcd13c7a55" prefix=" " category="inline-code"></block> campos.  Además, recomendamos darle a sus PV y PVC nombres únicos que representen la naturaleza de los datos almacenados en el volumen NFS de ONTAP correspondiente.  Por ejemplo, si el volumen contiene imágenes de defectos de fabricación, puede nombrar el PV,<block ref="7146834334002e1c2c8bbb00348a951c" prefix=" " category="inline-code"></block> , y el PVC,<block ref="2d04ce24c553ffe8e7f9b69269696618" prefix=" " category="inline-code"></block> .</block>
  <block id="3a0e23ff2bfd7dc5b55c1aeb14b0ce33" category="section-title">Registrar volumen de datos externos en Domino</block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">instrucciones</block>
  <block id="6d38ad9604bf23123ad6f1505f8f64ce" category="paragraph">A continuación, debe registrar un volumen de datos externo en Domino.  Para registrar un volumen de datos externo, consulte la<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> en la guía de administración de Domino.  Al registrar el volumen, asegúrese de seleccionar "NFS" en el menú desplegable "Tipo de volumen".  Después de seleccionar "NFS", debería ver su PVC en la lista "Volúmenes disponibles".</block>
  <block id="f759d0a96176c0ce67a4269c5b45bc42" category="paragraph"><block ref="f759d0a96176c0ce67a4269c5b45bc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f91c183558f2466e2e75a92424f7a3bf" category="section-title">Exponer volúmenes existentes que fueron aprovisionados por Trident</block>
  <block id="733e83e8c2052942f7f0e96fcd19e8a4" category="paragraph">Si su volumen existente fue aprovisionado por Trident, siga los pasos descritos en esta subsección.</block>
  <block id="57a045b809f3298056d203360becbd66" category="section-title">Editar PVC existente</block>
  <block id="aaf6f0a313e2fa37d3584aa97603489a" category="paragraph">Si su volumen fue aprovisionado por Trident, entonces ya tiene un reclamo de volumen persistente (PVC) correspondiente a su volumen.  Para exponer este volumen a Domino, debe editar el PVC y agregar la siguiente etiqueta a la lista de etiquetas en el<block ref="9cc59534218c9b00f7eb481861d14401" prefix=" " category="inline-code"></block> campo:</block>
  <block id="d2790ed8ab25c08ee1efd69f0773cade" category="paragraph">A continuación, debe registrar un volumen de datos externo en Domino.  Para registrar un volumen de datos externo, consulte la<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> en la guía de administración de Domino.  Al registrar el volumen, asegúrese de seleccionar "Genérico" en el menú desplegable "Tipo de volumen".  Después de seleccionar "Genérico", debería ver su PVC en la lista "Volúmenes disponibles".</block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA AI Enterprise con NetApp y VMware: dónde encontrar información adicional</block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise con VMware</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen, director sénior de NetApp</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac, administrador de sistemas, NetApp</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">Roney Daniel, ingeniero de marketing técnico, NetApp</block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA AI Enterprise con NetApp y VMware: Arquitectura</block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">Esta solución se basa en una arquitectura probada y familiar con sistemas certificados por NetApp, VMware y NVIDIA.  Consulte la siguiente tabla para obtener más detalles.</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">Software de inteligencia artificial y análisis de datos</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">NVIDIA AI Enterprise para VMware</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">Plataforma de virtualización</block>
  <block id="8887a9a417a1629326acdb917d224337" category="inline-link-macro">VMware vSphere</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">Plataforma de cómputo</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">Sistemas certificados por NVIDIA</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">Plataforma de gestión de datos</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="3e549e3b22de98c96646fb0586a93db3" category="paragraph"><block ref="3e549e3b22de98c96646fb0586a93db3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise es una suite integral de software de IA y análisis de datos nativo de la nube, optimizada para que cada organización pueda tener éxito con la IA.</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA AI Enterprise con NetApp y VMware</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">Para los arquitectos y administradores de TI, las herramientas de IA pueden ser complicadas y desconocidas.  Además, muchas plataformas de IA no están preparadas para el uso empresarial.  NVIDIA AI Enterprise, impulsado por NetApp y VMware, se creó para ofrecer una arquitectura de IA optimizada y de clase empresarial.</block>
  <block id="eb7e5009de0ce355dc9131d958a1541e" category="paragraph"><block ref="eb7e5009de0ce355dc9131d958a1541e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NVIDIA AI Enterprise con NetApp y VMware: utilice el software NVIDIA NGC - Configuración</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">Configuración</block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">Esta sección describe las tareas de configuración inicial que deben realizarse para utilizar el software empresarial NVIDIA NGC dentro de un entorno NVIDIA AI Enterprise.</block>
  <block id="1eb5d19d2c5071a5a7a569f58f2c9613" category="paragraph">Antes de realizar los pasos que se describen en esta sección, asumimos que ya ha implementado el software de host NVIDIA AI Enterprise siguiendo las instrucciones que se describen en la<block ref="b97b75086b5941ac63fab1eee89b4777" category="inline-link-macro-rx"></block> página.</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">Crear una máquina virtual invitada de Ubuntu con vGPU</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">Guía de implementación empresarial de NVIDIA AI</block>
  <block id="4be8ecb3320915437222a84e9761bcec" category="paragraph">Primero, debes crear una máquina virtual invitada Ubuntu 20.04 con vGPU.  Para crear una máquina virtual invitada Ubuntu 20.04 con vGPU, siga las instrucciones que se detallan en el<block ref="2009ba36309e23fc0bb68cec4d4a3e0d" category="inline-link-macro-rx"></block> .</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">Descargar e instalar el software invitado de NVIDIA</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">Guía de inicio rápido de NVIDIA AI Enterprise</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">A continuación, debe instalar el software invitado NVIDIA necesario dentro de la máquina virtual invitada que creó en el paso anterior.  Para descargar e instalar el software invitado NVIDIA necesario dentro de la máquina virtual invitada, siga las instrucciones descritas en las secciones 5.1 a 5.4 del manual.<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">Al realizar las tareas de verificación descritas en la sección 5.4, es posible que necesite utilizar una etiqueta de versión de imagen de contenedor CUDA diferente, ya que la imagen de contenedor CUDA se ha actualizado desde la redacción de esta guía.  En nuestra validación, utilizamos 'nvidia/cuda:11.0.3-base-ubuntu20.04'.</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">Descargar contenedor(es) del marco de IA/análisis</block>
  <block id="939ac3b79a18fc027a13bea0aeebcd3c" category="paragraph">A continuación, debe descargar las imágenes de contenedor del marco de análisis o IA necesarias de NVIDIA NGC para que estén disponibles en su máquina virtual invitada.  Para descargar contenedores del marco dentro de la máquina virtual invitada, siga las instrucciones que se describen en<block ref="7ea494a5b1819fa63a0ad0f42cf94b43" category="inline-link-macro-rx"></block> .</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">Instalar y configurar el kit de herramientas NetApp DataOps</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">A continuación, debe instalar NetApp DataOps Toolkit para entornos tradicionales dentro de la máquina virtual invitada.  El kit de herramientas NetApp DataOps se puede utilizar para administrar volúmenes de datos escalables en su sistema ONTAP directamente desde la terminal dentro de la máquina virtual invitada.  Para instalar NetApp DataOps Toolkit dentro de la máquina virtual invitada, realice las siguientes tareas.</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">Instalar pip.</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">Cierre la sesión de la terminal de la máquina virtual invitada y luego vuelva a iniciarla.</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">Configurar el kit de herramientas NetApp DataOps.  Para completar este paso, necesitará detalles de acceso a la API para su sistema ONTAP .  Es posible que necesite obtenerlos de su administrador de almacenamiento.</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">Crear una plantilla de máquina virtual invitada</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">Por último, debes crear una plantilla de VM basada en tu VM invitada.  Podrás usar esta plantilla para crear rápidamente máquinas virtuales invitadas para utilizar el software NVIDIA NGC.</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">Para crear una plantilla de VM basada en su VM invitada, inicie sesión en VMware vSphere, haga clic derecho en el nombre de la VM invitada, elija "Clonar", elija "Clonar a plantilla..." y luego siga el asistente.</block>
  <block id="ae46b5fec5e9fa6540317c6aff2886d0" category="paragraph"><block ref="ae46b5fec5e9fa6540317c6aff2886d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA AI Enterprise con NetApp y VMware: configuración inicial</block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">Esta sección describe las tareas de configuración inicial que deben realizarse para utilizar NVIDIA AI Enterprise con NetApp y VMware.</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">Matriz de soporte de productos empresariales de IA de NVIDIA</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">Documentación de soluciones de NetApp y VMware</block>
  <block id="06a8848af5cbb48d04a6b9d27ea22cae" category="paragraph">Antes de realizar los pasos que se describen en esta sección, asumimos que ya ha implementado VMware vSphere y NetApp ONTAP.  Consulte la<block ref="fca8480728eb091fdea60a7b3cdc16f7" category="inline-link-macro-rx"></block> para obtener detalles sobre las versiones de vSphere compatibles.  Consulte la<block ref="dde322875ea0d7cfe426ecec0c0dad4c" category="inline-link-macro-rx"></block> para obtener detalles sobre la implementación de VMware vSphere con NetApp ONTAP.</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">Instalar el software de host empresarial NVIDIA AI</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">Para instalar el software de host NVIDIA AI Enterprise, siga las instrucciones descritas en las secciones 1 a 4 del<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA AI Enterprise con NetApp y VMware: descripción general de la tecnología</block>
  <block id="d54433e43cda21e1ff5ab715c73883de" category="paragraph">Esta sección proporciona una descripción general de la tecnología para NVIDIA AI Enterprise con NetApp y VMware.</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise es una suite integral de software de inteligencia artificial y análisis de datos nativa de la nube, optimizada, certificada y respaldada por NVIDIA para ejecutarse en VMware vSphere con sistemas certificados NVIDIA.  Este software facilita la implementación, la gestión y el escalamiento simples y rápidos de cargas de trabajo de IA en el entorno de nube híbrida moderno.</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC alberga un catálogo de software optimizado para GPU para que los profesionales de IA desarrollen sus soluciones de IA.  También proporciona acceso a varios servicios de IA, incluidos NVIDIA Base Command para entrenamiento de modelos, NVIDIA Fleet Command para implementar y monitorear modelos, y NGC Private Registry para acceder y administrar de forma segura software de IA propietario.  Además, los clientes de NVIDIA AI Enterprise pueden solicitar soporte a través del portal NGC.</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere es la plataforma de virtualización de VMware, que transforma los centros de datos en infraestructuras informáticas agregadas que incluyen recursos de CPU, almacenamiento y redes. vSphere administra estas infraestructuras como un entorno operativo unificado y proporciona a los administradores las herramientas para administrar los centros de datos que participan en ese entorno.</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">Los dos componentes principales de vSphere son ESXi y vCenter Server.  ESXi es la plataforma de virtualización donde los administradores crean y ejecutan máquinas virtuales y dispositivos virtuales. vCenter Server es el servicio a través del cual los administradores gestionan múltiples hosts conectados en una red y agrupan los recursos del host.</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">NetApp DataOps Toolkit es una herramienta basada en Python que simplifica la gestión de espacios de trabajo de desarrollo/entrenamiento y servidores de inferencia respaldados por almacenamiento NetApp de alto rendimiento y escalabilidad horizontal.  Las capacidades clave incluyen:</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">Clone casi instantáneamente espacios de trabajo de JupyterLab de alta capacidad para permitir la experimentación o la iteración rápida.</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">Guarde casi instantáneamente instantáneas de espacios de trabajo de JupyterLab de alta capacidad para realizar copias de seguridad y/o trazabilidad/establecimiento de referencia.</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">Aprovisione, clone y cree instantáneas de volúmenes de datos de alto rendimiento y alta capacidad de manera casi instantánea.</block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA AI Enterprise con NetApp y VMware: uso del software NVIDIA NGC (caso práctico de ejemplo) - Formación en TensorFlow</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">Ejemplo de caso de uso: trabajo de capacitación de TensorFlow</block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">Esta sección describe las tareas que deben realizarse para ejecutar un trabajo de entrenamiento de TensorFlow dentro de un entorno de NVIDIA AI Enterprise.</block>
  <block id="0733928d94b0eba77ac6cf7f3c950257" category="paragraph">Antes de realizar los pasos que se describen en esta sección, asumimos que ya ha creado una plantilla de máquina virtual invitada siguiendo las instrucciones que se describen en la<block ref="ad0d852572366b07cdb7f9f854b3aedf" category="inline-link-macro-rx"></block> página.</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">Crear una máquina virtual invitada a partir de una plantilla</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">Primero, debes crear una nueva VM invitada a partir de la plantilla que creaste en la sección anterior.  Para crear una nueva VM invitada a partir de su plantilla, inicie sesión en VMware vSphere, haga clic derecho en el nombre de la plantilla, seleccione "Nueva VM a partir de esta plantilla..." y luego siga el asistente.</block>
  <block id="d31d5f91fee0f03911daa3d20a90e607" category="paragraph"><block ref="d31d5f91fee0f03911daa3d20a90e607" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">Crear y montar un volumen de datos</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">A continuación, debe crear un nuevo volumen de datos en el que almacenar su conjunto de datos de entrenamiento.  Puede crear rápidamente un nuevo volumen de datos utilizando el kit de herramientas NetApp DataOps.  El comando de ejemplo que sigue muestra la creación de un volumen llamado 'imagenet' con una capacidad de 2 TB.</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">Antes de poder rellenar su volumen de datos con datos, debe montarlo dentro de la máquina virtual invitada.  Puede montar rápidamente un volumen de datos utilizando el kit de herramientas NetApp DataOps.  El comando de ejemplo que sigue muestra el montaje del volumen que se creó en el paso anterior.</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">Rellenar volumen de datos</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">Una vez aprovisionado y montado el nuevo volumen, se puede recuperar el conjunto de datos de entrenamiento de la ubicación de origen y colocarlo en el nuevo volumen.  Por lo general, esto implicará extraer los datos de un lago de datos S3 o Hadoop y, a veces, requerirá la ayuda de un ingeniero de datos.</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">Ejecutar trabajo de entrenamiento de TensorFlow</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">Ahora, está listo para ejecutar su trabajo de entrenamiento de TensorFlow.  Para ejecutar su trabajo de entrenamiento de TensorFlow, realice las siguientes tareas.</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">Extraiga la imagen del contenedor TensorFlow empresarial NVIDIA NGC.</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">Inicie una instancia del contenedor TensorFlow empresarial NVIDIA NGC.  Utilice la opción '-v' para adjuntar su volumen de datos al contenedor.</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">Ejecute su programa de entrenamiento de TensorFlow dentro del contenedor.  El siguiente comando de ejemplo muestra la ejecución de un programa de entrenamiento ResNet-50 de ejemplo que está incluido en la imagen del contenedor.</block>
  <block id="9dd88053035e8518106da3a40ce3aa3b" category="summary">MLOps de código abierto con NetApp : Implementación de Apache Airflow</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Implementación de Apache Airflow</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="paragraph">Esta sección describe las tareas que debe completar para implementar Airflow en su clúster de Kubernetes.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Es posible implementar Airflow en plataformas distintas a Kubernetes.  La implementación de Airflow en plataformas distintas a Kubernetes está fuera del alcance de esta solución.</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">Antes de realizar el ejercicio de implementación que se describe en esta sección, asumimos que ya ha realizado las siguientes tareas:</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Ya tienes un clúster de Kubernetes en funcionamiento.</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link-macro">Documentación de Trident</block>
  <block id="85dd9fb465515fcb64ad8d6b67591898" category="list-text">Ya ha instalado y configurado NetApp Trident en su clúster de Kubernetes.  Para obtener más detalles sobre Trident, consulte la<block ref="6bc4e9e49caf522f01de7c1314cd2006" category="inline-link-macro-rx"></block> .</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Instalar Helm</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">instrucciones de instalación</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Airflow se implementa utilizando Helm, un administrador de paquetes popular para Kubernetes.  Antes de implementar Airflow, debe instalar Helm en el host de salto de implementación.  Para instalar Helm en el host de salto de implementación, siga las instrucciones<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> en la documentación oficial de Helm.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">Establecer la clase de almacenamiento predeterminada de Kubernetes</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Implementación de Kubeflow</block>
  <block id="53b8c224038ee8370989019811dd9379" category="paragraph">Antes de implementar Airflow, debe designar una StorageClass predeterminada dentro de su clúster de Kubernetes.  El proceso de implementación de Airflow intenta aprovisionar nuevos volúmenes persistentes utilizando la clase de almacenamiento predeterminada.  Si no se designa ninguna StorageClass como StorageClass predeterminada, la implementación falla.  Para designar una StorageClass predeterminada dentro de su clúster, siga las instrucciones que se describen en la<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> sección.  Si ya ha designado una StorageClass predeterminada dentro de su clúster, puede omitir este paso.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Utilice Helm para implementar el flujo de aire</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Para implementar Airflow en su clúster de Kubernetes usando Helm, realice las siguientes tareas desde el host de salto de implementación:</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">instrucciones de implementación</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Implemente Airflow usando Helm siguiendo las instrucciones<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> para el gráfico oficial de flujo de aire en Artifact Hub.  Los comandos de ejemplo que siguen muestran la implementación de Airflow usando Helm.  Modificar, agregar y/o eliminar valores en el<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block> archivo según sea necesario dependiendo de su entorno y la configuración deseada.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">Confirme que todos los pods Airflow estén en funcionamiento.  Es posible que pasen algunos minutos hasta que se inicien todos los pods.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">Obtenga la URL del servicio web Airflow siguiendo las instrucciones que se imprimieron en la consola cuando implementó Airflow usando Helm en el paso 1.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Confirme que puede acceder al servicio web Airflow.</block>
  <block id="ae954beef496ebe087806e1ce5f985b1" category="paragraph"><block ref="ae954beef496ebe087806e1ce5f985b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1358ee6f6793d8ad5c774e77af0ef2f8" category="summary">MLOps de código abierto con NetApp : utilice el kit de herramientas NetApp DataOps con Airflow</block>
  <block id="a6341ca5ab25e7d3076dec050c9e5a97" category="doc">Utilice el kit de herramientas NetApp DataOps con Airflow</block>
  <block id="a408a973f45f990bcd545653e35109ff" category="paragraph">El<block ref="d2f8e20a78f43c00804244e7ccbfa516" category="inline-link-rx"></block> Se puede utilizar junto con Airflow.  El uso de NetApp DataOps Toolkit con Airflow le permite incorporar operaciones de administración de datos de NetApp , como la creación de instantáneas y clones, en flujos de trabajo automatizados orquestados por Airflow.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">Ejemplos de flujo de aire</block>
  <block id="b6cc356bf5062501529145b3a4643413" category="paragraph">Consulte la<block ref="7c367129528d87aa1adf73a57a51aa4d" category="inline-link-rx"></block> sección dentro del repositorio de GitHub de NetApp DataOps Toolkit para obtener detalles sobre el uso del kit de herramientas con Airflow.</block>
  <block id="95cd1b9d487589b619592ac7a94f1001" category="summary">MLOps de código abierto con NetApp - Arquitectura</block>
  <block id="21d5dd37b5f077a36d22ba32af4054e6" category="paragraph">Esta solución no depende de hardware específico.  La solución es compatible con cualquier dispositivo de almacenamiento físico, instancia definida por software o servicio en la nube de NetApp que sea compatible con NetApp Trident.  Los ejemplos incluyen un sistema de almacenamiento NetApp AFF , Amazon FSx ONTAP, Azure NetApp Files, Google Cloud NetApp Volumes o una instancia de NetApp Cloud Volumes ONTAP .  Además, la solución se puede implementar en cualquier clúster de Kubernetes siempre que la versión de Kubernetes utilizada sea compatible con NetApp Trident y los demás componentes de la solución que se estén implementando.  Para obtener una lista de las versiones de Kubernetes compatibles con Trident, consulte la<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .  Consulte las siguientes tablas para obtener detalles sobre los entornos que se utilizaron para validar los distintos componentes de esta solución.</block>
  <block id="f9004e284a207cf92c8642965dc258f6" category="section-title">Entorno de validación de Apache Airflow</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">Componente de software</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">Flujo de aire de Apache</block>
  <block id="78fd3ce4c7835c8336b8c4f52bbd8570" category="inline-link-macro">Diagrama del timón Apache Airflow</block>
  <block id="923fc06abfe0b856f72313cb88706558" category="cell">2.0.1, implementado a través de<block ref="d1ea82e80be31e00d2b939c38f87e0a0" category="inline-link-macro-rx"></block> 8.0.8</block>
  <block id="836eb480bf66641d4fb44675e000d22b" category="cell">1,18</block>
  <block id="d029b605d0129cdb050642645b32b1db" category="cell">21,01</block>
  <block id="44ce1bc6a7380dccbb311f0fa6cd1972" category="section-title">Entorno de validación de JupyterHub</block>
  <block id="6a1bd94b05289cc97fd96ec055920439" category="cell">JupyterHub</block>
  <block id="263ec1d326c1f5a1bfd24b88cb972a38" category="inline-link-macro">Gráfico de Helm de JupyterHub</block>
  <block id="6af30397902bd26914df2ae5955c4be8" category="cell">4.1.5, implementado a través de<block ref="26830a1e301761faef592d8e74481ce6" category="inline-link-macro-rx"></block> 3.3.7</block>
  <block id="c272116b61605b9462784a01f5899785" category="cell">1,29</block>
  <block id="4e9b156e7e2788c8cd4b0877fd922657" category="cell">24,02</block>
  <block id="aa3652d1dedca9375b76c8e59797d756" category="section-title">Entorno de validación de MLflow</block>
  <block id="c8d3451e7307fb1b46769ec23ea7906a" category="cell">Flujo de ml</block>
  <block id="04d257103d25b778df7089d6dbb0cb44" category="inline-link-macro">Diagrama de Helm de MLflow</block>
  <block id="4814bad32946214124af37f70a7bee91" category="cell">2.14.1, implementado a través de<block ref="4baf34adb826df0481d498e42290114c" category="inline-link-macro-rx"></block> 1.4.12</block>
  <block id="6eeb675638e9c361028379b88415e2de" category="section-title">Entorno de validación de Kubeflow</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="cell">Kubeflow</block>
  <block id="e0d8584ae6ed8fd534954ae8ed8755a3" category="inline-link-macro">desplegarKF</block>
  <block id="bb675cbb86ae4db4a1f3da16e57113cd" category="cell">1.7, implementado a través de<block ref="f0761e2008489c964db22d8d03da0a67" category="inline-link-macro-rx"></block> 0.1.1</block>
  <block id="32b2e96c4f6d14da1df5b25db372de8f" category="cell">1,26</block>
  <block id="217af7d1776d22530d98be04d104fd49" category="cell">23,07</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">Soporte</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">Contactar con NetApp</block>
  <block id="952c6ea6549ebf347f6aae3d6b029756" category="paragraph">NetApp no ofrece soporte empresarial para Apache Airflow, JupyterHub, MLflow, Kubeflow o Kubernetes.  Si está interesado en una plataforma MLOps totalmente compatible,<block ref="15a32e54137b30751a17b6bf2b412f99" category="inline-link-macro-rx"></block> sobre soluciones MLOps totalmente compatibles que NetApp ofrece conjuntamente con sus socios.</block>
  <block id="6999319a5a39a9ca41436977f2cb8b8d" category="summary">MLOps de código abierto con NetApp : descripción general de la tecnología</block>
  <block id="4c9ffff73cd2c66ec9f6be3cb2b21333" category="paragraph">Esta sección se centra en la descripción general de la tecnología para MLOps de código abierto con NetApp.</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">Inteligencia artificial</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">La IA es una disciplina de la informática en la que se entrena a las computadoras para imitar las funciones cognitivas de la mente humana.  Los desarrolladores de IA entrenan a las computadoras para aprender y resolver problemas de una manera similar, o incluso superior, a la de los humanos.  El aprendizaje profundo y el aprendizaje automático son subcampos de la IA.  Las organizaciones están adoptando cada vez más IA, ML y DL para respaldar sus necesidades comerciales críticas.  Algunos ejemplos son los siguientes:</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">Analizar grandes cantidades de datos para descubrir información empresarial previamente desconocida</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">Interactuar directamente con los clientes mediante el procesamiento del lenguaje natural</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">Automatizar diversos procesos y funciones empresariales</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">Las cargas de trabajo de inferencia y entrenamiento de IA modernas requieren capacidades informáticas masivamente paralelas.  Por lo tanto, las GPU se utilizan cada vez más para ejecutar operaciones de IA porque las capacidades de procesamiento paralelo de las GPU son muy superiores a las de las CPU de propósito general.</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">Contenedores</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">Los contenedores son instancias de espacio de usuario aisladas que se ejecutan sobre un núcleo de sistema operativo host compartido.  La adopción de contenedores está aumentando rápidamente.  Los contenedores ofrecen muchos de los mismos beneficios de sandbox de aplicaciones que ofrecen las máquinas virtuales (VM).  Sin embargo, debido a que se han eliminado las capas de hipervisor y sistema operativo invitado de los que dependen las máquinas virtuales, los contenedores son mucho más livianos.  La siguiente figura muestra una visualización de máquinas virtuales versus contenedores.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Sitio web de Docker</block>
  <block id="d1920cb2aa1d83b6e74ea477546e30a3" category="paragraph">Los contenedores también permiten el empaquetado eficiente de dependencias de aplicaciones, tiempos de ejecución, etc., directamente con una aplicación.  El formato de embalaje de contenedores más utilizado es el contenedor Docker.  Una aplicación que se ha contenedorizado en el formato de contenedor Docker se puede ejecutar en cualquier máquina que pueda ejecutar contenedores Docker.  Esto es cierto incluso si las dependencias de la aplicación no están presentes en la máquina porque todas las dependencias están empaquetadas en el propio contenedor.  Para obtener más información, visite el<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block> .</block>
  <block id="0d64529eaeaf491f582b2ba0df6149c7" category="paragraph"><block ref="0d64529eaeaf491f582b2ba0df6149c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Sitio web de Kubernetes</block>
  <block id="f0ce8ef614fdf23fe30bc43ff89f53d3" category="paragraph">Kubernetes es una plataforma de orquestación de contenedores distribuida y de código abierto que fue diseñada originalmente por Google y ahora es mantenida por la Cloud Native Computing Foundation (CNCF).  Kubernetes permite la automatización de funciones de implementación, administración y escalamiento para aplicaciones en contenedores.  En los últimos años, Kubernetes ha surgido como la plataforma dominante de orquestación de contenedores.  Para obtener más información, visite el<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block> .</block>
  <block id="759b696484e9a0ab24afe3237dd85e66" category="paragraph"><block ref="0d26e0900d0eeb1b6e1c8f5cfee8510e" category="inline-link-macro-rx"></block>permite el consumo y la gestión de recursos de almacenamiento en todas las plataformas de almacenamiento NetApp más populares, en la nube pública o en las instalaciones, incluidas ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), el servicio Azure NetApp Files y Google Cloud NetApp Volumes.  Trident es un orquestador de almacenamiento dinámico compatible con la interfaz de almacenamiento de contenedores (CSI) que se integra de forma nativa con Kubernetes.</block>
  <block id="db7f413e96e248375d3fabd005ca4fee" category="paragraph">El<block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block> es una herramienta basada en Python que simplifica la gestión de espacios de trabajo de desarrollo/entrenamiento y servidores de inferencia respaldados por almacenamiento NetApp de alto rendimiento y escalabilidad horizontal.  Las capacidades clave incluyen:</block>
  <block id="b96dbbd391395e38a8ba72ae75c21dc9" category="list-text">Aprovisione rápidamente nuevos espacios de trabajo de alta capacidad respaldados por almacenamiento NetApp de alto rendimiento y escalabilidad horizontal.</block>
  <block id="629509198041b5749e015afa6a9b2629" category="list-text">Clonar casi instantáneamente espacios de trabajo de alta capacidad para permitir la experimentación o la iteración rápida.</block>
  <block id="01f719401b5bc2f16f328b588b0bef97" category="list-text">Guarde casi instantáneamente instantáneas de espacios de trabajo de alta capacidad para realizar copias de seguridad y/o trazabilidad/establecimiento de referencia.</block>
  <block id="8b4d3b8f8e04f8cfef020d43ad93e87a" category="paragraph">Apache Airflow es una plataforma de gestión de flujo de trabajo de código abierto que permite la creación, programación y supervisión programática de flujos de trabajo empresariales complejos.  A menudo se utiliza para automatizar flujos de trabajo de ETL y canalización de datos, pero no se limita a estos tipos de flujos de trabajo.  El proyecto Airflow fue iniciado por Airbnb, pero desde entonces se ha vuelto muy popular en la industria y ahora está bajo los auspicios de The Apache Software Foundation.  Airflow está escrito en Python, los flujos de trabajo de Airflow se crean a través de scripts de Python y Airflow está diseñado bajo el principio de "configuración como código".  Muchos usuarios empresariales de Airflow ahora ejecutan Airflow sobre Kubernetes.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">Gráficos acíclicos dirigidos (DAG)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">En Airflow, los flujos de trabajo se denominan gráficos acíclicos dirigidos (DAG).  Los DAG se componen de tareas que se ejecutan en secuencia, en paralelo o en una combinación de ambas, según la definición del DAG.  El programador Airflow ejecuta tareas individuales en una matriz de trabajadores, cumpliendo con las dependencias a nivel de tarea que se especifican en la definición de DAG.  Los DAG se definen y crean mediante scripts de Python.</block>
  <block id="802125395813e0bec35472d0403ab94e" category="section-title">Cuaderno Jupyter</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Sitio web de Jupyter</block>
  <block id="2ea401316bb56cd0dd460196fdb8bddc" category="paragraph">Los Jupyter Notebooks son documentos tipo wiki que contienen código en vivo y texto descriptivo.  Los Jupyter Notebooks se utilizan ampliamente en la comunidad de IA y ML como un medio para documentar, almacenar y compartir proyectos de IA y ML.  Para obtener más información sobre Jupyter Notebooks, visite el sitio web<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block> .</block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="section-title">Servidor de Jupyter Notebook</block>
  <block id="1ceb0a3b747e9e685e69bf855aa91001" category="paragraph">Un servidor Jupyter Notebook es una aplicación web de código abierto que permite a los usuarios crear Jupyter Notebooks.</block>
  <block id="d837769caeb4d9edfd53e4a5a4b94fce" category="inline-link">Sitio web de JupyterHub</block>
  <block id="aa77da24b3b7d00c6c4b22044c64a028" category="paragraph">JupyterHub es una aplicación multiusuario que permite a un usuario individual aprovisionar y acceder a su propio servidor Jupyter Notebook.  Para obtener más información sobre JupyterHub, visite el sitio<block ref="8b235ac1daecf8d06ace248b8ac07b97" category="inline-link-rx"></block> .</block>
  <block id="891056fdef376263d6563716a06437cd" category="inline-link">Sitio web de MLflow</block>
  <block id="ea79d93ff06996ce8a177ec9a6f59b26" category="paragraph">MLflow es una popular plataforma de gestión del ciclo de vida de la IA de código abierto.  Las características clave de MLflow incluyen el seguimiento de experimentos de IA/ML y un repositorio de modelos de IA/ML.  Para obtener más información sobre MLflow, visite el sitio web<block ref="7d5e77d7cbcfeeed8850444afe1d66af" category="inline-link-rx"></block> .</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Sitio web de Kubeflow</block>
  <block id="9a9c31b74376d75ed88c300dfd734acf" category="paragraph">Kubeflow es un kit de herramientas de inteligencia artificial y aprendizaje automático de código abierto para Kubernetes que fue desarrollado originalmente por Google.  El proyecto Kubeflow hace que las implementaciones de flujos de trabajo de IA y ML en Kubernetes sean simples, portátiles y escalables.  Kubeflow abstrae las complejidades de Kubernetes, lo que permite a los científicos de datos centrarse en lo que mejor saben: la ciencia de datos.  Vea la siguiente figura para ver una visualización.  Kubeflow es una buena opción de código abierto para las organizaciones que prefieren una plataforma MLOps todo en uno.  Para obtener más información, visite el<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block> .</block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Tuberías de Kubeflow</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">documentación oficial de Kubeflow</block>
  <block id="f69bb06b79f60baced2f6faf97fc9e14" category="paragraph">Las canalizaciones de Kubeflow son un componente clave de Kubeflow.  Kubeflow Pipelines es una plataforma y un estándar para definir e implementar flujos de trabajo de IA y ML portátiles y escalables. Para obtener más información, consulte la<block ref="34d1e4686e190f53e3511c4faa8ac68b" category="inline-link-rx"></block> .</block>
  <block id="7724cfbda1ff4c3052c280f6b4af599c" category="section-title">Cuadernos de Kubeflow</block>
  <block id="352ec4b0886cdd10b69d3efaa4071648" category="paragraph">Kubeflow simplifica el aprovisionamiento y la implementación de servidores Jupyter Notebook en Kubernetes.  Para obtener más información sobre Jupyter Notebooks en el contexto de Kubeflow, consulte<block ref="273f9b54e4f57ca19b4597f14d191196" category="inline-link-rx"></block> .</block>
  <block id="d8d51bb44e1cdcb1d7fde82b687339bd" category="section-title">Katib</block>
  <block id="8f5f81b63b950128a2104cb77339c846" category="paragraph">Katib es un proyecto nativo de Kubernetes para el aprendizaje automático automatizado (AutoML).  Katib admite el ajuste de hiperparámetros, la detención anticipada y la búsqueda de arquitectura neuronal (NAS).  Katib es un proyecto que es agnóstico a los marcos de aprendizaje automático (ML).  Puede ajustar hiperparámetros de aplicaciones escritas en cualquier lenguaje elegido por el usuario y admite de forma nativa muchos marcos de ML, como TensorFlow, MXNet, PyTorch, XGBoost y otros.  Katib admite muchos algoritmos AutoML diferentes, como optimización bayesiana, estimadores de árbol de Parzen, búsqueda aleatoria, estrategia de evolución de adaptación de matriz de covarianza, hiperbanda, búsqueda de arquitectura neuronal eficiente, búsqueda de arquitectura diferenciable y muchos más.  Para obtener más información sobre Jupyter Notebooks en el contexto de Kubeflow, consulte<block ref="5b959b0f3dbfc4557138b63a781b201c" category="inline-link-rx"></block> .</block>
  <block id="592d6ad3868437ff65a70353ab870f50" category="list-text">Escalabilidad fluida y operaciones sin interrupciones.  ONTAP admite la incorporación de capacidad sin interrupciones a controladores existentes y a clústeres de escalamiento horizontal.  Los clientes pueden actualizar a las últimas tecnologías sin necesidad de costosas migraciones de datos ni interrupciones.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">Copias instantáneas de NetApp</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">Una copia Snapshot de NetApp es una imagen de un volumen en un punto en el tiempo y de solo lectura.  La imagen consume un espacio de almacenamiento mínimo y genera una sobrecarga de rendimiento insignificante porque solo registra los cambios en los archivos creados desde que se realizó la última copia de instantánea, como se muestra en la siguiente figura.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Las copias instantáneas deben su eficiencia a la tecnología central de virtualización de almacenamiento de ONTAP , Write Anywhere File Layout (WAFL).  Al igual que una base de datos, WAFL utiliza metadatos para señalar bloques de datos reales en el disco.  Pero, a diferencia de una base de datos, WAFL no sobrescribe los bloques existentes.  Escribe datos actualizados en un nuevo bloque y cambia los metadatos.  Esto se debe a que ONTAP hace referencia a metadatos cuando crea una copia instantánea, en lugar de copiar bloques de datos, que las copias instantáneas son tan eficientes.  Al hacerlo así se elimina el tiempo de búsqueda que otros sistemas incurren para localizar los bloques a copiar, así como el coste de realizar la copia en sí.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">Puede utilizar una copia instantánea para recuperar archivos individuales o LUN o para restaurar todo el contenido de un volumen.  ONTAP compara la información del puntero en la copia instantánea con los datos del disco para reconstruir el objeto faltante o dañado, sin tiempo de inactividad ni un costo de rendimiento significativo.</block>
  <block id="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="paragraph"><block ref="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">Tecnología FlexClone de NetApp</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">La tecnología NetApp FlexClone hace referencia a metadatos de Snapshot para crear copias grabables en un punto determinado del tiempo de un volumen.  Las copias comparten bloques de datos con sus padres y no consumen almacenamiento excepto lo necesario para los metadatos hasta que se escriben los cambios en la copia, como se muestra en la siguiente figura.  Donde las copias tradicionales pueden tardar minutos o incluso horas en crearse, el software FlexClone le permite copiar incluso los conjuntos de datos más grandes casi instantáneamente.  Esto lo hace ideal para situaciones en las que se necesitan múltiples copias de conjuntos de datos idénticos (un espacio de trabajo de desarrollo, por ejemplo) o copias temporales de un conjunto de datos (probar una aplicación contra un conjunto de datos de producción).</block>
  <block id="f28d7ba8bb28ad8ce873b4ec7ed61164" category="paragraph"><block ref="f28d7ba8bb28ad8ce873b4ec7ed61164" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">Tecnología de replicación de datos SnapMirror de NetApp</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">El software NetApp SnapMirror es una solución de replicación unificada rentable y fácil de usar en toda la estructura de datos.  Replica datos a altas velocidades a través de LAN o WAN.  Le ofrece alta disponibilidad de datos y rápida replicación de datos para aplicaciones de todo tipo, incluidas aplicaciones críticas para el negocio en entornos virtuales y tradicionales.  Cuando replica datos a uno o más sistemas de almacenamiento NetApp y actualiza continuamente los datos secundarios, sus datos se mantienen actualizados y están disponibles siempre que los necesite.  No se requieren servidores de replicación externos.  Vea la siguiente figura para ver un ejemplo de una arquitectura que aprovecha la tecnología SnapMirror .</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">El software SnapMirror aprovecha las eficiencias de almacenamiento de NetApp ONTAP al enviar solo los bloques modificados a través de la red.  El software SnapMirror también utiliza compresión de red incorporada para acelerar las transferencias de datos y reducir la utilización del ancho de banda de la red hasta en un 70%.  Con la tecnología SnapMirror , puede aprovechar un flujo de datos de replicación delgada para crear un único repositorio que mantenga tanto el espejo activo como las copias de puntos en el tiempo anteriores, lo que reduce el tráfico de red hasta en un 50%.</block>
  <block id="2ab1a10694bb0d67320839630a1c9ccb" category="paragraph"><block ref="c4152c5b1804294b9bc91a2fa3a92230" category="inline-link-macro-rx"></block>Es un servicio de NetApp para la sincronización de datos rápida y segura.  Ya sea que necesite transferir archivos entre recursos compartidos de archivos NFS o SMB locales, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob, Google Cloud Storage o IBM Cloud Object Storage, BlueXP Copy and Sync mueve los archivos donde los necesita de manera rápida y segura.</block>
  <block id="7e333cc0e24ef7489559129fd944c91f" category="paragraph">Una vez transferidos los datos, estarán totalmente disponibles para su uso tanto en el origen como en el destino.  BlueXP Copy and Sync puede sincronizar datos a pedido cuando se activa una actualización o sincronizar datos de manera continua según un cronograma predefinido.  De todos modos, BlueXP Copy and Sync solo mueve los deltas, por lo que se minimiza el tiempo y el dinero gastados en la replicación de datos.</block>
  <block id="22716a1c6493f7fb09f4caf2084ad23c" category="paragraph">BlueXP Copy and Sync es una herramienta de software como servicio (SaaS) extremadamente sencilla de configurar y utilizar.  Las transferencias de datos que se activan mediante BlueXP Copy and Sync se llevan a cabo a través de corredores de datos.  Los agentes de datos de copia y sincronización de BlueXP se pueden implementar en AWS, Azure, Google Cloud Platform o en las instalaciones locales.</block>
  <block id="204b9ffafe28e07fef53f08e2924e621" category="paragraph"><block ref="8eb894646a418e33ca3d088f11e4914c" category="inline-link-macro-rx"></block>es un software basado en el cliente para migraciones de datos de cualquier plataforma NetApp y de NetApp a NetApp , así como para obtener información sobre sistemas de archivos.  XCP está diseñado para escalar y lograr el máximo rendimiento al utilizar todos los recursos del sistema disponibles para manejar conjuntos de datos de gran volumen y migraciones de alto rendimiento.  XCP le ayuda a obtener visibilidad completa del sistema de archivos con la opción de generar informes.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">Volúmenes FlexGroup de NetApp ONTAP</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">Un conjunto de datos de entrenamiento puede ser una colección de potencialmente miles de millones de archivos.  Los archivos pueden incluir texto, audio, video y otras formas de datos no estructurados que deben almacenarse y procesarse para poder leerse en paralelo.  El sistema de almacenamiento debe almacenar grandes cantidades de archivos pequeños y debe leer esos archivos en paralelo para realizar E/S secuenciales y aleatorias.</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">Un volumen FlexGroup es un espacio de nombres único que comprende múltiples volúmenes miembros constituyentes, como se muestra en la siguiente figura.  Desde el punto de vista de un administrador de almacenamiento, un volumen FlexGroup se administra y actúa como un FlexVol volume de NetApp .  Los archivos de un volumen FlexGroup se asignan a volúmenes miembro individuales y no se distribuyen entre volúmenes o nodos.  Permiten las siguientes capacidades:</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">Los volúmenes FlexGroup proporcionan múltiples petabytes de capacidad y una latencia baja predecible para cargas de trabajo con alto contenido de metadatos.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">Admiten hasta 400 mil millones de archivos en el mismo espacio de nombres.</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">Admiten operaciones paralelizadas en cargas de trabajo NAS en CPU, nodos, agregados y volúmenes FlexVol constituyentes.</block>
  <block id="b0d8567b3e8a1e892d0b59f7a3c27292" category="paragraph"><block ref="b0d8567b3e8a1e892d0b59f7a3c27292" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6459218853a974bb2b38718e6db79ed" category="summary">Esta solución tiene como objetivo demostrar varias herramientas y marcos de código abierto diferentes que se pueden incorporar a un flujo de trabajo MLOps.  Estas diferentes herramientas y marcos se pueden utilizar juntos o por separado según los requisitos y el caso de uso.</block>
  <block id="eb1b19572557d2f13528a30754e9997a" category="doc">MLOps de código abierto con NetApp</block>
  <block id="aa27e598d8d01ff612acd83b47a13b21" category="paragraph">Mike Oglesby, NetApp Sufian Ahmad, NetApp Rick Huang, NetApp Mohan Acharya, NetApp</block>
  <block id="36160a80da6291faa3ebc68ede194279" category="paragraph">Empresas y organizaciones de todos los tamaños y de muchas industrias están recurriendo a la inteligencia artificial (IA) para resolver problemas del mundo real, ofrecer productos y servicios innovadores y obtener una ventaja en un mercado cada vez más competitivo.  Muchas organizaciones están recurriendo a herramientas MLOps de código abierto para mantenerse al día con el rápido ritmo de innovación en la industria.  Estas herramientas de código abierto ofrecen capacidades avanzadas y características de última generación, pero a menudo no tienen en cuenta la disponibilidad ni la seguridad de los datos.  Lamentablemente, esto significa que los científicos de datos altamente capacitados se ven obligados a pasar una cantidad significativa de tiempo esperando obtener acceso a los datos o esperando que se completen operaciones rudimentarias relacionadas con los datos.  Al combinar las populares herramientas MLOps de código abierto con una infraestructura de datos inteligente de NetApp, las organizaciones pueden acelerar sus canales de datos, lo que, a su vez, acelera sus iniciativas de IA.  Pueden extraer valor de sus datos y al mismo tiempo garantizar que permanezcan protegidos y seguros.  Esta solución demuestra la combinación de las capacidades de gestión de datos de NetApp con varias herramientas y marcos de código abierto populares para abordar estos desafíos.</block>
  <block id="ad3ca69dbfa62630ace9a188e93d1f45" category="paragraph">La siguiente lista destaca algunas capacidades clave que permite esta solución:</block>
  <block id="e6ffdd80d6efdfae1a367b394ef6afdf" category="list-text">Los usuarios pueden aprovisionar rápidamente nuevos volúmenes de datos de alta capacidad y espacios de trabajo de desarrollo respaldados por almacenamiento NetApp de alto rendimiento y escalabilidad horizontal.</block>
  <block id="24f5e64e89b475fca21e0a2d5536aa48" category="list-text">Los usuarios pueden clonar casi instantáneamente volúmenes de datos de alta capacidad y espacios de trabajo de desarrollo para permitir la experimentación o la iteración rápida.</block>
  <block id="4657d40d11cf0257f60a599a2bc266b6" category="list-text">Los usuarios pueden guardar casi instantáneamente instantáneas de volúmenes de datos de alta capacidad y espacios de trabajo de desarrollo para realizar copias de seguridad y/o trazabilidad/establecimiento de referencia.</block>
  <block id="953c95173b5d3944693633d3b6ae7711" category="paragraph"><block ref="953c95173b5d3944693633d3b6ae7711" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3e3d207c7705b0f7dc0142df9cc2790a" category="inline-link-macro">Cuadernos Jupyter</block>
  <block id="d1a5554bae0723fdaf349b8047aa0d08" category="paragraph">Un flujo de trabajo típico de MLOps incorpora espacios de trabajo de desarrollo, que generalmente toman la forma de<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> seguimiento de experimentos; canales de entrenamiento automatizados; canales de datos; e inferencia/implementación.  Esta solución destaca varias herramientas y marcos diferentes que pueden usarse de forma independiente o en conjunto para abordar los diferentes aspectos del flujo de trabajo.  También demostramos la combinación de las capacidades de gestión de datos de NetApp con cada una de estas herramientas.  Esta solución está diseñada para ofrecer bloques de construcción a partir de los cuales una organización puede construir un flujo de trabajo MLOps personalizado que sea específico para sus casos de uso y requisitos.</block>
  <block id="0b34fcae55a765c46410fb4116433e75" category="paragraph">Esta solución cubre las siguientes herramientas y marcos:</block>
  <block id="074cd5ab3a3581efcb92b990cd4ed3b6" category="list-text"><block ref="074cd5ab3a3581efcb92b990cd4ed3b6" category="inline-link-macro-rx"></block></block>
  <block id="ac10ff0174545b18e3fd3b7ab41ebc08" category="list-text"><block ref="ac10ff0174545b18e3fd3b7ab41ebc08" category="inline-link-macro-rx"></block></block>
  <block id="4275daa2701a7c7ad4c1c5df1088ada8" category="list-text"><block ref="4275daa2701a7c7ad4c1c5df1088ada8" category="inline-link-macro-rx"></block></block>
  <block id="a0cf58c060e740cca7f48b1bb399e974" category="list-text"><block ref="a0cf58c060e740cca7f48b1bb399e974" category="inline-link-macro-rx"></block></block>
  <block id="9717b9722e82e47dc4445d7ffc90b79d" category="paragraph">La siguiente lista describe patrones comunes para implementar estas herramientas de forma independiente o en conjunto.</block>
  <block id="3f7626e711a1e660dae85d17fdc35882" category="list-text">Implementar JupyterHub, MLflow y Apache Airflow en conjunto - JupyterHub para<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , MLflow para seguimiento de experimentos y Apache Airflow para capacitación automatizada y canalización de datos.</block>
  <block id="1dceee44b0bde0ef7364704241dced5a" category="list-text">Implementar Kubeflow y Apache Airflow en conjunto - Kubeflow para<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> seguimiento de experimentos, canales de entrenamiento automatizados e inferencia; y Apache Airflow para canales de datos.</block>
  <block id="aa815dfaf0c405504952ea2a361a2a3e" category="list-text">Implemente Kubeflow como una solución de plataforma MLOps todo en uno para<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , seguimiento de experimentos, entrenamiento automatizado y canalización de datos, e inferencia.</block>
  <block id="6ca687fb1fabca3bf671bc9bf39dbf27" category="summary">MLOps de código abierto con NetApp : implementación de JupyterHub</block>
  <block id="09d2043b79460eb224957589f59ab494" category="doc">Implementación de JupyterHub</block>
  <block id="2ab6902fa61e1ea6912baf903a3b0bf1" category="paragraph">Esta sección describe las tareas que debe completar para implementar JupyterHub en su clúster de Kubernetes.</block>
  <block id="26e29fcdb4d615c34b7fedb3a0564f8f" category="admonition">Es posible implementar JupyterHub en plataformas distintas a Kubernetes.  La implementación de JupyterHub en plataformas distintas a Kubernetes está fuera del alcance de esta solución.</block>
  <block id="99b37bb800ce4a91a3634a32f40b891b" category="list-text">Ya ha instalado y configurado NetApp Trident en su clúster de Kubernetes.  Para obtener más detalles sobre Trident, consulte la<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="2ac6b5f4951f689f17ae54334df0112f" category="paragraph">JupyterHub se implementa utilizando Helm, un administrador de paquetes popular para Kubernetes.  Antes de implementar JupyterHub, debe instalar Helm en su nodo de control de Kubernetes.  Para instalar Helm, siga las instrucciones<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> en la documentación oficial de Helm.</block>
  <block id="c0b1a9427c281e6178bd6cbeb95bc3a8" category="paragraph">Antes de implementar JupyterHub, debe designar una StorageClass predeterminada dentro de su clúster de Kubernetes.  Para designar una StorageClass predeterminada dentro de su clúster, siga las instrucciones que se describen en la<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> sección.  Si ya ha designado una StorageClass predeterminada dentro de su clúster, puede omitir este paso.</block>
  <block id="771d8827304382e84db174fab916e726" category="section-title">Implementar JupyterHub</block>
  <block id="cca32ccd336a1d99e57fe4b732c1db03" category="paragraph">Después de completar los pasos anteriores, ahora está listo para implementar JupyterHub.  La implementación de JupyterHub requiere los siguientes pasos:</block>
  <block id="02e6e3cd99fedc7e13d22d86bad5b831" category="section-title">Configurar la implementación de JupyterHub</block>
  <block id="ce95551547fa8ef240a593be5a20f5ee" category="paragraph">Antes de la implementación, es una buena práctica optimizar la implementación de JupyterHub para su entorno respectivo.  Puede crear un archivo *config.yaml* y utilizarlo durante la implementación mediante el gráfico Helm.</block>
  <block id="53db901aeed4328fe567404ccb21206d" category="paragraph">Se puede encontrar un archivo *config.yaml* de ejemplo en<block ref="8c152549701847c833121b3ad8e4af72" category="inline-link-rx"></block></block>
  <block id="d4acad87b1acbfd617a3b4988bfb1864" category="admonition">En este archivo config.yaml, puede establecer el parámetro *(singleuser.storage.dynamic.storageClass)* para NetApp Trident StorageClass.  Esta es la clase de almacenamiento que se utilizará para aprovisionar los volúmenes para espacios de trabajo de usuarios individuales.</block>
  <block id="fc1be4924094aec74f37b59bbd957af8" category="section-title">Agregar volúmenes compartidos</block>
  <block id="67e834a52ce0a7019fd9a1bec4bae36f" category="paragraph">Si desea utilizar un volumen compartido para todos los usuarios de JupyterHub, puede ajustar su *config.yaml* en consecuencia.  Por ejemplo, si tiene un PersistentVolumeClaim compartido llamado jupyterhub-shared-volume, podría montarlo como /home/shared en todos los pods de usuario de la siguiente manera:</block>
  <block id="a66a54102aa462ebdfe0146ca96eaf33" category="admonition">Este es un paso opcional, puedes ajustar estos parámetros según tus necesidades.</block>
  <block id="67c7fe5cd005737db341f115281a5f71" category="section-title">Implementar JupyterHub con Helm Chart</block>
  <block id="54ad8b66fcd369a80298610d95ca37d9" category="paragraph">Haga que Helm conozca el repositorio de gráficos de Helm de JupyterHub.</block>
  <block id="f98aad3b24c5bab5b4737b8fad3a723f" category="paragraph">Esto debería mostrar un resultado como el siguiente:</block>
  <block id="4e29332ac1db944879502e11ab327960" category="paragraph">Ahora instale el gráfico configurado por su config.yaml ejecutando este comando desde el directorio que contiene su config.yaml:</block>
  <block id="be118fb1d0e987a9d25c71312374ffdf" category="admonition">En este ejemplo:</block>
  <block id="750e13a1159e4f2b96ba2d8fadfb1aab" category="paragraph">&lt;helm-release-name&gt; se establece en my-jupyterhub, que será el nombre de su versión de JupyterHub.  &lt;k8s-namespace&gt; está configurado en my-namespace, que es el espacio de nombres donde desea instalar JupyterHub.  El indicador --create-namespace se utiliza para crear el espacio de nombres si aún no existe.  El indicador --values especifica el archivo config.yaml que contiene las opciones de configuración deseadas.</block>
  <block id="0873eec3dcb328f01cc596581047ae60" category="section-title">Comprobar implementación</block>
  <block id="5b252fe874ba4bfb32f7c039993801ab" category="paragraph">Mientras se ejecuta el paso 2, puedes ver los pods que se crean desde el siguiente comando:</block>
  <block id="828e0f094cad198231ffd340f281e098" category="paragraph">Espere a que el concentrador y el módulo proxy entren en el estado de ejecución.</block>
  <block id="4f8f16ff2582a84eb01cbef90f467393" category="section-title">Acceder a JupyterHub</block>
  <block id="c7433009ea218afe4c1117491e4afccb" category="paragraph">Encuentra la IP que podemos usar para acceder a JupyterHub.  Ejecute el siguiente comando hasta que la IP EXTERNA del servicio proxy público esté disponible como en la salida del ejemplo.</block>
  <block id="7261a4593eb504b7857e5e4dd9a5459c" category="admonition">Usamos el servicio NodePort en nuestro archivo config.yaml, que puedes ajustar a tu entorno según tu configuración (por ejemplo, LoadBalancer).</block>
  <block id="a5673ab624b33fdb767b6ec77b9901ca" category="paragraph">Para utilizar JupyterHub, ingrese la IP externa del servicio proxy público en un navegador.</block>
  <block id="9b5d03606d5f2609a4b9a6f1ac626a8d" category="summary">MLOps de código abierto con NetApp : utilice el kit de herramientas NetApp DataOps con JupyterHub</block>
  <block id="8fc5f752dfcb57cd9232177f28b14765" category="doc">Utilice el kit de herramientas NetApp DataOps con JupyterHub</block>
  <block id="0162e970f8577425266cb5c97d21c2a7" category="paragraph">El<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> se puede utilizar junto con JupyterHub.  El uso del kit de herramientas NetApp DataOps con JupyterHub permite a los usuarios finales crear instantáneas de volumen para realizar copias de seguridad del espacio de trabajo o para la trazabilidad del conjunto de datos al modelo directamente desde un Jupyter Notebook.</block>
  <block id="8f08aaf2916d1654fc96af766c150251" category="paragraph">Antes de poder usar DataOps Toolkit con JupyterHub, debe otorgar los permisos adecuados a la cuenta de servicio de Kubernetes que JupyterHub asigna a los pods de Jupyter Notebook Server de usuarios individuales.  JupyterHub utiliza la cuenta de servicio especificada por el<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> variable en su archivo de configuración del gráfico Helm de JupyterHub.</block>
  <block id="a815fb28e94390b627bc7915911578cf" category="section-title">Crear un rol de clúster para el kit de herramientas DataOps</block>
  <block id="333372e6f3961af5df82304243a2d5ba" category="paragraph">Primero, cree una función de clúster denominada "netapp-dataops" que tenga los permisos de API de Kubernetes necesarios para crear instantáneas de volumen.</block>
  <block id="3805f69a30879fb016e5c3d0a85fab77" category="section-title">Asignar rol de clúster a la cuenta de servicio del servidor Notebook</block>
  <block id="19506ab4aa03158eeea933145bd0471d" category="paragraph">Cree un enlace de rol que asigne el rol de clúster 'netapp-dataops-snapshots' a la cuenta de servicio adecuada en el espacio de nombres apropiado.  Por ejemplo, si instaló JupyterHub en el espacio de nombres 'jupyterhub' y especificó la cuenta de servicio 'predeterminada' a través de<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> variable, asignaría la función de clúster 'netapp-dataops-snapshots' a la cuenta de servicio 'predeterminada' en el espacio de nombres 'jupyterhub' como se muestra en el siguiente ejemplo.</block>
  <block id="fe7233ebd9f644239a2437c55d3419e1" category="section-title">Crear instantáneas de volumen dentro de Jupyter Notebook</block>
  <block id="02dd051970bea675e5def458342cd6e3" category="paragraph">Ahora, los usuarios de JupyterHub pueden usar NetApp DataOps Toolkit para crear instantáneas de volumen directamente desde un Jupyter Notebook como se muestra en el siguiente ejemplo.</block>
  <block id="6bd0178572fd0f85ae777cd2c67d0907" category="paragraph"><block ref="6bd0178572fd0f85ae777cd2c67d0907" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ffc4debfa03808ebe14380555e9a891" category="summary">Ingesta de datos con NetApp SnapMirror</block>
  <block id="c9cfa55f76ce30116dc6c4a9d937fa9d" category="doc">Ingerir datos en JupyterHub con NetApp SnapMirror</block>
  <block id="98aa5dbb610473a52540e5d0699bd079" category="paragraph">NetApp SnapMirror es una tecnología de replicación que le permite replicar datos entre sistemas de almacenamiento NetApp .  SnapMirror se puede utilizar para ingerir datos de entornos remotos en JupyterHub.</block>
  <block id="815eb616a6188ae082d3024fbb91e45e" category="section-title">Ejemplo de flujo de trabajo y demostración</block>
  <block id="a3e50a098653f80e6a42662ee52e8b55" category="inline-link-macro">Esta publicación del blog de Tech ONTAP</block>
  <block id="5eae3f83c7f60bb551b097ccf3a4012b" category="paragraph">Referirse a<block ref="585bdb2d9e21d8036a261701b86d814c" category="inline-link-macro-rx"></block> para obtener un ejemplo detallado de flujo de trabajo y una demostración del uso de NetApp SnapMirror para ingerir datos en JupyterHub.</block>
  <block id="ba47b65d29a2bcf968281d1e04ee29bb" category="summary">MLOps de código abierto con NetApp : implementación de Kubeflow</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">Esta sección describe las tareas que debe completar para implementar Kubeflow en su clúster de Kubernetes.</block>
  <block id="f3538dfada37d551dd71f26249dd82c6" category="list-text">Ya tienes un clúster de Kubernetes en funcionamiento y estás ejecutando una versión de Kubernetes compatible con la versión de Kubeflow que deseas implementar.  Para obtener una lista de las versiones compatibles de Kubernetes, consulte las dependencias para su versión de Kubeflow en<block ref="b84967824090781ee960169bb3232fc6" category="inline-link-macro-rx"></block> .</block>
  <block id="84d21063d216560d873bc66cd38d62e8" category="paragraph">Antes de implementar Kubeflow, recomendamos designar una StorageClass predeterminada dentro de su clúster de Kubernetes.  El proceso de implementación de Kubeflow puede intentar aprovisionar nuevos volúmenes persistentes utilizando la clase de almacenamiento predeterminada.  Si no se designa ninguna StorageClass como StorageClass predeterminada, la implementación puede fallar.  Para designar una StorageClass predeterminada dentro de su clúster, realice la siguiente tarea desde el host de salto de implementación.  Si ya ha designado una StorageClass predeterminada dentro de su clúster, puede omitir este paso.</block>
  <block id="d371ec612c125519e69855ad89d4445b" category="list-text">Designe una de sus StorageClasses existentes como la StorageClass predeterminada.  Los comandos de ejemplo que siguen muestran la designación de una StorageClass denominada<block ref="19a55e78496416c8db6565a114cfd5f3" prefix=" " category="inline-code"></block> como la clase de almacenamiento predeterminada.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">El<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> El tipo Trident Backend tiene un tamaño mínimo de PVC que es bastante grande.  De forma predeterminada, Kubeflow intenta aprovisionar PVC que tengan solo unos pocos GB de tamaño.  Por lo tanto, no debe designar una StorageClass que utilice el<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Tipo de backend como StorageClass predeterminado para los fines de implementación de Kubeflow.</block>
  <block id="7724a5f9edc284eef2e4bc112adc1dd9" category="section-title">Opciones de implementación de Kubeflow</block>
  <block id="e135506d2171533787a405262eeb67bc" category="paragraph">Hay muchas opciones diferentes para implementar Kubeflow.  Consulte la<block ref="59d814781a574912b676e75f9fe0e882" category="inline-link-macro-rx"></block> para obtener una lista de opciones de implementación y elegir la opción que mejor se adapte a sus necesidades.</block>
  <block id="07379a7db414d96104f4d3ab35ee3d59" category="admonition">Para fines de validación, implementamos Kubeflow 1.7 usando<block ref="f36b6222867dc75589b32398e1411061" category="inline-link-macro-rx"></block> 0.1.1.</block>
  <block id="0dbcc7b3c9a4c5ed6afff19c771a989d" category="summary">MLOps de código abierto con NetApp : utilice el kit de herramientas DataOps de NetApp con Kubeflow</block>
  <block id="3b70474868bce72e0d5d1fac42d1f643" category="doc">Utilice el kit de herramientas NetApp DataOps con Kubeflow</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">Kit de herramientas de ciencia de datos de NetApp para Kubernetes</block>
  <block id="4065ea77b68b6d949a165c54fc532d2a" category="paragraph">El<block ref="6f920cea43eeb6dd3a1bfb8ce1f9946a" category="inline-link-rx"></block> se puede utilizar junto con Kubeflow.  El uso del kit de herramientas de ciencia de datos de NetApp con Kubeflow proporciona los siguientes beneficios:</block>
  <block id="0a19b387d7028ea674dc64f74ecb97ea" category="list-text">Los científicos de datos pueden realizar operaciones avanzadas de gestión de datos de NetApp , como la creación de instantáneas y clones, directamente desde un Jupyter Notebook.</block>
  <block id="f4a972e1ae8aa85c6e67d7ad0ccc6dc4" category="list-text">Las operaciones avanzadas de gestión de datos de NetApp , como la creación de instantáneas y clones, se pueden incorporar a flujos de trabajo automatizados mediante el marco Kubeflow Pipelines.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Ejemplos de Kubeflow</block>
  <block id="f1db0bc6ea6a4eee559e5d9946fd92ea" category="paragraph">Consulte la<block ref="a5886b5aa215f1fd67a69d09a2725b9d" category="inline-link-rx"></block> sección dentro del repositorio de GitHub de NetApp Data Science Toolkit para obtener detalles sobre el uso del kit de herramientas con Kubeflow.</block>
  <block id="0e82e7615bc43e60306731cd1402df29" category="summary">MLOps de código abierto con NetApp : aprovisione un espacio de trabajo de Jupyter Notebook para uso de desarrolladores o científicos de datos</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">Proporcionar un espacio de trabajo de Jupyter Notebook para uso de desarrolladores o científicos de datos</block>
  <block id="b09a995a770ac7d1022303afcc4effb0" category="paragraph">Kubeflow es capaz de aprovisionar rápidamente nuevos servidores Jupyter Notebook para que actúen como espacios de trabajo de científicos de datos.  Para obtener más información sobre Jupyter Notebooks dentro del contexto de Kubeflow, consulte la<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block> .</block>
  <block id="6b9617f7154782faea34239e9eb5ea4a" category="paragraph"><block ref="6b9617f7154782faea34239e9eb5ea4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6dc629616db1f269870318e89e7522" category="summary">MLOps de código abierto con NetApp : ejemplo de flujo de trabajo: entrenamiento de un modelo de reconocimiento de imágenes mediante Kubeflow y el kit de herramientas DataOps de NetApp</block>
  <block id="659e23f00660c05c4b7cf730eae0befe" category="doc">Ejemplo de flujo de trabajo: Entrenamiento de un modelo de reconocimiento de imágenes mediante Kubeflow y el kit de herramientas DataOps de NetApp</block>
  <block id="cc799f8653f5775220453347865834a9" category="paragraph">Esta sección describe los pasos necesarios para entrenar e implementar una red neuronal para reconocimiento de imágenes utilizando Kubeflow y NetApp DataOps Toolkit.  Esto pretende servir como ejemplo para mostrar un trabajo de capacitación que incorpora almacenamiento NetApp .</block>
  <block id="b759ef76b26f922987fbf418c77766cb" category="paragraph">Cree un Dockerfile con las configuraciones necesarias para utilizar en los pasos de entrenamiento y prueba dentro del pipeline de Kubeflow.  Aquí hay un ejemplo de un Dockerfile:</block>
  <block id="d1658ed5f5e35aee28cc518869591c5b" category="paragraph">Dependiendo de sus requisitos, instale todas las bibliotecas y paquetes necesarios para ejecutar el programa.  Antes de entrenar el modelo de aprendizaje automático, se supone que ya tienes una implementación de Kubeflow en funcionamiento.</block>
  <block id="1d7fb7fa777edda515304ad19af75036" category="section-title">Entrene una red neuronal pequeña con datos MNIST usando PyTorch y Kubeflow Pipelines</block>
  <block id="a2d6c085b2bfbb3fc92caceedba6806e" category="paragraph">Utilizamos el ejemplo de una pequeña red neuronal entrenada con datos MNIST.  El conjunto de datos MNIST consta de imágenes escritas a mano de dígitos del 0 al 9.  Las imágenes tienen un tamaño de 28x28 píxeles.  El conjunto de datos se divide en 60.000 imágenes de trenes y 10.000 imágenes de validación.  La red neuronal utilizada para este experimento es una red de propagación hacia adelante de dos capas.  El entrenamiento se ejecuta utilizando Kubeflow Pipelines. Consulte la documentación<block ref="bcb10ee1db2d847a3cadc06c872375ac" category="inline-link-rx"></block> Para más información.  Nuestra canalización de Kubeflow incorpora la imagen de Docker de la sección Requisitos previos.</block>
  <block id="edfa32db89306c0de4efde13667133a5" category="inline-image-macro">Visualización de la ejecución de la canalización de Kubeflow</block>
  <block id="c0bdd0d6d088108de0d2d172bd2f25be" category="paragraph"><block ref="c0bdd0d6d088108de0d2d172bd2f25be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7d85cbff0f5dec5d5092004b5b8774e" category="section-title">Visualizar resultados con Tensorboard</block>
  <block id="d3246eab9678602f9301a80184803dff" category="inline-link">Tablero tensor</block>
  <block id="12e2a8be9c4e17ffc7dc66217d8530ff" category="paragraph">Una vez entrenado el modelo, podemos visualizar los resultados utilizando Tensorboard.<block ref="a07862d9a0e51dec9c3587e87c541181" category="inline-link-rx"></block> Está disponible como una función en el panel de Kubeflow.  Puede crear un tensorboard personalizado para su trabajo.  A continuación se muestra un ejemplo de la gráfica de la precisión del entrenamiento frente al número de épocas y de la pérdida de entrenamiento frente al número de épocas.</block>
  <block id="1618fe0e500d9ed850d5e614c6620fd8" category="inline-image-macro">Gráfico de Tensorboard para pérdida y precisión de entrenamiento</block>
  <block id="cd45b495d2fd4d214ea7c430a9980d0a" category="paragraph"><block ref="cd45b495d2fd4d214ea7c430a9980d0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbdd778d6f4497497010df3f4ae35a67" category="section-title">Experimente con hiperparámetros usando Katib</block>
  <block id="a47bff2eb2b867ca89a553eeb14da493" category="paragraph"><block ref="98b590f3a453d1e0809708b45d553c8f" category="inline-link-rx"></block>es una herramienta dentro de Kubeflow que se puede utilizar para experimentar con los hiperparámetros del modelo.  Para crear un experimento, primero defina una métrica/objetivo deseado.  Generalmente esta es la precisión de la prueba.  Una vez definida la métrica, elija los hiperparámetros con los que desea experimentar (optimizador/tasa de aprendizaje/número de capas).  Katib realiza un barrido de hiperparámetros con los valores definidos por el usuario para encontrar la mejor combinación de parámetros que satisfagan la métrica deseada.  Puede definir estos parámetros en cada sección de la interfaz de usuario.  Alternativamente, podría definir un archivo *YAML* con las especificaciones necesarias.  A continuación se muestra una ilustración de un experimento de Katib:</block>
  <block id="70e367edef0d0f2a63f6fff084365aa4" category="inline-image-macro">Panel de experimentación de Katib con hiperparámetros</block>
  <block id="12f61d15ca34416b644cbd8238634541" category="paragraph"><block ref="12f61d15ca34416b644cbd8238634541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd53955b02bf4a8bb0a318390df24ae6" category="inline-image-macro">Comprobación de prueba exitosa</block>
  <block id="600782cca16442259d603526a7cd0b29" category="paragraph"><block ref="600782cca16442259d603526a7cd0b29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d3e96caf95415deff9bb8b5bc25063" category="section-title">Utilice instantáneas de NetApp para guardar datos para trazabilidad</block>
  <block id="0b6ef7f84e44ffbb76d4eef1ef587269" category="paragraph">Durante el entrenamiento del modelo, es posible que queramos guardar una instantánea del conjunto de datos de entrenamiento para facilitar la trazabilidad.  Para ello, podemos agregar un paso de instantánea a la canalización como se muestra a continuación.  Para crear la instantánea, podemos utilizar el<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> .</block>
  <block id="9f205d5330ff4142363e15d261753156" category="inline-image-macro">Código para crear una canalización de Snapshot en Kubeflow</block>
  <block id="18242bdffd149a4d04c88b7208997f55" category="paragraph"><block ref="18242bdffd149a4d04c88b7208997f55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe2b6f01ffb206a03c2e0fd0a802a4ca" category="inline-link">Ejemplo de NetApp DataOps Toolkit para Kubeflow</block>
  <block id="7ba41dac79bc84ef4a806ce87fc4f97a" category="paragraph">Consulte la <block ref="f0b3c05b3c22509c21d3296c77ee92d9" category="inline-link-rx"></block> Para más información.</block>
  <block id="8ec1b3ffcff14d3a7476fee4a3e80bbd" category="summary">MLOps de código abierto con NetApp : implementación de MLflow</block>
  <block id="1e24ddb7a6a8df2478eebd688cf1f1df" category="doc">Implementación de MLflow</block>
  <block id="eba75f7702c8d580f100f5c6e819419a" category="paragraph">Esta sección describe las tareas que debe completar para implementar MLflow en su clúster de Kubernetes.</block>
  <block id="1988a9fc415911c1b6cb091f9672aa99" category="admonition">Es posible implementar MLflow en plataformas distintas a Kubernetes.  La implementación de MLflow en plataformas distintas a Kubernetes está fuera del alcance de esta solución.</block>
  <block id="effe3b356a9db8beeafdbe3692a3df6b" category="paragraph">MLflow se implementa utilizando Helm, un administrador de paquetes popular para Kubernetes.  Antes de implementar MLflow, debe instalar Helm en su nodo de control de Kubernetes.  Para instalar Helm, siga las instrucciones<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> en la documentación oficial de Helm.</block>
  <block id="01fb0f36d01f7edcdcc66273b214f218" category="paragraph">Antes de implementar MLflow, debe designar una StorageClass predeterminada dentro de su clúster de Kubernetes.  Para designar una StorageClass predeterminada dentro de su clúster, siga las instrucciones que se describen en la<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> sección.  Si ya ha designado una StorageClass predeterminada dentro de su clúster, puede omitir este paso.</block>
  <block id="6369a4aa768b1882566ceb106febe885" category="section-title">Implementar MLflow</block>
  <block id="4996360f41c2160eefec53bc938631c4" category="paragraph">Una vez que se cumplan los requisitos previos, puede comenzar con la implementación de MLflow utilizando el gráfico de Helm.</block>
  <block id="9b40c49f5b19b6b30c8e46c9a322cfa9" category="section-title">Configurar la implementación del gráfico Helm de MLflow.</block>
  <block id="54662ab0339cacf58980938d0d2997f6" category="paragraph">Antes de implementar MLflow utilizando el gráfico Helm, podemos configurar la implementación para usar la clase de almacenamiento NetApp Trident y cambiar otros parámetros para adaptarlos a nuestras necesidades utilizando un archivo *config.yaml*.  Puedes encontrar un ejemplo de archivo *config.yaml* en:<block ref="3fb631fe4b90fe5302819c1b11e0f768" category="inline-link-rx"></block></block>
  <block id="3ffd497fc5215b526be90b762ad3c730" category="admonition">Puede configurar la clase de almacenamiento Trident en el parámetro *global.defaultStorageClass* en el archivo config.yaml (por ejemplo, clase de almacenamiento: "ontap-flexvol").</block>
  <block id="b0e9e89059c66feb24d2bae1faade5b4" category="section-title">Instalación del cuadro de mandos Helm</block>
  <block id="e2de44bdf60d5282b2d1f5dce8ef9fb8" category="paragraph">El gráfico Helm se puede instalar con el archivo *config.yaml* personalizado para MLflow usando el siguiente comando:</block>
  <block id="b8fe21ea18633e2ba5c911e2b6c64135" category="admonition">El comando implementa MLflow en el clúster de Kubernetes en la configuración personalizada a través del archivo *config.yaml* proporcionado.  MLflow se implementa en el espacio de nombres indicado y se proporciona un nombre de versión aleatorio a través de Kubernetes para la versión.</block>
  <block id="fe92b5543c9bb0daa69543a737a9937a" category="paragraph">Una vez finalizada la implementación del gráfico de Helm, puedes comprobar si el servicio es accesible mediante:</block>
  <block id="5001194091e3ac05acb36e50188181cd" category="admonition">Reemplace *jupyterhub* con el espacio de nombres que utilizó durante la implementación.</block>
  <block id="624995aae5a71a1b6b698d125dfa593f" category="paragraph">Debería ver los siguientes servicios:</block>
  <block id="0727c036d98dcf728bf3678abc379532" category="admonition">Editamos el archivo config.yaml para usar el servicio NodePort para acceder a MLflow en el puerto 30002.</block>
  <block id="49ed0a1879305290bd3f5a83a6ebc4a2" category="section-title">Acceso a MLflow</block>
  <block id="4336069c7c6830c86e24b3590bc33968" category="paragraph">Una vez que todos los servicios relacionados con MLflow estén en funcionamiento, puede acceder a él utilizando la dirección IP de NodePort o LoadBalancer indicada (por ejemplo,<block ref="4470100f30fdceb8d4bf43ad086f55fe" prefix=" " category="inline-code"></block> )</block>
  <block id="4cdff711c1556a59f967422b42a85088" category="summary">MLOps de código abierto con NetApp : trazabilidad de conjunto de datos a modelo con NetApp y MLflow</block>
  <block id="96ea5f01f5435b957b4ccda05e9edc2a" category="doc">Trazabilidad del conjunto de datos al modelo con NetApp y MLflow</block>
  <block id="49f4e58115751b6e777c0881bed17f7b" category="paragraph">El<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> se puede utilizar junto con las capacidades de seguimiento de experimentos de MLflow para implementar la trazabilidad del conjunto de datos al modelo o del espacio de trabajo al modelo.</block>
  <block id="a6086bfa36daf4e19b000df54ab1dd1e" category="paragraph">Para implementar la trazabilidad del conjunto de datos al modelo o del espacio de trabajo al modelo, simplemente cree una instantánea de su conjunto de datos o volumen del espacio de trabajo utilizando el kit de herramientas DataOps como parte de su ejecución de entrenamiento, como se muestra en el siguiente fragmento de código de ejemplo.  Este código guardará el nombre del volumen de datos y el nombre de la instantánea como etiquetas asociadas con la ejecución de entrenamiento específica que está registrando en su servidor de seguimiento de experimentos de MLflow.</block>
  <block id="f8e6fa4a88901fdc129b3ce376463f53" category="summary">MLOps de código abierto con NetApp : Ejecute una carga de trabajo de IA distribuida y sincrónica</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">Ejecutar una carga de trabajo de IA distribuida sincrónica</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Para ejecutar un trabajo de IA y ML sincrónico de múltiples nodos en su clúster de Kubernetes, realice las siguientes tareas en el host de salto de implementación.  Este proceso le permite aprovechar los datos almacenados en un volumen de NetApp y utilizar más GPU de las que un solo nodo de trabajo puede proporcionar.  Vea la siguiente figura para ver una representación de un trabajo de IA distribuido sincrónico.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">Los trabajos distribuidos sincrónicos pueden ayudar a aumentar el rendimiento y la precisión del entrenamiento en comparación con los trabajos distribuidos asincrónicos.  Una discusión de los pros y contras de los trabajos sincrónicos versus los trabajos asincrónicos está fuera del alcance de este documento.</block>
  <block id="dd02d155f88fd3ea2f5dfd5720641a55" category="paragraph"><block ref="dd02d155f88fd3ea2f5dfd5720641a55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46300fa439cc237919f854816fc89fc2" category="inline-link-macro">Ejecutar una carga de trabajo de IA de un solo nodo</block>
  <block id="252bb749f76608017bf1d4a822ebba6d" category="list-text">Los siguientes comandos de ejemplo muestran la creación de un trabajador que participa en la ejecución distribuida sincrónica del mismo trabajo de referencia de TensorFlow que se ejecutó en un solo nodo en el ejemplo de la sección<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .  En este ejemplo específico, solo se implementa un único trabajador porque el trabajo se ejecuta en dos nodos de trabajo.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">documentación oficial de Kubernetes</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">Esta implementación de trabajador de ejemplo solicita ocho GPU y, por lo tanto, puede ejecutarse en un solo nodo de trabajador de GPU que tenga ocho o más GPU.  Si sus nodos de trabajo de GPU cuentan con más de ocho GPU, para maximizar el rendimiento, es posible que desee aumentar este número para que sea igual a la cantidad de GPU que cuentan sus nodos de trabajo.  Para obtener más información sobre las implementaciones de Kubernetes, consulte<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block> .</block>
  <block id="4b59e69845bd812b9cddcb0b700f3680" category="paragraph">En este ejemplo se crea una implementación de Kubernetes porque este trabajador en contenedor específico nunca se completaría por sí solo.  Por lo tanto, no tiene sentido implementarlo utilizando la construcción del trabajo de Kubernetes.  Si su trabajador está diseñado o escrito para completarse por sí solo, entonces podría tener sentido utilizar la construcción del trabajo para implementar su trabajador.</block>
  <block id="57e84b8262eb9db582d9f861e85ed291" category="paragraph">Al pod que se especifica en esta especificación de implementación de ejemplo se le asigna un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  Este valor significa que el pod utiliza la pila de red del nodo de trabajo host en lugar de la pila de red virtual que Kubernetes normalmente crea para cada pod.  Esta anotación se utiliza en este caso porque la carga de trabajo específica depende de Open MPI, NCCL y Horovod para ejecutarla de manera distribuida sincrónica.  Por lo tanto, requiere acceso a la pila de red del host.  Una discusión sobre Open MPI, NCCL y Horovod está fuera del alcance de este documento.  Sea esto o no<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block> La anotación es necesaria dependiendo de los requisitos de la carga de trabajo específica que esté ejecutando.  Para obtener más información sobre la<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> campo, ver el<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block> .</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">Confirme que la implementación del trabajador que creó en el paso 1 se inició correctamente.  Los siguientes comandos de ejemplo confirman que se creó un solo pod de trabajo para la implementación, como se indica en la definición de implementación, y que este pod se está ejecutando actualmente en uno de los nodos de trabajo de la GPU.</block>
  <block id="77fed810b2a592adcab667c30e5c0bdb" category="list-text">Cree un trabajo de Kubernetes para un maestro que inicie, participe y realice un seguimiento de la ejecución del trabajo multinodo sincrónico.  Los siguientes comandos de ejemplo crean un maestro que inicia, participa y rastrea la ejecución distribuida sincrónica del mismo trabajo de referencia de TensorFlow que se ejecutó en un solo nodo en el ejemplo de la sección<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">Este trabajo maestro de ejemplo solicita ocho GPU y, por lo tanto, puede ejecutarse en un solo nodo de trabajo de GPU que tenga ocho o más GPU.  Si sus nodos de trabajo de GPU cuentan con más de ocho GPU, para maximizar el rendimiento, es posible que desee aumentar este número para que sea igual a la cantidad de GPU que cuentan sus nodos de trabajo.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">Al pod maestro que se especifica en esta definición de trabajo de ejemplo se le asigna un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> , justo cuando se le dio un puesto al trabajador<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> en el paso 1.  Consulte el paso 1 para obtener detalles sobre por qué es necesario este valor.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">Confirme que el trabajo maestro que creó en el paso 3 se esté ejecutando correctamente.  El siguiente comando de ejemplo confirma que se creó un solo pod maestro para el trabajo, como se indica en la definición del trabajo, y que este pod se está ejecutando actualmente en uno de los nodos de trabajo de la GPU.  También debería ver que el pod de trabajo que vio originalmente en el paso 1 todavía está ejecutándose y que los pods maestro y de trabajo se están ejecutando en nodos diferentes.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">Confirme que el trabajo maestro que creó en el paso 3 se complete exitosamente.  Los siguientes comandos de ejemplo confirman que el trabajo se completó correctamente.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">Elimina la implementación del trabajador cuando ya no la necesites.  Los siguientes comandos de ejemplo muestran la eliminación del objeto de implementación de trabajador que se creó en el paso 1.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">Cuando elimina el objeto de implementación del trabajador, Kubernetes elimina automáticamente todos los pods de trabajador asociados.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*Opcional:* Limpiar los artefactos del trabajo maestro.  Los siguientes comandos de ejemplo muestran la eliminación del objeto de trabajo maestro que se creó en el paso 3.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">Cuando elimina el objeto de trabajo maestro, Kubernetes elimina automáticamente todos los pods maestros asociados.</block>
  <block id="3b1ef0ea9661ba5d2eeba15fab13cf00" category="summary">MLOps de código abierto con NetApp : Ejecute una carga de trabajo de IA de un solo nodo</block>
  <block id="9e339bbe1fec0fc2a91b7c2f8dd9d7f7" category="paragraph">Para ejecutar un trabajo de IA y ML de un solo nodo en su clúster de Kubernetes, realice las siguientes tareas desde el host de salto de implementación.  Con Trident, puede hacer que un volumen de datos, que potencialmente contenga petabytes de datos, sea accesible a una carga de trabajo de Kubernetes de manera rápida y sencilla.  Para que dicho volumen de datos sea accesible desde un pod de Kubernetes, simplemente especifique una PVC en la definición del pod.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">Esta sección asume que ya ha contenedorizado (en el formato de contenedor Docker) la carga de trabajo de IA y ML específica que está intentando ejecutar en su clúster de Kubernetes.</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">Sitio web de ImageNet</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">Los siguientes comandos de ejemplo muestran la creación de un trabajo de Kubernetes para una carga de trabajo de referencia de TensorFlow que utiliza el conjunto de datos ImageNet.  Para obtener más información sobre el conjunto de datos ImageNet, consulte<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block> .</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">Este trabajo de ejemplo solicita ocho GPU y, por lo tanto, puede ejecutarse en un solo nodo de trabajo de GPU que tenga ocho o más GPU.  Este trabajo de ejemplo podría enviarse en un clúster en el que no hay un nodo de trabajo con ocho o más GPU presente o que actualmente está ocupado con otra carga de trabajo.  Si es así, el trabajo permanece en estado pendiente hasta que dicho nodo de trabajo esté disponible.</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">Además, para maximizar el ancho de banda de almacenamiento, el volumen que contiene los datos de entrenamiento necesarios se monta dos veces dentro del pod que crea este trabajo.  Otro volumen también está montado en la cápsula.  Este segundo volumen se utilizará para almacenar resultados y métricas.  Estos volúmenes se referencian en la definición del trabajo mediante los nombres de las PVC.  Para obtener más información sobre los trabajos de Kubernetes, consulte<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block> .</block>
  <block id="c1cf1b159caffa27246be2b5201cdd54" category="paragraph">Un<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volumen con un<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block> valor de<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block> está montado en<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> en el pod que crea este trabajo de ejemplo.  El tamaño predeterminado de la<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> El volumen virtual que crea automáticamente el entorno de ejecución del contenedor Docker a veces puede ser insuficiente para las necesidades de TensorFlow.  Montaje de un<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> El volumen como en el siguiente ejemplo proporciona un volumen suficientemente grande.<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> volumen virtual.  Para obtener más información sobre<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volúmenes, véase el<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block> .</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">Al contenedor único que se especifica en esta definición de trabajo de ejemplo se le asigna un<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block> valor de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  Este valor significa que el contenedor efectivamente tiene acceso root en el host.  Esta anotación se utiliza en este caso porque la carga de trabajo específica que se está ejecutando requiere acceso root.  Específicamente, una operación de limpieza de caché que realiza la carga de trabajo requiere acceso root.  Sea esto o no<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block> La anotación es necesaria dependiendo de los requisitos de la carga de trabajo específica que esté ejecutando.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">Confirme que el trabajo que creó en el paso 1 se esté ejecutando correctamente.  El siguiente comando de ejemplo confirma que se creó un solo pod para el trabajo, como se especifica en la definición del trabajo, y que este pod se está ejecutando actualmente en uno de los nodos de trabajo de la GPU.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">Confirme que el trabajo que creó en el paso 1 se complete exitosamente.  Los siguientes comandos de ejemplo confirman que el trabajo se completó correctamente.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*Opcional:* Limpiar los artefactos del trabajo.  Los siguientes comandos de ejemplo muestran la eliminación del objeto de trabajo que se creó en el paso 1.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">Cuando elimina el objeto de trabajo, Kubernetes elimina automáticamente todos los pods asociados.</block>
  <block id="91ab0152618ead1fcdc42eff8c2d0735" category="summary">MLOps de código abierto con NetApp : ejemplos de backends Trident para implementaciones de NetApp AIPod</block>
  <block id="9137107e8d97a11b9174eb6766c2051f" category="doc">Ejemplos de backends Trident para implementaciones de NetApp AIPod</block>
  <block id="bf498d2b211c45a57e0eaa477b958b58" category="inline-link-macro">NetApp AIPod</block>
  <block id="8b57fa6d8107ac5ef8cc72bed591a355" category="paragraph">Antes de poder usar Trident para aprovisionar dinámicamente recursos de almacenamiento dentro de su clúster de Kubernetes, debe crear uno o más backends de Trident .  Los ejemplos que siguen representan diferentes tipos de backends que podría querer crear si está implementando componentes de esta solución en un<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  Para obtener más información sobre backends y, por ejemplo, backends para otras plataformas/entornos, consulte<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="5bce19d939aea54f55df565bb07b573b" category="list-text">NetApp recomienda crear un backend Trident habilitado para FlexGroup para su AIPod.</block>
  <block id="987adc3703d1f7aeb77e70a3d25e35ca" category="paragraph">Los comandos de ejemplo que siguen muestran la creación de un Trident Backend habilitado para FlexGroup para una máquina virtual de almacenamiento AIPod (SVM).  Este backend utiliza el<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> controlador de almacenamiento.  ONTAP admite dos tipos principales de volúmenes de datos: FlexVol y FlexGroup.  Los volúmenes FlexVol tienen un límite de tamaño (al momento de escribir este artículo, el tamaño máximo depende de la implementación específica).  Por otro lado, los volúmenes FlexGroup pueden escalar linealmente hasta 20 PB y 400 mil millones de archivos, proporcionando un único espacio de nombres que simplifica enormemente la gestión de datos.  Por lo tanto, los volúmenes FlexGroup son óptimos para cargas de trabajo de IA y ML que dependen de grandes cantidades de datos.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">Si está trabajando con una pequeña cantidad de datos y desea utilizar volúmenes FlexVol en lugar de volúmenes FlexGroup , puede crear Trident Backends que utilicen los<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> controlador de almacenamiento en lugar del<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> controlador de almacenamiento.</block>
  <block id="112efecf6dc8105639ea7e0b2a19f0e1" category="list-text">NetApp también recomienda crear un backend Trident habilitado para FlexVol .  Es posible que desee utilizar volúmenes FlexVol para alojar aplicaciones persistentes, almacenar resultados, salida, información de depuración, etc.  Si desea utilizar volúmenes FlexVol , debe crear uno o más Trident Backends habilitados para FlexVol .  Los comandos de ejemplo que siguen muestran la creación de un único backend Trident habilitado para FlexVol .</block>
  <block id="860fee506515550a9fba4086f9358bf0" category="summary">MLOps de código abierto con NetApp : ejemplo de operaciones Trident</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="doc">Ejemplo de operaciones Trident</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">Esta sección incluye ejemplos de varias operaciones que quizás desee realizar con Trident.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">Importar un volumen existente</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Si hay volúmenes existentes en su sistema/plataforma de almacenamiento NetApp que desea montar en contenedores dentro de su clúster de Kubernetes, pero que no están vinculados a PVC en el clúster, entonces debe importar estos volúmenes.  Puede utilizar la funcionalidad de importación de volumen de Trident para importar estos volúmenes.</block>
  <block id="8a87b71bee3405ddd29416b675ef7c61" category="paragraph">Los comandos de ejemplo que siguen muestran la importación de un volumen llamado<block ref="49f0544a1f0d45f5d68ad2e883eaec4a" prefix=" " category="inline-code"></block> .  Para obtener más información sobre los PVC, consulte la<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .  Para obtener más información sobre la funcionalidad de importación de volumen, consulte la<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">Un<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valor de<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block> se especifica en los archivos de especificaciones de PVC de ejemplo.  Para obtener más información sobre la<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> campo, ver el<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">Proporcionar un nuevo volumen</block>
  <block id="6b2d9cc0e6416b1fddc173d87e1ebad4" category="paragraph">Puede utilizar Trident para aprovisionar un nuevo volumen en su sistema o plataforma de almacenamiento NetApp .</block>
  <block id="4268e244b7de91b44bea226a48855c28" category="section-title">Aprovisionar un nuevo volumen usando kubectl</block>
  <block id="d5c5993dfd543be5e01f6d98516d64cb" category="paragraph">Los siguientes comandos de ejemplo muestran el aprovisionamiento de un nuevo FlexVol volume mediante kubectl.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">Un<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valor de<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> se especifica en el siguiente archivo de definición de PVC de ejemplo.  Para obtener más información sobre la<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> campo, ver el<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="3b12f01a10ad45fb526861fc286c7953" category="section-title">Aprovisionar un nuevo volumen mediante el kit de herramientas NetApp DataOps</block>
  <block id="55876228853abf632dec9346a4f372ec" category="inline-link-macro">documentación</block>
  <block id="b1e49394b547d60433afdf0d608bc52b" category="paragraph">También puede utilizar NetApp DataOps Toolkit para Kubernetes para aprovisionar un nuevo volumen en su sistema o plataforma de almacenamiento NetApp .  El kit de herramientas NetApp DataOps para Kubernetes utiliza Trident para aprovisionar volúmenes, pero simplifica el proceso para el usuario.  Consulte la<block ref="37e4d77423419479f43c92e2fdd640ea" category="inline-link-macro-rx"></block> Para más detalles.</block>
  <block id="fdc02d1c80a87a40b5361ca1abf33964" category="summary">MLOps de código abierto con NetApp : ejemplos de clases de almacenamiento de Kubernetes para implementaciones de NetApp AIPod</block>
  <block id="d25894e802e87270d1f6b560c3332055" category="doc">Ejemplos de clases de almacenamiento de Kubernetes para implementaciones de NetApp AIPod</block>
  <block id="98384d229f6fec246185f9bfa14fcb7a" category="paragraph">Antes de poder usar Trident para aprovisionar dinámicamente recursos de almacenamiento dentro de su clúster de Kubernetes, debe crear una o más StorageClasses de Kubernetes.  Los ejemplos que siguen representan diferentes tipos de StorageClasses que podría querer crear si está implementando componentes de esta solución en un<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  Para obtener más información sobre StorageClasses y, por ejemplo, StorageClasses para otras plataformas/entornos, consulte la<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="3f91a2c4d8ba66304e817a6c1c8d8086" category="inline-link-macro">NFS sobre RDMA</block>
  <block id="5f9e4626ef73df529e1be620feb3c403" category="list-text">NetApp recomienda crear una StorageClass para el Trident Backend habilitado para FlexGroup que creó en la sección<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , paso 1.  Los comandos de ejemplo que siguen muestran la creación de múltiples StorageClasses que corresponden al ejemplo Backend que se creó en la sección<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , paso 1 - uno que utilice<block ref="2f98f20aaeb2334cc6d03f1e60eea86f" category="inline-link-macro-rx"></block> y uno que no.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Documentación de Kubernetes</block>
  <block id="063f66d6e76f1f9cc44a56824e67f49c" category="paragraph">Para que un volumen persistente no se elimine cuando se elimina el PersistentVolumeClaim (PVC) correspondiente, el siguiente ejemplo utiliza un<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> valor de<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block> .  Para obtener más información sobre la<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> campo, ver el oficial<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block> .</block>
  <block id="b1c0c18c267e82c16a2fb0fd855fea96" category="paragraph">Nota: Las siguientes clases de almacenamiento de ejemplo utilizan un tamaño de transferencia máximo de 262144.  Para utilizar este tamaño de transferencia máximo, debe configurar el tamaño de transferencia máximo en su sistema ONTAP según corresponda.  Consulte la<block ref="e88143f84eca8f5af17b24d59e272642" category="inline-link-macro-rx"></block> Para más detalles.</block>
  <block id="611c47063b50d4e29ff14b57ac5d1a76" category="paragraph">Nota: Para utilizar NFS sobre RDMA, debe configurar NFS sobre RDMA en su sistema ONTAP .  Consulte la<block ref="299f3386ca6234337ede91409b59779f" category="inline-link-macro-rx"></block> Para más detalles.</block>
  <block id="8dffb2755e3c128c00970dd619da5b34" category="paragraph">Nota: En el siguiente ejemplo, se especifica un Backend específico en el campo storagePool en el archivo de definición StorageClass.</block>
  <block id="cce8016ccbbe58eeb47eb8596b78018e" category="inline-link-macro">Ejemplos de backends Trident para implementaciones de AIPod</block>
  <block id="6c9233cf2164bf9b74bbca02d5360c85" category="list-text">NetApp también recomienda crear una StorageClass que corresponda al Trident Backend habilitado para FlexVol que creó en la sección<block ref="f93f354f4df9d1f116edb5ebdff3f7d5" category="inline-link-macro-rx"></block> , paso 2.  Los comandos de ejemplo que siguen muestran la creación de una única StorageClass para volúmenes FlexVol .</block>
  <block id="fc614170d6c05a82aef1df8658cdddbb" category="paragraph">Nota: En el siguiente ejemplo, no se especifica un Backend particular en el campo storagePool en el archivo de definición StorageClass.  Cuando utiliza Kubernetes para administrar volúmenes mediante esta StorageClass, Trident intenta usar cualquier backend disponible que use la<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> conductor.</block>
  <block id="3ad98aba8e7b278dbcb8d707671576f7" category="list-text">Clone casi instantáneamente espacios de trabajo de JupyterLab de alta capacidad para permitir la experimentación o la iteración rápida.</block>
  <block id="85ca8d103a016e6e8898855c4ecfa6e2" category="list-text">Guarde casi instantáneamente instantáneas de espacios de trabajo de JupyterLab de alta capacidad para realizar copias de seguridad y/o trazabilidad/establecimiento de referencia.</block>
  <block id="60a1b5ff80d3333df7174eb4d8d7f4e1" category="list-text">Aprovisione, clone y cree instantáneas de volúmenes de datos de alto rendimiento y alta capacidad de forma casi instantánea.</block>
  <block id="c4bca757471e0afa8bcb4da8a5f5e802" category="paragraph"><block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block></block>
  <block id="e74b9287ad8cc207ad48fbfdff9cf078" category="summary">Conclusión: solución de base de datos vectorial para NetApp</block>
  <block id="b4eb3fd5fa52ba6b8d0eac43bac21d6f" category="paragraph">Esta sección concluye la solución de base de datos vectorial para NetApp.</block>
  <block id="ec77b1d1c933a6b137ec223a695b5ace" category="paragraph">En conclusión, este documento proporciona una descripción general completa de la implementación y la administración de bases de datos vectoriales, como Milvus y pgvector, en soluciones de almacenamiento de NetApp .  Analizamos las pautas de infraestructura para aprovechar el almacenamiento de objetos NetApp ONTAP y StorageGRID y validamos la base de datos Milvus en AWS FSx ONTAP a través del almacenamiento de archivos y objetos.</block>
  <block id="9799eea6b7d21ae2ad3b8f14f6de8b57" category="paragraph">Exploramos la dualidad archivo-objeto de NetApp, demostrando su utilidad no sólo para datos en bases de datos vectoriales sino también para otras aplicaciones.  También destacamos cómo SnapCenter, el producto de gestión empresarial de NetApp, ofrece funcionalidades de backup, restauración y clonación para datos de bases de datos vectoriales, garantizando la integridad y disponibilidad de los datos.</block>
  <block id="31068d7cc739be3f40f71a1c2165b247" category="paragraph">El documento también profundiza en cómo la solución de nube híbrida de NetApp ofrece replicación y protección de datos en entornos locales y en la nube, brindando una experiencia de gestión de datos segura y sin inconvenientes.  Proporcionamos información sobre la validación del rendimiento de bases de datos vectoriales como Milvus y pgvecto en NetApp ONTAP, ofreciendo información valiosa sobre su eficiencia y escalabilidad.</block>
  <block id="48b5d59439c5cbfd986de5db0e4585aa" category="paragraph">Finalmente, analizamos dos casos de uso de IA generativa: RAG con LLM y ChatAI interno de NetApp.  Estos ejemplos prácticos subrayan las aplicaciones y los beneficios reales de los conceptos y prácticas descritos en este documento.  En general, este documento sirve como una guía completa para cualquiera que busque aprovechar las potentes soluciones de almacenamiento de NetApp para administrar bases de datos vectoriales.</block>
  <block id="95ab8b5192fec6278c61d897cbcc59b7" category="paragraph">El autor desea expresar su más sincero agradecimiento a los siguientes colaboradores y a otras personas que brindaron sus comentarios y sugerencias para que este documento sea valioso para los clientes y los campos de NetApp .</block>
  <block id="cf069f89f8b650e3f6d927f7417a21f1" category="list-text">Sathish Thyagarajan, ingeniero de marketing técnico, ONTAP AI &amp; Analytics, NetApp</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">Mike Oglesby, ingeniero de marketing técnico, NetApp</block>
  <block id="633e7060d92a08658a3f5248a7c7cdf2" category="list-text">AJ Mahajan, director sénior de NetApp</block>
  <block id="4963f582fdf68104e20554eb28bcf2ca" category="list-text">Joe Scott, gerente de ingeniería de rendimiento de carga de trabajo, NetApp</block>
  <block id="710fcc80e2c0809a7239d471028d8f70" category="list-text">Puneet Dhawan, director sénior de gestión de productos Fsx, NetApp</block>
  <block id="7b62519a4ae964c6b307925c68166ca7" category="list-text">Yuval Kalderon, gerente sénior de productos, equipo de productos FSx, NetApp</block>
  <block id="b97cdeb80b669ea57564c9bf0542d2ef" category="list-text">Documentación de Milvus -<block ref="35e085709f47cfca6bbc0746cd0ba49f" category="inline-link-rx"></block></block>
  <block id="f7356e8678620084b93884e3b7a23a9f" category="list-text">Documentación independiente de Milvus:<block ref="a47fb3f2bfaa36fa0b44dc5f5ba452a4" category="inline-link-rx"></block></block>
  <block id="8b8bc5296c7be638754abb2f408d2099" category="list-text">Documentación de productos de NetApp<block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="3852b719e664b2ae1596e622f21daba3" category="inline-link-macro">documentación de installclustr</block>
  <block id="9351f6d4d819e15d23724c78a36aea99" category="list-text">instaclustr -<block ref="39b68163c56ae9979050121a6264d765" category="inline-link-macro-rx"></block></block>
  <block id="3b3d7bce734c0832c20ba464b1f2d199" category="cell">abril de 2024</block>
  <block id="123ffe6774f72f5d1c22607445987e46" category="summary">Preparar datos para la solución de base de datos vectorial para NetApp</block>
  <block id="f7ab9b609aa315a4d224e6e33b2a10ee" category="doc">Apéndice B: prepare_data_netapp_new.py</block>
  <block id="8d5099e275cc435c14417dc8e6bd49aa" category="paragraph">Esta sección proporciona un ejemplo de script de Python utilizado para preparar datos para la base de datos vectorial.</block>
  <block id="fe51a53701c4e0dd7696bed40b6f70db" category="summary">Procedimiento de implementación de base de datos vectorial: solución de base de datos vectorial para NetApp</block>
  <block id="19988795e8f88dfff005718f72472b6c" category="paragraph">En esta sección se analiza el procedimiento de implementación de la solución de base de datos vectorial para NetApp.</block>
  <block id="fa0b3671f099fc4fc4fbe3ac8374d92c" category="section-title">Procedimiento de despliegue</block>
  <block id="b63c54c37cdb817c256ef1a7e50fc5fe" category="paragraph">En esta sección de implementación, utilizamos la base de datos vectorial milvus con Kubernetes para la configuración del laboratorio como se muestra a continuación.</block>
  <block id="e275837fe1aa897ebc01eed7a7354278" category="paragraph"><block ref="e275837fe1aa897ebc01eed7a7354278" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b4b9b6998f8b3056b486430aa9c6fd" category="paragraph">El almacenamiento de NetApp proporciona almacenamiento para que el clúster conserve los datos de los clientes y los datos del clúster de Milvus.</block>
  <block id="46d201d3a5d870036bd7573752054979" category="section-title">Configuración de almacenamiento de NetApp – ONTAP</block>
  <block id="1fa9de5db47759d3e586f783f647d3e8" category="paragraph">Siga los pasos a continuación para NFS (sistema de archivos de red):</block>
  <block id="932d306add3eb18c39b41633590f1ad6" category="list-text">Cree un volumen FlexGroup para NFSv4.  En nuestra configuración para esta validación, hemos utilizado 48 SSD, 1 SSD dedicado para el volumen raíz del controlador y 47 SSD distribuidos para NFSv4. Verifique que la política de exportación de NFS para el volumen FlexGroup tenga permisos de lectura y escritura para la red de nodos de Kubernetes (K8s).  Si estos permisos no están disponibles, otorgue permisos de lectura/escritura (rw) para la red de nodos K8s.</block>
  <block id="a53a2ae8c8ba1b0def8ad999e086f94c" category="list-text">En todos los nodos de K8s, cree una carpeta y monte el volumen FlexGroup en esta carpeta a través de una interfaz lógica (LIF) en cada nodo de K8s.</block>
  <block id="b02cc86a747fc07392e2eceafa48816f" category="paragraph">Siga los pasos a continuación para NAS S3 (Servicio de almacenamiento simple de almacenamiento conectado a red):</block>
  <block id="a1ec6ff754c8c8958a577b43995e9caf" category="list-text">Cree un volumen FlexGroup para NFS.</block>
  <block id="c550fe4970f3cf4781625e620b4e30a9" category="list-text">Cree un depósito NAS configurando su tipo en "nas" y proporcionando la ruta al volumen NFSv3.  También es posible utilizar un bucket S3 para este propósito.</block>
  <block id="81f40424ce0b0dbbc91e2bc42bee8924" category="section-title">Configuración de almacenamiento de NetApp : StorageGRID</block>
  <block id="c8462ad4cf62a8bf6b594e7929097b68" category="list-text">Instalar el software storageGRID.</block>
  <block id="aec1f80331e64507a359fd96a93d2dee" category="list-text">Crear un inquilino y un depósito.</block>
  <block id="6eea00d5693e3a2106cc3859939c6e8e" category="list-text">Crear usuario con el permiso requerido.</block>
  <block id="5288dc14a18d189389b382eda1a7f83a" category="paragraph">Por favor consulte más detalles en<block ref="c095f7864703639165de914bdacb9488" category="inline-link-rx"></block></block>
  <block id="1b4b1bbd037e26c942386744e0c37fb6" category="summary">docker-compose.xml: solución de base de datos vectorial para NetApp</block>
  <block id="05b4af2cc796ae07ae3efb49a12abe45" category="doc">Apéndice D: docker-compose.yml</block>
  <block id="4f50d45b7589f5ba7443aff7e641e0ce" category="paragraph">Esta sección incluye código YAML de muestra para la solución de base de datos vectorial para NetApp.</block>
  <block id="1746460223f3daa35634698cf8a11429" category="summary">Protección de bases de datos vectoriales con SnapCenter: solución para bases de datos vectoriales de NetApp</block>
  <block id="72043cdd90d91317b18d2fcdc935eea8" category="doc">Protección de bases de datos vectoriales mediante SnapCenter</block>
  <block id="0cbe53988249acb8210e165c8f9d4ff1" category="paragraph">En esta sección se describe cómo proporcionar protección de datos para la base de datos vectorial mediante NetApp SnapCenter.</block>
  <block id="62e16ceab82346a15bf6bb06f5076498" category="section-title">Protección de bases de datos vectoriales mediante NetApp SnapCenter.</block>
  <block id="03e2211bf15aaf80440217e34090ab7a" category="paragraph">Por ejemplo, en la industria de producción cinematográfica, los clientes a menudo poseen datos incrustados importantes, como archivos de vídeo y audio.  La pérdida de estos datos, debido a problemas como fallas en el disco duro, puede tener un impacto significativo en sus operaciones, poniendo potencialmente en peligro empresas multimillonarias.  Hemos encontrado casos en los que se perdió contenido invaluable, lo que causó interrupciones sustanciales y pérdidas financieras.  Por lo tanto, garantizar la seguridad e integridad de estos datos esenciales es de suma importancia en esta industria.  En esta sección, profundizamos en cómo SnapCenter protege los datos de la base de datos vectorial y los datos de Milvus que residen en ONTAP.  Para este ejemplo, utilizamos un depósito NAS (milvusdbvol1) derivado de un volumen NFS ONTAP (vol1) para datos de clientes y un volumen NFS separado (vectordbpv) para datos de configuración del clúster Milvus. Por favor, consulte la<block ref="d81f12ee1ce058489f6dd74377fd8f1e" category="inline-link-macro-rx"></block> para el flujo de trabajo de copia de seguridad de SnapCenter</block>
  <block id="e159df91d2537b3f0b589d157dfbffd9" category="list-text">Configure el host que se utilizará para ejecutar los comandos de SnapCenter .</block>
  <block id="0d3b27c161709a06da0484a310f325e3" category="paragraph"><block ref="0d3b27c161709a06da0484a310f325e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00ebf5cec061915cd0462d73602dcad8" category="inline-link-macro">Tienda de automatización de NetApp</block>
  <block id="e5dbb47baa2442a0c626c78cd3791dfb" category="list-text">Instalar y configurar el complemento de almacenamiento.  Desde el host agregado, seleccione "Más opciones".  Navegue hasta el complemento de almacenamiento descargado y selecciónelo desde el<block ref="6d50396c8bd3accea0ce09d72830daea" category="inline-link-macro-rx"></block> .  Instale el complemento y guarde la configuración.</block>
  <block id="4225308f0df24ace1516a7673df5f583" category="paragraph"><block ref="4225308f0df24ace1516a7673df5f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="56efc857e5b28976189acb94af8f4ac8" category="list-text">Configurar el sistema de almacenamiento y el volumen: agregue el sistema de almacenamiento en “Sistema de almacenamiento” y seleccione SVM (Máquina virtual de almacenamiento).  En este ejemplo, hemos elegido "vs_nvidia".</block>
  <block id="6d0b2d59ec18c3814b7e5430ff27609f" category="paragraph"><block ref="6d0b2d59ec18c3814b7e5430ff27609f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2dcb622158143845f18538a410575a" category="list-text">Establecer un recurso para la base de datos vectorial, incorporando una política de respaldo y un nombre de instantánea personalizado.</block>
  <block id="a8f4ce53516fd9e67b7eb9a099d49120" category="list-text">Habilite la copia de seguridad del grupo de consistencia con valores predeterminados y habilite SnapCenter sin consistencia del sistema de archivos.</block>
  <block id="6230f7a2a3dc9bac46ff1cd677466af1" category="list-text">En la sección Huella de almacenamiento, seleccione los volúmenes asociados con los datos del cliente de la base de datos vectorial y los datos del clúster Milvus.  En nuestro ejemplo, estos son "vol1" y "vectordbpv".</block>
  <block id="61f90f32ea94cd1e612c6ce7a1713b45" category="list-text">Cree una política para la protección de la base de datos vectorial y proteja el recurso de la base de datos vectorial utilizando la política.</block>
  <block id="de59432e970871e34ec01050d133ea25" category="paragraph"><block ref="de59432e970871e34ec01050d133ea25" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc8a652b9ab6e0d4b7d2a344da503ff6" category="list-text">Inserte datos en el depósito NAS S3 mediante un script de Python.  En nuestro caso, modificamos el script de respaldo proporcionado por Milvus, concretamente 'prepare_data_netapp.py', y ejecutamos el comando 'sync' para vaciar los datos del sistema operativo.</block>
  <block id="3474edc9b3792a7404f86710df9ef875" category="list-text">Verifique los datos en el depósito NAS S3.  En nuestro ejemplo, los archivos con la marca de tiempo '2024-04-08 21:22' fueron creados por el script 'prepare_data_netapp.py'.</block>
  <block id="d47a679804c0cbffd0dc44fe5bb8fd17" category="list-text">Inicie una copia de seguridad utilizando la instantánea del grupo de consistencia (CG) del recurso 'milvusdb'</block>
  <block id="fe4f644e0cbbb28bc2dc58c59ba4712f" category="paragraph"><block ref="fe4f644e0cbbb28bc2dc58c59ba4712f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511f6b9ef02b86884feaa7670c95ad25" category="list-text">Para probar la funcionalidad de respaldo, agregamos una nueva tabla después del proceso de respaldo o eliminamos algunos datos del NFS (depósito NAS S3).</block>
  <block id="b32454a703c99d763bb542ccb4127d18" category="paragraph">Para esta prueba, imagine un escenario en el que alguien creó una colección nueva, innecesaria o inapropiada después de la copia de seguridad.  En tal caso, necesitaríamos revertir la base de datos vectorial a su estado anterior a que se agregara la nueva colección.  Por ejemplo, se han insertado nuevas colecciones como 'hello_milvus_netapp_sc_testnew' y 'hello_milvus_netapp_sc_testnew2'.</block>
  <block id="90fecf651d0359e3ca580f04477241cd" category="list-text">Ejecute una restauración completa del bucket NAS S3 desde la instantánea anterior.</block>
  <block id="aad1d0bff0a7a377e2981515a3b2b613" category="paragraph"><block ref="aad1d0bff0a7a377e2981515a3b2b613" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78a091f299be6eaf4277ba82c2e35823" category="list-text">Utilice un script de Python para verificar los datos de las colecciones 'hello_milvus_netapp_sc_test' y 'hello_milvus_netapp_sc_test2'.</block>
  <block id="d680ce42e26a573726db92b9c2422bcc" category="list-text">Verifique que la colección innecesaria o inapropiada ya no esté presente en la base de datos.</block>
  <block id="9a792fb5937b90853e4c8d032e6cb887" category="paragraph">En conclusión, el uso de SnapCenter de NetApp para salvaguardar los datos de bases de datos vectoriales y los datos Milvus que residen en ONTAP ofrece beneficios significativos a los clientes, particularmente en industrias donde la integridad de los datos es primordial, como la producción cinematográfica.  La capacidad de SnapCenter para crear copias de seguridad consistentes y realizar restauraciones de datos completas garantiza que los datos críticos, como archivos de audio y video integrados, estén protegidos contra pérdidas debido a fallas del disco duro u otros problemas.  Esto no sólo evita interrupciones operativas sino que también protege contra pérdidas financieras sustanciales.</block>
  <block id="2f51cfb1dd79ff854c52264b771ee6f7" category="paragraph">En esta sección, demostramos cómo se puede configurar SnapCenter para proteger los datos que residen en ONTAP, incluida la configuración de hosts, la instalación y configuración de complementos de almacenamiento y la creación de un recurso para la base de datos vectorial con un nombre de instantánea personalizado.  También mostramos cómo realizar una copia de seguridad utilizando la instantánea del grupo de consistencia y verificar los datos en el depósito NAS S3.</block>
  <block id="f3b4f7a7e2767144ed9c5f0d9d729580" category="paragraph">Además, simulamos un escenario en el que se creó una colección innecesaria o inapropiada después de la copia de seguridad.  En tales casos, la capacidad de SnapCenter de realizar una restauración completa a partir de una instantánea anterior garantiza que la base de datos vectorial pueda revertirse a su estado anterior a la adición de la nueva colección, manteniendo así la integridad de la base de datos.  Esta capacidad de restaurar datos a un punto específico en el tiempo es invaluable para los clientes, brindándoles la seguridad de que sus datos no solo están seguros, sino que también se mantienen correctamente.  De este modo, el producto SnapCenter de NetApp ofrece a sus clientes una solución robusta y fiable para la protección y gestión de datos.</block>
  <block id="8ceee6fd58c3c198cf913f99da69f893" category="summary">Recuperación ante desastres con NetApp SnapMirror : solución de base de datos vectorial para NetApp</block>
  <block id="e55b3630a4d66c6bf27e22779ce5d63e" category="doc">Recuperación ante desastres mediante NetApp SnapMirror</block>
  <block id="86e29a6d4e0a7a64c8112c7cec13c84f" category="paragraph">En esta sección se analiza la recuperación ante desastres (DR) con SnapMirror para la solución de base de datos vectorial para NetApp.</block>
  <block id="b8bf217f690a13ed504fd70caf142a75" category="paragraph"><block ref="b8bf217f690a13ed504fd70caf142a75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b0f055a15ce6f9f633fb54c0d2436b6" category="paragraph">La recuperación ante desastres es crucial para mantener la integridad y disponibilidad de una base de datos vectorial, especialmente dada su función en la gestión de datos de alta dimensión y la ejecución de búsquedas de similitud complejas.  Una estrategia de recuperación ante desastres bien planificada e implementada garantiza que los datos no se pierdan ni se vean comprometidos en caso de incidentes imprevistos, como fallas de hardware, desastres naturales o ciberataques.  Esto es especialmente importante para las aplicaciones que dependen de bases de datos vectoriales, donde la pérdida o corrupción de datos podría provocar importantes interrupciones operativas y pérdidas financieras.  Además, un plan de recuperación ante desastres sólido también garantiza la continuidad del negocio al minimizar el tiempo de inactividad y permitir la rápida restauración de los servicios.  Esto se logra a través del producto de replicación de datos SnapMirror de NetApp en diferentes ubicaciones geográficas, copias de seguridad periódicas y mecanismos de conmutación por error.  Por lo tanto, la recuperación ante desastres no es sólo una medida de protección, sino un componente crítico de una gestión responsable y eficiente de bases de datos vectoriales.</block>
  <block id="c37567d5fe01335124697e36ce452df7" category="paragraph">SnapMirror de NetApp proporciona replicación de datos de un controlador de almacenamiento NetApp ONTAP a otro, y se utiliza principalmente para recuperación ante desastres (DR) y soluciones híbridas.  En el contexto de una base de datos vectorial, esta herramienta facilita la transición fluida de datos entre entornos locales y en la nube.  Esta transición se logra sin necesidad de realizar conversiones de datos ni refactorizar aplicaciones, lo que mejora la eficiencia y la flexibilidad de la gestión de datos en múltiples plataformas.</block>
  <block id="b6c8a7338bea39b5f253444e1d873d4d" category="paragraph">La solución híbrida de NetApp en un escenario de base de datos vectorial puede aportar más ventajas:</block>
  <block id="bea498b35d669ee9af3e28b8fdb8e155" category="list-text">Escalabilidad: la solución de nube híbrida de NetApp ofrece la capacidad de escalar sus recursos según sus requisitos.  Puede utilizar recursos locales para cargas de trabajo regulares y predecibles y recursos en la nube como Amazon FSx ONTAP para NetApp ONTAP y Google Cloud NetApp Volume (NetApp Volumes) para horas pico o cargas inesperadas.</block>
  <block id="c471a0669949fb6902a8ba657759604f" category="list-text">Eficiencia de costos: el modelo de nube híbrida de NetApp le permite optimizar sus costos al utilizar recursos locales para cargas de trabajo regulares y pagar por los recursos de la nube solo cuando los necesita.  Este modelo de pago por uso puede resultar bastante rentable con una oferta de servicios instaclustr de NetApp .  Para los principales proveedores de servicios locales y en la nube, instaclustr brinda soporte y consultoría.</block>
  <block id="6544e3cb40acee466e12bad4b51cee88" category="list-text">Flexibilidad: la nube híbrida de NetApp le brinda la flexibilidad de elegir dónde procesar sus datos.  Por ejemplo, puede optar por realizar operaciones vectoriales complejas en sus instalaciones donde tiene hardware más potente y operaciones menos intensivas en la nube.</block>
  <block id="2a11cdb9dd362247d7154c07bd516471" category="list-text">Continuidad del negocio: en caso de desastre, tener sus datos en una nube híbrida de NetApp puede garantizar la continuidad del negocio.  Puede cambiar rápidamente a la nube si sus recursos locales se ven afectados.  Podemos aprovechar NetApp SnapMirror para trasladar los datos desde las instalaciones locales a la nube y viceversa.</block>
  <block id="3350f193c79eb670e977c23ae0a74f52" category="list-text">Innovación: Las soluciones de nube híbrida de NetApp también pueden permitir una innovación más rápida al brindar acceso a servicios y tecnologías de nube de vanguardia.  Las innovaciones de NetApp en la nube, como Amazon FSx ONTAP para NetApp ONTAP, Azure NetApp Files y Google Cloud NetApp Volumes, son productos innovadores y NAS preferidos de los proveedores de servicios en la nube.</block>
  <block id="2adc0d5a06f39e5bd606c62ac1bdec94" category="summary">instaclustr con pgvector: solución de base de datos vectorial para NetApp</block>
  <block id="8505d7d1a5bb8f0709861077b6053aac" category="doc">Base de datos vectorial con Instaclustr usando PostgreSQL: pgvector</block>
  <block id="45b4ccfe4060d903229f2ce1dcae0219" category="paragraph">En esta sección se analizan los detalles de cómo el producto instaclustr se integra con la funcionalidad pgvector de PostgreSQL en la solución de base de datos vectorial para NetApp.</block>
  <block id="126ac9f6149081eb0e97c2e939eaad52" category="inline-link-macro">blog</block>
  <block id="d2674849e623e64434efc8a6aa010be4" category="paragraph">En esta sección, profundizamos en los detalles de cómo el producto instaclustr se integra con postgreSQL en la funcionalidad pgvector.  Tenemos un ejemplo de "Cómo mejorar la precisión y el rendimiento de su LLM con PGVector y PostgreSQL: Introducción a las incrustaciones y el papel de PGVector".  Por favor revise el<block ref="f7c4562444dacce2474e07621eb487a5" category="inline-link-macro-rx"></block> Para obtener más información.</block>
  <block id="755a3ba009d32e46dd37e73b1449ec79" category="summary">Introducción a la solución de base de datos vectorial para NetApp</block>
  <block id="65fe25204f25a29d6784b93a3361bbd8" category="paragraph">Esta sección proporciona una introducción a la solución de base de datos vectorial para NetApp.</block>
  <block id="16091ccd671260c1a85526587bdd6247" category="paragraph">Las bases de datos vectoriales abordan de manera efectiva los desafíos que están diseñados para manejar las complejidades de la búsqueda semántica en modelos de lenguaje grandes (LLM) y en inteligencia artificial generativa (IA).  A diferencia de los sistemas de gestión de datos tradicionales, las bases de datos vectoriales son capaces de procesar y buscar en varios tipos de datos, incluidas imágenes, vídeos, texto, audio y otras formas de datos no estructurados, utilizando el contenido de los datos en sí en lugar de etiquetas o rótulos.</block>
  <block id="abd729dd7dfee14433df8341cdef1b8d" category="paragraph">Las limitaciones de los sistemas de gestión de bases de datos relacionales (RDBMS) están bien documentadas, en particular sus dificultades con las representaciones de datos de alta dimensión y los datos no estructurados comunes en las aplicaciones de IA.  Los RDBMS a menudo requieren un proceso lento y propenso a errores para aplanar los datos y convertirlos en estructuras más manejables, lo que genera demoras e ineficiencias en las búsquedas.  Sin embargo, las bases de datos vectoriales están diseñadas para sortear estos problemas, ofreciendo una solución más eficiente y precisa para gestionar y buscar datos complejos y de alta dimensión, facilitando así el avance de las aplicaciones de IA.</block>
  <block id="5059454011de9c1f28ed1489b3d5e352" category="paragraph">Este documento sirve como una guía completa para los clientes que actualmente utilizan o planean utilizar bases de datos vectoriales y detalla las mejores prácticas para utilizar bases de datos vectoriales en plataformas como NetApp ONTAP, NetApp StorageGRID, Amazon FSx ONTAP para NetApp ONTAP y SnapCenter.  El contenido proporcionado aquí cubre una variedad de temas:</block>
  <block id="a7e003a045fea49874b32ab9648eeff1" category="list-text">Pautas de infraestructura para bases de datos vectoriales, como Milvus, proporcionadas por el almacenamiento de NetApp a través de NetApp ONTAP y el almacenamiento de objetos StorageGRID .</block>
  <block id="dad32bf9f8412e678e687e1cf7bb9ca2" category="list-text">Validación de la base de datos Milvus en AWS FSx ONTAP a través del almacén de archivos y objetos.</block>
  <block id="68c4bdd7361d54de76b6a70ce9e66b6e" category="list-text">Profundiza en la dualidad archivo-objeto de NetApp, demostrando su utilidad para datos en bases de datos vectoriales y otras aplicaciones.</block>
  <block id="8aa4f3c0608b2b5d04870a90085180a0" category="list-text">Cómo el producto de gestión de protección de datos de NetApp, SnapCenter, ofrece funcionalidades de respaldo y restauración para datos de bases de datos vectoriales.</block>
  <block id="413963cd7c6051b3cbc48462a3167d68" category="list-text">Cómo la nube híbrida de NetApp ofrece replicación y protección de datos en entornos locales y en la nube.</block>
  <block id="73d0a81a7f19b02b2cf3e9084b655966" category="list-text">Proporciona información sobre la validación del rendimiento de bases de datos vectoriales como Milvus y pgvector en NetApp ONTAP.</block>
  <block id="de2054eca65b6e345160d8320bfa3d17" category="list-text">Dos casos de uso específicos: Retrieval Augmented Generation (RAG) con Large Language Models (LLM) y ChatAI del equipo de TI de NetApp , que ofrecen ejemplos prácticos de los conceptos y prácticas descritos.</block>
  <block id="11eb7151c13e504e17cca8ecf079bd88" category="summary">Base de datos vectorial: solución de base de datos vectorial para NetApp</block>
  <block id="34e317d16a291e422cfed7563b8e4b74" category="doc">Base de datos de vectores</block>
  <block id="bb6e7da57bf9b9f451aff5682584af81" category="paragraph">Esta sección cubre la definición y el uso de una base de datos vectorial en las soluciones de IA de NetApp .</block>
  <block id="02cf9216cd9290a38db4e591b2d891a3" category="paragraph">Una base de datos vectorial es un tipo especializado de base de datos diseñada para manejar, indexar y buscar datos no estructurados utilizando incrustaciones de modelos de aprendizaje automático.  En lugar de organizar los datos en un formato tabular tradicional, organiza los datos como vectores de alta dimensión, también conocidos como incrustaciones vectoriales.  Esta estructura única permite que la base de datos maneje datos complejos y multidimensionales de manera más eficiente y precisa.</block>
  <block id="ee365553124acd5ca06a0026c4856306" category="paragraph">Una de las capacidades clave de una base de datos vectorial es el uso de IA generativa para realizar análisis.  Esto incluye búsquedas de similitud, donde la base de datos identifica puntos de datos que son similares a una entrada dada, y detección de anomalías, donde puede detectar puntos de datos que se desvían significativamente de la norma.</block>
  <block id="145e8c4c44e4cdc9ac189d0799494e03" category="paragraph">Además, las bases de datos vectoriales son adecuadas para manejar datos temporales o datos con marca de tiempo.  Este tipo de datos proporciona información sobre "qué" sucedió y cuándo sucedió, en secuencia y en relación con todos los demás eventos dentro de un sistema de TI determinado.  Esta capacidad de manejar y analizar datos temporales hace que las bases de datos vectoriales sean particularmente útiles para aplicaciones que requieren una comprensión de los eventos a lo largo del tiempo.</block>
  <block id="196ef3e0d720a0c9b617f7c8c553f64f" category="section-title">Ventajas de las bases de datos vectoriales para ML e IA:</block>
  <block id="2143262d5355c4a47b87575a67b2545b" category="list-text">Búsqueda de alta dimensión: las bases de datos vectoriales se destacan en la gestión y recuperación de datos de alta dimensión, que a menudo se generan en aplicaciones de IA y ML.</block>
  <block id="eaec9d6e0bc3d169492279c991b5c1e1" category="list-text">Escalabilidad: Pueden escalar de manera eficiente para manejar grandes volúmenes de datos, respaldando el crecimiento y la expansión de proyectos de IA y ML.</block>
  <block id="1a581e9eb96703e6c387548283765d0f" category="list-text">Flexibilidad: Las bases de datos vectoriales ofrecen un alto grado de flexibilidad, lo que permite la adaptación de diversos tipos y estructuras de datos.</block>
  <block id="23f1f41790fda943f83f4fee180eb9c7" category="list-text">Rendimiento: Proporcionan gestión y recuperación de datos de alto rendimiento, fundamentales para la velocidad y la eficiencia de las operaciones de IA y ML.</block>
  <block id="5ec5f2c444dccfe97885b44e9f81c73a" category="list-text">Indexación personalizable: las bases de datos vectoriales ofrecen opciones de indexación personalizables, lo que permite una organización y recuperación optimizadas de datos según necesidades específicas.</block>
  <block id="431b6b79e58c421f73a7d7653f3a2641" category="section-title">Bases de datos vectoriales y casos de uso.</block>
  <block id="03e65b2645d14a51684616a56e46e74b" category="paragraph">Esta sección proporciona varias bases de datos vectoriales y detalles de sus casos de uso.</block>
  <block id="4873dee9aab8428a3bad0247c8891122" category="section-title">Faiss y ScaNN</block>
  <block id="f8255a0712bd834e092674fb685b593d" category="paragraph">Son bibliotecas que sirven como herramientas cruciales en el ámbito de la búsqueda vectorial.  Estas bibliotecas proporcionan una funcionalidad útil para la gestión y búsqueda de datos vectoriales, lo que las convierte en recursos invaluables en esta área especializada de gestión de datos.</block>
  <block id="45e23a169652aaf95ce80da844f3df0d" category="section-title">Elasticsearch</block>
  <block id="7bdddec875d1ea093ba8b35566b1775c" category="paragraph">Es un motor de búsqueda y análisis ampliamente utilizado, que recientemente ha incorporado capacidades de búsqueda vectorial.  Esta nueva característica mejora su funcionalidad, permitiéndole manejar y buscar datos vectoriales de manera más efectiva.</block>
  <block id="f6af38c920e468b8adbdd5793a09b4ca" category="section-title">Piña</block>
  <block id="e50d3eac5e6bdb3d1ddd1f564ee13308" category="paragraph">Es una base de datos vectorial robusta con un conjunto único de características.  Admite vectores densos y dispersos en su funcionalidad de indexación, lo que mejora su flexibilidad y adaptabilidad.  Una de sus principales fortalezas radica en su capacidad de combinar métodos de búsqueda tradicionales con la búsqueda vectorial densa basada en IA, creando un enfoque de búsqueda híbrido que aprovecha lo mejor de ambos mundos.</block>
  <block id="8a6b6fbe69ba556a5fee7b289943c80b" category="paragraph">Pinecone, basado principalmente en la nube, está diseñado para aplicaciones de aprendizaje automático y se integra bien con una variedad de plataformas, incluidas GCP, AWS, Open AI, GPT-3, GPT-3.5, GPT-4, Catgut Plus, Elasticsearch, Haystack y más.  Es importante tener en cuenta que Pinecone es una plataforma de código cerrado y está disponible como una oferta de software como servicio (SaaS).</block>
  <block id="b30cd65a7e403a5d3e792a3c02cfe9ef" category="paragraph">Dadas sus capacidades avanzadas, Pinecone es particularmente adecuado para la industria de la ciberseguridad, donde sus capacidades de búsqueda de alta dimensión y búsqueda híbrida se pueden aprovechar de manera efectiva para detectar y responder a las amenazas.</block>
  <block id="12f586b0171cf0f06960a27796d811d6" category="section-title">Croma</block>
  <block id="44fcc1838437cfd155de42d2d5133fd3" category="paragraph">Es una base de datos vectorial que tiene una API central con cuatro funciones principales, una de las cuales incluye un almacén de vectores de documentos en memoria.  También utiliza la biblioteca Face Transformers para vectorizar documentos, mejorando su funcionalidad y versatilidad.  Chroma está diseñado para operar tanto en la nube como en las instalaciones, ofreciendo flexibilidad según las necesidades del usuario.  En particular, se destaca en aplicaciones relacionadas con el audio, lo que lo convierte en una excelente opción para motores de búsqueda basados en audio, sistemas de recomendación de música y otros casos de uso relacionados con el audio.</block>
  <block id="2a1e8d184d8101d9d99e3d491cd7be71" category="section-title">Tejer</block>
  <block id="bd8b2ae24665811d42f62aa51b8f92c4" category="paragraph">Es una base de datos vectorial versátil que permite a los usuarios vectorizar su contenido utilizando sus módulos integrados o módulos personalizados, proporcionando flexibilidad según necesidades específicas.  Ofrece soluciones totalmente administradas y auto hospedadas, que se adaptan a una variedad de preferencias de implementación.</block>
  <block id="5147cd0d10159454e367b25d270b0489" category="paragraph">Una de las características clave de Weaviate es su capacidad de almacenar tanto vectores como objetos, mejorando sus capacidades de manejo de datos.  Se utiliza ampliamente para una variedad de aplicaciones, incluida la búsqueda semántica y la clasificación de datos en sistemas ERP.  En el sector del comercio electrónico, potencia los motores de búsqueda y recomendación.  Weaviate también se utiliza para la búsqueda de imágenes, la detección de anomalías, la armonización automatizada de datos y el análisis de amenazas de ciberseguridad, lo que demuestra su versatilidad en múltiples dominios.</block>
  <block id="e111446745a1825b862f8727ae63bce4" category="section-title">Redis</block>
  <block id="58cbcbf294faed43c2a7b44bb5dcafcc" category="paragraph">Redis es una base de datos vectorial de alto rendimiento conocida por su rápido almacenamiento en memoria, que ofrece baja latencia para operaciones de lectura y escritura.  Esto lo convierte en una excelente opción para sistemas de recomendación, motores de búsqueda y aplicaciones de análisis de datos que requieren un acceso rápido a los datos.</block>
  <block id="4f9bdf8e8091be6f95cde54860bb88f7" category="paragraph">Redis admite varias estructuras de datos para vectores, incluidas listas, conjuntos y conjuntos ordenados.  También proporciona operaciones vectoriales como calcular distancias entre vectores o encontrar intersecciones y uniones.  Estas características son particularmente útiles para la búsqueda de similitud, la agrupación en clústeres y los sistemas de recomendación basados en contenido.</block>
  <block id="2391a64216fab42522be1700985c5a9e" category="paragraph">En términos de escalabilidad y disponibilidad, Redis se destaca en el manejo de cargas de trabajo de alto rendimiento y ofrece replicación de datos.  También se integra bien con otros tipos de datos, incluidas las bases de datos relacionales tradicionales (RDBMS).  Redis incluye una función de publicación/suscripción (Pub/Sub) para actualizaciones en tiempo real, lo que resulta beneficioso para administrar vectores en tiempo real.  Además, Redis es liviano y fácil de usar, lo que lo convierte en una solución fácil de usar para administrar datos vectoriales.</block>
  <block id="4f3d528166032bacea5de8a509bb4d17" category="section-title">Milvus</block>
  <block id="e6aa3b4ef4ac18024fd88c49647d8277" category="paragraph">Es una base de datos vectorial versátil que ofrece una API como un almacén de documentos, muy parecido a MongoDB.  Se destaca por su soporte para una amplia variedad de tipos de datos, lo que lo convierte en una opción popular en los campos de la ciencia de datos y el aprendizaje automático.</block>
  <block id="4b4464f60a3dfd428d4c07edb8cac802" category="paragraph">Una de las características únicas de Milvus es su capacidad de multivectorización, que permite a los usuarios especificar en tiempo de ejecución el tipo de vector a utilizar para la búsqueda.  Además, utiliza Knowwhere, una biblioteca que se encuentra encima de otras bibliotecas como Faiss, para administrar la comunicación entre las consultas y los algoritmos de búsqueda vectorial.</block>
  <block id="bd3a3ade101e0f6fe46ad769dbf3cfa0" category="paragraph">Milvus también ofrece una integración perfecta con los flujos de trabajo de aprendizaje automático, gracias a su compatibilidad con PyTorch y TensorFlow.  Esto lo convierte en una herramienta excelente para una variedad de aplicaciones, incluido el comercio electrónico, el análisis de imágenes y videos, el reconocimiento de objetos, la búsqueda de similitud de imágenes y la recuperación de imágenes basada en contenido.  En el ámbito del procesamiento del lenguaje natural, Milvus se utiliza para agrupar documentos, buscar semántica y sistemas de preguntas y respuestas.</block>
  <block id="df5acf267fd9d50988a9132e88ec089f" category="paragraph">Para esta solución, elegimos milvus para la validación de la solución.  Para el rendimiento, utilizamos tanto milvus como postgres(pgvecto.rs).</block>
  <block id="6b9a995b1c19c83b6360f58654598ab0" category="section-title">¿Por qué elegimos milvus para esta solución?</block>
  <block id="ac80bf421cb6dec4ca81d75401709fce" category="list-text">Código abierto: Milvus es una base de datos vectorial de código abierto que fomenta el desarrollo y las mejoras impulsados por la comunidad.</block>
  <block id="72e0b014c4927b1166a4c34028bf0a94" category="list-text">Integración de IA: aprovecha la incorporación de aplicaciones de IA y búsqueda de similitud para mejorar la funcionalidad de la base de datos vectorial.</block>
  <block id="1f3d7f832f4c276984a989e5a4760e7d" category="list-text">Manejo de grandes volúmenes: Milvus tiene la capacidad de almacenar, indexar y administrar más de mil millones de vectores de incrustación generados por redes neuronales profundas (DNN) y modelos de aprendizaje automático (ML).</block>
  <block id="be23175f1d046ec7a81f41bbfbb7a710" category="list-text">Fácil de usar: es fácil de usar y la configuración toma menos de un minuto.  Milvus también ofrece SDK para diferentes lenguajes de programación.</block>
  <block id="2c86f12d4bdb64f5ff99e182033e6664" category="list-text">Velocidad: Ofrece velocidades de recuperación increíblemente rápidas, hasta 10 veces más rápidas que algunas alternativas.</block>
  <block id="23a12a1d1c53642355185e4cf7fd3d30" category="list-text">Escalabilidad y disponibilidad: Milvus es altamente escalable, con opciones para escalar verticalmente o horizontalmente según sea necesario.</block>
  <block id="eaa6e5cbb0e6c82b8217f591711c391a" category="list-text">Rica en funciones: admite diferentes tipos de datos, filtrado de atributos, compatibilidad con funciones definidas por el usuario (UDF), niveles de consistencia configurables y tiempo de viaje, lo que la convierte en una herramienta versátil para diversas aplicaciones.</block>
  <block id="cb1e9d4cfab2279dd63f9f75796dc14f" category="section-title">Descripción general de la arquitectura de Milvus</block>
  <block id="9c5b9910474e7d9e8c210fd3d649af4d" category="paragraph"><block ref="9c5b9910474e7d9e8c210fd3d649af4d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03bd3b894648d2e8a48d648b0fcedfac" category="paragraph">Esta sección proporciona componentes y servicios de nivel superior que se utilizan en la arquitectura Milvus.  * Capa de acceso: está compuesta por un grupo de servidores proxy sin estado y actúa como capa frontal del sistema y punto final para los usuarios.  * Servicio de coordinación: asigna las tareas a los nodos de trabajo y actúa como el cerebro del sistema.  Tiene tres tipos de coordinador: coordenada raíz, coordenada de datos y coordenada de consulta.  * Nodos de trabajo: siguen las instrucciones del servicio coordinador y ejecutan comandos DML/DDL activados por el usuario. Tiene tres tipos de nodos de trabajo: el nodo de consulta, el nodo de datos y el nodo de índice.  * Almacenamiento: es responsable de la persistencia de los datos.  Incluye almacenamiento de metadatos, agente de registros y almacenamiento de objetos.  El almacenamiento de NetApp , como ONTAP y StorageGRID, proporciona almacenamiento de objetos y almacenamiento basado en archivos a Milvus tanto para datos de clientes como para datos de bases de datos vectoriales.</block>
  <block id="3ad011fbf1a887f55fe5db0f1c95891f" category="summary">milvus con Amazon FSx ONTAP para NetApp ONTAP : solución de base de datos vectorial para NetApp</block>
  <block id="dd69e86c3dc6fbad2a761367a22a0552" category="doc">Milvus con Amazon FSx ONTAP para NetApp ONTAP : dualidad de archivos y objetos</block>
  <block id="8cec9207499fc7ae92bcaff5ffed4880" category="paragraph">En esta sección se analiza la configuración del clúster milvus con Amazon FSx ONTAP para la solución de base de datos vectorial para NetApp.</block>
  <block id="74126d145913f667c84fb0fae63d5f30" category="section-title">Milvus con Amazon FSx ONTAP para NetApp ONTAP : dualidad de archivos y objetos</block>
  <block id="de1f3a826ad4a683281aa07d427c615a" category="paragraph">En esta sección, explicamos por qué necesitamos implementar una base de datos vectorial en la nube, así como los pasos para implementar una base de datos vectorial (milvus independiente) en Amazon FSx ONTAP para NetApp ONTAP dentro de contenedores Docker.</block>
  <block id="c7d712a8f39fa8b7654218edbb110e3e" category="paragraph">La implementación de una base de datos vectorial en la nube proporciona varios beneficios importantes, especialmente para aplicaciones que requieren manejar datos de alta dimensión y ejecutar búsquedas de similitud.  En primer lugar, la implementación basada en la nube ofrece escalabilidad, lo que permite ajustar fácilmente los recursos para adaptarse a los crecientes volúmenes de datos y cargas de consultas.  Esto garantiza que la base de datos pueda manejar de manera eficiente el aumento de demanda y al mismo tiempo mantener un alto rendimiento.  En segundo lugar, la implementación de la nube proporciona alta disponibilidad y recuperación ante desastres, ya que los datos se pueden replicar en diferentes ubicaciones geográficas, lo que minimiza el riesgo de pérdida de datos y garantiza un servicio continuo incluso durante eventos inesperados.  En tercer lugar, ofrece rentabilidad, ya que solo pagas por los recursos que utilizas y puedes ampliar o reducir según la demanda, evitando así la necesidad de una inversión inicial sustancial en hardware.  Por último, implementar una base de datos vectorial en la nube puede mejorar la colaboración, ya que se puede acceder a los datos y compartirlos desde cualquier lugar, lo que facilita el trabajo en equipo y la toma de decisiones basada en datos.  Verifique la arquitectura de milvus independiente con Amazon FSx ONTAP para NetApp ONTAP utilizada en esta validación.</block>
  <block id="f95a160e2c9ead1dd272587d85c4a8e3" category="paragraph"><block ref="f95a160e2c9ead1dd272587d85c4a8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1e75d11a34279b79d1140edc8f509e3" category="list-text">Cree una instancia de Amazon FSx ONTAP para NetApp ONTAP y anote los detalles de la VPC, los grupos de seguridad de VPC y la subred.  Esta información será necesaria al crear una instancia EC2.  Puede encontrar más detalles aquí -<block ref="600df3e2da0b9de1446fabf4802a063b" category="inline-link-rx"></block></block>
  <block id="d91af2df00186cd53f523a257cb2565a" category="list-text">Cree una instancia EC2, asegurándose de que la VPC, los grupos de seguridad y la subred coincidan con los de la instancia de Amazon FSx ONTAP para NetApp ONTAP .</block>
  <block id="3f49259cc5a532eaad35643b8ddc6724" category="list-text">Instale nfs-common usando el comando 'apt-get install nfs-common' y actualice la información del paquete usando 'sudo apt-get update'.</block>
  <block id="7cd964c493dd7e6f0abd19075ad234a1" category="list-text">Cree una carpeta de montaje y monte Amazon FSx ONTAP para NetApp ONTAP en ella.</block>
  <block id="79f2982e5eb61f29ccc9204d1e575199" category="list-text">Instale Docker y Docker Compose usando 'apt-get install'.</block>
  <block id="8b2bc8a7f7a7f8a83a1a126f0f97c496" category="list-text">Configure un clúster Milvus basado en el archivo docker-compose.yaml, que se puede descargar del sitio web de Milvus.</block>
  <block id="6667d03b2d7af61cacf9ce4779fbb601" category="list-text">En la sección 'volúmenes' del archivo docker-compose.yml, asigne el punto de montaje NFS de NetApp a la ruta del contenedor Milvus correspondiente, específicamente en etcd, minio y standalone.Verifique<block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block> Para obtener detalles sobre los cambios en yml</block>
  <block id="40722d15b9f6ad02c869cf6f587fd141" category="list-text">Verifique las carpetas y archivos montados.</block>
  <block id="b1c44a1b47e0ee05938bd8b62a636917" category="list-text">Ejecute 'docker-compose up -d' desde el directorio que contiene el archivo docker-compose.yml.</block>
  <block id="9a6325448af98c29154cb9ef7423c998" category="list-text">Verifique el estado del contenedor Milvus.</block>
  <block id="e5666f40cd9052040de973832a6b5fb8" category="list-text">Para validar la funcionalidad de lectura y escritura de la base de datos vectorial y sus datos en Amazon FSx ONTAP para NetApp ONTAP, utilizamos el SDK de Python Milvus y un programa de muestra de PyMilvus.  Instale los paquetes necesarios usando 'apt-get install python3-numpy python3-pip' e instale PyMilvus usando 'pip3 install pymilvus'.</block>
  <block id="77b346f241703e75634a6437339f3874" category="list-text">Validar las operaciones de escritura y lectura de datos de Amazon FSx ONTAP para NetApp ONTAP en la base de datos vectorial.</block>
  <block id="edeedbd869dbb3831a9bfc7c26f04200" category="list-text">Verifique la operación de lectura utilizando el script verify_data_netapp.py.</block>
  <block id="bda2d30c9f3f0d40ab873d7c99e8c13b" category="list-text">Si el cliente desea acceder (leer) datos NFS probados en la base de datos vectorial a través del protocolo S3 para cargas de trabajo de IA, esto se puede validar utilizando un programa Python sencillo.  Un ejemplo de esto podría ser una búsqueda de similitud de imágenes de otra aplicación como se menciona en la imagen que está al comienzo de esta sección.</block>
  <block id="8b97e19802900809af55c42c509e614a" category="paragraph">Esta sección demuestra eficazmente cómo los clientes pueden implementar y operar una configuración de Milvus independiente dentro de contenedores Docker, utilizando NetApp FSx ONTAP de Amazon para el almacenamiento de datos de NetApp ONTAP .  Esta configuración permite a los clientes aprovechar el poder de las bases de datos vectoriales para manejar datos de alta dimensión y ejecutar consultas complejas, todo dentro del entorno escalable y eficiente de los contenedores Docker.  Al crear una instancia de Amazon FSx ONTAP para NetApp ONTAP y una instancia EC2 correspondiente, los clientes pueden garantizar una utilización óptima de los recursos y una gestión de datos.  La validación exitosa de las operaciones de escritura y lectura de datos de FSx ONTAP en la base de datos vectorial brinda a los clientes la garantía de operaciones de datos confiables y consistentes.  Además, la capacidad de enumerar (leer) datos de cargas de trabajo de IA a través del protocolo S3 ofrece una accesibilidad mejorada a los datos.  Por lo tanto, este proceso integral proporciona a los clientes una solución sólida y eficiente para administrar sus operaciones de datos a gran escala, aprovechando las capacidades de FSx ONTAP de Amazon para NetApp ONTAP.</block>
  <block id="80f3b490016fb09dd087c51b2a8b26f5" category="summary">Configuración del clúster Milvus: solución de base de datos vectorial para NetApp</block>
  <block id="c0f2e2b603c0c8186341bf2945e1ad13" category="doc">Configuración de un clúster Milvus con Kubernetes en instalaciones locales</block>
  <block id="4a6f6b145c2d627bc6b03f4b1e6dd96a" category="paragraph">En esta sección se analiza la configuración del clúster milvus para la solución de base de datos vectorial para NetApp.</block>
  <block id="b5be4c6d053fbcf3d99fa7a27f14df10" category="section-title">Configuración de un clúster Milvus con Kubernetes en instalaciones locales</block>
  <block id="ae5afd2c726fae66bdccf19c83604efb" category="paragraph">Los desafíos del cliente para escalar de forma independiente en almacenamiento y computación, administración efectiva de la infraestructura y administración de datos, Kubernetes y las bases de datos vectoriales juntas forman una solución poderosa y escalable para administrar operaciones de grandes datos.  Kubernetes optimiza los recursos y administra los contenedores, mientras que las bases de datos vectoriales manejan eficientemente datos de alta dimensión y búsquedas de similitud.  Esta combinación permite el procesamiento rápido de consultas complejas en grandes conjuntos de datos y se adapta sin problemas a volúmenes de datos crecientes, lo que la hace ideal para aplicaciones de big data y cargas de trabajo de IA.</block>
  <block id="b74b373b546797287d3c21cceba52d3d" category="list-text">En esta sección, detallamos el proceso de instalación de un clúster Milvus en Kubernetes, utilizando un controlador de almacenamiento NetApp para los datos del clúster y los datos del cliente.</block>
  <block id="65c0326e8e372682bfaae45cec62723f" category="list-text">Para instalar un clúster Milvus, se requieren volúmenes persistentes (PV) para almacenar datos de varios componentes del clúster Milvus.  Estos componentes incluyen etcd (tres instancias), pulsar-bookie-journal (tres instancias), pulsar-bookie-ledgers (tres instancias) y pulsar-zookeeper-data (tres instancias).</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link-macro">este enlace</block>
  <block id="d33fb2ef35d69747411b9e87c7d3d69f" category="admonition">En el clúster Milvus, podemos usar Pulsar o Kafka como motor subyacente que respalda el almacenamiento confiable y la publicación/suscripción de flujos de mensajes del clúster Milvus.  Para Kafka con NFS, NetApp ha implementado mejoras en ONTAP 9.12.1 y versiones posteriores. Estas mejoras, junto con los cambios en NFSv4.1 y Linux incluidos en RHEL 8.7 o 9.1 y versiones posteriores, resuelven el problema de "cambio de nombre tonto" que puede ocurrir al ejecutar Kafka sobre NFS. Si está interesado en obtener información más detallada sobre la ejecución de Kafka con la solución NFS de NetApp, consulte:<block ref="19b6a7adb53ddda340943365a4b691d7" category="inline-link-macro-rx"></block> .</block>
  <block id="eea5737b25740da376e769b4f799f861" category="list-text">Creamos un único volumen NFS desde NetApp ONTAP y establecimos 12 volúmenes persistentes, cada uno con 250 GB de almacenamiento.  El tamaño de almacenamiento puede variar según el tamaño del clúster; por ejemplo, tenemos otro clúster donde cada PV tiene 50 GB.  Consulte a continuación uno de los archivos PV YAML para obtener más detalles; teníamos 12 archivos de este tipo en total.  En cada archivo, storageClassName se establece en 'predeterminado' y el almacenamiento y la ruta son únicos para cada PV.</block>
  <block id="4bd70516b6325446dd3ab13888cff57f" category="list-text">Ejecute el comando 'kubectl apply' para cada archivo PV YAML para crear los volúmenes persistentes y luego verifique su creación usando 'kubectl get pv'</block>
  <block id="3468fc776a2c10c6b885c4b8f38fbb6f" category="list-text">Para almacenar datos de clientes, Milvus admite soluciones de almacenamiento de objetos como MinIO, Azure Blob y S3.  En esta guía, utilizamos S3.  Los siguientes pasos se aplican tanto al almacén de objetos ONTAP S3 como al StorageGRID .  Usamos Helm para implementar el clúster Milvus.  Descargue el archivo de configuración, values.yaml, desde la ubicación de descarga de Milvus.  Consulte el apéndice para ver el archivo values.yaml que usamos en este documento.</block>
  <block id="ac8152f5c769ca08c180374241d9797c" category="list-text">Asegúrese de que 'storageClass' esté configurado como 'predeterminado' en cada sección, incluidas las de registro, etcd, zookeeper y bookkeeper.</block>
  <block id="3c27656d225ef946516e7bec88519049" category="list-text">En la sección MinIO, desactive MinIO.</block>
  <block id="a9c572c8c594acac80d859b834139c09" category="list-text">Cree un depósito NAS desde el almacenamiento de objetos ONTAP o StorageGRID e inclúyalos en un S3 externo con las credenciales de almacenamiento de objetos.</block>
  <block id="5c01f0212f13cb62a8e9c91143a9a0e8" category="list-text">Antes de crear el clúster Milvus, asegúrese de que PersistentVolumeClaim (PVC) no tenga ningún recurso preexistente.</block>
  <block id="8916cc7e0054297b71b9453a888657d1" category="list-text">Utilice Helm y el archivo de configuración values.yaml para instalar e iniciar el clúster Milvus.</block>
  <block id="774a1cf197a96a839f6b770e85cb2445" category="list-text">Verificar el estado de los PersistentVolumeClaims (PVC).</block>
  <block id="63b2b2b30427688208b8a24971cee62e" category="list-text">Verifique el estado de los pods.</block>
  <block id="1d419f9c469484aa1d54fd468448977e" category="paragraph">Asegúrese de que el estado de los pods sea "en ejecución" y funcione como se espera.</block>
  <block id="890a387ef3d7768088115e7fea8a9ff6" category="list-text">Pruebe la escritura y lectura de datos en el almacenamiento de objetos Milvus y NetApp .</block>
  <block id="e5aef6bb28887bb265d168f37e539b38" category="list-text">Escriba datos utilizando el programa Python "prepare_data_netapp_new.py".</block>
  <block id="db12c3e2840ba5032e784bab8e8fb917" category="list-text">Lea los datos utilizando el archivo Python "verify_data_netapp.py".</block>
  <block id="25ab62108c16e9b732c38f62755ec991" category="paragraph">Con base en la validación anterior, la integración de Kubernetes con una base de datos vectorial, como se demostró a través de la implementación de un clúster Milvus en Kubernetes usando un controlador de almacenamiento NetApp , ofrece a los clientes una solución robusta, escalable y eficiente para administrar operaciones de datos a gran escala.  Esta configuración brinda a los clientes la capacidad de manejar datos de alta dimensión y ejecutar consultas complejas de manera rápida y eficiente, lo que la convierte en una solución ideal para aplicaciones de big data y cargas de trabajo de IA.  El uso de volúmenes persistentes (PV) para varios componentes del clúster, junto con la creación de un único volumen NFS desde NetApp ONTAP, garantiza una utilización óptima de los recursos y la gestión de datos.  El proceso de verificar el estado de PersistentVolumeClaims (PVC) y pods, así como probar la escritura y lectura de datos, brinda a los clientes la seguridad de contar con operaciones de datos confiables y consistentes.  El uso del almacenamiento de objetos ONTAP o StorageGRID para los datos de los clientes mejora aún más la accesibilidad y la seguridad de los datos.  En general, esta configuración brinda a los clientes una solución de gestión de datos resistente y de alto rendimiento que puede escalar sin problemas con sus crecientes necesidades de datos.</block>
  <block id="34d3fa32b415d892eb0e14786cafccea" category="summary">Descripción general de la solución de base de datos vectorial para NetApp</block>
  <block id="351df3cce379006f4ba6b903c32e39a0" category="paragraph">Esta sección proporciona una descripción general de la solución de base de datos vectorial de NetApp .</block>
  <block id="84c35d4e8bb8f8f09d3728632bcee7ce" category="paragraph">Esta solución muestra los beneficios y capacidades distintivos que NetApp ofrece para abordar los desafíos que enfrentan los clientes de bases de datos vectoriales.  Al aprovechar NetApp ONTAP, StorageGRID, las soluciones en nube de NetApp y SnapCenter, los clientes pueden agregar valor significativo a sus operaciones comerciales.  Estas herramientas no sólo abordan problemas existentes, sino que también mejoran la eficiencia y la productividad, contribuyendo así al crecimiento general del negocio.</block>
  <block id="d383216ef38104a4ae0ac03e48c3f38c" category="section-title">¿Por qué NetApp?</block>
  <block id="c8850228b08f24ab3b77cf8228b9b2cf" category="list-text">Las ofertas de NetApp, como ONTAP y StorageGRID, permiten la separación del almacenamiento y el cómputo, lo que posibilita una utilización óptima de los recursos según requisitos específicos.  Esta flexibilidad permite a los clientes escalar de forma independiente su almacenamiento utilizando soluciones de almacenamiento de NetApp .</block>
  <block id="40251a62505d04ab7d80bacded5fec97" category="list-text">NetApp ONTAP proporciona soporte nativo para NAS y almacenamiento de objetos en los principales proveedores de servicios de nube como AWS, Azure y Google Cloud.  Esta amplia compatibilidad garantiza una integración perfecta, lo que permite la movilidad de los datos del cliente, la accesibilidad global, la recuperación ante desastres, la escalabilidad dinámica y el alto rendimiento.</block>
  <block id="6c1c83ac60affc59fcc3432ea130dd8f" category="list-text">Con las sólidas capacidades de gestión de datos de NetApp, los clientes pueden tener la tranquilidad de saber que sus datos están bien protegidos contra posibles riesgos y amenazas.  NetApp prioriza la seguridad de los datos, ofreciendo tranquilidad a los clientes con respecto a la seguridad e integridad de su valiosa información.</block>
  <block id="738158dc90e1d60ff7273e21bc2d2c4e" category="summary">Validación del rendimiento de bases de datos vectoriales: solución de bases de datos vectoriales para NetApp</block>
  <block id="39301670f58445b6e5aed7e2a2694632" category="doc">Validación del rendimiento de la base de datos vectorial</block>
  <block id="334e1c5c0681bc3d3d6b9321ff851f44" category="paragraph">Esta sección destaca la validación del rendimiento que se realizó en la base de datos vectorial.</block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">Validación del rendimiento</block>
  <block id="0dfe6e4dda5bda08f3b2f54fe5f51a3b" category="paragraph">La validación del rendimiento juega un papel fundamental tanto en las bases de datos vectoriales como en los sistemas de almacenamiento, y actúa como un factor clave para garantizar un funcionamiento óptimo y una utilización eficiente de los recursos.  Las bases de datos vectoriales, conocidas por manejar datos de alta dimensión y ejecutar búsquedas de similitud, necesitan mantener altos niveles de rendimiento para procesar consultas complejas con rapidez y precisión.  La validación del rendimiento ayuda a identificar cuellos de botella, ajustar configuraciones y garantizar que el sistema pueda manejar las cargas esperadas sin degradación del servicio.  De manera similar, en los sistemas de almacenamiento, la validación del rendimiento es esencial para garantizar que los datos se almacenen y recuperen de manera eficiente, sin problemas de latencia o cuellos de botella que puedan afectar el rendimiento general del sistema.  También ayuda a tomar decisiones informadas sobre actualizaciones o cambios necesarios en la infraestructura de almacenamiento.  Por lo tanto, la validación del rendimiento es un aspecto crucial de la gestión del sistema y contribuye significativamente a mantener una alta calidad del servicio, la eficiencia operativa y la confiabilidad general del sistema.</block>
  <block id="9115de397cf08aaab47480ba37fbda9b" category="paragraph">En esta sección, nuestro objetivo es profundizar en la validación del rendimiento de bases de datos vectoriales, como Milvus y pgvecto.rs, centrándonos en sus características de rendimiento de almacenamiento, como el perfil de E/S y el comportamiento del controlador de almacenamiento Netapp en apoyo de RAG y cargas de trabajo de inferencia dentro del ciclo de vida de LLM.  Evaluaremos e identificaremos cualquier diferenciador de rendimiento cuando estas bases de datos se combinen con la solución de almacenamiento ONTAP .  Nuestro análisis se basará en indicadores clave de rendimiento, como el número de consultas procesadas por segundo (QPS).</block>
  <block id="259349a97b2ad2022418ffa271915c7f" category="paragraph">Consulte la metodología utilizada para milvus y el progreso a continuación.</block>
  <block id="3805969a7e504e8baa224367a87cc5a8" category="cell">Milvus (independiente y en clúster)</block>
  <block id="1cfad7d7743394085072e5f7fcc3a203" category="cell">Postgres(pgvecto.rs) #</block>
  <block id="2af72f100c356273d46284f6fd1dfc08" category="cell">versión</block>
  <block id="c2ee74b62870d06b4b4ad6819b9bf142" category="cell">2.3.2</block>
  <block id="44b732a6709d52e07db0367d4938965c" category="cell">0.2.0</block>
  <block id="ac52cf637478f3656a1fdee5c02324fd" category="cell">Sistema de archivos</block>
  <block id="6f27ca3ac8a02564ce2eef7e706e1e50" category="cell">XFS en LUN iSCSI</block>
  <block id="30b5bb1d010e4fe15e0541fa9b96dbdc" category="cell">Generador de carga de trabajo</block>
  <block id="73676a7da2a7cbd819e3a72dab6d2364" category="inline-link-macro">Banco VectorDB</block>
  <block id="b9350528e041c5ef962f5553183ca801" category="cell"><block ref="5a4d2a4510eb4d9895b68971f8744a05" category="inline-link-macro-rx"></block>– versión 0.0.5</block>
  <block id="f1cb45f64cdd7b55480ba6aeecd7b797" category="cell">Conjuntos de datos</block>
  <block id="0adc231fd0cbf3d7d8d5a0ff68eb2783" category="cell">Conjunto de datos LAION * 10 millones de incrustaciones * 768 dimensiones * tamaño de conjunto de datos de ~300 GB</block>
  <block id="3941cf702a750210280a88643fe83810" category="cell">AFF 800 * Versión – 9.14.1 * 4 x 100 GbE – para milvus y 2 x 100 GbE para postgres * iscsi</block>
  <block id="39138e4aea637ddf9fc568de53bed3af" category="section-title">VectorDB-Bench con clúster independiente Milvus</block>
  <block id="3a82e1f5d5f2195d71ba779a6ede894f" category="paragraph">Realizamos la siguiente validación de rendimiento en el clúster independiente milvus con vectorDB-Bench.  La conectividad de red y servidor del clúster independiente milvus se muestra a continuación.</block>
  <block id="ef436c3d7bb0f3687e078dce4b9bdb28" category="paragraph"><block ref="ef436c3d7bb0f3687e078dce4b9bdb28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="663c78b1d11f60d7440f91f77e4f328a" category="paragraph">En esta sección, compartimos nuestras observaciones y resultados de la prueba de la base de datos independiente de Milvus. .  Seleccionamos DiskANN como el tipo de índice para estas pruebas. .  La ingesta, optimización y creación de índices para un conjunto de datos de aproximadamente 100 GB tomó alrededor de 5 horas.  Durante la mayor parte de este período, el servidor Milvus, equipado con 20 núcleos (lo que equivale a 40 vcpu cuando Hyper-Threading está habilitado), estuvo funcionando a su capacidad máxima de CPU del 100 %. Descubrimos que DiskANN es particularmente importante para conjuntos de datos grandes que exceden el tamaño de la memoria del sistema. .  En la fase de consulta, observamos una tasa de consultas por segundo (QPS) de 10,93 con una recuperación de 0,9987.  La latencia del percentil 99 para las consultas se midió en 708,2 milisegundos.</block>
  <block id="624dbbdc3175c82e67aadff554ee1850" category="paragraph">Desde la perspectiva del almacenamiento, la base de datos emitió alrededor de 1000 operaciones por segundo durante las fases de ingesta, optimización posterior a la inserción y creación del índice.  En la fase de consulta, demandó 32.000 operaciones por segundo.</block>
  <block id="2063cebb91be357ea64826c835821b9d" category="paragraph">En la siguiente sección se presentan las métricas de rendimiento del almacenamiento.</block>
  <block id="5805c53ecb86f7c7ae7765287eda00d6" category="cell">Fase de carga de trabajo</block>
  <block id="216ab40cda5c7c00ff42a4efb1827d89" category="cell">Métrico</block>
  <block id="7f2bb2bf609fe39698d58a2d1d86863a" category="cell">Ingesta de datos y optimización posterior a la inserción</block>
  <block id="79073619fba8242703524f16870ff858" category="cell">IOPS</block>
  <block id="648a472fd7585d9d0c15b90f36365597" category="cell">&lt; 1.000</block>
  <block id="26ae7bdd1d6fb8c4886e6fde8d12601c" category="cell">Estado latente</block>
  <block id="822500fd5bb8ac11d944779a6703df98" category="cell">&lt; 400 usecs</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">Carga de trabajo</block>
  <block id="59829f7cd61cf1113b8214b47aaeacd8" category="cell">Mezcla de lectura y escritura, principalmente escrituras</block>
  <block id="991ff9e60b05b3e05e67404474611720" category="cell">Tamaño de IO</block>
  <block id="6b29aa131a7b968826c90e6801bacd23" category="cell">64 KB</block>
  <block id="66c1b4c7f3dc385b68a9fa903ccd016d" category="cell">Consulta</block>
  <block id="7d38c4599a45db6312f66bfac2fbba0d" category="cell">Pico a los 32.000</block>
  <block id="866fc78d18122580af38eeff4375a3c0" category="cell">Lectura en caché al 100%</block>
  <block id="9632dc4ffd7ab759c4fc53341977d887" category="cell">Principalmente 8 KB</block>
  <block id="06b68ce1a31c0cdf5430d925dabff321" category="paragraph">El resultado de vectorDB-bench se muestra a continuación.</block>
  <block id="2a8bd0e83a84e623eafaed41ef4a0b48" category="paragraph"><block ref="2a8bd0e83a84e623eafaed41ef4a0b48" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf13afd123e82c2f8504d046ac979ce6" category="paragraph">A partir de la validación del rendimiento de la instancia independiente de Milvus, es evidente que la configuración actual es insuficiente para soportar un conjunto de datos de 5 millones de vectores con una dimensionalidad de 1536. Hemos determinado que el almacenamiento posee recursos adecuados y no constituye un cuello de botella en el sistema.</block>
  <block id="7a2e31e50716ca1d05ae61faa264e4d9" category="section-title">VectorDB-Bench con clúster milvus</block>
  <block id="1a3dd3962bc3776e2a670ea2dccbf4aa" category="paragraph">En esta sección, analizamos la implementación de un clúster Milvus dentro de un entorno de Kubernetes.  Esta configuración de Kubernetes se construyó sobre una implementación de VMware vSphere, que alojaba los nodos maestros y de trabajo de Kubernetes.</block>
  <block id="2f38e478e85318635a3c104d2f9689ea" category="paragraph">Los detalles de las implementaciones de VMware vSphere y Kubernetes se presentan en las siguientes secciones.</block>
  <block id="6b38cbd988bc17810219001208570634" category="paragraph"><block ref="ef20c4495e84beca29aabf20791bc97a" category="inline-image-macro-rx" type="image"></block> <block ref="6f1c220e845ab7b8291a1a21a3646cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09618a18978db1f9288bf0626e2e9d77" category="paragraph">En esta sección, presentamos nuestras observaciones y resultados de las pruebas de la base de datos Milvus.  *El tipo de índice utilizado fue DiskANN.  * La siguiente tabla proporciona una comparación entre las implementaciones independientes y en clúster cuando se trabaja con 5 millones de vectores con una dimensionalidad de 1536.  Observamos que el tiempo necesario para la ingesta de datos y la optimización posterior a la inserción fue menor en la implementación del clúster.  La latencia del percentil 99 para las consultas se redujo seis veces en la implementación del clúster en comparación con la configuración independiente.  * Aunque la tasa de consultas por segundo (QPS) fue mayor en la implementación del clúster, no estuvo en el nivel deseado.</block>
  <block id="fa7bae8c4e9fc0bec05867545cb65c08" category="paragraph"><block ref="fa7bae8c4e9fc0bec05867545cb65c08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec05b5e2e1b5d66f987712f952bfd377" category="paragraph">Las imágenes a continuación proporcionan una vista de varias métricas de almacenamiento, incluida la latencia del clúster de almacenamiento y el total de IOPS (operaciones de entrada/salida por segundo).</block>
  <block id="866b04fa947dc783f0a1ca67687a0b46" category="paragraph"><block ref="866b04fa947dc783f0a1ca67687a0b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f34ceedf45c53ac5bfc4732c7e9eb992" category="paragraph">En la siguiente sección se presentan las métricas clave del rendimiento del almacenamiento.</block>
  <block id="40c9acf8f61419691d77b3dec178cdc9" category="cell">Pico en 147.000</block>
  <block id="971ae6b3c89c8ab12e0eed4e70f3ad7a" category="paragraph">Con base en la validación del rendimiento tanto del Milvus independiente como del clúster Milvus, presentamos los detalles del perfil de E/S de almacenamiento.  * Observamos que el perfil de E/S permanece consistente tanto en implementaciones independientes como en clúster.  * La diferencia observada en el IOPS máximo se puede atribuir a la mayor cantidad de clientes en la implementación del clúster.</block>
  <block id="537edb0aa02f73a246f084214ff9a1e4" category="section-title">vectorDB-Bench con Postgres (pgvecto.rs)</block>
  <block id="62f6737d84249676fddeaa6678755d2a" category="paragraph">Realizamos las siguientes acciones en PostgreSQL(pgvecto.rs) usando VectorDB-Bench: Los detalles sobre la conectividad de red y servidor de PostgreSQL (específicamente, pgvecto.rs) son los siguientes:</block>
  <block id="467a4cd74d7adb713cf4f94b3dd642b7" category="paragraph"><block ref="467a4cd74d7adb713cf4f94b3dd642b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd9a767006e111bd203547a99e12e650" category="paragraph">En esta sección, compartimos nuestras observaciones y resultados de las pruebas de la base de datos PostgreSQL, específicamente utilizando pgvecto.rs.  * Seleccionamos HNSW como el tipo de índice para estas pruebas porque en el momento de la prueba, DiskANN no estaba disponible para pgvecto.rs.  * Durante la fase de ingesta de datos, cargamos el conjunto de datos Cohere, que consta de 10 millones de vectores con una dimensionalidad de 768.  Este proceso tardó aproximadamente 4,5 horas.  * En la fase de consulta, observamos una tasa de consultas por segundo (QPS) de 1,068 con un recall de 0,6344.  La latencia del percentil 99 para las consultas se midió en 20 milisegundos.  Durante la mayor parte del tiempo de ejecución, la CPU del cliente funcionó al 100 % de su capacidad.</block>
  <block id="1f3e94e90c6dc70493177c947144e128" category="paragraph">Las imágenes a continuación proporcionan una vista de varias métricas de almacenamiento, incluidas las IOPS totales (operaciones de entrada/salida por segundo) de latencia del clúster de almacenamiento.</block>
  <block id="887b48e40648d9beb4f86ffbf295813a" category="paragraph"><block ref="887b48e40648d9beb4f86ffbf295813a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59566b4d8c8fef1f2b244df87cbe1523" category="paragraph"><block ref="59566b4d8c8fef1f2b244df87cbe1523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa49276609916c00fd739a7d0474f2e0" category="section-title">Comparación del rendimiento entre milvus y postgres en Vector DB Bench</block>
  <block id="870f4bfca5a2e4c27797438cfbcdcafc" category="paragraph"><block ref="870f4bfca5a2e4c27797438cfbcdcafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a6bb1cc3086d7d67df39b7f25c55f2f" category="paragraph">Basándonos en nuestra validación del rendimiento de Milvus y PostgreSQL utilizando VectorDBBench, observamos lo siguiente:</block>
  <block id="edec147efc5d9e9f8c60dd4f8475a94a" category="list-text">Tipo de índice: HNSW</block>
  <block id="2d14d931ff962fab0d69fc6c540c032e" category="list-text">Conjunto de datos: Cohere con 10 millones de vectores en 768 dimensiones</block>
  <block id="0e18fa0193d93ed358d7fdb6a65a8bbc" category="paragraph">Descubrimos que pgvecto.rs logró una tasa de consultas por segundo (QPS) de 1068 con un recall de 0,6344, mientras que Milvus logró una tasa de QPS de 106 con un recall de 0,9842.</block>
  <block id="6f8820eba6bfb1c4427de7e140948640" category="paragraph">Si la alta precisión en sus consultas es una prioridad, Milvus supera a pgvecto.rs ya que recupera una mayor proporción de elementos relevantes por consulta.  Sin embargo, si el número de consultas por segundo es un factor más crucial, pgvecto.rs supera a Milvus.  Es importante señalar, sin embargo, que la calidad de los datos recuperados a través de pgvecto.rs es menor, y alrededor del 37 % de los resultados de búsqueda son elementos irrelevantes.</block>
  <block id="35a1dd67e98f2039e3b4dc79a35aaa3e" category="section-title">Observación basada en nuestras validaciones de desempeño:</block>
  <block id="e6b80e98176081ee739c8e730d3feb58" category="paragraph">Con base en nuestras validaciones de desempeño, hemos realizado las siguientes observaciones:</block>
  <block id="9d57f733c58a90a624b060f00ad469bd" category="paragraph">En Milvus, el perfil de E/S se parece mucho a una carga de trabajo OLTP, como la que se observa con Oracle SLOB.  El benchmark consta de tres fases: ingestión de datos, post-optimización y consulta.  Las etapas iniciales se caracterizan principalmente por operaciones de escritura de 64 KB, mientras que la fase de consulta implica predominantemente lecturas de 8 KB.  Esperamos que ONTAP gestione la carga de E/S de Milvus de manera competente.</block>
  <block id="e63d591f52bb0af8effc43c397a26a24" category="paragraph">El perfil de E/S de PostgreSQL no presenta una carga de trabajo de almacenamiento desafiante.  Dada la implementación en memoria actualmente en curso, no observamos ninguna E/S de disco durante la fase de consulta.</block>
  <block id="dca2ae788fda893b11a6e115cfbd0c5d" category="paragraph">DiskANN surge como una tecnología crucial para la diferenciación del almacenamiento.  Permite el escalamiento eficiente de la búsqueda en bases de datos vectoriales más allá del límite de la memoria del sistema.  Sin embargo, es poco probable que se establezca una diferenciación en el rendimiento del almacenamiento con índices de bases de datos vectoriales en memoria como HNSW.</block>
  <block id="dc94ef6a238640d927556506c546662f" category="paragraph">También vale la pena señalar que el almacenamiento no juega un papel crítico durante la fase de consulta cuando el tipo de índice es HSNW, que es la fase operativa más importante para las bases de datos vectoriales que admiten aplicaciones RAG.  La implicación aquí es que el rendimiento del almacenamiento no afecta significativamente el rendimiento general de estas aplicaciones.</block>
  <block id="0a5775b4af8d3c53f18b8ccaf913945d" category="summary">Esta es una página de resumen para la solución de base de datos vectorial con Netapp.</block>
  <block id="8df98bd508b3983f9578ff172fd33def" category="doc">Solución de base de datos vectorial con NetApp</block>
  <block id="7dff0a79d9410666d77e5f2ac7d0344f" category="paragraph">Karthikeyan Nagalingam y Rodrigo Nascimento, NetApp</block>
  <block id="01fbfceb794af743cb563e2676923b70" category="paragraph">Este documento proporciona una exploración exhaustiva de la implementación y la gestión de bases de datos vectoriales, como Milvus y pgvecto, una extensión PostgreSQL de código abierto, utilizando las soluciones de almacenamiento de NetApp.  Se detallan las pautas de infraestructura para el uso de NetApp ONTAP y el almacenamiento de objetos StorageGRID y se valida la aplicación de la base de datos Milvus en AWS FSx ONTAP.  El documento explica la dualidad archivo-objeto de NetApp y su utilidad para bases de datos vectoriales y aplicaciones que admiten incrustaciones vectoriales.  Se destacan las capacidades de SnapCenter, el producto de gestión empresarial de NetApp, al ofrecer funcionalidades de backup y restauración para bases de datos vectoriales, garantizando la integridad y disponibilidad de los datos.  El documento profundiza más en la solución de nube híbrida de NetApp y analiza su papel en la replicación y protección de datos en entornos locales y en la nube.  Incluye información sobre la validación del rendimiento de las bases de datos vectoriales en NetApp ONTAP y concluye con dos casos de uso prácticos sobre IA generativa: RAG con LLM y ChatAI interno de NetApp.  Este documento sirve como una guía completa para aprovechar las soluciones de almacenamiento de NetApp para administrar bases de datos vectoriales.</block>
  <block id="ad452e95198e544e4d893fc75ad47dd6" category="paragraph">La arquitectura de referencia se centra en lo siguiente:</block>
  <block id="710d95da54f78f69676ae8cb435c6e6e" category="list-text"><block ref="710d95da54f78f69676ae8cb435c6e6e" category="inline-link-macro-rx"></block></block>
  <block id="ada57c9cda1b1c751a4e899e578d38e3" category="list-text"><block ref="ada57c9cda1b1c751a4e899e578d38e3" category="inline-link-macro-rx"></block></block>
  <block id="82f4ace5dffbf97de80ca1ea103fbe56" category="list-text"><block ref="82f4ace5dffbf97de80ca1ea103fbe56" category="inline-link-macro-rx"></block></block>
  <block id="55496e6b06de6e72c19b578ad4ce71d8" category="inline-link-macro">Requisito de tecnología</block>
  <block id="4abf02f5e3deeb5036c0eded610de05a" category="list-text"><block ref="4abf02f5e3deeb5036c0eded610de05a" category="inline-link-macro-rx"></block></block>
  <block id="19c63a75039d0a9cb4cec3458cfe0581" category="list-text"><block ref="19c63a75039d0a9cb4cec3458cfe0581" category="inline-link-macro-rx"></block></block>
  <block id="8c8f8b93bc06c57499a04ec1b06dae28" category="inline-link-macro">Descripción general de la verificación de la solución</block>
  <block id="ca47b69088a672a9b65069106989453e" category="list-text"><block ref="ca47b69088a672a9b65069106989453e" category="inline-link-macro-rx"></block></block>
  <block id="55d7ef09813b4d6fdcb2c5626efe487e" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block></block>
  <block id="0bf83d510fcfec34ea35ee03c83ce577" category="list-text">Enlace: base de datos vectorial Milvus con Amazon FSx ONTAP para NetApp ONTAP[Milvus con Amazon FSx ONTAP para NetApp ONTAP : dualidad de archivos y objetos]</block>
  <block id="d6b228867818081bf3ee3cecad050baf" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block></block>
  <block id="f7ba02d22d83dabd12f0465a68c210ea" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block></block>
  <block id="9e30995c6d4864b29eb56e92d196baec" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block></block>
  <block id="bd1287beca719fc00531ba3dd533f70c" category="list-text"><block ref="bd1287beca719fc00531ba3dd533f70c" category="inline-link-macro-rx"></block></block>
  <block id="a4349288a9fe8fecb32674ed8a0e5d15" category="inline-link-macro">Casos de uso de bases de datos vectoriales</block>
  <block id="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="list-text"><block ref="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="inline-link-macro-rx"></block></block>
  <block id="da73b8a757c1735375b56d959d388619" category="list-text"><block ref="da73b8a757c1735375b56d959d388619" category="inline-link-macro-rx"></block></block>
  <block id="fec04177b34fde0762c2d0f1cb5bcf85" category="inline-link-macro">Apéndice A: values.yaml</block>
  <block id="4076746ca906dfd472a39281440bca63" category="list-text"><block ref="4076746ca906dfd472a39281440bca63" category="inline-link-macro-rx"></block></block>
  <block id="2c0fbb0e17a27b8dbff673fb6b03c50b" category="list-text"><block ref="2c0fbb0e17a27b8dbff673fb6b03c50b" category="inline-link-macro-rx"></block></block>
  <block id="016166f68a717d3a544b77970134fe92" category="inline-link-macro">Apéndice C: verify_data_netapp.py</block>
  <block id="1fa29d4bb8db316d27c057bc2ab73bcb" category="list-text"><block ref="1fa29d4bb8db316d27c057bc2ab73bcb" category="inline-link-macro-rx"></block></block>
  <block id="cb2986bd8f2d29c4cca582736e0a680f" category="list-text"><block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block></block>
  <block id="f60546114707495cbcefb83f806b47e2" category="summary">Requisito tecnológico: solución de base de datos vectorial para NetApp</block>
  <block id="73877510aa37e2bcf501625512e358c3" category="paragraph">Esta sección proporciona una descripción general de los requisitos para la solución de base de datos vectorial de NetApp .</block>
  <block id="1507fd593972e19976a48675eb11483a" category="paragraph">Las configuraciones de hardware y software que se describen a continuación se utilizaron para la mayoría de las validaciones realizadas en este documento, con excepción del rendimiento.  Estas configuraciones sirven como guía para ayudarle a configurar su entorno.  Sin embargo, tenga en cuenta que los componentes específicos pueden variar según los requisitos individuales del cliente.</block>
  <block id="7e9534170bcf0d2cab4a69e22cdca79c" category="cell">* A800 * ONTAP 9.14.1 * 48 x 3,49 TB SSD-NVM * Dos volúmenes de grupo flexibles: metadatos y datos.  * El volumen NFS de metadatos tiene 12 volúmenes persistentes con 250 GB.  * Los datos son un volumen ONTAP NAS S3</block>
  <block id="bcb4d8bb0642dc62c114f2a0a31f5aa3" category="cell">6 x FUJITSU PRIMERGY RX2540 M4</block>
  <block id="891b7b85ad27bcf31f4d6b9d3e5f55eb" category="cell">* 64 CPU * CPU Intel(R) Xeon(R) Gold 6142 a 2,60 GHz * Memoria física de 256 GM * 1 puerto de red de 100 GbE</block>
  <block id="4515188d6af40c03b16b310778b865c8" category="cell">* 1 SG100, 3 SGF6024 * 3 24 de 7,68 TB</block>
  <block id="e7f07d17d04d9ac60dd3ebc382a1d58b" category="cell">Cúmulo de Milvus</block>
  <block id="5c9a77f3be5149b25ef3dd4a0d42f61e" category="cell">* GRÁFICO - milvus-4.1.11.  * Versión de la aplicación: 2.3.4 * Paquetes dependientes como bookkeeper, zookeeper, pulsar, etcd, proxy, querynode, trabajador</block>
  <block id="b0654cc6796be715102b69214bddfb52" category="cell">* Clúster K8s de 5 nodos * 1 nodo maestro y 4 nodos de trabajo * Versión: 1.7.2</block>
  <block id="5b8215321456694f36bc83a178e44856" category="cell">*3.10.12.</block>
  <block id="5a019cf3628ae4961c3ba86198ac5410" category="summary">Caso de uso: solución de base de datos vectorial para NetApp</block>
  <block id="853fb1f37b200090af8f730400a34971" category="paragraph">Esta sección proporciona una descripción general de los casos de uso de la solución de base de datos vectorial de NetApp .</block>
  <block id="61798ad0c56d51680f77d6b9f4694877" category="paragraph">En esta sección, analizamos dos casos de uso, como la recuperación de generación aumentada con modelos de lenguaje grandes y el chatbot de TI de NetApp .</block>
  <block id="2b376c37a6f0c2c21b8ba7b62ac86693" category="section-title">Generación aumentada de recuperación (RAG) con modelos de lenguaje grandes (LLM)</block>
  <block id="6a482cb4a386f8c0b7889b5dc11a997a" category="paragraph">El operador NVIDIA Enterprise RAG LLM es una herramienta útil para implementar RAG en la empresa.  Este operador se puede utilizar para implementar un pipeline RAG completo.  La tubería RAG se puede personalizar para utilizar Milvus o pgvecto como base de datos vectorial para almacenar incrustaciones de la base de conocimientos.  Consulte la documentación para obtener más detalles.</block>
  <block id="4c1729beb205806fa130c0dbf0364b59" category="paragraph">Figura 1) RAG empresarial impulsado por NVIDIA NeMo Microservices y NetApp</block>
  <block id="b14745e6302744b3b3c226e1fdee230a" category="paragraph"><block ref="b14745e6302744b3b3c226e1fdee230a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da66e40722180b5a0466a9ff253976af" category="section-title">Caso de uso del chatbot de TI de NetApp</block>
  <block id="497416719429ff96f2462d991f6ea3f8" category="paragraph">El chatbot de NetApp sirve como otro caso de uso en tiempo real para la base de datos vectorial.  En este caso, NetApp Private OpenAI Sandbox proporciona una plataforma eficaz, segura y eficiente para gestionar las consultas de los usuarios internos de NetApp.  Al incorporar estrictos protocolos de seguridad, sistemas eficientes de gestión de datos y sofisticadas capacidades de procesamiento de IA, garantiza respuestas precisas y de alta calidad a los usuarios en función de sus roles y responsabilidades en la organización a través de la autenticación SSO.  Esta arquitectura resalta el potencial de fusionar tecnologías avanzadas para crear sistemas inteligentes centrados en el usuario.</block>
  <block id="8afdd8df71939b23b5b37041b4b0e243" category="paragraph"><block ref="8afdd8df71939b23b5b37041b4b0e243" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff2b3d5b17bdfc4a02990dd4115b7d4d" category="paragraph">El caso de uso se puede dividir en cuatro secciones principales.</block>
  <block id="e21f69fe36aefc844dcebf8fb52262a3" category="section-title">Autenticación y verificación de usuarios:</block>
  <block id="7457d61423f49fa817953d3c8e0c08cf" category="list-text">Las consultas de usuario primero pasan por el proceso de inicio de sesión único (SSO) de NetApp para confirmar la identidad del usuario.</block>
  <block id="3dedad86d8ac55d8b2b034f0ff353ea5" category="list-text">Después de una autenticación exitosa, el sistema verifica la conexión VPN para garantizar una transmisión de datos segura.</block>
  <block id="34ef9101314d114f1bed9a4fc8c13666" category="section-title">Transmisión y procesamiento de datos:</block>
  <block id="e5aa3164f4a76a72d1d074c0285a4d54" category="list-text">Una vez validada la VPN, los datos se envían a MariaDB a través de las aplicaciones web NetAIChat o NetAICreate.  MariaDB es un sistema de base de datos rápido y eficiente utilizado para administrar y almacenar datos de usuarios.</block>
  <block id="d0d4d700ca2ba3e943833a184fce15db" category="list-text">Luego, MariaDB envía la información a la instancia de Azure de NetApp , que conecta los datos del usuario con la unidad de procesamiento de IA.</block>
  <block id="b1cbaf6e413b3b5a92538942710197de" category="section-title">Interacción con OpenAI y filtrado de contenido:</block>
  <block id="e7a51c3da456741ac0fe5ae031a539a3" category="list-text">La instancia de Azure envía las preguntas del usuario a un sistema de filtrado de contenido.  Este sistema limpia la consulta y la prepara para su procesamiento.</block>
  <block id="8449bc1c7d0f0641656072f90d8d06db" category="list-text">Luego, la entrada limpiada se envía al modelo base de Azure OpenAI, que genera una respuesta basada en la entrada.</block>
  <block id="ce4abebf9a6d91e3d12d3bd86ebd308f" category="section-title">Generación y moderación de respuestas:</block>
  <block id="70ee91d51a5da426448f1ed59462804d" category="list-text">Primero se verifica la respuesta del modelo base para garantizar que sea precisa y cumpla con los estándares de contenido.</block>
  <block id="40d26f0ba80199b0eaf7b7e0525c7f34" category="list-text">Después de pasar la verificación, la respuesta se envía de vuelta al usuario.  Este proceso garantiza que el usuario reciba una respuesta clara, precisa y adecuada a su consulta.</block>
  <block id="705451e750819c9ce68fb278a7b09839" category="summary">values-xml: solución de base de datos vectorial para NetApp</block>
  <block id="6e6c82b93338e2283cf42123803b79d4" category="doc">Apéndice A: Valores.yaml</block>
  <block id="42cb737e154e9abe53c3f800eae00d4e" category="paragraph">Esta sección proporciona un código YAML de muestra para los valores utilizados en la solución de base de datos vectorial de NetApp .</block>
  <block id="bdcc26240ab0215ba46efad29038278d" category="summary">Descripción general de la verificación de la solución: solución de base de datos vectorial para NetApp</block>
  <block id="a11dfa705c151f0af3e80cc954126655" category="paragraph">Hemos realizado una validación integral de la solución centrada en cinco áreas clave, cuyos detalles se describen a continuación.  Cada sección profundiza en los desafíos que enfrentan los clientes, las soluciones proporcionadas por NetApp y los beneficios posteriores para el cliente.</block>
  <block id="748a76b95c3f380357377aefd2ed0474" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block>Desafíos del cliente para escalar de forma independiente en almacenamiento y computación, gestión efectiva de infraestructura y gestión de datos.  En esta sección, detallamos el proceso de instalación de un clúster Milvus en Kubernetes, utilizando un controlador de almacenamiento NetApp para los datos del clúster y los datos del cliente.</block>
  <block id="e840bff7e1e9715df98e16fead8076cb" category="list-text">enlace: vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP.html[Milvus con Amazon FSx ONTAP para NetApp ONTAP : dualidad de archivos y objetos] En esta sección, explicamos por qué necesitamos implementar una base de datos vectorial en la nube, así como los pasos para implementar una base de datos vectorial (milvus independiente) en Amazon FSx ONTAP para NetApp ONTAP dentro de contenedores Docker.</block>
  <block id="6cce3de9e8bf8cabbfe260cc36d61ac3" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block>En esta sección, profundizamos en cómo SnapCenter protege los datos de la base de datos vectorial y los datos de Milvus que residen en ONTAP.  Para este ejemplo, utilizamos un depósito NAS (milvusdbvol1) derivado de un volumen NFS ONTAP (vol1) para datos de clientes y un volumen NFS separado (vectordbpv) para datos de configuración del clúster Milvus.</block>
  <block id="918f8a4912d6a98fb31ac7ba46e00ffc" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block>En esta sección, analizamos la importancia de la recuperación ante desastres (DR) para la base de datos vectorial y cómo el producto de recuperación ante desastres SnapMirror de NetApp proporciona una solución DR para la base de datos vectorial.</block>
  <block id="2f1a6b813251891cca144a8b91cde4f5" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block>En esta sección, nuestro objetivo es profundizar en la validación del rendimiento de bases de datos vectoriales, como Milvus y pgvecto.rs, centrándonos en sus características de rendimiento de almacenamiento, como el perfil de E/S y el comportamiento del controlador de almacenamiento Netapp en apoyo de RAG y cargas de trabajo de inferencia dentro del ciclo de vida de LLM.  Evaluaremos e identificaremos cualquier diferenciador de rendimiento cuando estas bases de datos se combinen con la solución de almacenamiento ONTAP .  Nuestro análisis se basará en indicadores clave de rendimiento, como el número de consultas procesadas por segundo (QPS).</block>
  <block id="87c3db9ccf444604c258b88ee8489364" category="summary">verify_data_netapp.py: solución de base de datos vectorial para netapp</block>
  <block id="599675cccffd45ab676aea932c3fdfbd" category="paragraph">Esta sección contiene un script de Python de muestra que se puede utilizar para validar la base de datos vectorial en la solución de base de datos vectorial de NetApp .</block>
  <block id="48e4e86482d1e72b17c82feb1e930352" category="doc">Vea videos sobre soluciones de IA con NetApp</block>
  <block id="a9f5e6dcd1d44f9ba3dc3398020d2404" category="paragraph">Descubra cómo NetApp potencia las iniciativas de inteligencia artificial y aprendizaje automático.  Estas listas de reproducción de videos seleccionadas muestran soluciones de inteligencia artificial de NetApp y flujos de trabajo de MLOps, destacando estrategias de implementación, automatización y gestión de datos para análisis avanzados.</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="paragraph-title">Soluciones de IA de NetApp</block>
  <block id="b4bf3d1dd932a4fb0e32b91623652e42" category="inline-link-macro">Vea la lista de reproducción de soluciones de IA de NetApp</block>
  <block id="d3e2da82e7d75fc2a126141e7169de49" category="paragraph">Lista de reproducción de videos completa que cubre la infraestructura de IA, los sistemas convergentes y las implementaciones de IA empresarial.<block ref="af3f91668350fde9b89e361b330e6bf9" category="inline-link-macro-rx"></block></block>
  <block id="07aca6f404d3e6c525bac36328b0d27d" category="paragraph-title">Operaciones de aprendizaje automático (MLOps)</block>
  <block id="aee569e95a8498ede74e68ae8306e6e5" category="inline-link-macro">Mira la lista de reproducción de MLOps</block>
  <block id="d41374c7672e6e4fdbfbd6504b672d3c" category="paragraph">Serie de videos sobre flujos de trabajo de MLOps, canales de datos y mejores prácticas operativas.<block ref="70aea7fc5134cd09b86d7ff27c954117" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">Serie de videos y demostraciones que analizan las características de muchas de las soluciones de NetApp</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">Soluciones NetApp : Vídeos y demostraciones</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">Descripción general de los videos y demostraciones que destacan características específicas de muchas de las soluciones de NetApp.</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">Operaciones MLO</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="181a90cd4ce68792d6ce2049bb1ff6ec" category="summary">Registro de cambios recientes en el material complementario de las soluciones de inteligencia artificial de NetApp .</block>
  <block id="232dfabf5b2a241a9f7473820c81bf15" category="doc">Novedades en las soluciones de inteligencia artificial de NetApp</block>
  <block id="be647982bfc8c0837c019b8fdbc711b3" category="paragraph">Conozca las novedades en soluciones de inteligencia artificial.</block>
  <block id="bab52961b58c502c7991d35556c25367" category="section-title">18 de agosto de 2025</block>
  <block id="47e26e0d5bbeef43c544dd9ae72e66b0" category="inline-link-macro">Familia de soluciones NetApp</block>
  <block id="840125a006aee7dc0e8efd313e7b614e" category="paragraph">El sitio de NetApp Solutions ahora es el<block ref="f083b096ae581e72c5ab727ef8bd5732" category="inline-link-macro-rx"></block> , que incluye los siguientes sitios:</block>
  <block id="e87298059f60b0844dc971f315184cf5" category="list-text">Soluciones de inteligencia artificial de NetApp</block>
  <block id="9cae574c1dc1ca50a949c1e889637ba7" category="inline-link-macro">Soluciones de contenedores de NetApp</block>
  <block id="31d1ae0120af1d791e4320e17eb10687" category="list-text"><block ref="31d1ae0120af1d791e4320e17eb10687" category="inline-link-macro-rx"></block></block>
  <block id="3947417923606d3599bcba7a82f71f1b" category="inline-link-macro">Soluciones de gestión de datos de NetApp</block>
  <block id="56c054d4bb919790ebe189f7a7d11c3c" category="list-text"><block ref="56c054d4bb919790ebe189f7a7d11c3c" category="inline-link-macro-rx"></block></block>
  <block id="9bb3e58246c5654a6d8e08a7bddd60ec" category="inline-link-macro">Soluciones de bases de datos de NetApp</block>
  <block id="3e2420ab1ec1d6e02b32b017d3ba969a" category="list-text"><block ref="3e2420ab1ec1d6e02b32b017d3ba969a" category="inline-link-macro-rx"></block></block>
  <block id="a37049a2a78422ac5627c7987db5c337" category="inline-link-macro">Soluciones de nube pública e híbrida de NetApp</block>
  <block id="144417321224efbf0afc2ae665a84a46" category="list-text"><block ref="144417321224efbf0afc2ae665a84a46" category="inline-link-macro-rx"></block></block>
  <block id="2729aba3baa90aaaed37b282e515f6e4" category="inline-link-macro">Soluciones NetApp para SAP</block>
  <block id="5e056430559fb77ac659dbb71ecce256" category="list-text"><block ref="5e056430559fb77ac659dbb71ecce256" category="inline-link-macro-rx"></block></block>
  <block id="4ead908c2ca3b4c7156e0e703642415d" category="inline-link-macro">Soluciones de virtualización de NetApp</block>
  <block id="3100186c9f62cec85ac05309c5d10217" category="list-text"><block ref="3100186c9f62cec85ac05309c5d10217" category="inline-link-macro-rx"></block></block>
  <block id="fac83ccf1756a0c9cb3b8982d7f17073" category="sidebar">NetApp ofrece soluciones integrales de IA que combinan gestión de datos de nivel empresarial, arquitecturas de referencia validadas y asociaciones estratégicas para acelerar sus iniciativas de IA y respaldar resultados comerciales críticos.  Desde la implementación de infraestructura hasta la automatización de MLOps, nuestras soluciones escalan sin problemas en entornos de borde, centro de datos y nube híbrida.</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="sidebar">Empezar</block>
  <block id="33871b6190a8d5adbe8b15282054766c" category="sidebar">Qué hay de nuevo</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="sidebar">Blogs</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="sidebar">Vídeos y demostraciones</block>
  <block id="0356451dce8be030d34b4cddc51bd023" category="sidebar">Infraestructura de IA y sistemas convergentes</block>
  <block id="9547dc55d95184a53ea1a8366b5aeced" category="sidebar">NetApp AIPod con sistemas NVIDIA DGX</block>
  <block id="1f403aa196fd2c94e882669641695d63" category="sidebar">NVIDIA DGX SuperPOD con serie EF</block>
  <block id="ca2b44ea641055fab6c572a1ec645f40" category="sidebar">NetApp AIPod con Lenovo para NVIDIA OVX</block>
  <block id="71194b59e7e6e05cdd5e38686d46dd11" category="sidebar">Sistema de archivos paralelo BeeGFS con serie E</block>
  <block id="0490c28d4251b3da040883241b9a245b" category="sidebar">Casos de uso y aplicaciones de IA</block>
  <block id="03a2eeb037be2a65352a6ce833a5352d" category="sidebar">AIPod Mini para inferencia RAG</block>
  <block id="2a5e8ee0f85321457b5b5051848b33df" category="sidebar">Inferencia de IA en el borde</block>
  <block id="1f5ef80ba6fe60fcd8fc9b93428724ca" category="sidebar">Soluciones de bases de datos vectoriales</block>
  <block id="1c2e519ac88b24b944e313f1528b25ca" category="sidebar">Cargas de trabajo de la conducción autónoma</block>
  <block id="1f2d4372bbd3f4944eec91b65eb55b69" category="sidebar">Quantum StorNext con Serie E</block>
  <block id="dd12d2c2197bdac0454f49eaf82efcb1" category="sidebar">MLOps y gestión de datos</block>
  <block id="55200dead19623a5ed7fd47347cc531d" category="sidebar">MLOps de código abierto con NetApp</block>
  <block id="0fa95f40d436ae4b6b1a848a385c88f5" category="sidebar">MLOps multicloud híbrido con Domino Data Lab</block>
  <block id="ec441b7e7e90b2ae639b5c9784b469f9" category="sidebar">FSx ONTAP para MLOps</block>
  <block id="072e5110aacde0c4952afb7fa86bd5bf" category="sidebar">Soluciones de IA de big data y nube híbrida</block>
  <block id="248d62097e51f823fbf1797b8d71b837" category="sidebar">Soluciones de datos en la nube híbrida</block>
  <block id="01ba1aebae20e7ddfe20f3ea9572b0a6" category="sidebar">Soluciones Apache Spark</block>
  <block id="8f0ff6e8178c4e8f4ea0f489063d7586" category="sidebar">Confluent Kafka con almacenamiento NetApp ONTAP</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">NetApp StorageGRID con Splunk SmartStore</block>
  <block id="76a3eb07a798a5ace45b8500ba2aae19" category="sidebar">Dremio Lakehouse con almacenamiento NetApp</block>
  <block id="e95b75f557af9310f3d9c6299286a533" category="sidebar">Solicitudes de soluciones y comentarios</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">Automatización de solicitudes</block>
  <block id="776ab15fef436c9315c14738509d299e" category="sidebar">Proponer una nueva solución</block>
  <block id="cfdaac8ef24ac5b2612570c34da00954" category="sidebar">Proporcionar retroalimentación sobre la solución</block>
  <block id="9e34d9d231e4cd17fbacda95fb51929b" category="sidebar">Optimice sus flujos de trabajo de IA/ML con las soluciones integrales de gestión de datos y MLOps de NetApp.  Desde plataformas de código abierto hasta herramientas de nivel empresarial, nuestras soluciones permiten el desarrollo, la implementación y el escalamiento eficiente de modelos en entornos de nube híbrida al tiempo que garantizan la consistencia y el rendimiento de los datos.</block>
  <block id="e212a74da744d81b7be22fde8837f469" category="sidebar">Soluciones de gestión de datos y MLOps de NetApp</block>
  <block id="7c9c1738224214245dd19322f112f008" category="sidebar">Plataformas MLOps de código abierto</block>
  <block id="8225e12837234b91ab0ddcd265042318" category="sidebar">Configuración de NetApp Trident para AIPod</block>
  <block id="8b4f0b6bb6bc359f491be13c6d4217c4" category="sidebar">Implementación e integración de Apache Airflow</block>
  <block id="948fee9aa5251e39df94d1c32d0c25cf" category="sidebar">Implementación de JupyterHub y operaciones de datos</block>
  <block id="73cee63b0ef47212c43598d623b858e0" category="sidebar">Implementación y trazabilidad de MLflow</block>
  <block id="938ff6f66cfc08077aee20a94cb3555a" category="sidebar">Flujos de trabajo avanzados de MLOps</block>
  <block id="e037812c032cd0d9c22b13bc85e9e8b0" category="sidebar">Implementación y cuadernos de Kubeflow</block>
  <block id="3ff4473b7f6cd29fd2f032383a101ad3" category="sidebar">Entrena modelos de reconocimiento de imágenes con Kubeflow</block>
  <block id="4d72e4ce52deedeed5378320bb10ba60" category="sidebar">Ejecución de carga de trabajo de IA de un solo nodo</block>
  <block id="d4090ff0c5d6e77994fe88d878931a09" category="sidebar">Ejecución de carga de trabajo de IA distribuida</block>
  <block id="6d49da972d2b3e8021183d3dd882efc3" category="sidebar">Ingesta de datos con SnapMirror</block>
  <block id="13c4fd018be37b2e07ac1e3c7bf940da" category="sidebar">Soluciones MLOps empresariales</block>
  <block id="bf57be3e9bf09ff89214bcab0ffcd37f" category="sidebar">MLOps híbridos con Domino Data Lab</block>
  <block id="5a938de20177e2b1dcb267d6d7b4f069" category="sidebar">Acceso a datos entre entornos con Domino</block>
  <block id="86c9440e933f2848898cd3a50e0d30c5" category="sidebar">Integración del software NVIDIA NGC</block>
  <block id="e9eb61f514f368f5d8d0cf3ccfded4f9" category="sidebar">Integración de Cloud MLOps y AWS</block>
  <block id="b9a33eec860aee8b042190248e9c0978" category="sidebar">Amazon FSx para MLOps de ONTAP</block>
  <block id="19f22745fb509faf9a35f2999167b4b3" category="sidebar">Integrar FSx ONTAP como S3 privado en SageMaker</block>
  <block id="958182d4c4d2fbecef5e794dd36a2fcd" category="sidebar">Entrenamiento de modelos de FSx ONTAP para SageMaker</block>
  <block id="765bac8adf0ce0c27f43291f5f38e36e" category="sidebar">Cree una canalización de MLOps simplificada con FSx</block>
  <block id="cff078ffafce4368253406707fe938e2" category="sidebar">Bases de datos vectoriales y aplicaciones de IA</block>
  <block id="8817647abcdf406ecb3f743ce1f4d0c3" category="sidebar">Solución de base de datos vectorial con NetApp</block>
  <block id="eac46f1424b8a5f784861bfb337632d5" category="sidebar">Configuración del clúster Milvus con Kubernetes</block>
  <block id="e557c94c22c1c941bd40b8277f7f7753" category="sidebar">Protección de bases de datos vectoriales con SnapCenter</block>
  <block id="ba5dd0875f60bb8bfd1c4511266f65f1" category="sidebar">Validación del rendimiento de la base de datos vectorial</block>
  <block id="8d80ba264d116b7cc3e458ba8697ce83" category="sidebar">Casos de uso de bases de datos vectoriales</block>
  <block id="e90bb805ac6728252476dc4b6c9f33b8" category="sidebar">Herramientas de gestión y almacenamiento de datos</block>
  <block id="8825002f133fae0b139e8325ac7730cf" category="sidebar">Lago de datos StorageGRID para la conducción autónoma</block>
  <block id="bf25ffbc01db3077dbf625f1f66b0b81" category="sidebar">Recuperación ante desastres con SnapMirror</block>
  <block id="1e87a0e6a353196e3d5d6cd2e73a3e6e" category="sidebar">Implemente una infraestructura de IA preparada para la empresa con las arquitecturas de referencia validadas y los sistemas convergentes de NetApp.  Desde soluciones NetApp AIPod hasta plataformas de almacenamiento de alto rendimiento, nuestros diseños ofrecen el rendimiento, la escalabilidad y la confiabilidad necesarios para cargas de trabajo exigentes de IA/ML.</block>
  <block id="994ec7a86f72507f5352d2b180d45f33" category="sidebar">Infraestructura de IA y sistemas convergentes de NetApp</block>
  <block id="1c869286ed71535693a9462972519af4" category="sidebar">Arquitecturas de referencia de NetApp AIPod</block>
  <block id="b4f767e2f090ec487aa796e06a450c3b" category="sidebar">Arquitectura del AIPod</block>
  <block id="b6c79f2c0318b6d7625fb67322575ef8" category="sidebar">Detalles de la implementación del AIPod</block>
  <block id="8c660d55cc308e8a0142574e6cb06bb2" category="sidebar">Guía de validación y dimensionamiento del AIPod</block>
  <block id="f5a73cfaecb9184b2e8146ed455050a9" category="sidebar">Almacenamiento de alto rendimiento para cargas de trabajo de IA</block>
  <block id="dca52c3c8e9f73ebf5e2f52c01c943af" category="sidebar">NVIDIA DGX SuperPOD con almacenamiento de la serie EF</block>
  <block id="0cdb4340f983739886aeeabf55ded9a0" category="sidebar">IBM Spectrum Scale con almacenamiento E-Series</block>
  <block id="103956252a2179a2f41c37f503662e57" category="sidebar">NetApp ONTAP con Lenovo ThinkSystem</block>
  <block id="e5a53cbbfd61be59509da2fb28b87bd6" category="sidebar">Explore implementaciones de IA del mundo real con soluciones de NetApp , desde sistemas RAG empresariales e inferencia de borde hasta prácticas de IA responsables y estrategias de migración de datos.  Estos casos de uso demuestran cómo NetApp permite a las organizaciones implementar aplicaciones de IA en diversos entornos manteniendo la seguridad, el rendimiento y la escalabilidad.</block>
  <block id="7438b9f1311e240ca42a988e9d13e00c" category="sidebar">Casos de uso y aplicaciones de IA de NetApp</block>
  <block id="f5d80fd5b29670f59fa900f8c07fb329" category="sidebar">Explore implementaciones de IA del mundo real con soluciones de NetApp , desde sistemas RAG empresariales e inferencia de borde hasta prácticas de IA responsables y estrategias de migración de datos.  Estos casos de uso demuestran cómo NetApp habilita aplicaciones de IA en diversos entornos manteniendo la seguridad, el rendimiento y la escalabilidad.</block>
  <block id="0d6f02845b71bc324cd82a725369e788" category="sidebar">Aplicaciones y casos de uso de inteligencia artificial empresarial</block>
  <block id="a67b9cee4655d6177295261e4bcd604d" category="sidebar">NetApp AIPod Mini para RAG empresarial</block>
  <block id="f5d3d706e83df8136ffa361f6bf3de44" category="sidebar">IA generativa y valor de NetApp</block>
  <block id="e2c8fd379213f568475a9fd8d939677a" category="sidebar">Inferencia de inteligencia artificial de borde con NetApp y Lenovo</block>
  <block id="7625f6572992d4d6884af97bd58e8555" category="sidebar">Migración del análisis de big data a la IA</block>
  <block id="58f52c07cacafd13bf7c2b75bd52297b" category="sidebar">IA responsable</block>
  <block id="726a429bb7d3cf42471e4ef6d5064f39" category="sidebar">IA responsable con transformación de imágenes de Protopia</block>
  <block id="9aadc819040333a6a70c083f60934127" category="sidebar">Soluciones de almacenamiento e infraestructura de IA</block>
  <block id="4ec66dae70419b5536af92b7e6af12eb" category="sidebar">Diseño de Quantum StorNext con sistemas de la serie E</block>
  <block id="fdc9cddf0d9dda4d36a935baaa555437" category="sidebar">Implemente Quantum StorNext con sistemas de la serie E</block>
  <block id="2107e3f2176d1159c57518d8100b979c" category="sidebar">Transforme su infraestructura de análisis de datos con las soluciones probadas de NetApp para cargas de trabajo de big data, incluidas Apache Spark, Hadoop, Kafka y arquitecturas de lagos de datos modernas que escalan desde el borde hasta la nube.</block>
  <block id="a4c306bc134438ffdcde3dc25d141930" category="sidebar">Soluciones modernas de análisis de datos de NetApp</block>
  <block id="f6d439e305ff0317b08aeaad65bc202c" category="sidebar">Las soluciones de análisis de datos modernos de NetApp son un conjunto de capacidades estratégicas y tecnológicas que demuestran las capacidades del almacenamiento de NetApp en el espacio de la IA.</block>
  <block id="0c5c9c87a184244b0a7327aaef882e8e" category="sidebar">Soluciones Apache Kafka</block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">Cargas de trabajo de Apache Kafka con almacenamiento NFS de NetApp</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Confluent Kafka con controladores de almacenamiento NetApp ONTAP</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Mejores prácticas para Confluent Kafka</block>
  <block id="c9adcd46dfe28ab240bf984f9da39535" category="sidebar">Validación del rendimiento de Kafka con AWS</block>
  <block id="c6dc54040e7551a25c7f14dd83a3ca37" category="sidebar">Soluciones Apache Spark y Hadoop</block>
  <block id="75b5d408998484e1ea5a4ce3cc432cbe" category="sidebar">Soluciones de almacenamiento de NetApp para Apache Spark</block>
  <block id="d2e5b5510723b29c7f85a6f53b0b30fe" category="sidebar">Implementar la carga de trabajo de Apache Spark con almacenamiento de NetApp</block>
  <block id="d142861488d42c2de042afc4375049da" category="sidebar">Soluciones de datos en la nube híbrida de NetApp para Spark y Hadoop</block>
  <block id="15b1a623b46c0553eb7e0a02392de6f9" category="sidebar">Casos de uso y arquitecturas</block>
  <block id="7bbc21a3294c0070a8663140370d1f39" category="sidebar">Resultados de las pruebas de Apache Spark</block>
  <block id="8b809555e7e0cd658f51306db399d338" category="sidebar">Gestión de datos en la nube e IA</block>
  <block id="1d2114df6a9f8f5d7e8f597e9c70a6c1" category="sidebar">Gestión de datos en la nube con la dualidad archivo-objeto de NetApp y AWS SageMaker</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">Análisis de Big Data: Datos a Inteligencia Artificial</block>
  <block id="55cd26df7471de5ffbc83646a94fddbb" category="sidebar">Amazon FSx for NetApp ONTAP para MLOps</block>
  <block id="2a15fc3906339e08c458c8e62e447da3" category="sidebar">Solución de nube híbrida Apache Spark</block>
  <block id="e0afb7c0b35ca1c50d576d490c1f6f83" category="sidebar">Plataformas modernas de análisis y lagos de datos</block>
  <block id="2f8caf1cb27d10780daee2d12dfe6cf5" category="sidebar">Solución híbrida iceberg lakehouse de próxima generación de NetApp y Dremio</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E-Series E5700 y Splunk Enterprise</block>
  <block id="8cd58c89ff3d51a256ecfe3fe8bab20f" category="sidebar">Recursos adicionales</block>
  <block id="7cc3c71ee2fdbff1fd2efbfcded89f90" category="sidebar">Diferentes soluciones para diferentes estrategias analíticas</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">Blog: Apache Spark participa en el campo del análisis de datos de NetApp</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">Blog: Use XCP para migrar datos desde un lago de datos y HPC a ONTAP NFS</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV: Lista de reproducción de análisis de big data</block>
  <block id="5baf6ec1129c513e42641878b72ed0d8" category="sidebar">Soluciones de inteligencia artificial</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="sidebar">Vídeos</block>
  <block id="45552f1d8df5302f6b20a45bdca4873c" category="sidebar">Configuración de NetApp Trident</block>
  <block id="629606c7cd29d3a21eb21c6ac5139f33" category="sidebar">Backends Trident para implementaciones de AIPod</block>
  <block id="6c7cb31582a28a42e762b2046a1ce896" category="sidebar">Clases de almacenamiento de Kubernetes para implementaciones de AIPod</block>
  <block id="d9fd1af737bab40d222131485c9bb808" category="sidebar">Implementación de Apache Airflow</block>
  <block id="17f2e89c743299170fd62138fa80d495" category="sidebar">Implementación de JupyterHub</block>
  <block id="471efd78e003975a601bfbdaf70136d2" category="sidebar">Ingesta de datos con NetApp SnapMirror</block>
  <block id="7d6f6d1bc3093617ee4703c5e520774b" category="sidebar">Implementación de MLflow</block>
  <block id="7174f04026f1e5e87367c72c1c073824" category="sidebar">Trazabilidad del conjunto de datos al modelo con NetApp y MLflow</block>
  <block id="a38d89f197f605418a88b686e0175fa2" category="sidebar">Implementación de Kubeflow</block>
  <block id="b540e10006be068e5e5fd93d05b7b12c" category="sidebar">Aprovisionar el espacio de trabajo de Jupyter Notebook</block>
  <block id="e8816281bfd02443de2002db66789462" category="sidebar">Entrenar un modelo de reconocimiento de imágenes: ejemplo de flujo de trabajo</block>
  <block id="4c71560715665aa3108585868c989cdc" category="sidebar">Ejemplo de operaciones Trident</block>
  <block id="1c6a3a6b23e40077c58b45d05d4d411f" category="sidebar">Ejemplos de trabajos de alto rendimiento para implementaciones de AIPod</block>
  <block id="dcdebd18dbab6da6d511c220479f6460" category="sidebar">Ejecutar una carga de trabajo de IA de un solo nodo</block>
  <block id="98053e2b2531af18e4f885fb8a731327" category="sidebar">Ejecutar una carga de trabajo de IA distribuida sincrónica</block>
  <block id="7406ea045ac944a9db15b50dba8cc04b" category="sidebar">MLOps híbridos con Domino Data Lab y NetApp</block>
  <block id="1231369e1218613623e1b520c27ce190" category="sidebar">Configuración inicial</block>
  <block id="e5726f3da1ad0304974cf103e75da470" category="sidebar">Exponer volúmenes NetApp existentes a Domino</block>
  <block id="f62030848d7cb177a11eb3916356bb29" category="sidebar">Acceda a los mismos datos en diferentes entornos</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="sidebar">Información adicional</block>
  <block id="f4c44872f09acb0f4e8f90890004d4ab" category="sidebar">Utilice el software NVIDIA NGC</block>
  <block id="a12d6a26832d73816bca1235e9f4d8a1" category="sidebar">Ejemplo de caso de uso: trabajo de capacitación de TensorFlow</block>
  <block id="0975e7e38dac95fd7ce3d2e3966e26be" category="sidebar">Parte 1: Integrar Amazon FSx for NetApp ONTAP como un bucket S3 privado en AWS SageMaker</block>
  <block id="b675f3bab2742c1723ed556f8535349d" category="sidebar">Parte 2: Aproveche Amazon FSx for NetApp ONTAP como fuente de datos para el entrenamiento de modelos en SageMaker</block>
  <block id="7609ccc24e4c12c32d0ad617fe91161e" category="sidebar">Parte 3: Construir una canalización de MLOps simplificada</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">NetApp StorageGRID Data Lake para cargas de trabajo de conducción autónoma</block>
  <block id="a20ee4ebc8e6614143815c881916cbba" category="sidebar">Solución de base de datos vectorial con NetApp</block>
  <block id="e5df4bbe7b124f2fe5398d42696d57b3" category="sidebar">Base de datos de vectores</block>
  <block id="9934c7eb2c2161e05fedd3b280e4eedc" category="sidebar">Requisito de tecnología</block>
  <block id="951de808fb87ba9bc035ce3cf467b064" category="sidebar">Protección de bases de datos vectoriales mediante SnapCenter</block>
  <block id="f0a132dd5ea90d189f80995d831f9b91" category="sidebar">Recuperación ante desastres mediante SnapMirror</block>
  <block id="e813a53d42d6bfe69e6907df9b0675d5" category="sidebar">Base de datos vectorial con Instaclustr usando PostGreSQL: pgvector</block>
  <block id="7fad254d8199fbf6d695e96590444cff" category="sidebar">Apéndice B: prepare_data_netapp_new_py</block>
  <block id="4d4989117d6e4f26e57cc7135af8f508" category="sidebar">Apéndice D: docker_compose.yml</block>
  <block id="46aa0a2ad138d7cd72baea1b2f96553c" category="sidebar">Infraestructuras convergentes de IA</block>
  <block id="503011292be147bd4172e92de477a75e" category="sidebar">NVA-1173 NetApp AIPod con sistemas NVIDIA DGX</block>
  <block id="34df2039718349f1b8c838bff98ae8fa" category="sidebar">Componentes de hardware</block>
  <block id="7d19d593db0bb056876a9535cbced90a" category="sidebar">Componentes de software</block>
  <block id="aee745c6de04f3d08c0e628809cab1e7" category="sidebar">Detalles de implementación de ejemplo</block>
  <block id="56d2d7506e6dac3733b0a45a9eaf441d" category="sidebar">Guía de validación y dimensionamiento</block>
  <block id="db182982505626c6e79adca149851ca6" category="sidebar">Conclusión e información adicional</block>
  <block id="013e704990294f0b327123a61911f4cc" category="sidebar">NVIDIA DGX SuperPOD con la serie EF de NetApp</block>
  <block id="944c042dcc47f293062f941954082ceb" category="sidebar">BeeGFS en NetApp con almacenamiento E-Series</block>
  <block id="9af29e4b3d0045c948a7dd30b1c7f8ae" category="sidebar">Implemente IBM Spectrum Scale con almacenamiento E-Series</block>
  <block id="79bca636cb614580cfd2da67b668570e" category="sidebar">ONTAP y Lenovo ThinkSystem para IA</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">NetApp ONTAP y Lenovo ThinkSystem SR670 para IA</block>
  <block id="b669bc138f2f455218d4dce65e4693b4" category="sidebar">Casos de uso de IA</block>
  <block id="adb8741d27ea996906508affc4dfbc75" category="sidebar">NetApp AIPod Mini para inferencia RAG</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">IA responsable e inferencias confidenciales: IA de NetApp con Protopia Image Transformation</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">Trasladar datos de un entorno de big data a un entorno de IA</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">Inferencia de IA en el borde: NetApp con Lenovo ThinkSystem: Diseño de soluciones</block>
  <block id="df901f2197cd86d62a25f2f43e523352" category="sidebar">Guía de diseño de sistemas Quantum StorNext con NetApp E-Series</block>
  <block id="e313734313e7ef573613df8b6edae0af" category="sidebar">Guía de implementación de sistemas Quantum StorNext con NetApp E-Series</block>
  <block id="78daadab78234c06769e4f331411d302" category="sidebar">Análisis de datos modernos</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">Solución de NetApp para un problema de cambio de nombre tonto en la carga de trabajo de NFS a Kafka</block>
  <block id="d7fd58c27a131209e8f320d109b293cc" category="sidebar">Descripción general del rendimiento y validación en AWS - Cloud Volume ONTAP</block>
  <block id="076002e1839cd6d440e56b26850e1223" category="sidebar">Descripción general del rendimiento y validación en AWS - FSx para NetApp ONTAP</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">Descripción general del rendimiento y validación con AFF local</block>
  <block id="2835924be4bc657cfe3a5bd988b96845" category="sidebar">Validación del rendimiento de Confluent</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">Resumen de casos de uso</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">De GPFS a NFS: pasos detallados</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Clústeres confluentes de autorreequilibrio</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">Soluciones de datos en la nube híbrida de NetApp : Spark y Hadoop, basadas en casos de uso de clientes</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">Caso de uso 1: Copia de seguridad de datos de Hadoop</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">Caso de uso 2: Copia de seguridad y recuperación ante desastres desde la nube a las instalaciones locales</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">Caso de uso 3: Habilitación de DevTest en datos Hadoop existentes</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">Caso de uso 4: Protección de datos y conectividad multicloud</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">Caso de uso 5: Acelerar las cargas de trabajo analíticas</block>
  <block id="2c1c3f6b0e9a17650f389f1aab405e8a" category="sidebar">Solución Iceberg Lakehouse híbrida de próxima generación de NetApp y Dremio</block>
  <block id="1256c51dea275f8f002d62c89274c4dc" category="sidebar">Casos de uso de clientes</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">Diferentes soluciones para diferentes estrategias analíticas Resumen de la solución</block>
  <block id="2b95dd053e967c99de1428e8953dd453" category="sidebar">Funciones de StorageGRID para Splunk SmartStore</block>
  <block id="42c2f45afefbd5150f5aa52986b2a3cc" category="sidebar">Nivelación y ahorro de costes</block>
  <block id="039a70e0c8e34414c8b3f34333f95ca8" category="sidebar">Rendimiento de SmartStore de un solo sitio</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">Carga de trabajo Apache Spark con solución de almacenamiento NetApp (Guía de implementación)</block>
  <block id="74916818f2584b32e727fdc509b2f992" category="cell">P4X-GNR6980P-SRPL2-UCC</block>
  <block id="abaa679b5e80256d8e1d4fd65296a270" category="cell">Intel Xeon 6980P 2P 128C 2G 504M 500W SGX512</block>
  <block id="22f22b60e3e496fa07e67cfbf53cb70e" category="cell">RPL-E 6369P IP 8C/16T 3.3G 24MB 95W 1700 BO</block>
</blocks>