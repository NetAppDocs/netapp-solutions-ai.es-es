---
sidebar: sidebar 
permalink: data-analytics/bda-ai-introduction.html 
keywords: tr-4732, tr4732, 4732, introduction, concepts, components 
summary: Este documento proporciona pautas para trasladar datos de análisis de big data y datos de HPC a IA mediante el uso de NetApp XCP y NIPAM.  También analizamos los beneficios comerciales de trasladar datos de big data y HPC a IA. 
---
= TR-4732: Análisis de big data para inteligencia artificial
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


Karthikeyan Nagalingam, NetApp

[role="lead"]
Este documento describe cómo trasladar datos de análisis de big data y datos de HPC a IA.  La IA procesa datos NFS a través de exportaciones NFS, mientras que los clientes a menudo tienen sus datos de IA en una plataforma de análisis de big data, como HDFS, Blob o almacenamiento S3, así como plataformas HPC como GPFS.  Este documento proporciona pautas para trasladar datos de análisis de big data y datos de HPC a IA mediante el uso de NetApp XCP y NIPAM.  También analizamos los beneficios comerciales de trasladar datos de big data y HPC a IA.



== Conceptos y componentes



=== Almacenamiento de análisis de big data

Big Data Analytics es el principal proveedor de almacenamiento para HDFS.  Un cliente a menudo utiliza un sistema de archivos compatible con Hadoop (HCFS), como Windows Azure Blob Storage, MapR File System (MapR-FS) y almacenamiento de objetos S3.



=== Sistema de archivos paralelo general

GPFS de IBM es un sistema de archivos empresarial que ofrece una alternativa a HDFS.  GPFS proporciona flexibilidad para que las aplicaciones decidan el tamaño del bloque y el diseño de la replicación, lo que proporciona buen rendimiento y eficiencia.



=== Módulo de análisis local de NetApp

El módulo de análisis local de NetApp (NIPAM) funciona como controlador para que los clústeres de Hadoop accedan a datos NFS.  Tiene cuatro componentes: un grupo de conexiones, un NFS InputStream, un caché de controladores de archivos y un NFS OutputStream. Para obtener más información, consulte  https://www.netapp.com/pdf.html?item=/media/16351-tr-4382pdf.pdf[] .



=== Copia distribuida de Hadoop

Hadoop Distributed Copy (DistCp) es una herramienta de copia distribuida que se utiliza para grandes tareas de copia entre clústeres y dentro de clústeres.  Esta herramienta utiliza MapReduce para la distribución de datos, el manejo de errores y la generación de informes.  Amplía la lista de archivos y directorios y los ingresa en tareas de mapeo para copiar los datos de la lista de origen.  La siguiente imagen muestra la operación DistCp en HDFS y no HDFS.

image:bda-ai-001.png["Figura que muestra el diálogo de entrada/salida o representa contenido escrito"]

Hadoop DistCp mueve datos entre los dos sistemas HDFS sin utilizar un controlador adicional.  NetApp proporciona el controlador para sistemas que no son HDFS.  Para un destino NFS, NIPAM proporciona el controlador para copiar datos que Hadoop DistCp utiliza para comunicarse con destinos NFS al copiar datos.



== Google Cloud NetApp Volumes

Google Cloud NetApp Volumes es un servicio de archivos nativo de la nube con un rendimiento extremo.  Este servicio ayuda a los clientes a acelerar su tiempo de comercialización activando y desactivando rápidamente los recursos y utilizando las características de NetApp para mejorar la productividad y reducir el tiempo de inactividad del personal.  Google Cloud NetApp Volumes es la alternativa adecuada para la recuperación ante desastres y la copia de seguridad en la nube porque reduce el espacio total del centro de datos y consume menos almacenamiento nativo en la nube pública.



== XCP de NetApp

NetApp XCP es un software cliente que permite una migración rápida y confiable de datos de cualquier plataforma a NetApp y de NetApp a NetApp .  Esta herramienta está diseñada para copiar una gran cantidad de datos NAS no estructurados desde cualquier sistema NAS a un controlador de almacenamiento NetApp .  La herramienta de migración XCP utiliza un motor de transmisión de E/S multicanal y multinúcleo que puede procesar muchas solicitudes en paralelo, como migración de datos, listados de archivos o directorios e informes de espacio.  Esta es la herramienta de migración de datos de NetApp predeterminada.  Puede utilizar XCP para copiar datos de un clúster de Hadoop y HPC al almacenamiento NFS de NetApp .  El siguiente diagrama muestra la transferencia de datos desde un clúster de Hadoop y HPC a un volumen NFS de NetApp mediante XCP.

image:bda-ai-002.png["Figura que muestra el diálogo de entrada/salida o representa contenido escrito"]



== Copia y sincronización de NetApp BlueXP

NetApp BlueXP Copy and Sync es un software como servicio de replicación de datos híbrido que transfiere y sincroniza datos NFS, S3 y CIFS de forma segura y sin problemas entre el almacenamiento local y el almacenamiento en la nube.  Este software se utiliza para migración de datos, archivado, colaboración, análisis y más.  Una vez transferidos los datos, BlueXP Copy and Sync sincroniza continuamente los datos entre el origen y el destino.  De ahí en adelante se transfiere el delta.  También protege los datos dentro de su propia red, en la nube o en sus instalaciones.  Este software se basa en un modelo de pago por uso, que proporciona una solución rentable y proporciona capacidades de monitoreo y generación de informes para su transferencia de datos.
